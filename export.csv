id,url,title,category,command_group,parent_command,full_command,raw_content,last_scraped,content_hash,metadata
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/index,Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Snowflake CLI[¶](#sf-cli ""Link to this heading"")

## What is Snowflake CLI?[¶](#what-is-sf-cli ""Link to this heading"")

Snowflake CLI is an open-source command-line tool explicitly designed for developer-centric workloads in addition to SQL operations. It is a flexible and extensible tool that can accommodate modern development practices and technologies.

With Snowflake CLI, developers can create, manage, update, and view apps running on Snowflake across workloads such as Streamlit in Snowflake, the Snowflake Native App Framework, Snowpark Container Services, and Snowpark. It supports a range of Snowflake features, including user-defined functions, stored procedures, Streamlit in Snowflake, and SQL execution.

## What’s in this guide?[¶](#what-s-in-this-guide ""Link to this heading"")

This guide introduces and explains how to install and use Snowflake CLI. It includes the following sections:

*   [Introducing Snowflake CLI](introduction/introduction)
    
*   [Installing Snowflake CLI](installation/installation)
    
*   [Configuring Snowflake CLI and connecting to Snowflake](connecting/connect)
    
*   [Bootstrapping a project from a template](bootstrap-project/bootstrap)
    
*   [About project definition files](project-definitions/about)
    
*   [Managing Snowflake objects](objects/manage-objects)
    
*   [Managing Snowflake stages](stages/manage-stages)
    
*   [Managing Snowpark Container Services in Snowflake CLI](services/overview)
    
*   [Using Snowpark in Snowflake CLI](snowpark/overview)
    
*   [Using Snowflake Notebooks](notebooks/use-notebooks)
    
*   [Managing Streamlit apps with Snowflake CLI](streamlit-apps/overview)
    
*   [Using Snowflake Native App in Snowflake CLI](native-apps/overview)
    
*   [Executing SQL statements](sql/execute-sql)
    
*   [Managing Git repositories](git/overview)
    
*   [Snowflake CLI command reference](command-reference/overview)
    

For more information about supported Snowflake products, see the following:

*   [Snowflake Cortex](../../user-guide/snowflake-cortex/aisql) documentation
    
*   [Native App Framework](../native-apps/native-apps-about) documentation
    
*   [Snowflake notebooks](../../user-guide/ui-snowsight/notebooks) documentation
    
*   [Snowpark Container Services](../snowpark-container-services/overview) documentation
    
*   [Snowpark](../snowpark/index) documentation
    
*   [SQL](../../reference) documentation
    
*   [Git](../git/git-overview) documentation
    
*   [Streamlit](../streamlit/about-streamlit) documentation
    

To see what changed in this release, see the [Snowflake CLI release notes](../../release-notes/clients-drivers/snowflake-cli).

Snowflake CLI is an open-source project available in the [Snowflake CLI Git repository](https://github.com/snowflakedb/snowflake-cli).

On this page

1.  [What is Snowflake CLI?](#what-is-sf-cli)
2.  [What’s in this guide?](#what-s-in-this-guide)

Related content

1.  [Introducing Snowflake CLI](/developer-guide/snowflake-cli/introduction/introduction)
2.  [Git in Snowflake](/developer-guide/snowflake-cli/../git/git-overview)
3.  [Native App Framework](/developer-guide/snowflake-cli/../native-apps/native-apps-about)
4.  [Snowflake Notebooks](/developer-guide/snowflake-cli/../../user-guide/ui-snowsight/notebooks)
5.  [Snowpark Container Services](/developer-guide/snowflake-cli/../snowpark-container-services/overview)
6.  [Snowpark](/developer-guide/snowflake-cli/../snowpark/index)
7.  [SQL](/developer-guide/snowflake-cli/../../reference)
8.  [Streamlit](/developer-guide/snowflake-cli/../streamlit/about-streamlit)
9.  [Snowflake CLI release notes](/developer-guide/snowflake-cli/../../release-notes/clients-drivers/snowflake-cli)
10.  [Snowflake CLI Git repository](https://github.com/snowflakedb/snowflake-cli)",NULL,f739a843f76e222c9380af7bf1db5f386e31c683859c3753c01aebd88516a114,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/introduction/introduction,Introducing Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Introducing Snowflake CLI[¶](#introducing-sf-cli ""Link to this heading"")

Snowflake CLI’s open-source nature means that developers can leverage the community’s collective knowledge and contributions to improve and enhance the tool. By using Snowflake CLI, developers can expect a streamlined, efficient experience that empowers them to work with Snowflake in new and innovative ways. Snowflake CLI is a powerful and flexible tool that helps developers streamline their workflow and optimize their Snowflake experience.

As a command-line interface (CLI), Snowflake CLI provides several benefits for developers, such as:

*   Speed and efficiency
    
    A CLI allows developers to perform tasks quickly and efficiently by executing commands from the terminal without needing a graphical user interface. This can save developers significant time and effort, especially when performing repetitive or complex tasks.
    
*   Automation
    
    A CLI can automate tasks and workflows, such as building, testing, CI/CD, and deploying applications. CLI can help developers streamline their development process and reduce the risk of errors or inconsistencies.
    
*   Portability
    
    A CLI is often platform-independent and can be used across different operating systems and environments. Developers can work more easily on multiple projects or collaborate with others who use different systems.
    
*   Version control
    
    A CLI can be integrated with version control systems like Git to manage changes and track code history, which can help developers collaborate more effectively, resolve conflicts, and document changes appropriately.
    
*   Customization
    
    A CLI can be customized and extended by using modules and scripts, so developers can tailor it to their needs and preferences. Automating common tasks and workflows can help developers work more efficiently and effectively.
    
*   Accessibility
    
    CLI can be accessed remotely, so developers can work on servers and other remote systems without a graphical interface.
    

## How does Snowflake CLI differ from SnowSQL?[¶](#how-does-sf-cli-differ-from-snowsql ""Link to this heading"")

SnowSQL is the command-line client for connecting to Snowflake to execute SQL queries and perform all DDL and DML operations, including loading data into and unloading data out of database tables.

The Snowflake CLI command-line client, in contrast, focuses primarily on managing workloads and applications that connect to Snowflake. Snowflake CLI lets you locally run and debug Snowflake apps, with the following benefits:

*   You can search, create, and upload Python packages that might not be supported in Anaconda yet.
    
*   Snowflake CLI supports Snowpark Python user-defined functions and stored procedures, warehouses, and Streamlit apps.
    
*   You can define packages by using `requirements.txt`, with dependencies automatically added through integration with Anaconda at deployment time.
    
*   Snowflake CLI can include packages that are identified in `requirements.txt`—but aren’t yet in Anaconda—in the application package deployed to Snowflake. (This feature only works with packages that don’t rely on native libraries).
    
*   When you update existing applications, code and dependencies are automatically altered as needed.
    
*   Deployment artifacts are automatically managed and uploaded to Snowflake stages.
    

Snowflake plans to continue enhancing Snowflake CLI to provide developers a robust tool for leveraging all of the SnowSQL capabilities in a new open source CLI.

On this page

1.  [How does Snowflake CLI differ from SnowSQL?](#how-does-sf-cli-differ-from-snowsql)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/introduction/../index)",NULL,564c14d7c971c06cb75f9c38dd6f77179e2a0d0f8e2ebbb8db8f2ac774c512c3,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/installation/installation,Installing Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Installing Snowflake CLI[¶](#installing-sf-cli ""Link to this heading"")

This topic explains how to install Snowflake CLI on [supported platforms](../../../release-notes/requirements.html#label-client-operating-system-support). Note that Snowflake CLI is not currently available for AIX systems.

Snowflake recommends using binary installation methods, such as package managers, to install Snowflake CLI on your system. You can download the binary installers from the official [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).

## Requirements[¶](#requirements ""Link to this heading"")

*   Before using Snowflake CLI, you must have a valid Snowflake account.
    
*   To run Streamlit in Snowflake using Snowflake CLI, you must have a Snowflake account with permission to use Streamlit.
    
*   To run Snowpark Container Services in Snowflake using Snowflake CLI, you must have a Snowflake account with privileges to use Snowpark Container Services.
    

Tip

If your Snowflake account requires MFA (multi-factor authentication), Snowflake CLI requires approval for every command. You can use MFA caching to require authentication only once every four hours. For more information, see [Use multi-factor authentication (MFA)](../connecting/configure-connections.html#label-snowcli-mfa).

## Install Snowflake CLI using package managers[¶](#install-sf-cli-using-package-managers ""Link to this heading"")

To install Snowflake CLI using platform-specific package managers, use one of the following procedures:

*   [Install using Linux package managers (rpm, deb)](#label-snowcli-install-linux-package-managers).
    
*   [Install using MacOS installer](#label-snowcli-install-macos-installer).
    
*   [Install using Windows installer](#label-snowcli-install-windows-installer).
    
*   [Install using Homebrew](#label-snowcli-install-homebrew).
    

### Install with Linux package managers[¶](#install-with-linux-package-managers ""Link to this heading"")

If you use a Linux operating system, you can install Snowflake CLI with package managers that support the following:

*   `deb` packages,
    
*   `rpm` packages.
    

To install Snowflake CLI using the `deb` package manager:

1.  Download the Snowflake CLI `deb` from the [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).
    
2.  Install the package by running the following command:
    
    ```
    sudo dpkg -i snowflake-cli-<version>.deb
    
    ```
    
    Copy
    

To install Snowflake CLI using the `rpm` package manager:

1.  Download the Snowflake CLI `rpm` package from the [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).
    
2.  Install the package by running the following command:
    
    ```
    sudo rpm -i snowflake-cli-<version>.rpm
    
    ```
    
    Copy
    
3.  To verify that the software was installed successfully, run the following command:
    
    ```
    snow --help
    
    ```
    
    Copy
    
    ```
    Usage: snow [OPTIONS] COMMAND [ARGS]...
    
    Snowflake CLI tool for developers.
    
    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ --version                           Shows version of the Snowflake CLI                                                                   │
    │ --info                              Shows information about the Snowflake CLI                                                            │
    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │
    │ --install-completion                Install completion for the current shell.                                                            │
    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │
    │ --help                -h            Show this message and exit.                                                                          │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ app          Manages a Snowflake Native App                                                                                              │
    │ connection   Manages connections to Snowflake.                                                                                           │
    │ cortex       Provides access to Snowflake Cortex.                                                                                        │
    │ git          Manages git repositories in Snowflake.                                                                                      │
    │ notebook     Manages notebooks in Snowflake.                                                                                             │
    │ object       Manages Snowflake objects like warehouses and stages                                                                        │
    │ snowpark     Manages procedures and functions.                                                                                           │
    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │
    │ sql          Executes Snowflake query.                                                                                                   │
    │ stage        Manages stages.                                                                                                             │
    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    
4.  [Configure the Snowflake connection](../connecting/connect).
    

### Install with the MacOS package installer[¶](#install-with-the-macos-package-installer ""Link to this heading"")

To install Snowflake CLI on MacOS, do the following:

1.  Download the Snowflake CLI installer from the [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).
    
2.  Run the installer and follow the instructions to install Snowflake CLI.
    
3.  To verify that the software was installed successfully, open new terminal and run the following command:
    
    ```
    snow --help
    
    ```
    
    Copy
    
    ```
    Usage: snow [OPTIONS] COMMAND [ARGS]...
    
    Snowflake CLI tool for developers.
    
    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ --version                           Shows version of the Snowflake CLI                                                                   │
    │ --info                              Shows information about the Snowflake CLI                                                            │
    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │
    │ --install-completion                Install completion for the current shell.                                                            │
    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │
    │ --help                -h            Show this message and exit.                                                                          │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ app          Manages a Snowflake Native App                                                                                              │
    │ connection   Manages connections to Snowflake.                                                                                           │
    │ cortex       Provides access to Snowflake Cortex.                                                                                        │
    │ git          Manages git repositories in Snowflake.                                                                                      │
    │ notebook     Manages notebooks in Snowflake.                                                                                             │
    │ object       Manages Snowflake objects like warehouses and stages                                                                        │
    │ snowpark     Manages procedures and functions.                                                                                           │
    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │
    │ sql          Executes Snowflake query.                                                                                                   │
    │ stage        Manages stages.                                                                                                             │
    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    
4.  [Configure the Snowflake connection](../connecting/connect).
    

### Install with the Windows installer[¶](#install-with-the-windows-installer ""Link to this heading"")

To install Snowflake CLI on Windows, do the following:

1.  Download the Snowflake CLI installer from the [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).
    
2.  Run the installer and follow the instructions to install Snowflake CLI.
    
3.  To verify that the software was installed successfully, open new terminal and run the following command:
    
    ```
    snow --help
    
    ```
    
    Copy
    
    ```
    Usage: snow [OPTIONS] COMMAND [ARGS]...
    
    Snowflake CLI tool for developers.
    
    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ --version                           Shows version of the Snowflake CLI                                                                   │
    │ --info                              Shows information about the Snowflake CLI                                                            │
    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │
    │ --install-completion                Install completion for the current shell.                                                            │
    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │
    │ --help                -h            Show this message and exit.                                                                          │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ app          Manages a Snowflake Native App                                                                                              │
    │ connection   Manages connections to Snowflake.                                                                                           │
    │ cortex       Provides access to Snowflake Cortex.                                                                                        │
    │ git          Manages git repositories in Snowflake.                                                                                      │
    │ notebook     Manages notebooks in Snowflake.                                                                                             │
    │ object       Manages Snowflake objects like warehouses and stages                                                                        │
    │ snowpark     Manages procedures and functions.                                                                                           │
    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │
    │ sql          Executes Snowflake query.                                                                                                   │
    │ stage        Manages stages.                                                                                                             │
    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    
4.  [Configure the Snowflake connection](../connecting/connect).
    

### Install with Homebrew[¶](#install-with-homebrew ""Link to this heading"")

If you use a Mac operating system, you can install Snowflake CLI with [Homebrew](https://brew.sh/).

1.  Install [Homebrew](https://brew.sh/), if necessary.
    
2.  To give Homebrew access to the Snowflake CLI repository, run the following command:
    
    ```
    brew tap snowflakedb/snowflake-cli
    brew update
    
    ```
    
    Copy
    
3.  To install Snowflake CLI, run the following command:
    
    ```
    brew install snowflake-cli
    
    ```
    
    Copy
    
4.  To verify that the software was installed successfully, run the following command:
    
    ```
    snow --help
    
    ```
    
    Copy
    
    ```
    Usage: snow [OPTIONS] COMMAND [ARGS]...
    
    Snowflake CLI tool for developers.
    
    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ --version                           Shows version of the Snowflake CLI                                                                   │
    │ --info                              Shows information about the Snowflake CLI                                                            │
    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │
    │ --install-completion                Install completion for the current shell.                                                            │
    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │
    │ --help                -h            Show this message and exit.                                                                          │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ app          Manages a Snowflake Native App                                                                                              │
    │ connection   Manages connections to Snowflake.                                                                                           │
    │ cortex       Provides access to Snowflake Cortex.                                                                                        │
    │ git          Manages git repositories in Snowflake.                                                                                      │
    │ notebook     Manages notebooks in Snowflake.                                                                                             │
    │ object       Manages Snowflake objects like warehouses and stages                                                                        │
    │ snowpark     Manages procedures and functions.                                                                                           │
    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │
    │ sql          Executes Snowflake query.                                                                                                   │
    │ stage        Manages stages.                                                                                                             │
    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    
5.  [Configure the Snowflake connection](../connecting/connect).
    

## Advanced local installations[¶](#advanced-local-installations ""Link to this heading"")

You can also install Snowflake CLI as a Python package using either of the following:

*   [pip (PyPi)](#label-snowcli-install-pip)
    
*   [pipx](#label-snowcli-install-pipx)
    

Snowflake recommends installing as a Python package only for development purposes or when installing binaries isn’t possible in your environment.

### Install with pip (PyPi)[¶](#install-with-pip-pypi ""Link to this heading"")

Note

This method modifies the Python environment where you install Snowflake CLI. Consider using [pipx](#label-snowcli-install-pipx) instead to avoid dependency conflicts.

To install Snowflake CLI using `pip`, you must have [Python](https://python.org) version 3.10 or later installed.

1.  Run the following shell command:
    
    ```
    pip install snowflake-cli
    
    ```
    
    Copy
    
2.  To verify that the software was installed successfully, run the following command:
    
    ```
    snow --help
    
    ```
    
    Copy
    
    ```
    Usage: snow [OPTIONS] COMMAND [ARGS]...
    
    Snowflake CLI tool for developers.
    
    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ --version                           Shows version of the Snowflake CLI                                                                   │
    │ --info                              Shows information about the Snowflake CLI                                                            │
    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │
    │ --install-completion                Install completion for the current shell.                                                            │
    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │
    │ --help                -h            Show this message and exit.                                                                          │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ app          Manages a Snowflake Native App                                                                                              │
    │ connection   Manages connections to Snowflake.                                                                                           │
    │ cortex       Provides access to Snowflake Cortex.                                                                                        │
    │ git          Manages git repositories in Snowflake.                                                                                      │
    │ notebook     Manages notebooks in Snowflake.                                                                                             │
    │ object       Manages Snowflake objects like warehouses and stages                                                                        │
    │ snowpark     Manages procedures and functions.                                                                                           │
    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │
    │ sql          Executes Snowflake query.                                                                                                   │
    │ stage        Manages stages.                                                                                                             │
    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    
3.  [Configure the Snowflake connection](../connecting/connect).
    

### Install with pipx[¶](#install-with-pipx ""Link to this heading"")

[pipx](https://github.com/pypa/pipx) provides an alternative to `pip` that installs and executes Python packages into isolated virtual environments. Installing Snowflake CLI with `pipx` does not, therefore, modify your current Python environment.

To install Snowflake CLI using `pipx`, you must have [pipx](https://github.com/pypa/pipx) installed.

1.  Run the following shell command:
    
    ```
    pipx install snowflake-cli
    
    ```
    
    Copy
    
2.  To verify that the software was installed successfully, run the following command:
    
    ```
    snow --help
    
    ```
    
    Copy
    
    ```
    Usage: snow [OPTIONS] COMMAND [ARGS]...
    
    Snowflake CLI tool for developers.
    
    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ --version                           Shows version of the Snowflake CLI                                                                   │
    │ --info                              Shows information about the Snowflake CLI                                                            │
    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │
    │ --install-completion                Install completion for the current shell.                                                            │
    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │
    │ --help                -h            Show this message and exit.                                                                          │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ app          Manages a Snowflake Native App                                                                                              │
    │ connection   Manages connections to Snowflake.                                                                                           │
    │ cortex       Provides access to Snowflake Cortex.                                                                                        │
    │ git          Manages git repositories in Snowflake.                                                                                      │
    │ notebook     Manages notebooks in Snowflake.                                                                                             │
    │ object       Manages Snowflake objects like warehouses and stages                                                                        │
    │ snowpark     Manages procedures and functions.                                                                                           │
    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │
    │ sql          Executes Snowflake query.                                                                                                   │
    │ stage        Manages stages.                                                                                                             │
    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    
3.  [Configure the Snowflake connection](../connecting/connect).
    

## Installing Snowflake CLI in FIPS-compliant environments[¶](#installing-sf-cli-in-fips-compliant-environments ""Link to this heading"")

You can use a Docker image to install Snowflake CLI in an environment that is compliant with FIPS (Federal Information Processing Standards).

### Prerequisites[¶](#prerequisites ""Link to this heading"")

Before installing Snowflake CLI in a FIPS-compliant environment, ensure that you meet the following prerequisites:

*   **FIPS-compliant Python**: Python must be preinstalled, built, and configured for FIPS compliance. This typically means Python is linked against a FIPS-enabled OpenSSL library.
    
*   **FIPS-enabled OpenSSL**: The system’s OpenSSL libraries must be FIPS-compliant and available to Python at runtime.
    
*   **Build tools**: Standard build tools (such as a C compiler and Python development headers) must be available, as dependencies will be built from source.
    
*   **Network Access**: The environment must allow access to PyPI or your internal package index for downloading source distributions.
    

### Install Snowflake CLI in a FIPS-compliant Dockerfile[¶](#install-sf-cli-in-a-fips-compliant-dockerfile ""Link to this heading"")

To install Snowflake CLI in a FIPS-compliant environment, follow these steps:

1.  Create a Python virtual environment in the container, as shown in the following example:
    
    ```
    python -m venv .venv
    
    ```
    
    Copy
    
2.  Activate the Python virtual environment in the container, as shown in the following example:
    
    ```
    source ~/.venv/bin/activate
    
    ```
    
    Copy
    
3.  Upgrade `pip` and `setuptools` in the container, as shown in the following example:
    
    ```
    pip install -U setuptools pip
    
    ```
    
    Copy
    
4.  Install the cryptography, Python connector, and Snowflake CLI dependencies from source in the container, as shown in the following example. Note that all dependencies must be installed from source to ensure they are built against your FIPS-compliant libraries.
    
    ```
    pip install cryptography==44.0.3 --no-binary cryptography
    pip install -U snowflake-connector-python[secure-local-storage] --no-binary snowflake-connector-python[secure-local-storage]
    pip install -U snowflake-cli --no-binary snowflake-cli
    
    ```
    
    Copy
    
    The `--no-binary` option forces installation from source, ensuring that the builds use FIPS-ready libraries.
    

### Validate the Docker image[¶](#validate-the-docker-image ""Link to this heading"")

To confirm that your Python environment uses a FIPS-enabled OpenSSL library, enter the following command in the running container:

```
python -c ""import ssl; print(ssl.OPENSSL_VERSION)""

```

Copy

After installing Snowflake CLI and validating the Docker image, you can use Snowflake CLI in the container.

```
snow <your-command>

```

Copy

where <_your-command_\> is any valid Snowflake CLI command, such as `snow --help`.

## Install command auto-completion functionality[¶](#install-command-auto-completion-functionality ""Link to this heading"")

Snowflake CLI supports standard shell tab completion functionality.

To install auto-completion into Snowflake CLI, perform the following steps:

1.  Run the `snow --install-completion` command:
    
    ```
    snow --install-completion
    
    ```
    
    Copy
    
    ```
    zsh completion installed in <user home>/.zfunc/_snow
    Completion will take effect once you restart the terminal
    
    ```
    
2.  Run the `snow --show-completion` command to generate the commands you need to add to your shell profile (`.bashrc`, `.bash_profile`, `.zshrc`, and others):
    
    ```
    snow --show-completion
    
    ```
    
    Copy
    
    ```
    _snow_completion() {
       local IFS=$'
    '
       COMPREPLY=( $( env COMP_WORDS=""${COMP_WORDS[*]}"" \
                      COMP_CWORD=$COMP_CWORD \
                      _SNOW_COMPLETE=complete_bash $1 ) )
       return 0
    }
    
    complete -o default -F _snow_completion snow
    
    ```
    
3.  Select and copy the command output text.
    
4.  Open your shell profile file, `.bashrc` in this example, and paste the copied text:
    
    ```
    export SHELL=/bin/bash
    
    ...
    
    _snow_completion() {
       local IFS=$'
    '
       COMPREPLY=( $( env COMP_WORDS=""${COMP_WORDS[*]}"" \
                      COMP_CWORD=$COMP_CWORD \
                      _SNOW_COMPLETE=complete_bash $1 ) )
       return 0
    }
    
    complete -o default -F _snow_completion snow
    
    ```
    
5.  Save the file.
    
6.  To activate the tab-completion functionality, restart your shell or `source` your shell profile file, such as:
    
    ```
    source ~/.bashrc
    
    ```
    
    Copy
    
7.  To test the feature, enter a snow command followed by a `TAB`, as shown:
    
    ```
    snow app [TAB]
    
    ```
    
    Copy
    
    ```
    deploy    init      open      run       teardown  version
    
    ```
    

On this page

1.  [Requirements](#requirements)
2.  [Install Snowflake CLI using package managers](#install-sf-cli-using-package-managers)
3.  [Install with Linux package managers](#install-with-linux-package-managers)
4.  [Install with the MacOS package installer](#install-with-the-macos-package-installer)
5.  [Install with the Windows installer](#install-with-the-windows-installer)
6.  [Install with Homebrew](#install-with-homebrew)
7.  [Advanced local installations](#advanced-local-installations)
8.  [Install with pip (PyPi)](#install-with-pip-pypi)
9.  [Install with pipx](#install-with-pipx)
10.  [Installing Snowflake CLI in FIPS-compliant environments](#installing-sf-cli-in-fips-compliant-environments)
11.  [Prerequisites](#prerequisites)
12.  [Install Snowflake CLI in a FIPS-compliant Dockerfile](#install-sf-cli-in-a-fips-compliant-dockerfile)
13.  [Validate the Docker image](#validate-the-docker-image)
14.  [Install command auto-completion functionality](#install-command-auto-completion-functionality)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/installation/../index)
2.  [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html)",NULL,e0249aa57ae417f58b757a27170f25b2214ed4e5b87e5c9bf659411a39ea2e33,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/connecting/connect,Configuring Snowflake CLI and connecting to Snowflake¶,NULL,NULL,NULL,NULL,"# Configuring Snowflake CLI and connecting to Snowflake[¶](#configuring-sf-cli-and-connecting-to-snowflake ""Link to this heading"")

This section explains how to configure, test, and manage your Snowflake connections.

*   [Configuring Snowflake CLI](configure-cli)
    
*   [Managing Snowflake connections](configure-connections)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/connecting/../index)",NULL,022416edf88df83a916e1df5d187e4b2ebf18e0d5f7f61a6c039ceeab7e9f687,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/connecting/configure-cli,Configuring Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Configuring Snowflake CLI[¶](#configuring-sf-cli ""Link to this heading"")

Snowflake CLI uses a global configuration file called `config.toml` to configure connections and logs for Snowflake CLI. If the file does not exist, running any `snow` command for the first time automatically creates an empty `config.toml` file that you can then populate with the desired connections. For more information about `toml` file formats, see [TOML (Tom’s Obvious Minimal Language)](https://toml.io/en/). Snowflake Python libraries currently support TOML version 1.0.0.

The `config.toml` supports the following sections:

*   `[connections]` for defining and managing connections
    
*   `[logs]` for configuring which types of messages are saved to log files
    

A Snowflake CLI configuration file has the following structure:

```
default_connection_name = ""myconnection""

[connections]
[connections.myconnection]
account = ""myorganization-myaccount""
user = ""jdoe""
...

[connections.testingconnection]
account = ""myorganization-myaccount""
user = ""jdoe""
...

[cli.logs]
save_logs = true
level = ""info""
path = ""/home/<username>/.snowflake/logs""

```

Copy

You can generate the basic settings for the TOML configuration file in Snowsight. For information, see [Configuring a client, driver, library, or third-party application to connect to Snowflake](../../../user-guide/gen-conn-config).

Note

If a `connection.toml` file exists, Snowflake CLI uses the connections defined in it instead of those defined in the `config.toml` file.

## Location of the `.toml` configuration file[¶](#location-of-the-toml-configuration-file ""Link to this heading"")

By default Snowflake CLI looks for the `config.toml` file in the `~/.snowflake` directory or, in case this directory does not exist, in a system-specific location, as listed below. You can also specify which configuration file should be used using `--config-file` flag or `SNOWFLAKE_HOME` environment variable.

*   If you specify the `--config-file` option (such as, `snow --config-file ./my-config-file-path`), Snowflake CLI uses the specified configuration file.
    
*   If the `SNOWFLAKE_HOME` environment variable is set, Snowflake CLI uses the location specified by this variable.
    
*   If a `~/.snowflake` directory exists on your machine, Snowflake CLI uses the `~/.snowflake/config.toml` file.
    
*   Otherwise, Snowflake CLI uses the `config.toml` file in the one of the following locations, based on your operating system:
    
    > *   Linux: `~/.config/snowflake/config.toml`, but you can update it with XDG vars
    >     
    > *   Windows: `%USERPROFILE%\AppData\Local\snowflake\config.toml`
    >     
    > *   Mac: `~/Library/Application Support/snowflake/config.toml`
    >     
    

Note

For MacOS and Linux systems, Snowflake CLI requires the `config.toml` file to limit its file permissions to read and write for the file owner only. To set the file required file permissions execute the following commands:

```
chown $USER config.toml
chmod 0600 config.toml

```

Copy

### Choose a different configuration file[¶](#choose-a-different-configuration-file ""Link to this heading"")

In some situations, such as a continuous integration and continuous deployment (CI/CD) environments, you might prefer to create dedicated configuration files for testing and deployment pipelines instead of defining all of the possible configurations in a single Snowflake default configuration file.

To use a different configuration file that your default file, you can use the `--config-file` option for the `snow` command, as shown:

```
snow --config-file=""my_config.toml"" connection test

```

Copy

### Support for system environment variables[¶](#support-for-system-environment-variables ""Link to this heading"")

Snowflake CLI supports using system environment variables to override parameter values defined in your `config.toml` file, using the following format:

```
SNOWFLAKE_<config-section>_<variable>=<value>

```

Copy

where:

*   `<config_section>` is the name of a section in the configuration file with periods (`.`) replaced with underscores (`_`), such as `CLI_LOGS`.
    
*   variable is the name of a variable defined in that section, such as `path`.
    

Some examples include:

*   Override the `path` parameter in the `[cli.logs]` section in the `config.toml` file:
    
    ```
    export SNOWFLAKE_CLI_LOGS_PATH=""/Users/jondoe/snowcli_logs""
    
    ```
    
    Copy
    
*   Set the password for the `myconnection` connection:
    
    ```
    export SNOWFLAKE_CONNECTIONS_MYCONNECTION_PASSWORD=""*******""
    
    ```
    
    Copy
    
*   Set the default connection name:
    
    ```
    export SNOWFLAKE_DEFAULT_CONNECTION_NAME=""myconnection""
    
    ```
    
    Copy
    

## Add an authentication policy that limits access to Snowflake CLI only[¶](#add-an-authentication-policy-that-limits-access-to-sf-cli-only ""Link to this heading"")

Users can create an [authentication policy](../../../user-guide/authentication-policies) that limits access permission to drivers, as well as Snowflake CLI. If you want to allow access to Snowflake CLI only (and exclude the drivers), you can do the following:

*   Create a new authentication policy that limits access strictly to Snowflake CLI.
    
*   Enable the policy in the `config.toml` file.
    

### Create an authentication policy limited to Snowflake CLI[¶](#create-an-authentication-policy-limited-to-sf-cli ""Link to this heading"")

To create a new authentication policy for only Snowflake CLI, follow these steps:

1.  Execute the [CREATE AUTHENTICATION POLICY](../../../sql-reference/sql/create-authentication-policy) SQL command, setting the CLIENT\_TYPES parameter to include `'SNOWFLAKE_CLI'`.
    
    ```
    CREATE AUTHENTICATION POLICY snowflake_cli_only
      CLIENT_TYPES = ('SNOWFLAKE_CLI');
    
    ```
    
    Copy
    
2.  Add the policy to the user, as shown:
    
    ```
    ALTER USER user1
      SET AUTHENTICATION POLICY snowflake_cli_only;
    
    ```
    
    Copy
    

### Enable the policy in the Snowflake CLI configuration[¶](#enable-the-policy-in-the-sf-cli-configuration ""Link to this heading"")

The `enable_separate_authentication_policy_id` configuration parameter lets you enable access to Snowflake CLI separately from the drivers. When this access is enabled, specified users can access Snowflake CLI but not the other Snowflake drivers.

Warning

If you already have an authentication policy that allows access only to drivers and don’t have one that allows access to Snowflake CLI only, enabling the `enable_separate_authentication_policy_id` parameter will cause the users to lose access to Snowflake CLI if you don’t create the new policy first. Make sure to add SNOWFLAKE\_CLI to your authentication policy before enabling the configuration parameter.

To enable the SNOWFLAKE\_CLI policy, add the `enable_separate_authentication_policy_id` parameter to the `[cli.features]` section in the `config.toml` file, as shown:

```
[cli.features]
enable_separate_authentication_policy_id = true

```

Copy

Note

Enabling this parameter affects all connections made by Snowflake CLI.

## Use a proxy server[¶](#use-a-proxy-server ""Link to this heading"")

To use a proxy server, configure the following environment variables:

*   HTTP\_PROXY
    
*   HTTPS\_PROXY
    
*   NO\_PROXY
    

For example:

Linux or macOS:

```
export HTTP_PROXY='http://username:password@proxyserver.example.com:80'
export HTTPS_PROXY='http://username:password@proxyserver.example.com:80'

```

Copy

Windows:

```
set HTTP_PROXY=http://username:password@proxyserver.example.com:80
set HTTPS_PROXY=http://username:password@proxyserver.example.com:80

```

Copy

Tip

Snowflake’s security model does not allow Secure Sockets Layer (SSL) proxies (using an HTTPS certificate). Your proxy server must use a publicly-available Certificate Authority (CA), reducing potential security risks such as a MITM (Man In The Middle) attack through a compromised proxy.

If you must use your SSL proxy, we strongly recommend that you update the server policy to pass through the Snowflake certificate such that no certificate is altered in the middle of communications.

Optionally `NO_PROXY` can be used to bypass the proxy for specific communications. For example, access to Amazon S3 can bypass the proxy server by specifying `NO_PROXY="".amazonaws.com""`.

`NO_PROXY` does not support wildcards. Each value specified should be one of the following:

*   The end of a hostname (or a complete hostname), for example:
    
    *   .amazonaws.com
        
    *   myorganization-myaccount.snowflakecomputing.com
        
*   An IP address, for example:
    
    *   192.196.1.15
        

If more than one value is specified, values should be separated by commas, for example:

> ```
> localhost,.example.com,.snowflakecomputing.com,192.168.1.15,192.168.1.16
> 
> ```
> 
> Copy

## Configure logging[¶](#configure-logging ""Link to this heading"")

By default, Snowflake CLI automatically saves `INFO`, `WARNING`, and `ERROR` level messages to log files. To disable or customize logging, create a `[cli.logs]` section in your `config.toml` file:

```
[cli.logs]
save_logs = true
level = ""info""
path = ""/home/<username>/.snowflake/logs""

```

Copy

where:

*   `save_logs` indicates whether to save logs to files. Default: `true`.
    
*   `level` specifies which levels of messages to save to log files. Choose from the following levels, which includes all levels below the selected one:
    
    *   `debug`
        
        Warning
        
        Switching to the `debug` logging level can expose sensitive information, such as executed SQL queries. Use caution when enabling this level.
        
    *   `info`
        
    *   `warning`
        
    *   `error`
        
    
    Default: `info`
    
*   `path` specifies the absolute path to save the log files. The format of the path varies based on your operating system, as shown:
    
    *   Linux: `path = ""/home/<your_username>/.config/snowflake/logs""`
        
    *   MacOS: `path = ""/Users/<your_username>/Library/Application Support/snowflake/logs""`
        
    *   Windows: `path = ""C:\\Users\\<your_username>\\AppData\\Local\\snowflake\\logs""`
        
    
    If not specified, the command creates a `logs` directory in the default `config.toml` file location.
    

If your `config.toml` was created automatically, the `config.toml` file contains the `|cli.logs|` section filled with default values.

Logs from a single day are appended to file `snowflake-cli.log`, which is later renamed to `snowflake-cli.log.YYYY-MM-DD`, as shown.

```
ls logs/

```

Copy

```
snowflake-cli.log            snowflake-cli.log.2024-10-22

```

## Suppress version update notifications[¶](#suppress-version-update-notifications ""Link to this heading"")

By default, Snowflake CLI checks for newer versions and displays a notification message when a newer version is available. You can suppress these notifications using either a configuration file setting or an environment variable, as follows:

*   Add the `ignore_new_version_warning` setting to the `config.toml` file:
    
    ```
    [cli]
    ignore_new_version_warning = true
    
    ```
    
    Copy
    
*   Set the `SNOWFLAKE_CLI_IGNORE_NEW_VERSION_WARNING` environment variable:
    
    ```
    export SNOWFLAKE_CLI_IGNORE_NEW_VERSION_WARNING=true
    
    ```
    
    Copy
    

On this page

1.  [Location of the .toml configuration file](#location-of-the-toml-configuration-file)
2.  [Add an authentication policy that limits access to Snowflake CLI only](#add-an-authentication-policy-that-limits-access-to-sf-cli-only)
3.  [Use a proxy server](#use-a-proxy-server)
4.  [Configure logging](#configure-logging)
5.  [Suppress version update notifications](#suppress-version-update-notifications)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/connecting/../index)
2.  [Managing Snowflake connections](/developer-guide/snowflake-cli/connecting/configure-connections)",NULL,6bee41caf2348ad0a6abc4723b5fc31d2c464a9b1bd8d8c57c27e77a1b2507ab,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/bootstrap-project/bootstrap,Bootstrapping a project from a template¶,NULL,NULL,NULL,NULL,"# Bootstrapping a project from a template[¶](#bootstrapping-a-project-from-a-template ""Link to this heading"")

To make it easier for you to instantiate projects, Snowflake CLI implements project templating. You can [create your own project templates](#label-cli-project-templating-custom-templates) or use samples provided by Snowflake in the [Snowflake CLI templates](https://github.com/snowflakedb/snowflake-cli-templates/) public Git repository.

The [snow init](../command-reference/bootstrap-commands/init) command creates a project directory and populates it with file structure defined in the specified template.

*   If you don’t provide the `--no-interactive` option, the command prompts for each variable specified by the template (`template.yml`) that you don’t provide with the `-D` (or `--variable`) option.
    
*   If you do provide the `--no-interactive` option, the command uses the default values of variables (defined by the template). If the template does not define a default value for a variable and you don’t use the `-D` option to provide it, the command exits with an error.
    

The `snow init` command uses the following syntax:

```
snow init PATH [--template-source SOURCE] [--template NAME] [-D key1=value1 -D key2=value2...] [--no-interactive]

```

Copy

where:

*   `PATH` is a new directory where the command initializes the project. If you specify an existing directory, the command exits with an error.
    
*   `[--template-source SOURCE]` is one of the following:
    
    *   A local file path of the template directory.
        
    *   A valid Git URL to the directory containing the project template. If not specified, the command defaults to the [Snowflake CLI templates](https://github.com/snowflakedb/snowflake-cli-templates/) Git repository.
        
*   `[--template NAME]` specifies which subdirectory of `SOURCE` to use as a template (useful for remote sources). If not provided, `SOURCE` is treated as a single template.
    
*   `[-D key1=value1 -D key2=value2...]` is a list of one or more name-value pairs, providing values for variables defined in the template (in `template.yml`). The command does not prompt for variables you provide with this option.
    
*   `[--no-interactive]` disables prompts for user input. If you use this option, you must provide all of the required values with the `[-D key1=value1 -D key2=value2...]` options; otherwise, the command exists with an error.
    

For more information, see the [snow init](../command-reference/bootstrap-commands/init) command reference.

## Examples[¶](#examples ""Link to this heading"")

*   Initialize project from `example_snowpark` template from default repository:
    
    ```
    snow init my_snowpark_test_app --template example_snowpark
    
    ```
    
    Copy
    
    The command prompts for (default values are shown in square brackets):
    
    ```
    Project identifier (used to determine artifacts stage path) [my_snowpark_project]:
    What stage should the procedures and functions be deployed to? [dev_deployment]: snowpark
    Initialized the new project in my_snowpark_test_app
    
    ```
    
*   Initialize the project from the local template.
    
    ```
    snow init new_streamlit_project --template-source ../local_templates/example_streamlit -D query_warehouse=dev_wareshouse -D stage=testing
    
    ```
    
    Copy
    
    In this example, `query_warehouse` and `stage` variables are specified with the `-D` option, so the command only prompts for the following:
    
    ```
    Name of the streamlit app [streamlit_app]:
    Initialized the new project in new_streamlit_project
    
    ```
    

## Creating custom templates[¶](#creating-custom-templates ""Link to this heading"")

### Template layout[¶](#template-layout ""Link to this heading"")

A project template requires a `template.yml` file that contains data that explains how the `snow init` command should render the template. If the file is not present in the template’s root directory, `snow init` finishes with an error. For more information, see [template.yml syntax.](#label-cli-project-templating-template-yml)

### Template syntax[¶](#template-syntax ""Link to this heading"")

Template variables and expressions should be enclosed in `<! ... !>`. Snowflake CLI also supports basic jinja2 expressions and filters, for example:

> ```
> some_file_spec:
>   filename: <! file_name !>
>   size: ""<! [ max_file_size_mb, 4 ] | max !> MB""
> 
> ```
> 
> Copy

Snowflake CLI project templates also support the following reserved variable and filter:

*   `project_dir_name` variable, which automatically resolves to the root directory of the created project.
    
    For example, suppose your `snowflake.yml` file contains the following:
    
    ```
    definition_version: ""1.1""
    snowpark:
      project_name: <! project_dir_name !>
      ...
    
    ```
    
    Copy
    
    If you then execute the following command to initialize the project from your custom template:
    
    ```
    snow init examples/new_snowpark_project --template-source my_example_template/
    
    ```
    
    Copy
    
    The `snow init` command renders the `snowflake.yml` file as follows:
    
    ```
    definition_version: ""1.1""
    snowpark:
      project_name: new_snowpark_project
      ...
    
    ```
    
    Copy
    
*   `to_snowflake_identifier` filter, which formats user-provided strings into to correctly-formatted Snowflake identifiers.
    
    Snowflake strongly recommends using this filter when a variable references a Snowflake object.
    
    For example, suppose your `snowflake.yml` file contains the following:
    
    ```
    definition_version: ""1.1""
    streamlit:
      name: <! name | to_snowflake_identifier !>
      ...
    
    ```
    
    Copy
    
    If you then execute the following command to initialize a project from your custom template:
    
    ```
    snow init examples/streamlit --template-source my_example_template2/ -D name='My test streamlit'
    
    ```
    
    Copy
    
    The `snow init` command renders the `snowflake.yml` file as follows:
    
    ```
    definition_version: ""1.1""
    streamlit:
      name: My_test_streamlit
      ...
    
    ```
    
    Copy
    
    If a string cannot be converted into a valid Snowflake identifier, the `snow init` command exits with an error, as shown:
    
    ```
    snow init examples/streamlit --template-source my_example_template2/ -D name=1234567890
    
    ```
    
    Copy
    
    ```
    ╭─ Error ────────────────────────────────────────────────────────────────────────╮
    │ Value '123456789' cannot be converted to valid Snowflake identifier.         │
    │ Consider enclosing it in double quotes: """"                                   │
    ╰────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    

### About the `template.yml` project template file[¶](#about-the-template-yml-project-template-file ""Link to this heading"")

The `template.yml` project template file stores all of the data needed to render the project. For example:

```
minimum_cli_version: ""2.7.0""
files_to_render:
  - snowflake.yml
variables:
  - name: name
    default: streamlit_app
    prompt: ""Name of the streamlit app""
    type: string
  - name: stage
    default: my_streamlit_stage
    prompt: ""What stage should the app be deployed to?""
    type: string
  - name: query_warehouse
    default: my_streamlit_warehouse
    prompt: ""On which warehouse SQL queries issued by the application are run""
    type: string

```

Copy

The following table lists the properties in a `template.yml` project template file.

| Property | Definition |
| --- | --- |
| minimum_cli_versionoptional, string (default:None) | Minimum Snowflake CLI version. If specified, the snow init command checks the version of Snowflake CLI installed and exits with an error if the installed version is lower than the specified version. |
| files_to_renderoptional, string list (default: []) | List of files to be rendered by the snow init command. Each path should be relative to the templates root.NoteTemplate files not included in this list are added to the new project, but their content remains unchanged. |
| variablesoptional, variable list (default: []) | List of template variables. It supports customizing prompts, providing default values for optional variables and basic type checking. See the Variables property parameters table below for more details. Variable values are determined in order from this list.If you omit any variable used in the snowflake.yml file from this list, the snow init command exits with the following error.╭─ Error ─────────────────────────────────────────────────────────╮
│ Cannot determine value of variable undefined_variable         │
╰─────────────────────────────────────────────────────────────────╯ |

The following table lists the parameters of a variable property.

| Property | Definition |
| --- | --- |
| namerequired, string | Name of the variable. It is used in the template files, such as <! name !> and in -D option, such as -D name=value. |
| promptoptional, string | Prompt to display to the user to get a value. If you don’t set this parameter, the command displays the name of the parameter as the prompt text.If you define the prompt as follows:variables:
  - name: project_id
    prompt: The identifier for the project
Copysnow init displays this prompt for the project_id variable.The identifier for the project: |
| defaultoptional, string/int/float | Default value of the variable. If not provided, the variable is treated as required, so a user needs to provide the value after a prompt or by specifying it with the -D command-line option.The following example defines two variables with default values:variables:
  - name: max_file_size_mb
    default: 16
  - name: file_name
    default: 'default_file_name.zip'
CopyWhen executed, the snow init command displays the following prompts for these two variables:file_name [default_file_name.zip]:
max_file_size_mb [16]: 5
CopyIn this example, the command uses the default value (default_file_name.zip) for the file_name variable has a default value, and sets max_file_size_mb to the value provided by the user (5). |
| typeoptional, string | Data type of the variable. Valid values include: string, int, and float. If not specified, the command assumes the value is a string.The following example defines a variable as an int data type:variables:
  - name: max_file_size_mb
    type: int
CopyWhen executed, the snow init command displays the following errors if the user enters a value of the wrong data type:max_file_size_mb: not an int
Error: 'not an int' is not a valid integer.
max_file_size_mb: 14.5
Error: '14.5' is not a valid integer.
max_file_size_mb: 6
Initialized the new project in example_dir |

On this page

1.  [Examples](#examples)
2.  [Creating custom templates](#creating-custom-templates)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/bootstrap-project/../index)
2.  [snow init](/developer-guide/snowflake-cli/bootstrap-project/../command-reference/bootstrap-commands/init)
3.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/bootstrap-project/../streamlit-apps/overview)
4.  [Using Snowpark in Snowflake CLI](/developer-guide/snowflake-cli/bootstrap-project/../snowpark/overview)",NULL,15b05ab882bddcbf662e632cd97ba61a4efd99d2a0a73cb43b61dbb12f11a103,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/about,About project definition files¶,NULL,NULL,NULL,NULL,"# About project definition files[¶](#about-project-definition-files ""Link to this heading"")

When developing Streamlit or Snowpark applications you often work with multiple files and objects, be it python file or stored procedures. Organizing this in a clear and concise way is very important for smooth development experience. That’s the reason why Snowflake CLI is using the concept of _project definition files_.

A project definition file (usually named `snowflake.yml`) is a file containing information about the Snowflake objects you are developing. The following `snowflake.yml` example shows a project with a Snowpark UDF and a stored procedure.

```
definition_version: 2
entities:
  test_function:
    type: ""function""
    stage: ""dev_deployment""
    artifacts: [""app/""]
    handler: ""functions.hello_function""
    signature: """"
    returns: string

  hello_procedure:
    type: ""procedure""
    stage: ""dev_deployment""
    artifacts: [""app/""]
    handler: ""procedures.hello_procedure""
    signature:
      - name: ""name""
        type: ""string""
    returns: string

```

Copy

## Project definition properties[¶](#project-definition-properties ""Link to this heading"")

The following table describes the project definition properties used by all projects.

| Property | Definition |
| --- | --- |
| definition_versionrequired, int | Version of the project definition schema, which is currently 2. |
| entitiesoptional, string | List of entity definitions, such as procedures, functions, and so on. For more information, see Specify entities. |
| envoptional, string sequence | List of default environment specifications to be used in project templates. For more information, see Create project definition file templates. |
| mixinsoptional, string sequence | List of common values for entity properties. For more information, see Project mixins. |

Each project requires specific information about what you are building. Snowflake CLI currently supports the following entity definitions from the following Snowflake domains:

*   [Native App Framework](../native-apps/project-definitions)
    
*   [Notebooks](../notebooks/use-notebooks)
    
*   [Snowpark](../snowpark/create.html#label-snowcli-create-snowpark)
    
*   Snowpark Container Services (SPCS)
    
    *   [Compute pools](../services/manage-compute-pools.html#label-sfcli-pool-pdf)
        
    *   [Image repositories](../services/manage-images.html#label-sfcli-repo-pdf)
        
    *   [Services](../services/manage-services.html#label-sfcli-service-pdf)
        
*   [Streamlit](../streamlit-apps/manage-apps/initialize-app.html#label-snowcli-streamlit-project-definition)
    
*   [SQL](../sql/execute-sql.html#label-cli-sql-env-vars)
    

Caution

Files inside a project directory are processed by Snowflake CLI and could be uploaded to Snowflake when executing other `snow` commands. You should use caution when putting any sensitive information inside files in a project directory.

On this page

1.  [Project definition properties](#project-definition-properties)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",NULL,4f202f9eebb65c4569207b5c04db9477171e30d95e1564815fa051281ecbfcd1,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/objects/manage-objects,Managing Snowflake objects¶,NULL,NULL,NULL,NULL,"# Managing Snowflake objects[¶](#managing-snowflake-objects ""Link to this heading"")

The `snow object` commands provide you with a convenient way of managing most Snowflake objects, such as stages, Snowpark functions, or Streamlit apps. Instead of using separate commands for each type of object, you can use these commands to perform common tasks, including the following:

*   [Create an object of a specific type](#label-snowcli-object-create)
    
*   [List available objects of a specified type](#label-snowcli-object-list).
    
*   [Display the description of an object](#label-snowcli-object-describe).
    
*   [Delete an object](#label-snowcli-object-drop).
    

To see a list of supported types use the `--help` option for any of the `snow object` commands, such as the following:

```
snow object list --help

```

Copy

```
Usage: snow object list [OPTIONS] OBJECT_TYPE

Lists all available Snowflake objects of given type.
Supported types: compute-pool, database, function, image-repository, integration, network-rule,
procedure, role, schema, secret, service, stage, stream, streamlit, table, task,
user, view, warehouse

...

```

The object subcommands let you perform common operations, while leaving service-specific commands groups dedicated to service-specific operations.

## Create an object of a specific type[¶](#create-an-object-of-a-specific-type ""Link to this heading"")

The `snow object create` command creates a specified object based on the definition provided, using the following syntax:

```
snow object create TYPE ([OBJECT_ATTRIBUTES]|[--json {OBJECT_DEFINITION}])

```

Copy

where:

*   `TYPE` is a Snowflake object type:
    
    *   `account`
        
    *   `catalog-integration`
        
    *   `compute-pool`
        
    *   `database`
        
    *   `database-role`
        
    *   `dynamic-table`
        
    *   `event-table`
        
    *   `external-volume`
        
    *   `function`
        
    *   `image-repository`
        
    *   `managed-account`
        
    *   `network-policy`
        
    *   `notebook`
        
    *   `notification-integration`
        
    *   `pipe`
        
    *   `procedure`
        
    *   `role`
        
    *   `schema`
        
    *   `service`
        
    *   `stage`
        
    *   `stream`
        
    *   `table`
        
    *   `task`
        
    *   `user-defined-function`
        
    *   `view`
        
    *   `warehouse`
        

*   `OBJECT_ATTRIBUTES` contains the object definition in the form of a list of `<key>=<value>` pairs, such as:
    
    ```
    snow object create database name=my_db comment=""Created with Snowflake CLI""
    
    ```
    
    Copy
    
*   `--json {OBJECT_DEFINITION}` contains the object definition in JSON, such as:
    
    ```
    snow object create database --json '{""name"":""my_db"", ""comment"":""Created with Snowflake CLI""}'
    
    ```
    
    Copy
    

Note

The following object types require a database to be identified in the connection configuration, such as `config.toml`, or passed to the command using the `--database` option.

*   image-repository
    
*   schema
    
*   service
    
*   table
    
*   task
    

To create a database object using the `option-attributes` parameter:

```
snow object create database name=my_db comment='Created with Snowflake CLI'

```

Copy

To create a table object using the `option-attributes` parameter:

```
snow object create table name=my_table columns='[{""name"":""col1"",""datatype"":""number"", ""nullable"":false}]' constraints='[{""name"":""prim_key"", ""column_names"":[""col1""], ""constraint_type"":""PRIMARY KEY""}]' --database my_db --schema public

```

Copy

To create a database using the `--json object-definition` option:

```
snow object create database --json '{""name"":""my_db"", ""comment"":""Created with Snowflake CLI""}'

```

Copy

To create a table using the `--json object-definition` option:

```
snow object create table --json ""$(cat table.json)"" --database my_db

```

Copy

where `table.json` contains the following:

```
{
  ""name"": ""my_table"",
  ""columns"": [
    {
      ""name"": ""col1"",
      ""datatype"": ""number"",
      ""nullable"": false
    }
  ],
  ""constraints"": [
    {
      ""name"": ""prim_key"",
      ""column_names"": [""col1""],
      ""constraint_type"": ""PRIMARY KEY""
    }
  ]
}

```

Copy

## List all objects of a specific type[¶](#list-all-objects-of-a-specific-type ""Link to this heading"")

The `snow object list` command lists all objects of given type available with your permissions.

```
snow object list TYPE

```

Copy

where `TYPE` is the type of the object. Use `snow object list --help` for the full list of supported types.

To list all role objects, enter the following command:

```
snow object list role

```

Copy

```
+--------------------------------------------------------------------------------------------------------------------------------+
|            |            |            |            | is_inherit | assigned_t | granted_to | granted_ro |            |           |
| created_on | name       | is_default | is_current | ed         | o_users    | _roles     | les        | owner      | comment   |
|------------+------------+------------+------------+------------+------------+------------+------------+------------+-----------|
| 2023-07-24 | ACCOUNTADM | N          | N          | N          | 2          | 0          | 2          |            | Account   |
| 06:05:49-0 | IN         |            |            |            |            |            |            |            | administr |
| 7:00       |            |            |            |            |            |            |            |            | ator can  |
|            |            |            |            |            |            |            |            |            | manage    |
|            |            |            |            |            |            |            |            |            | all       |
|            |            |            |            |            |            |            |            |            | aspects   |
|            |            |            |            |            |            |            |            |            | of the    |
|            |            |            |            |            |            |            |            |            | account.  |
| 2023-07-24 | PUBLIC     | N          | N          | Y          | 0          | 0          | 0          |            | Public    |
| 06:05:48.9 |            |            |            |            |            |            |            |            | role is   |
| 56000-07:0 |            |            |            |            |            |            |            |            | automatic |
| 0          |            |            |            |            |            |            |            |            | ally      |
|            |            |            |            |            |            |            |            |            | available |
|            |            |            |            |            |            |            |            |            | to every  |
|            |            |            |            |            |            |            |            |            | user in   |
|            |            |            |            |            |            |            |            |            | the       |
|            |            |            |            |            |            |            |            |            | account.  |
| 2023-07-24 | SYSADMIN   | N          | N          | N          | 0          | 1          | 0          |            | System    |
| 06:05:49.0 |            |            |            |            |            |            |            |            | administr |
| 33000-07:0 |            |            |            |            |            |            |            |            | ator can  |
| 0          |            |            |            |            |            |            |            |            | create    |
|            |            |            |            |            |            |            |            |            | and       |
|            |            |            |            |            |            |            |            |            | manage    |
|            |            |            |            |            |            |            |            |            | databases |
|            |            |            |            |            |            |            |            |            | and       |
|            |            |            |            |            |            |            |            |            | warehouse |
|            |            |            |            |            |            |            |            |            | s.        |
| 2023-07-24 | USERADMIN  | N          | N          | N          | 0          | 1          | 0          |            | User      |
| 06:05:49.0 |            |            |            |            |            |            |            |            | administr |
| 45000-07:0 |            |            |            |            |            |            |            |            | ator can  |
| 0          |            |            |            |            |            |            |            |            | create    |
|            |            |            |            |            |            |            |            |            | and       |
|            |            |            |            |            |            |            |            |            | manage    |
|            |            |            |            |            |            |            |            |            | users and |
|            |            |            |            |            |            |            |            |            | roles     |
+--------------------------------------------------------------------------------------------------------------------------------+

```

You can also use the `--like [-l] <pattern>` to filter objects by name using a SQL LIKE pattern. For example, `list function --like ""my%""` lists all functions that begin with **my**. For more information about SQL patterns syntax, see [SQL LIKE Keyword](https://www.w3schools.com/sql/sql_ref_like.asp).

To list only role objects that begin with the string, **public**, enter the following command:

```
snow object list role --like public%

```

Copy

```
show roles like 'public%'
+-------------------------------------------------------------------------------
| created_on                       | name        | is_default | is_current | ...
|----------------------------------+-------------+------------+------------+----
| 2023-02-01 15:25:04.105000-08:00 | PUBLIC      | N          | N          | ...
| 2024-01-15 12:55:05.840000-08:00 | PUBLIC_TEST | N          | N          | ...
+-------------------------------------------------------------------------------

```

## Display the description for an object of a specified type[¶](#display-the-description-for-an-object-of-a-specified-type ""Link to this heading"")

The `snow object describe` command provides a description of an object of given type.

```
snow object describe TYPE IDENTIFIER

```

Copy

where:

*   `TYPE` is the type of the object. Use `snow object describe --help` for the full list of supported types.
    
*   `IDENTIFIER` is the name of the object. For procedures and functions, the identifier must specify arguments types, such as `""hello(int,string)""`.
    

To describe a function object, enter a command similar to the following:

```
snow object describe function ""hello_function(string)""

```

Copy

```
describe function hello_function(string)
+---------------------------------------------------------------------
| property           | value
|--------------------+------------------------------------------------
| signature          | (NAME VARCHAR)
| returns            | VARCHAR(16777216)
| language           | PYTHON
| null handling      | CALLED ON NULL INPUT
| volatility         | VOLATILE
| body               | None
| imports            |
| handler            | functions.hello_function
| runtime_version    | 3.9
| packages           | ['snowflake-snowpark-python']
| installed_packages | ['_libgcc_mutex==0.1','_openmp_mutex==5.1',...
+---------------------------------------------------------------------

```

## Delete an object of a specified type[¶](#delete-an-object-of-a-specified-type ""Link to this heading"")

The `snow object drop` command deletes a Snowflake object of given name and type.

```
snow object drop TYPE IDENTIFIER

```

Copy

where:

*   `TYPE` is the type of the object. Use `snow object drop --help` for the full list of supported types.
    
*   `IDENTIFIER` is the name of the object. For procedures and functions, the identifier must specify arguments types, such as `""hello(int,string)""`.
    

To drop a procedure, enter a commands similar to the following:

```
snow object drop procedure ""test_procedure()""

```

Copy

```
drop procedure test_procedure()
+--------------------------------------+
| status                               |
|--------------------------------------|
| TEST_PROCEDURE successfully dropped. |
+--------------------------------------+

```

On this page

1.  [Create an object of a specific type](#create-an-object-of-a-specific-type)
2.  [List all objects of a specific type](#list-all-objects-of-a-specific-type)
3.  [Display the description for an object of a specified type](#display-the-description-for-an-object-of-a-specified-type)
4.  [Delete an object of a specified type](#delete-an-object-of-a-specified-type)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/objects/../index)
2.  [snow object commands](/developer-guide/snowflake-cli/objects/../command-reference/object-commands/overview)",NULL,8c4fc19274932f93d3a795c51eadab7d19c70d1916b9d015e8618a99c08b333c,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/stages/manage-stages,Managing Snowflake stages¶,NULL,NULL,NULL,NULL,"# Managing Snowflake stages[¶](#managing-snowflake-stages ""Link to this heading"")

The `snow stage` commands let you perform additional stage-specific tasks:

*   [Create a named stage if it does not already exist](#label-snowcli-stage-create).
    
*   [Copy all files from source to target directory](#label-snowcli-stage-copy).
    
*   [List the contents of a stage](#label-snowcli-stage-list).
    
*   [Execute SQL files from a stage](#label-snowcli-stage-execute).
    
*   [Remove a file from a stage](#label-snowcli-stage-remove).
    

## Create a named stage[¶](#create-a-named-stage ""Link to this heading"")

The `snow stage create` command creates a named stage if it does not already exist.

```
snow stage create <stage_name>

```

Copy

For example, to create a stage called `new_stage`, enter the following command:

```
snow stage create new_stage

```

Copy

```
+-----------------------------------------------------+
| key    | value                                      |
|--------+--------------------------------------------|
| status | Stage area NEW_STAGE successfully created. |
+-----------------------------------------------------+

```

The following example shows what happens if you try to create a stage, `packages`, that already exists.

```
# stage that already exists
snow stage create packages

```

Copy

```
+--------------------------------------------------------+
| key    | value                                         |
|--------+-----------------------------------------------|
| status | PACKAGES already exists, statement succeeded. |
+--------------------------------------------------------+

```

If you want to specify the type of encryption to use for all files stored on the stage, add the `--encryption` option to specify whether you want to full encryption (`SNOWFLAKE_FULL`) or only server-side encryption (`SNOWFLAKE_SSE`).

```
snow stage create new_stage --encryption SNOWFLAKE_FULL

```

Copy

```
+-----------------------------------------------------+
| key    | value                                      |
|--------+--------------------------------------------|
| status | Stage area NEW_STAGE successfully created. |
+-----------------------------------------------------+

```

## Copy files to and from a stage[¶](#copy-files-to-and-from-a-stage ""Link to this heading"")

The `snow stage copy` command copies a file from the local machine to a stage, from a stage to a local machine, or between named stages.

```
snow stage copy <source_path> <destination_path>

```

Copy

Note the following guidelines:

*   The stage path must start with `@`, as shown in the following examples.
    
*   When you copy a single file, `<destination_path>` must identify a directory, not a file. If the specified directory does not exist, the command creates it.
    
*   By default, when you copy a local directory to a stage, the local directory must contain only files. You can use the `--recursive` option to upload sub-directories in the local directory. You can use glob patterns with the `--recursive` option.
    
*   When you copy a directory from a stage to a local filesystem, the command currently flattens its internal tree structure. To illustrate, assume your local directory contains the following:
    
    ```
    test_case.py
    tests/abc.py
    tests/test1/x1.txt
    tests/test1/x2.txt
    
    ```
    
    After copying the directory from the stage, the local filesystem directory contains the following:
    
    ```
    test_case.py
    abc.py
    x1.txt
    x2.txt
    
    ```
    
    Note
    
    If you want to maintain the file structure from the source directory, you can include the `--recursive` option.
    

### Copy files to a stage[¶](#copy-files-to-a-stage ""Link to this heading"")

*   To copy files from the local machine to a stage, enter a command similar to the following:
    
    ```
    snow stage copy local_example_app @example_app_stage/app
    
    ```
    
    Copy
    
    ```
    put file:///.../local_example_app/* @example_app_stage/app4 auto_compress=false parallel=4 overwrite=False
    +--------------------------------------------------------------------------------------
    | source           | target           | source_size | target_size | source_compression...
    |------------------+------------------+-------------+-------------+--------------------
    | environment.yml  | environment.yml  | 62          | 0           | NONE             ...
    | snowflake.yml    | snowflake.yml    | 252         | 0           | NONE             ...
    | streamlit_app.py | streamlit_app.py | 109         | 0           | NONE             ...
    +--------------------------------------------------------------------------------------
    
    ```
    

You can use the `snow stage list-files` command to verify the command copied the files successfully:

```
snow stage list-files example_app_stage

```

Copy

```
ls @example_app_stage
​+------------------------------------------------------------------------------------
| name                                   | size | md5                              | ...
|----------------------------------------+------+----------------------------------+-
| example_app_stage/app/environment.yml  | 64   | 45409c8da098125440bfb7ffbcd900f5 | ...
| example_app_stage/app/snowflake.yml    | 256  | a510b1d59fa04f451b679d43c703b6d4 | ...
| example_app_stage/app/streamlit_app.py | 112  | e6c2a89c5a164e34a0faf60b086bbdfc | ...
+------------------------------------------------------------------------------------

```

### Copy files from a stage[¶](#copy-files-from-a-stage ""Link to this heading"")

*   To copy files from a stage to a directory on the local machine, enter a command similar to the following:
    
    ```
    mkdir local_app_backup
    snow stage copy @example_app_stage/app local_app_backup
    
    ```
    
    Copy
    
    ```
    get @example_app_stage/app file:///.../local_app_backup/ parallel=4
    +------------------------------------------------+
    | file             | size | status     | message |
    |------------------+------+------------+---------|
    | environment.yml  | 62   | DOWNLOADED |         |
    | snowflake.yml    | 252  | DOWNLOADED |         |
    | streamlit_app.py | 109  | DOWNLOADED |         |
    +------------------------------------------------+
    
    ```
    

You can list the directory contents to verify the command copied the files correctly:

```
ls local_app_backup

```

Copy

```
environment.yml  snowflake.yml    streamlit_app.py

```

Note that the local directory must exist.

You can copy from a user stage (`@~`):

> ```
> snow stage copy ""@~"" . --recursive
> 
> ```
> 
> Copy
> 
> ```
> +------------------------------------------------+
> | file             | size | status     | message |
> |------------------+------+------------+---------|
> | environment.yml  | 62   | DOWNLOADED |         |
> | snowflake.yml    | 252  | DOWNLOADED |         |
> | streamlit_app.py | 109  | DOWNLOADED |         |
> +------------------------------------------------+
> 
> ```

### Copy files between stages[¶](#copy-files-between-stages ""Link to this heading"")

You can copy files directly between two named stages without downloading them to your local machine first. This can be useful for organizing files across different stages or creating backups.

*   To copy files from one stage to another, use the following syntax:
    
    ```
    snow stage copy @source_stage @destination_stage
    
    ```
    
    Copy
    

The following example copies all files from the `production_stage` to the `backup_stage`:

```
snow stage copy @production_stage @backup_stage

```

Copy

```
+------------------------------------------------------------+
| file                                                       |
|------------------------------------------------------------|
| __init__.py                                                |
| main.py                                                    |
| procedure.py                                               |
+------------------------------------------------------------+

```

Note

When you copy between stages, the destination cannot be a user stage (`@~`). You must specify named stages for both source and destination.

### Use glob patterns to specify files[¶](#use-glob-patterns-to-specify-files ""Link to this heading"")

You can specify multiple files matching a regular expression by using a glob pattern for the `source_path` argument. You must enclose the glob pattern in single or double quotes.

The following example copies all `.txt` files in a directory to a stage.

```
snow stage copy ""testdir/*.txt"" @TEST_STAGE_3

```

Copy

```
put file:///.../testdir/*.txt @TEST_STAGE_3 auto_compress=false parallel=4 overwrite=False
+------------------------------------------------------------------------------------------------------------+
| source | target | source_size | target_size | source_compression | target_compression | status   | message |
|--------+--------+-------------+-------------+--------------------+--------------------+----------+---------|
| b1.txt | b1.txt | 3           | 16          | NONE               | NONE               | UPLOADED |         |
| b2.txt | b2.txt | 3           | 16          | NONE               | NONE               | UPLOADED |         |
+------------------------------------------------------------------------------------------------------------+

```

## List the contents of a stage[¶](#list-the-contents-of-a-stage ""Link to this heading"")

The `snow stage list-files` command lists the stage contents.

```
snow stage list-files <stage_path>

```

Copy

For example, to list the packages in a stage, enter the following command:

```
snow stage list-files packages

```

Copy

```
ls @packages
+-------------------------------------------------------------------------------------
| name                 | size     | md5                              | last_modified
|----------------------+----------+----------------------------------+----------------
| packages/plp.Ada.zip | 824736   | 90639175a0ac7735e67525118b81047c | Tue, 16 Jan ...
| packages/samrand.zip | 13721024 | 648f0bae2f65fd4c9f178b17c23de7e5 | Tue, 16 Jan ...
+-------------------------------------------------------------------------------------

```

## Execute files from a stage[¶](#execute-files-from-a-stage ""Link to this heading"")

Note

Snowflake CLI does not support executing Python files for Python versions 3.12 and above.

The `snow stage execute` command executes SQL or Python files from a stage.

```
snow stage execute <stage_path>

```

Copy

*   For `.sql` files, the it performs an [EXECUTE IMMEDIATE FROM](../../../sql-reference/sql/execute-immediate-from) command on `.sql` files from a stage.
    
*   For `.py` files, it executes a session-scoped [Snowpark Python procedure](../../snowpark/python/creating-sprocs).
    
    Snowflake CLI executes the procedure in Snowflake to guarantee a consistent execution environment. If your Python scripts require additional requirements, you should specify them in a `requirements.txt` file that resides in the same directory as the files on the stage. The `snow stage execute` command only supports packages from the Snowflake Anaconda channel.
    
    By default, the command looks for the `requirements.txt` file in the following precedence:
    
    *   Stage path specified in the command’s `stage_path` parameter.
        
    *   Parent directories of the specified stage path hierarchy, until it reaches the stage.
        
    *   If you don’t specify a `requirements.txt` file, the command assumes no additional packages are necessary.
        
    
    For example, if you run `snow stage execute @my_stage/ml/app1/scripts`, the command looks for the file as follows:
    
    *   `my_stage/ml/app1/scripts/requirements.txt`
        
    *   `my_stage/ml/app1/requirements.txt`
        
    *   `my_stage/ml/requirements.txt`
        
    *   `my_stage/ml/requirements.txt`
        

The following examples illustrate ways to execute different sets of `.sql` files from a stage:

*   Specify only a stage name to execute all `.sql` files in the stage:
    
    ```
    snow stage execute ""@scripts""
    
    ```
    
    Copy
    
    ```
    SUCCESS - scripts/script1.sql
    SUCCESS - scripts/script2.sql
    SUCCESS - scripts/dir/script.sql
    +------------------------------------------+
    | File                   | Status  | Error |
    |------------------------+---------+-------|
    | scripts/script1.sql    | SUCCESS | None  |
    | scripts/script2.sql    | SUCCESS | None  |
    | scripts/dir/script.sql | SUCCESS | None  |
    +------------------------------------------+
    
    ```
    
*   Specify a user stage (`@~`) to execute the `script.sql` files in the user stage:
    
    ```
    snow stage execute ""@~/script1.sql""
    
    ```
    
    Copy
    
    ```
    SUCCESS - scripts/script1.sql
    +------------------------------------------+
    | File                   | Status  | Error |
    |------------------------+---------+-------|
    | @~/script.sql          | SUCCESS | None  |
    +------------------------------------------+
    
    ```
    

### Use glob patterns to select subsets of files[¶](#use-glob-patterns-to-select-subsets-of-files ""Link to this heading"")

*   Specify a glob-like pattern to execute all `.sql` files in the `dir` directory:
    
    ```
    snow stage execute ""@scripts/dir/*""
    
    ```
    
    Copy
    
    ```
    SUCCESS - scripts/dir/script.sql
    +------------------------------------------+
    | File                   | Status  | Error |
    |------------------------+---------+-------|
    | scripts/dir/script.sql | SUCCESS | None  |
    +------------------------------------------+
    
    ```
    
*   Specify a glob-like pattern to execute only `.sql` files in the `dir` directory that begin with “script”, followed by one character:
    
    ```
    snow stage execute ""@scripts/script?.sql""
    
    ```
    
    Copy
    
    ```
    SUCCESS - scripts/script1.sql
    SUCCESS - scripts/script2.sql
    +---------------------------------------+
    | File                | Status  | Error |
    |---------------------+---------+-------|
    | scripts/script1.sql | SUCCESS | None  |
    | scripts/script2.sql | SUCCESS | None  |
    +---------------------------------------+
    
    ```
    
*   Specify a direct file path with the `--silent` option:
    
    ```
    snow stage execute ""@scripts/script1.sql"" --silent
    
    ```
    
    Copy
    
    ```
    +---------------------------------------+
    | File                | Status  | Error |
    |---------------------+---------+-------|
    | scripts/script1.sql | SUCCESS | None  |
    +---------------------------------------+
    
    ```
    

## Remove a file from a stage[¶](#remove-a-file-from-a-stage ""Link to this heading"")

The `snow stage remove` command removes a file from a stage.

```
snow stage remove <stage_name> <file_name>

```

Copy

For example, to remove a file from a stage, enter a command similar to the following:

```
snow stage remove example_app_stage app/pages/my_page.py

```

Copy

```
+-------------------------------------------------+
| key    | value                                  |
|--------+----------------------------------------|
| name   | example_app_stage/app/pages/my_page.py |
| result | removed                                |
+-------------------------------------------------+

```

On this page

1.  [Create a named stage](#create-a-named-stage)
2.  [Copy files to and from a stage](#copy-files-to-and-from-a-stage)
3.  [List the contents of a stage](#list-the-contents-of-a-stage)
4.  [Execute files from a stage](#execute-files-from-a-stage)
5.  [Remove a file from a stage](#remove-a-file-from-a-stage)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/stages/../index)
2.  [snow stage commands](/developer-guide/snowflake-cli/stages/../command-reference/stage-commands/overview)",NULL,a83392c9b940376f07d67a723f54920173ee33d9cd2f5a7acda20416aeb95c6a,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/overview,Managing Git repositories¶,NULL,NULL,NULL,NULL,"# Managing Git repositories[¶](#managing-git-repositories ""Link to this heading"")

You can integrate your remote Git repository with Snowflake so that files from the repository are synchronized to a special kind of stage called a _repository stage_. The repository stage acts as a local Git repository with a full clone of the remote repository, including branches, tags, and commits.

For more information, see [Using a Git repository in Snowflake](../../git/git-overview).

Snowflake CLI supports the following git operations:

*   [Setting up a Git repository](setup-git)
    
*   [Refreshing a repository](refresh-repo)
    
*   [Listing the contents of a repository](list-contents)
    
*   [Copying files in Git](copy-files)
    
*   [Executing files from a repository](execute-sql)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)
2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)",NULL,64010c9454d1180d0fc9ee55c1c15535e63a5caa030dc7c492a0111847375c56,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/services/overview,Managing Snowpark Container Services in Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Managing Snowpark Container Services in Snowflake CLI[¶](#managing-snowpark-container-services-in-sf-cli ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Snowpark Container Services is a fully managed container offering that helps you easily deploy, manage, and scale containerized applications without having to move data out of Snowflake. As a fully managed service, it comes with Snowflake security, configuration, and operational best practices built in.

Snowpark Container Services is fully integrated with Snowflake. For example, your application can easily:

*   Connect to Snowflake and run SQL in a Snowflake virtual warehouse.
    
*   Access data files in a Snowflake stage.
    

Snowpark Container Services is also integrated with third-party tools. It allows you to use third-party clients (such as Docker) to easily upload your application images to Snowflake. Seamless integration makes it easier for teams to focus on building the data applications, not the environment.

This section describes the following topics:

*   [Working with image registries and repositories](manage-images)
    
*   [Managing compute pools](manage-compute-pools)
    
*   [Managing services](manage-services)
    

Related content

1.  [spcs command reference](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/overview)",NULL,440401bed49bdc293ea4f502d2717c19d68c157a7e0e774a34195063cc5a5a46,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/overview,Using Snowpark in Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Using Snowpark in Snowflake CLI[¶](#using-snowpark-in-sf-cli ""Link to this heading"")

The [Snowpark API](../../snowpark/index) provides an intuitive library for querying and processing data at scale in Snowflake, without using SQL. Using a library for any of three languages, you can build applications that process data in Snowflake—without moving data to the system where your application code runs—and process at scale as part of the elastic and serverless Snowflake engine.

Snowflake CLI gives developers convenient tooling for developing and managing their Snowpark functions and procedures. To create and maintain Snowpark functions and procedures, use the following process:

*   [Initialize](initialize) — create a boilerplate
    
    The `snow init <project-name> --template example_snowpark` command creates a boilerplate project that you can customize.
    
*   [Create](create) — create a project definition
    
    You edit the `snowflake.yml` file with the project details.
    
*   [Build](build) — create artifacts
    
    The `snow snowpark build` command builds the Snowpark project as a `.zip` archive that can be used by the `snow snowpark deploy` command. The archive is built using only the `src` directory specified in the `snowflake.yml` file.
    
*   [Deploy](deploy) — create Snowflake objects
    
    The `snow snowpark deploy` command uploads local files to the specified stage and creates procedure and function objects defined in the project.
    
*   [Execute](execute) — use deployed procedures and functions
    
    The `snow snowpark execute` command executes deployed procedures and functions.
    
*   [Upload](upload) — upload already implemented Snowpark functions, procedures, and custom packages, such as from PyPi, in your projects.
    
    The `snow snowpark package` commands let you reuse existing packages.
    
*   [Manage](manage) — manage your Snowpark functions and procedures
    
    The `snow snowpark` and `snow object` commands let you create, list, execute, and delete Snowpark functions and procedures.
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)
3.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",NULL,eb0b39afc756f936f82e4362b2cfeaff154908eaedd9a3f2d5870d0319d44fbb,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/notebooks/use-notebooks,Using Snowflake Notebooks¶,NULL,NULL,NULL,NULL,"# Using Snowflake Notebooks[¶](#using-snowflake-notebooks ""Link to this heading"")

Snowflake CLI includes the following `snow notebook` commands that let you create and execute [Snowflake notebooks](../../../user-guide/ui-snowsight/notebooks) from the command line:

*   [snow notebook create](../command-reference/notebook-commands/create)
    
*   [snow notebook deploy](../command-reference/notebook-commands/deploy)
    
*   [snow notebook execute](../command-reference/notebook-commands/execute)
    
*   [snow notebook get-url](../command-reference/notebook-commands/get-url)
    
*   [snow notebook open](../command-reference/notebook-commands/open)
    
*   [Snowflake notebooks](../../../user-guide/ui-snowsight/notebooks)
    

## Create a notebook[¶](#create-a-notebook ""Link to this heading"")

Note

Beginning with version 3.4.0, Snowflake CLI added the `snow notebook deploy` command to replace the `snow notebook create` command. To support backward compatibility, you can still create a notebook using the `snow notebook create` command, but Snowflake recommends that you begin using the new [Deploy and create a notebook](#label-cli-deploy-notebook) procedure.

The `snow notebook create` command creates a notebook from an existing notebook on stage. The command returns a link to the new notebook. The following example creates the MY\_NOTEBOOK notebook from the specified staged notebook:

```
snow notebook create MY_NOTEBOOK -f @MY_STAGE/path/to/notebook.ipynb

```

Copy

The command creates the notebook in the default warehouse defined for the connection. You can use the `--warehouse` option to specify an alternative warehouse or to specify one if the connection doesn’t define a default warehouse.

## Deploy and create a notebook[¶](#deploy-and-create-a-notebook ""Link to this heading"")

The `snow notebook deploy` command uploads local files to a stage and creates a new Notebook object inside your chosen database and schema. Your project definition file should specify the main notebook file and query warehouse. The `--replace` option replaces the specified Notebook object if it already exists.

Each notebook in Snowflake must include a `snowflake.yml` project definition file.

The following example shows a sample `snowflake.yml` notebook project definition file:

```
definition_version: 2
entities:
  my_notebook:
    type: notebook
    query_warehouse: xsmall
    notebook_file: notebook.ipynb
    runtime_environment_version: ""2025.07""
    artifacts:
    - notebook.ipynb
    - data.csv

```

Copy

The following table describes the properties of a notebook [project definition](../project-definitions/about):

| Property | Definition |
| --- | --- |
| typerequired, string | Must be notebook. |
| query_warehouserequired, string | Snowflake warehouse to host the notebook. |
| notebook_filerequired, string | Path to the notebook file. |
| artifactsrequired, string sequence | List of files uploaded to the stage. Notebook file should be included in this list. |
| stage_pathoptional, string | Path to the stage where the artifacts will be stored. Default: notebooks/<notebook_id>. |
| compute_pooloptional, string | Compute pool for a containerized notebook to use.NoteContainerized notebooks are currently in PuPr. |
| runtime_nameoptional, string | Name of the Container Runtime for a containerized notebook to use. The following values are valid:SYSTEM$BASIC_RUNTIME for CPU runtimeSYSTEM$GPU_RUNTIME for GPU runtimeNoteContainerized notebooks are currently in PuPr. |
| runtime_environment_versionoptional, string | Runtime environment version for a notebook entity in your project definition file.Notebook entity deployments will be rejected if both compute_pool and runtime_environment_version are specified in the configuration, leading to a validation failure.NoteThis field currently applies only to notebooks running on standard Snowflake warehouses, not those using compute pools (containerized notebooks). |
| identifieroptional, string | Optional Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-notebook-id
CopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (e.g., ’”My Notebook”’).Objectidentifier:
  name: my-notebook-id
  schema: my-schema # optional
  database: my-db # optional
CopyNoteAn error occurs if you specify a schema or database and use a fully qualified name in the name property (such as mydb.schema1.my-notebook). |

The following example uploads the files specified in your project definition file and creates a new notebook named `my_notebook`:

```
snow notebook deploy my_notebook

```

Copy

```
Uploading artifacts to @notebooks/my_notebook
  Creating stage notebooks if not exists
  Uploading artifacts
Creating notebook my_notebook
Notebook successfully deployed and available under https://snowflake.com/provider-deduced-from-connection/#/notebooks/DB.SCHEMA.MY_NOTEBOOK

```

## Execute a notebook[¶](#execute-a-notebook ""Link to this heading"")

The snow notebook execute command executes a notebook in headless mode. Currently, the command only returns a message indicating whether the notebook executed successfully.

```
snow notebook execute MY_NOTEBOOK

```

Copy

```
Notebook MY_NOTEBOOK executed.

```

On this page

1.  [Create a notebook](#create-a-notebook)
2.  [Deploy and create a notebook](#deploy-and-create-a-notebook)
3.  [Execute a notebook](#execute-a-notebook)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/notebooks/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/notebooks/../command-reference/overview)
3.  [snow notebook commands](/developer-guide/snowflake-cli/notebooks/../command-reference/notebook-commands/overview)",NULL,f894108eae812b1e9843f4a8906f29563a3496535a184a8ac4963d88ac6ac07e,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/overview,Managing Streamlit apps with Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Managing Streamlit apps with Snowflake CLI[¶](#managing-streamlit-apps-with-sf-cli ""Link to this heading"")

For Streamlit developers who currently use a local IDE development flow and a Git-backed continuous integration and deployment (CI/CD) collaboration workflow, switching to in-browser editing for [Streamlit in Snowflake](../../streamlit/about-streamlit) can be difficult. Snowflake CLI gives developers critical and familiar tooling to integrate SiS into their current development flow.

Using Snowflake CLI, developers can now easily deploy apps from a CLI and perform operations efficiently without requiring any SQL knowledge. Without Snowflake CLI, Streamlit app developers had to deploy locally developed apps to the Snowflake infrastructure by executing SQL commands and copying local files to a stage. Now, these app developers can use whichever method they prefer.

You can perform the following operations when managing Streamlit apps:

*   [Creating a Streamlit app](manage-apps/initialize-app)
    
*   [Deploying a Streamlit app](manage-apps/deploy-app)
    
*   [Retrieving the URL for a Streamlit app](manage-apps/get-url)
    
*   [Share a Streamlit app](manage-apps/share-app)
    
*   [Managing Streamlit apps](manage-apps/manage-app)
    

For more information about Streamlit apps in Native Apps, see [Add a Streamlit app](../../native-apps/adding-streamlit).

Related content

1.  [About Streamlit in Snowflake](/developer-guide/snowflake-cli/streamlit-apps/../../streamlit/about-streamlit)",NULL,2c322c760742b33ca2f897c69aee3892682e4c9c032db5ec1669ec42fa0cdf7a,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/overview,Using Snowflake Native App in Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Using Snowflake Native App in Snowflake CLI[¶](#using-native-app-in-sf-cli ""Link to this heading"")

Snowflake Native App developers can now initiate their own Snowflake Native App code repository from an existing git template, create and deploy their application package and application instance within minutes, and drop these objects once they are done verifying this behavior — all through the Snowflake CLI without requiring any SQL knowledge.

Developers no longer need to keep track of different platforms for performing uploads to stage or creating Snowflake objects, and will have an easier time with their local development of a Snowflake Native App.

Before you can get started with the CLI commands, here are a few new concepts you will find useful:

*   [About Snowflake Native App projects](about-projects)
    
*   [Project definition files](project-definitions)
    
*   [Creating and managing Snowflake Native App objects](create-manage-apps)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [About Snowflake Native App projects](/developer-guide/snowflake-cli/native-apps/about-projects)
3.  [Project definition files](/developer-guide/snowflake-cli/native-apps/project-definitions)
4.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)
5.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)
6.  [Opening an app in a browser](/developer-guide/snowflake-cli/native-apps/open-app)
7.  [Publishing a Snowflake Native App to customers](/developer-guide/snowflake-cli/native-apps/publish-app)
8.  [Dropping Snowflake Native App objects](/developer-guide/snowflake-cli/native-apps/drop-objects)
9.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",NULL,11025c315ea4100f867f6f0635562d8bbec7458f92c09e656793f9423793964c,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/sql/execute-sql,Executing SQL statements¶,NULL,NULL,NULL,NULL,"# Executing SQL statements[¶](#executing-sql-statements ""Link to this heading"")

The [snow sql](../command-reference/sql-commands/sql) command lets you execute ad-hoc SQL queries or files containing SQL queries using the following options:

*   To execute an ad-hoc query, use the `-q` command-line option. For example, to execute a simple SQL SELECT query, as shown in the following example:
    
    ```
    snow sql -q ""SELECT * FROM FOO;""
    
    ```
    
    Copy
    
*   To execute a file containing a SQL query, use the `-f` command-line option to specify the path to the file. For example, to execute a file containing a SQL query, as shown in the following example:
    
    ```
    snow sql -f my_query.sql
    
    ```
    
    Copy
    

The `snow sql` command also can execute multiple statements; in that case, multiple result sets are returned. For example running:

```
snow sql  -q ""select 'a', 'b'; select 'c', 'd';""

```

Copy

results in the following output:

```
select 'a', 'b';
+-----------+
| 'A' | 'B' |
|-----+-----|
| a   | b   |
+-----------+

select 'c', 'd';
+-----------+
| 'C' | 'D' |
|-----+-----|
| c   | d   |
+-----------+

```

You can also execute [scripting blocks](../../snowflake-scripting/running-examples) in Snowflake CLI with a caveat relating to the `$$` delimiter.

For example:

```
EXECUTE IMMEDIATE $$
-- Snowflake Scripting code
DECLARE
  radius_of_circle FLOAT;
  area_of_circle FLOAT;
BEGIN
  radius_of_circle := 3;
  area_of_circle := pi() * radius_of_circle * radius_of_circle;
  RETURN area_of_circle;
END;
$$
;

```

Copy

Some operating systems interpret `$$`, such as a process ID (PID), instead of recognizing it as a scripting block delimiter. To address this limitation, you can use the following alternatives:

> *   If you still want to specify the scripting block on the command line, you can escape the `$$` delimiters, as in `\$\$`.
>     
> *   You can also put the scripting block with the default `$$` delimiters into a separate file and call it with the `snow sql -f <filename>` command.
>     

For more information, see the [snow sql](../command-reference/sql-commands/sql) command.

## Using variables for SQL templates[¶](#using-variables-for-sql-templates ""Link to this heading"")

In certain situations, you might want to change your SQL queries based on the context. The `snow sql` command supports client-side variable substitution that lets you use variables in the command that are resolved locally before submitting the query. Variables in the SQL string take the form `<% variable_name %>`, and the `-D` (or `--variable`) option specifies the value of the variable.

> Note
> 
> You can currently use the SnowSQL `&variable_name` and `<% variable_name %>` syntax for templates. However, Snowflake recommends using the `<% variable_name %>` syntax.

For example, to specify a database using a client-side variable, you can enter a command similar to the following:

```
snow sql -q ""select * from <% database %>.logs"" -D ""database=dev""

```

Copy

When executed, the command substitutes the value `dev` in the `<% database %>` variable to create the `dev.logs` filename and then sends the `select * from dev.logs` SQL query to Snowflake for processing.

You can also specify multiple variable inputs, as shown:

```
snow sql \
-q ""grant usage on database <% database %> to <% role %>"" \
-D ""database=dev"" \
-D ""role=eng_rl""

```

Copy

This example generates the following SQL query:

```
grant usage on database dev to eng_rl

```

Copy

The `--enable-templating` option lets you specify which templating syntaxes are resolved in a SQL query. Snowflake CLI supports the following syntaxes:

*   `STANDARD`: Support the standard Snowflake CLI variable syntax (`<% variable_name %>`). Enabled by default.
    
*   `LEGACY`: Support the SnowSQL variable syntax (`&{ variable_name }` or `&variable_name`). Enabled by default.
    
*   `JINJA`: Support the jinja variable syntax (`{{ variable_name }}`). Disabled by default.
    
*   `ALL`: Allow all supported syntaxes. Disabled by default.
    
*   `NONE`: Do not support templating. Disabled by default.
    

The following examples illustrate different ways to support templating:

*   Disable templating, so that neither of the query variables is resolved:
    
    ```
    snow sql --enable-templating NONE -q ""select '<% not_resolved %> &not_resolved'""
    
    ```
    
    Copy
    
*   Allow JINJA and STANDARD templating, while disallowing LEGACY templating:
    
    ```
    snow sql --enable-templating JINJA --enable-templating STANDARD -q ""select '<% resolved %> {{ resolved }} &not_resolved'""
    
    ```
    
    Copy
    
*   Enable all syntaxes, so the SQL query resolves all three syntaxes:
    
    ```
    snow sql --enable-templating ALL -q ""select '<% resolved %> {{ resolved }}'""
    snow sql --enable-templating ALL -q ""select '&resolved {{ resolved }}'""
    
    ```
    
    Copy
    

Note

JINJA variables, if enabled, are resolved after STANDARD and LEGACY variables.

## Storing variables in the `snowflake.yml` project definition file[¶](#storing-variables-in-the-snowflake-yml-project-definition-file ""Link to this heading"")

Specifying variables as `snow sql` command-line options might not always be practical, or perhaps you might not want to specify sensitive values on the command line. In such cases, you can define variables and values in the `snowflake.yml` project definition file. Then you can just specify the variable names in the form `<% ctx.env.<variable_name> %>` instead of using the `-D ""<variable> = <value>""` option.

Using the example from the previous section, you could store the database and role variables in `snowflake.yml` file and change the query to:

```
snow sql -q ""grant usage on database <% ctx.env.database %> to <% ctx.env.role %>""

```

Copy

In this example, the `snow sql` command looks for the variable definitions in the project definition file and extracts the values without making them visible on the command line. The `snowflake.yml` file should be located either in the current working directory or in the location specified with the `-p` option.

For more information about storing these values in the project definition file, see [Use variables in SQL](../project-definitions/use-sql-variables).

## Executing SQL queries asynchronously[¶](#executing-sql-queries-asynchronously ""Link to this heading"")

Snowflake CLI lets you execute one or more SQL queries asynchronously. Instead of waiting for a result, the `snow sql` command schedules the queries at Snowflake and returns a query ID. After a query finishes, you can get the result using the [!result](#label-snowcli-sql-query-result-cmd) query command or the SQL [RESULT\_SCAN](../../../sql-reference/functions/result_scan) command.

To execute a SQL query asynchronously, end the query with `;>` instead of `;`, as shown:

```
snow sql -q 'select ""My async query"" ;>'

```

Copy

The following example executes a single query asynchronously:

```
snow sql -q ""select 'This is async query';>""

```

Copy

```
select 'This is async query'
+--------------------------------------+
| scheduled query ID                   |
|--------------------------------------|
| 01bc3011-080f-f2d7-0001-c1be14bae7c2 |
+--------------------------------------+

```

You can then use the returned query ID in the [!result](#label-snowcli-sql-query-result-cmd) query command to display the query result:

```
snow sql -q '!result 01bc3011-080f-f2d7-0001-c1be14bae7c2'

```

Copy

```
path-to-private-key-file
+-----------------------+
| 'THIS IS ASYNC QUERY' |
|-----------------------|
| This is async query   |
+-----------------------+

```

You can also execute multiple queries in the query string, both asynchronously and synchronously, as shown:

```
snow sql -q ""select 'This is async query';> select 'Not an async query'; select 'Another async query';>""

```

Copy

```
select 'This is async query'
+--------------------------------------+
| scheduled query ID                   |
|--------------------------------------|
| 01bc3b8c-0109-2e81-0000-0f2d0e5a4a32 |
+--------------------------------------+

select 'Not an async query';
+----------------------+
| 'NOT AN ASYNC QUERY' |
|----------------------|
| Not an async query   |
+----------------------+

select 'Another async query'
+--------------------------------------+
| scheduled query ID                   |
|--------------------------------------|
| 01bc3b8c-0109-2e81-0000-0f2d0e5a4a36 |
+--------------------------------------+

```

## Working with SQL query commands[¶](#working-with-sql-query-commands ""Link to this heading"")

Snowflake CLI provides the following commands that you can use inside your SQL queries:

*   [!source](#label-snowcli-sql-query-source-cmd), which executes SQL in local files or URLs.
    
*   [!queries](#label-snowcli-sql-query-queries-cmd), which lists all SQL queries.
    
*   [!result](#label-snowcli-sql-query-result-cmd), which displays the result of a SQL query.
    
*   [!abort](#label-snowcli-sql-query-abort-cmd), which aborts an active SQL query.
    
*   [!edit](#label-snowcli-sql-query-edit-cmd), which opens an external editor to modify and execute SQL commands.
    

Tip

If you enclose your SQL query in double quotes (`""""`) instead of single quotes (`''`), you might need to escape the exclamation point (`!`) based on which shell you use.

### Execute SQL in local files or URLs[¶](#execute-sql-in-local-files-or-urls ""Link to this heading"")

You can use the `!source` query command in your SQL query to execute SQL in local files or a URL-based file. For example, the following command executes all SQL commands in a local file named `my_sql_code.sql`:

```
snow sql -q '!source my_sql_code.sql'

```

Copy

You can also nest `!source` commands in the SQL files, such as:

```
select emp_id FROM employees;
!source code_file_2.sql

```

Copy

In this example, the command executes the SELECT query and then executes the SQL commands in the `code_file_2.sql` file. Before executing `!source` queries, Snowflake CLI does the following:

*   Evaluates variable substitutions and templates.
    
*   Reads the contents of all nested files to ensure that no recursion occurs.
    

When the variables and templates are resolved and no recursion is detected, the command sends the code to Snowflake for execution.

Note

If you use double quotes (`""""`) instead of single quotes (`''`) around a `!source` query, you might need to escape the `!` (`\!`) depending on which shell you use.

The following examples illustrate different ways you can execute source files.

*   Execute code in a local file.
    
    This example assumes you have a simple query in a local SQL file.
    
    ```
    cat code_to_execute.sql
    
    ```
    
    Copy
    
    ```
    select 73;
    
    ```
    
    To execute the code in the file, enter the following command:
    
    ```
    snow sql -q '!source code_to_execute.sql'
    
    ```
    
    Copy
    
    ```
    select 73;
    +----+
    | 73 |
    |----|
    | 73 |
    +----+
    
    ```
    
*   Execute code in a URL-based file.
    
    This example assumes you have the same simple query in a SQL file at a URL.
    
    To execute the code in the file, enter the following command:
    
    ```
    snow sql -q '!source https://trusted-host/trusted-content.sql'
    
    ```
    
    Copy
    
    ```
    select 73;
    +----+
    | 73 |
    |----|
    | 73 |
    +----+
    
    ```
    
*   Execute code that uses variable substitution and templating.
    
    This example assumes you have a query in a local SQL file that uses a template variable.
    
    ```
    cat code_with_variable.sql
    
    ```
    
    Copy
    
    ```
    select '<% ctx.env.Message %>';
    
    ```
    
    To execute the code in the file, enter the following command that defines the variable value:
    
    ```
    snow sql -q '!source code_&value.sql;' -D value=with_variable --env Message='Welcome !'
    
    ```
    
    Copy
    
    ```
    select 'Welcome !';
    +-------------+
    | 'WELCOME !' |
    |-------------|
    | Welcome !   |
    +-------------+
    
    ```
    

Note

The `!source` command supports the legacy `!load` alias.

### List all SQL queries[¶](#list-all-sql-queries ""Link to this heading"")

The `!queries` query command lists all queries for an account. By default, the command lists the 25 most recent queries executed in the current session.

For example, the following `!queries` query command returns the three most recent queries for a specific user:

> ```
> snow sql -q '!queries user=user1 amount=3'
> 
> ```
> 
> Copy
> 
> ```
> +-------------------------------------------------------------------------------------------------------------------------------------+
> | QUERY ID                             | SQL TEXT                                                           | STATUS    | DURATION_MS |
> |--------------------------------------+--------------------------------------------------------------------+-----------+-------------|
> | 01bc3040-080f-f4f9-0001-c1be14bb603a | select current_version();                                          | SUCCEEDED | 3858        |
> | 01bc303d-080f-f4e9-0001-c1be14bb1812 | SELECT SYSTEM$CANCEL_QUERY('01bc3011-080f-f2d7-0001-c1be14bae7c2') | SUCCEEDED | 564         |
> | 01bc3011-080f-f2d7-0001-c1be14bae7c2 | select 'This is async query'                                       | SUCCEEDED | 931         |
> +-------------------------------------------------------------------------------------------------------------------------------------+
> 
> ```

You can use the following filters to narrow the list of returned queries:

| Filter | Default | Description |
| --- | --- | --- |
| amount (integer) | 25 | Number of recent queries to return (default: 25). |
| session (boolean) | N/A | If provided, return only queries executed in the current session. |
| warehouse (string) | None | Return queries executed only on the specified warehouse. |
| user (string) | None | Return queries executed only by the specified user. |
| duration (milliseconds) | 0 | Return only queries that took at least the specified number of milliseconds. |
| start_date (string) | None | Return only queries executed after the specified date. Date is expected to be provided in ISO format (for example 2025-01-01T09:00:00) |
| end_date (string) | None | Return only queries executed before the specified date. Date is expected to be provided in ISO format (for example 2025-01-01T09:00:00) |
| start (integer) | None | Return only queries executed after the specified Unix timestamp (in milliseconds). |
| end (integer) | None | Return only queries executed before the specified Unix timestamp (in milliseconds). |
| status (enum) | None | Return only queries in one of the following statuses:RUNNINGSUCCEEDEDFAILEDBLOCKEDQUEUEDABORTED |
| type | None | Return only queries of one of the following types:SELECTINSERTUPDATEDELETEMERGEMULTI_TABLE_INSERTCOPYCOMMITROLLBACKBEGIN_TRANSACTIONSHOWGRANTCREATEALTER |

The following examples return queries using different filters:

*   Return the 25 most recent queries executed in the current session:
    
    ```
    snow sql -q 'select 42; select 15; !queries session'
    
    ```
    
    Copy
    
*   Return the 20 most recent queries executed in the account:
    
    ```
    snow sql -q '!queries amount=20'
    
    ```
    
    Copy
    
*   Return the 20 most recent queries executed in the account that took longer than 200 milliseconds to run:
    
    ```
    snow sql -q '!queries amount=20 duration=200'
    
    ```
    
    Copy
    
*   Return the 25 most recent queries executed in the specified warehouse:
    
    ```
    snow sql -q '!queries warehouse=mywh'
    
    ```
    
    Copy
    

### Return a completed SQL query result[¶](#return-a-completed-sql-query-result ""Link to this heading"")

The `!result` query command returns the result of a completed query, given its query ID. You can obtain the query ID in the following ways:

*   Check the [Query History page](../../../user-guide/ui-snowsight-activity) in Snowsight.
    
*   Run the `!queries` SQL query command.
    
*   Use the ID returned by an [asynchronous query](#label-snowcli-sql-async).
    

```
snow sql -q '!result 01bc3011-080f-f2d7-0001-c1be14bae7c2'

```

Copy

```
+-----------------------+
| 'THIS IS ASYNC QUERY' |
|-----------------------|
| This is async query   |
+-----------------------+

```

### Abort an active SQL query[¶](#abort-an-active-sql-query ""Link to this heading"")

The `!abort` query command aborts an active query, given its query ID. You can obtain the query ID in the following ways:

*   Check the [Query History page](../../../user-guide/ui-snowsight-activity) in Snowsight.
    
*   Run the `!queries` SQL query command.
    
*   Use the ID returned by an [asynchronous query](#label-snowcli-sql-async).
    

```
snow sql -q '!abort 01bc3011-080f-f2d7-0001-c1be14bae7c2'

```

Copy

```
+-------------------------------------------------------------+
| SYSTEM$CANCEL_QUERY('01BC3011-080F-F2D7-0001-C1BE14BAE7C2') |
|-------------------------------------------------------------|
| Identified SQL statement is not currently executing.        |
+-------------------------------------------------------------+

```

### Open an external editor to modify and execute SQL commands[¶](#open-an-external-editor-to-modify-and-execute-sql-commands ""Link to this heading"")

The `!edit` query command opens an external editor where you can modify SQL commands to execute when you exit the editor. The editor is specified in the `EDITOR` environment variable or, if the environment variable is not set, the default system editor is used.

To enter commands in an external editor, follow these steps:

1.  If not already defined in your shell, set the `EDITOR` environment variable to your preferred text editor.
    
2.  Enter the `snow sql` command:
    
    ```
    snow sql
    
    ```
    
    Copy
    
3.  At the `>` prompt, enter the `!edit` command:
    
    ```
    > !edit
    
    ```
    
    Copy
    
    The command opens the specified text editor.
    
4.  Enter your SQL commands in the editor, as shown:
    
    ```
    SELECT current_user() ;
    
    ```
    
    Copy
    
5.  Save the file and exit the editor.
    
    The commands you entered are displayed, as shown:
    
    ```
    ✓ Edited SQL loaded into prompt. Modify as needed or press Enter to execute.
    > select current_user();
    
    ```
    
6.  To execute the commands, select `ENTER`.
    
    The command output is displayed, as shown:
    
    ```
    +----------------+
    | CURRENT_USER() |
    |----------------|
    | USER1          |
    +----------------+
    
    ```
    

## Entering multiple commands in a single transaction[¶](#entering-multiple-commands-in-a-single-transaction ""Link to this heading"")

The `--single-transaction` option lets you enter multiple SQL commands to execute as an all-or-nothing set of commands. By executing commands in a single transaction, you can ensure that all of the commands are completed successfully before committing any of the changes. If any of the commands fail, none of the changes from the successful commands persist.

The following examples show successful and unsuccessful transactions:

*   Successful command execution
    
    ```
    snow sql -q ""insert into my_tbl values (123); insert into my_tbl values (124);"" --single-transaction
    
    ```
    
    Copy
    
    ```
    BEGIN;
    +----------------------------------+
    | status                           |
    |----------------------------------|
    | Statement executed successfully. |
    +----------------------------------+
    
    insert into my_tbl values (123);
    +-------------------------+
    | number of rows inserted |
    |-------------------------|
    | 1                       |
    +-------------------------+
    
    insert into my_tbl values (124);
    +-------------------------+
    | number of rows inserted |
    |-------------------------|
    | 1                       |
    +-------------------------+
    
    COMMIT
    +----------------------------------+
    | status                           |
    |----------------------------------|
    | Statement executed successfully. |
    +----------------------------------+
    
    ```
    
    You can then verify that the commands were committed to the database:
    
    ```
    snow sql -q ""select count(*) from my_tbl""
    
    ```
    
    Copy
    
    ```
    select count(*) from my_tbl
    +----------+
    | COUNT(*) |
    |----------|
    | 2        |
    +----------+
    
    ```
    
*   Unsuccessful single transaction
    
    ```
    snow sql -c patcli -q ""insert into my_tbl values (123); insert into my_tbl values (124); select BAD;"" --single-transaction
    
    ```
    
    Copy
    
    ```
    BEGIN;
    +----------------------------------+
    | status                           |
    |----------------------------------|
    | Statement executed successfully. |
    +----------------------------------+
    
    insert into my_tbl values (123);
    +-------------------------+
    | number of rows inserted |
    |-------------------------|
    | 1                       |
    +-------------------------+
    
    insert into my_tbl values (124);
    +-------------------------+
    | number of rows inserted |
    |-------------------------|
    | 1                       |
    +-------------------------+
    
    select BAD;
    ╭─ Error ───────────────────────────────────────────────────────────────────────────────╮
    │ 000904 (42000): 01bc3b84-0810-0247-0001-c1be14ee11ce: SQL compilation error: error    │
    │ line 1 at position 7                                                                  │
    │ invalid identifier 'BAD'                                                              │
    ╰───────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    

> You can then verify that the commands were not committed to the database:
> 
> > ```
> > snow sql -q ""select count(*) from my_tbl""
> > 
> > ```
> > 
> > Copy
> > 
> > ```
> > select count(*) from my_tbl
> > +----------+
> > | COUNT(*) |
> > |----------|
> > | 0        |
> > +----------+
> > 
> > ```

## Entering SQL commands in interactive mode[¶](#entering-sql-commands-in-interactive-mode ""Link to this heading"")

The `snow sql` command supports an interactive mode that lets you enter SQL commands one at a time. Interactive mode provides the following features:

*   Syntax highlighting
    
    ![Interactive mode syntax highlighting](../../../_images/interactive-sql-syntax-highlight.png)
    
*   Code completion while typing
    
    ![Interactive mode code completion](../../../_images/interactive-sql-code-completion.png)
    
*   Searchable history
    
    Pressing CTRL\-R: lets you search your command history:
    
    ![Interactive mode searchable history](../../../_images/interactive-sql-history.png)
    
*   Multi-line input
    
    Pressing ENTER on a line that does not end with a semicolon (`;`) moves the cursor to the next line for more commands until a statement ends with a semicolon.
    
    ![Interactive mode multi-line input](../../../_images/interactive-sql-multiline.png)
    

To use interactive mode, enter the `snow sql` command followed by ENTER, as shown:

```
snow sql

```

Copy

The command opens a sub-shell with a `>` prompt where you can enter SQL commands interactively:

```
$ snow sql
  ╭───────────────────────────────────────────────────────────────────────────────────╮
  │ Welcome to Snowflake-CLI REPL                                                     │
  │ Type 'exit' or 'quit' to leave                                                    │
  ╰───────────────────────────────────────────────────────────────────────────────────╯
  >

```

You can then enter SQL commands, as shown:

```
> create table my_table (c1 int);

```

Copy

```
+-------------------------------------+
| status                              |
|-------------------------------------|
| Table MY_TABLE successfully created.|
+-------------------------------------+

```

Note

You must end each SQL statement with a semicolon (`;`).

To exit interactive mode, enter `exit`, `quit`, or CTRL\-D.

On this page

1.  [Using variables for SQL templates](#using-variables-for-sql-templates)
2.  [Storing variables in the snowflake.yml project definition file](#storing-variables-in-the-snowflake-yml-project-definition-file)
3.  [Executing SQL queries asynchronously](#executing-sql-queries-asynchronously)
4.  [Working with SQL query commands](#working-with-sql-query-commands)
5.  [Execute SQL in local files or URLs](#execute-sql-in-local-files-or-urls)
6.  [List all SQL queries](#list-all-sql-queries)
7.  [Return a completed SQL query result](#return-a-completed-sql-query-result)
8.  [Abort an active SQL query](#abort-an-active-sql-query)
9.  [Open an external editor to modify and execute SQL commands](#open-an-external-editor-to-modify-and-execute-sql-commands)
10.  [Entering multiple commands in a single transaction](#entering-multiple-commands-in-a-single-transaction)
11.  [Entering SQL commands in interactive mode](#entering-sql-commands-in-interactive-mode)

Related content

1.  [snow sql](/developer-guide/snowflake-cli/sql/../command-reference/sql-commands/sql)
2.  [SQL reference](/developer-guide/snowflake-cli/sql/../../../reference)",NULL,6e6ff835bdadff3500bca7475bcb18feb24970a4c89c70f259120de9b015ea7f,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/data-pipelines/data-pipelines,Managing data pipelines in Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Managing data pipelines in Snowflake CLI[¶](#managing-data-pipelines-in-sf-cli ""Link to this heading"")

*   [Managing dbt Projects on Snowflake using Snowflake CLI](dbt-projects)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/data-pipelines/../index)",NULL,c295cb24f1888363de169da239fc2cb6711e0a2c4623953f57bbf72e7a7a0ec8,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/cicd/integrate-ci-cd,Integrating CI/CD with Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Integrating CI/CD with Snowflake CLI[¶](#integrating-ci-cd-with-sf-cli ""Link to this heading"")

Snowflake CLI integrates popular CI/CD (continuous integration and continuous delivery) systems and frameworks, such as [GitHub Actions](https://github.com/features/actions), to efficiently automate your Snowflake workflows for SQL, Snowpark, Native Apps, or Notebooks.

The following illustration shows a typical CI/CD workflow in Snowflake CLI.

![Snowflake CI/CD workflow](../../../_images/cli-cicd-devops-flow.png)

## CI/CD workflow steps[¶](#ci-cd-workflow-steps ""Link to this heading"")

1.  **Store:** Configure a remote Git repository to manage your Snowflake files securely.
    
2.  **Code:** Develop your Snowflake code using an IDE or Snowsight, tailored to your preferences.
    
3.  **Install:** [Install](../installation/installation) Snowflake CLI, and provision your preferred CI/CD provider, such as GitHub Actions.
    
4.  **Deploy:** Automate deployment by combining the Snowflake CLI with your selected CI/CD tool.
    
5.  **Monitor:** Track code and workflow performance in Snowflake using [Snowflake Trail](https://www.snowflake.com/en/product/features/snowflake-trail/) for real-time insights.
    
6.  **Iterate:** Apply small, frequent updates to your project for continuous improvement; smaller changes simplify management and rollback, if necessary.
    

## CI/CD with GitHub Actions[¶](#ci-cd-with-github-actions ""Link to this heading"")

A Snowflake CLI action is a GitHub action designed to integrate Snowflake CLI into CI/CD pipelines. You can use it to automate execution of Snowflake CLI commands within your GitHub workflows. For more information, see the [snowflake-cli-action](https://github.com/snowflakedb/snowflake-cli-action) repository.

## Using Snowflake CLI actions[¶](#using-sf-cli-actions ""Link to this heading"")

Github Actions streamlines the process of installing and using Snowflake CLI in your CI/CD workflows. The CLI is installed in an isolated way, ensuring that it won’t conflict with the dependencies of your project. It automatically sets up the input configuration file within the `~/.snowflake/` directory.

The action enables automation of your Snowflake CLI tasks, such as deploying Snowflake Native Apps or running Snowpark scripts within your Snowflake environment.

### Input parameters[¶](#input-parameters ""Link to this heading"")

A Snowflake CLI action uses the following inputs from your Github workflow YAML file, such as `<repo-name>/.github/workflows/my-workflow.yaml`:

*   `cli-version`: The specified Snowflake CLI version, such as `3.11.0`. If not provided, the latest version of the Snowflake CLI is used.
    
*   `custom-github-ref`: The branch, tag, or commit in the Github repository that you want to install Snowflake CLI directly from.
    
    Note
    
    You cannot use both `cli-version` and `custom-github-ref` together; specify only one of these parameters.
    
*   `default-config-file-path`: Path to the configuration file (`config.toml`) in your repository. The path must be relative to the root of the repository. The configuration file is not required when a temporary connection (`-x` option) is used. For more information, see [Managing Snowflake connections](../connecting/configure-connections).
    
*   `use-oidc`: Boolean flag to enable OIDC authentication. When set to `true`, the action configures the CLI to use GitHub’s OIDC token for authentication with Snowflake, eliminating the need for storing private keys as secrets. Default is `false`.
    

### Install Snowflake CLI from a GitHub branch or tag[¶](#install-sf-cli-from-a-github-branch-or-tag ""Link to this heading"")

*   To install Snowflake CLI from a specific branch, tag, or commit in the GitHub repository (for example, to test unreleased features or a fork), use the following configuration:
    

```
- uses: snowflakedb/snowflake-cli-action@v2.0
  with:
    custom-github-ref: ""feature/my-branch"" # or a tag/commit hash

```

Copy

You can also include other [input parameters](#label-cli-cicd-inputs).

This feature is available in snowflake-cli-action version 1.6 or later.

### Safely configure the action in your CI/CD workflow[¶](#safely-configure-the-action-in-your-ci-cd-workflow ""Link to this heading"")

You can safely configure the action in your CI/CD workflow by using either of the following methods:

*   [Use workload identity federation (WIF) OpenID Connect (OIDC) authentication](#label-cli-github-actions-oidc-auth)
    
*   [Use private key authentication](#label-cli-github-actions-private-key-auth)
    

#### Use workload identity federation (WIF) OpenID Connect (OIDC) authentication[¶](#use-workload-identity-federation-wif-openid-connect-oidc-authentication ""Link to this heading"")

Note

WIF OIDC authentication requires Snowflake CLI version 3.11.0 or later.

WIF OIDC authentication provides a secure and modern way to authenticate with Snowflake without storing private keys as secrets. This approach uses GitHub’s OIDC (OpenID Connect) token to authenticate with Snowflake.

To set up WIF OIDC authentication, follow these steps:

1.  Configure WIF OIDC by setting up a service user with the OIDC workload identity type:
    
    ```
    CREATE USER <username>
    TYPE = SERVICE
    WORKLOAD_IDENTITY = (
      TYPE = OIDC
      ISSUER = 'https://token.actions.githubusercontent.com'
      SUBJECT = '<your_subject>'
    )
    
    ```
    
    Copy
    

Note

> By default, your subject should look like `repo:<repository-owner/repository-name>:environment:<environment>`.

*   To simplify generation of the subject, use `gh` command, where `<environment_name>` is the environment defined in your repository settings, as shown in the following example:
    

> ```
> gh repo view <repository-owner/repository-name> --json nameWithOwner | jq -r '""repo:\(.nameWithOwner):environment:<environment_name>""'
> 
> ```
> 
> Copy
> 
> For more information about customizing your subject, see the [OpenID Connect](https://docs.github.com/en/actions/reference/security/oidc) reference on GitHub.

1.  Store your Snowflake account identifier in GitHub secrets. For more information, see [GitHub Actions documentation](https://docs.github.com/en/actions/security-guides/using-secrets-in-github-actions#creating-secrets-for-a-repository).
    
2.  Configure the Snowflake CLI action in your GitHub workflow YAML file, as shown:
    
    ```
    name: Snowflake OIDC
    on: [push]
    
    permissions:
      id-token: write  # Required for OIDC token generation
      contents: read
    
    jobs:
      oidc-job:
        runs-on: ubuntu-latest
        environment: test-env # this should match the environment used in the subject
        steps:
          - uses: actions/checkout@v4
            with:
              persist-credentials: false
          - name: Set up Snowflake CLI
            uses: snowflakedb/snowflake-cli-action@v2.0
            with:
              use-oidc: true
              cli-version: ""3.11""
          - name: test connection
            env:
              SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
            run: snow connection test -x
    
    ```
    
    Copy
    
    For more information about setting up WIF OIDC authentication for your Snowflake account and configuring the GitHub OIDC provider, see [Workload identity federation](../../../user-guide/workload-identity-federation).
    

#### Use private key authentication[¶](#use-private-key-authentication ""Link to this heading"")

To use private key authentication, you need to store your Snowflake private key in GitHub secrets and configure the Snowflake CLI action to use it.

1.  Store your Snowflake private key in GitHub secrets.
    

For more information, see [GitHub Actions documentation](https://docs.github.com/en/actions/security-guides/using-secrets-in-github-actions#creating-secrets-for-a-repository).

2.  Configure the Snowflake CLI action in your GitHub workflow YAML file, as shown:
    
    ```
    name: Snowflake Private Key
    on: [push]
    
    jobs:
      private-key-job:
        runs-on: ubuntu-latest
        steps:
          - uses: actions/checkout@v4
            with:
              persist-credentials: false
          - name: Set up Snowflake CLI
            uses: snowflakedb/snowflake-cli-action@v2.0
    
    ```
    
    Copy
    

## Defining connections[¶](#defining-connections ""Link to this heading"")

You can define a GitHub action to connect to Snowflake with a temporary connection or with a connection defined in your configuration file. For more information about managing connections, see [Managing Snowflake connections](../connecting/configure-connections).

### Use a temporary connection[¶](#use-a-temporary-connection ""Link to this heading"")

For more information about temporary connections, see [Use a temporary connection](../connecting/configure-connections.html#label-snowcli-temporary-connection).

To set up your Snowflake credentials for a temporary connection, follow these steps:

1.  Map secrets to environment variables in your GitHub workflow, in the form `SNOWFLAKE_<key>=<value>`, as shown:
    
    ```
    env:
      SNOWFLAKE_PRIVATE_KEY_RAW: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
    
    ```
    
    Copy
    
2.  Configure the Snowflake CLI action.
    
    If you use the latest version of Snowflake CLI, you do not need to include the `cli-version` parameter. The following example instructs the action to use Snowflake CLI version 3.11.0 specifically:
    
    ```
    - uses: snowflakedb/snowflake-cli-action@v2.0
      with:
        cli-version: ""3.11.0""
    
    ```
    
    Copy
    
3.  Optional: If your private key is encrypted, to set up a passphrase, set the PRIVATE\_KEY\_PASSPHRASE environment variable to the private key passphrase. Snowflake uses this passphrase to decrypt the private key. For example:
    
    ```
    - name: Execute Snowflake CLI command
      env:
        PRIVATE_KEY_PASSPHRASE: ${{ secrets.PASSPHARSE }}
    
    ```
    
    Copy
    
    To use a password instead of a private key, unset the `SNOWFLAKE_AUTHENTICATOR` environment variable, and add the `SNOWFLAKE_PASSWORD` variable, as follows:
    
    ```
    - name: Execute Snowflake CLI command
      env:
        SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
        SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
    
    ```
    
    Copy
    
    Note
    
    To enhance your experience when using a password and MFA, Snowflake recommends that you [configure MFA caching](../connecting/configure-connections.html#label-snowcli-mfa-caching).
    
    For more information about setting Snowflake credentials in environment variables, see [Use environment variables for Snowflake credentials](../connecting/configure-connections.html#label-snowcli-environment-creds), and for information about defining environment variables within your GitHub CI/CD workflow, see [Defining environment variables for a single workflow](https://docs.github.com/en/actions/learn-github-actions/variables#defining-environment-variables-for-a-single-workflow).
    
4.  Add the `snow` commands you want to execute with the temporary connection, as shown:
    
    ```
    run: |
      snow --version
      snow connection test --temporary-connection
    
    ```
    
    Copy
    

The following example shows a completed sample `<repo-name>/.github/workflows/my-workflow.yaml` file:

```
name: deploy
on: [push]

jobs:
  version:
    name: ""Check Snowflake CLI version""
    runs-on: ubuntu-latest
    steps:
      # Snowflake CLI installation
      - uses: snowflakedb/snowflake-cli-action@v2.0

        # Use the CLI
      - name: Execute Snowflake CLI command
        env:
          SNOWFLAKE_AUTHENTICATOR: SNOWFLAKE_JWT
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_PRIVATE_KEY_RAW: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
          PRIVATE_KEY_PASSPHRASE: ${{ secrets.PASSPHARSE }} # Passphrase is only necessary if private key is encrypted.
        run: |
          snow --help
          snow connection test -x

```

Copy

After verifying that your action can connect to Snowflake successfully, you can add more Snowflake CLI commands like `snow notebook create` or `snow git execute`. For information about supported commands, see [Snowflake CLI command reference](../command-reference/overview).

### Use a configuration file[¶](#use-a-configuration-file ""Link to this heading"")

For more information about defining connections, see [Define connections](../connecting/configure-connections.html#label-snowcli-define-connections).

To set up your Snowflake credentials for a specific connection, follow these steps:

1.  Create a `config.toml` file at the root of your Git repository with an empty configuration connection, as shown:
    
    ```
    default_connection_name = ""myconnection""
    
    [connections.myconnection]
    
    ```
    
    Copy
    
    This file serves as a template and should not contain actual credentials.
    
2.  Map secrets to environment variables in your GitHub workflow, in the form `SNOWFLAKE_<key>=<value>`, as shown:
    
    ```
    env:
      SNOWFLAKE_CONNECTIONS_MYCONNECTION_PRIVATE_KEY_RAW: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
      SNOWFLAKE_CONNECTIONS_MYCONNECTION_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
    
    ```
    
    Copy
    
3.  Configure the Snowflake CLI action.
    
    If you use the latest version of Snowflake CLI, you do not need to include the `cli-version` parameter. The following example specifies a desired version and the name of your default configuration file:
    
    ```
    - uses: snowflakedb/snowflake-cli-action@v2.0
      with:
        cli-version: ""3.11.0""
        default-config-file-path: ""config.toml""
    
    ```
    
    Copy
    
4.  Optional: If your private key is encrypted, to set up a passphrase, set the PRIVATE\_KEY\_PASSPHRASE environment variable to the private key passphrase. Snowflake uses this passphrase to decrypt the private key. For example:
    
    ```
    - name: Execute Snowflake CLI command
      env:
        PRIVATE_KEY_PASSPHRASE: ${{ secrets.PASSPHARSE }}
    
    ```
    
    Copy
    
    To use a password instead of a private key, unset the `SNOWFLAKE_AUTHENTICATOR` environment variable, and add the `SNOWFLAKE_PASSWORD` variable, as follows:
    
    ```
    - name: Execute Snowflake CLI command
      env:
        SNOWFLAKE_CONNECTIONS_MYCONNECTION_USER: ${{ secrets.SNOWFLAKE_USER }}
        SNOWFLAKE_CONNECTIONS_MYCONNECTION_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
        SNOWFLAKE_CONNECTIONS_MYCONNECTION_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
    
    ```
    
    Copy
    
    Note
    
    To enhance your experience when using a password and MFA, Snowflake recommends that you [configure MFA caching](../connecting/configure-connections.html#label-snowcli-mfa-caching).
    
5.  Add the `snow` commands you want to execute with a named connection, as shown:
    
    ```
    run: |
      snow --version
      snow connection test
    
    ```
    
    Copy
    

The following example shows a sample `config.toml` file in your Git repository and a completed sample `<repo-name>/.github/workflows/my-workflow.yaml` file:

*   Sample `config.toml` file:
    
    ```
    default_connection_name = ""myconnection""
    
    [connections.myconnection]
    
    ```
    
    Copy
    
*   Sample Git workflow file:
    
    ```
    name: deploy
    on: [push]
    jobs:
      version:
        name: ""Check Snowflake CLI version""
        runs-on: ubuntu-latest
        steps:
          # Checkout step is necessary if you want to use a config file from your repo
          - name: Checkout repo
            uses: actions/checkout@v4
            with:
              persist-credentials: false
    
            # Snowflake CLI installation
          - uses: snowflakedb/snowflake-cli-action@v2.0
            with:
              default-config-file-path: ""config.toml""
    
            # Use the CLI
          - name: Execute Snowflake CLI command
            env:
              SNOWFLAKE_CONNECTIONS_MYCONNECTION_AUTHENTICATOR: SNOWFLAKE_JWT
              SNOWFLAKE_CONNECTIONS_MYCONNECTION_USER: ${{ secrets.SNOWFLAKE_USER }}
              SNOWFLAKE_CONNECTIONS_MYCONNECTION_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
              SNOWFLAKE_CONNECTIONS_MYCONNECTION_PRIVATE_KEY_RAW: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
              PRIVATE_KEY_PASSPHRASE: ${{ secrets.PASSPHARSE }} #Passphrase is only necessary if private key is encrypted.
            run: |
              snow --help
              snow connection test
    
    ```
    
    Copy
    

After verifying that your action can connect to Snowflake successfully, you can add more Snowflake CLI commands like `snow notebook create` or `snow git execute`. For information about supported commands, see [Snowflake CLI command reference](../command-reference/overview).

On this page

1.  [CI/CD workflow steps](#ci-cd-workflow-steps)
2.  [CI/CD with GitHub Actions](#ci-cd-with-github-actions)
3.  [Using Snowflake CLI actions](#using-sf-cli-actions)
4.  [Defining connections](#defining-connections)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/cicd/../index)",NULL,fc928df2bf4d42adfc491ee6547df3ceabc58e16f64207466a2fb0331719f307,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/overview,Snowflake CLI command reference¶,NULL,NULL,NULL,NULL,"# Snowflake CLI command reference[¶](#sf-cli-command-reference ""Link to this heading"")

Snowflake CLI supports commands for the following objects and activities:

*   [snow](snow) command
    
*   Bootstrap commands
    
    *   [snow bootstrap commands](bootstrap-commands/overview)
        
*   Connection commands
    
    *   [snow connection commands](connection-commands/overview)
        
*   Cortex commands
    
    *   [snow cortex commands](cortex-commands/overview)
        
*   Git commands
    
    *   [snow git commands](git-commands/overview)
        
*   Helpers commands
    
    *   [snow helpers commands](helpers-commands/overview)
        
*   Logs commands
    
    *   [snow logs commands](logs-commands/overview)
        
*   Notebook commands
    
    *   [snow notebook commands](notebook-commands/overview)
        
*   Snowflake Native App Framework commands
    
    *   [snow app commands](native-apps-commands/overview)
        
*   Snowflake objects commands
    
    *   [snow object commands](object-commands/overview)
        
*   Snowpark commands
    
    *   [snow snowpark commands](snowpark-commands/overview)
        
    *   [snow snowpark package commands](snowpark-commands/package-commands/overview)
        
*   Snowpark Container Services (spcs) commands
    
    *   [snow spcs image-registry commands](spcs-commands/image-registry-commands/overview)
        
    *   [snow spcs image-repository commands](spcs-commands/image-repository-commands/overview)
        
    *   [snow spcs compute-pool commands](spcs-commands/compute-pool-commands/overview)
        
    *   [snow spcs service commands](spcs-commands/service-commands/overview)
        
*   SQL commands
    
    *   [snow sql commands](sql-commands/overview)
        
*   Stage commands
    
    *   [snow stage commands](stage-commands/overview)
        
*   Streamlit commands
    
    *   [snow streamlit commands](streamlit-commands/overview)
        

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/../index)",NULL,60239ba000514eb9f03101a8dcba70326cafadd4462402457221e9cb5175af5a,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/connecting/configure-connections,Managing Snowflake connections¶,NULL,NULL,NULL,NULL,"# Managing Snowflake connections[¶](#managing-snowflake-connections ""Link to this heading"")

Before you can use Snowflake CLI, you must define connections, which specify how Snowflake CLI connects to Snowflake. Snowflake CLI uses the following precedence hierarchy to determine which value to use when a connection parameter is defined in multiple locations:

*   Command-line parameters
    
*   Environment variables overriding specific `config.toml` parameters, such as `SNOWFLAKE_CONNECTIONS_MYCONNECTION_PASSWORD`
    
*   Connections defined in `config.toml` file manually or using `snow connection add` command
    
*   Generic environment variables, such as `SNOWFLAKE_USER`.
    

You can also use the `--temporary-connection` option, which does not require defining it in `config.toml`.

Caution

For improved security, Snowflake strongly recommends using either `SNOWFLAKE_CONNECTIONS_<NAME>_PASSWORD` or `SNOWFLAKE_PASSWORD` environment variable.

## Define connections[¶](#define-connections ""Link to this heading"")

Connection definitions are stored in the `[connections]` section of the `config.toml` file, similar to the following block of code:

```
[connections.myconnection]
account = ""myaccount""
user = ""jondoe""
password = ""password""
warehouse = ""my-wh""
database = ""my_db""
schema = ""my_schema""

```

Copy

Connection definitions support the same configuration options as the [Snowflake Connector for Python](../../python-connector/python-connector-api.html#label-snowflake-connector-methods-connect). Additionally, you can specify a default connection in the `default_connection_name` variable at the top of the file. You cannot include it within a connection definition. For example:

```
default_connection_name = ""myconnection""

[connections.myconnection]
account = ""myaccount""
...

```

Copy

Note

For MacOS and Linux systems, Snowflake CLI requires the `config.toml` file to limit its file permissions to read and write for the file owner only. To set the file required file permissions execute the following commands:

```
chown $USER config.toml
chmod 0600 config.toml

```

Copy

### Alternative configuration file[¶](#alternative-configuration-file ""Link to this heading"")

Note

For Snowflake CLI, Snowflake recommends that you use the `config.toml` file for configuration definitions. However, you can use the `connections.toml` file, if desired.

Snowflake CLI also supports the `connections.toml` configuration file. The file should be placed in the same directory as the `config.toml` file, and it should contain only connections. Configurations in `connections.toml` require a different section name, without `connections`. For example, `[connections.myconnection]` would be just `[myconnection]`.

Note

If both the `config.toml` and `connections.toml` configurations contain connections, Snowflake CLI uses only configurations from `connections.toml`.

## Manage or add your connections to Snowflake with the `snow connection` commands[¶](#manage-or-add-your-connections-to-snowflake-with-the-snow-connection-commands ""Link to this heading"")

The `snow connection` commands let you create, manage, and test Snowflake connections.

### Add a connection[¶](#add-a-connection ""Link to this heading"")

Note

If you need to add a connection for Snowflake Open Catalog, see [Create a Snowflake CLI connection for Open Catalog](https://other-docs.snowflake.com/opencatalog/sso-configure-open-catalog#create-a-snowflake-cli-connection-for-open-catalog) in the Open Catalog documentation. You might need to add this connection for tasks like configuring Open Catalog to use SSO.

To create a new connection and add it to the [configuration file](configure-cli.html#label-cli-config-locations), do the following:

1.  Execute the `snow connection add` command:
    
    > ```
    > snow connection add
    > 
    > ```
    > 
    > Copy
    
2.  When prompted, supply the required connection, account, and username parameters, as well as any other desired optional parameters.
    
    > ```
    > Enter connection name: <connection_name>
    > Enter account: <account>
    > Enter user: <user-name>
    > Enter password: <password>
    > Enter role: <role-name>
    > Enter warehouse: <warehouse-name>
    > Enter database: <database-name>
    > Enter schema: <schema-name>
    > Enter host: <host-name>
    > Enter port: <port-number>
    > Enter region: <region-name>
    > Enter authenticator: <authentication-method>
    > Enter private key file: <path-to-private-key-file>
    > Enter token file path: <path-to-mfa-token>
    > Do you want to configure key pair authentication? [y/N]: y
    > Key length [2048]: <key-length>
    > Output path [~/.ssh]: <path-to-output-file>
    > Private key passphrase: <key-description>
    > Wrote new connection <connection-name> to config.toml
    > 
    > ```
    

You can also add values for specific parameters on the command line, as shown:

```
snow --config-file config.toml connection add -n myconnection2 --account myaccount2 --user jdoe2

```

Copy

Note

If the command finishes with an error, such as if the `--private_key_file` option references a non-existing file, the connection is not saved in the `config.toml` configuration file.

By default, the `snow connection add` command prompts for optional parameters if they are not specified on the command line. If you want to add connections without specifying some optional parameter, like `account`, and skip the interactive prompts, you can use the `--no-interactive` option, as shown:

```
snow connection add -n myconnection2 --user jdoe2 --no-interactive

```

Copy

After adding a connection, you can [test the connection](#label-cli-test-connection) to make sure it works correctly.

### List defined connections[¶](#list-defined-connections ""Link to this heading"")

To list the available connections, enter the `snow connection list` command, as shown:

```
snow connection list

```

Copy

```
+-------------------------------------------------------------------------------------------------+
| connection_name | parameters                                                       | is_default |
|-----------------+------------------------------------------------------------------+------------|
| myconnection    | {'account': 'myaccount', 'user': 'jondoe', 'password': '****',   | False      |
|                 | 'database': 'my_db', 'schema': 'my_schema', 'warehouse':         |            |
|                 | 'my-wh'}                                                         |            |
| myconnection2   | {'account': 'myaccount2', 'user': 'jdoe2'}                       | False      |
+-------------------------------------------------------------------------------------------------+

```

### Test and diagnose a connection[¶](#test-and-diagnose-a-connection ""Link to this heading"")

To test whether a connection can successfully connect to Snowflake, enter the `snow connection test` command, similar to the following:

```
snow connection test -c myconnection2

```

Copy

```
+--------------------------------------------------+
| key             | value                          |
|-----------------+--------------------------------|
| Connection name | myconnection2                  |
| Status          | OK                             |
| Host            | example.snowflakecomputing.com |
| Account         | myaccount2                     |
| User            | jdoe2                          |
| Role            | ACCOUNTADMIN                   |
| Database        | not set                        |
| Warehouse       | not set                        |
+--------------------------------------------------+

```

If you encounter connectivity issues, you can run diagnostics directly within Snowflake CLI. Snowflake Support might also request this information to help you with connectivity issues.

The diagnostics collection uses the following `snow connection test` command options:

*   `--enable-diag` to generate a diagnostic report.
    
*   `--diag-log-path` to specify the absolute path for the generated report.
    
*   `--diag-allowlist-path` to specify the absolute path to a JSON file containing the output of the SYSTEM$ALLOWLIST() or SYSTEM$ALLOWLIST\_PRIVATELINK() SQL commands. This option is required only if the user defined in the connection does not have permission to run the system allowlist functions or if connecting to the account URL fails.
    

The following example generates a diagnostic report for the `myconnection2` connection and stores in the `~/report/SnowflakeConnectionTestReport.txt` file:

```
snow connection test -c myconnection2 --enable-diag --diag-log-path $(HOME)/report

```

Copy

```
+----------------------------------------------------------------------------+
| key                  | value                                               |
|----------------------+-----------------------------------------------------|
| Connection name      | myconnection2                                       |
| Status               | OK                                                  |
| Host                 | example.snowflakecomputing.com                      |
| Account              | myaccount2                                          |
| User                 | jdoe2                                               |
| Role                 | ACCOUNTADMIN                                        |
| Database             | not set                                             |
| Warehouse            | not set                                             |
| Diag Report Location | /Users/<username>/SnowflakeConnectionTestReport.txt |
+----------------------------------------------------------------------------+

```

You can review the report for any connectivity issues and discuss them with your network team. You can also provide the report to Snowflake Support for additional assistance.

### Remove a connection[¶](#remove-a-connection ""Link to this heading"")

You can use the `snow connection remove` command to delete a specific connection, similar to the following:

```
snow connection remove bad_connection

```

Copy

```
Removed connection bad_connection from /Users/jdoe/.snowflake/config.toml.

```

### Set the default connection[¶](#set-the-default-connection ""Link to this heading"")

You can use the `snow connection set-default` command to specify which configuration Snowflake CLI should use as the default, overriding the `default_connection_name` configuration file and `SNOWFLAKE_DEFAULT_CONNECTION_NAME` variables, if set.

The following example sets the default connection to `myconnection2`:

```
snow connection set-default myconnection2

```

Copy

```
Default connection set to: myconnection2

```

Note

If both `connections.toml` and `config.toml` files are present, Snowflake CLI uses only connections defined in `connections.toml`.

### Use environment variables for Snowflake credentials[¶](#use-environment-variables-for-snowflake-credentials ""Link to this heading"")

You can specify Snowflake credentials in system environment variables instead of in configuration files. You can use the following generic environment variables only to specify connection parameters:

*   `SNOWFLAKE_ACCOUNT`
    
*   `SNOWFLAKE_USER`
    
*   `SNOWFLAKE_PASSWORD`
    
*   `SNOWFLAKE_DATABASE`
    
*   `SNOWFLAKE_SCHEMA`
    
*   `SNOWFLAKE_ROLE`
    
*   `SNOWFLAKE_WAREHOUSE`
    
*   `SNOWFLAKE_AUTHENTICATOR`
    
*   `SNOWFLAKE_PRIVATE_KEY_PATH`
    
*   `SNOWFLAKE_PRIVATE_KEY_RAW`
    
*   `SNOWFLAKE_SESSION_TOKEN`
    
*   `SNOWFLAKE_MASTER_TOKEN`
    
*   `SNOWFLAKE_TOKEN`
    
*   `SNOWFLAKE_TOKEN_FILE_PATH`
    
*   `SNOWFLAKE_OAUTH_CLIENT_ID`
    
*   `SNOWFLAKE_OAUTH_CLIENT_SECRET`
    
*   `SNOWFLAKE_OAUTH_AUTHORIZATION_URL`
    
*   `SNOWFLAKE_OAUTH_TOKEN_REQUEST_URL`
    
*   `SNOWFLAKE_OAUTH_REDIRECT_URI`
    
*   `SNOWFLAKE_OAUTH_SCOPE`
    
*   `SNOWFLAKE_OAUTH_DISABLE_PKCE`
    
*   `SNOWFLAKE_OAUTH_ENABLE_REFRESH_TOKENS`
    
*   `SNOWFLAKE_OAUTH_ENABLE_SINGLE_USE_REFRESH_TOKENS`
    
*   `SNOWFLAKE_CLIENT_STORE_TEMPORARY_CREDENTIAL`
    
*   `SNOWFLAKE_WORKLOAD_IDENTITY_PROVIDER`
    

### Pass connection parameters to the `snow` command[¶](#pass-connection-parameters-to-the-snow-command ""Link to this heading"")

You can pass connection parameters directly in every `snow` command that requires a connection. For a full list of connection configuration parameters, execute the `snow sql --help` command, as shown. Note that the output shows only the section with the connection configuration options.

```
snow sql --help

```

Copy

```
╭─ Connection configuration ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ --connection,--environment             -c      TEXT     Name of the connection, as defined in your config.toml. Default: default.
│ --host                                         TEXT     Host address for the connection. Overrides the value specified for the connection.
│ --port                                         INTEGER  Port for the connection. Overrides the value specified for the connection.
│ --account,--accountname                        TEXT     Name assigned to your Snowflake account. Overrides the value specified for the connection.
│ --user,--username                              TEXT     Username to connect to Snowflake. Overrides the value specified for the connection.
│ --password                                     TEXT     Snowflake password. Overrides the value specified for the connection.
│ --authenticator                                TEXT     Snowflake authenticator. Overrides the value specified for the connection.
│ --private-key-file,--private-key-path          TEXT     Snowflake private key file path. Overrides the value specified for the connection.
│ --token                                        TEXT     OAuth token to use when connecting to Snowflake.
│ --token-file-path                              TEXT     Path to file with an OAuth token that should be used when connecting to Snowflake.
│ --database,--dbname                            TEXT     Database to use. Overrides the value specified for the connection.
│ --schema,--schemaname                          TEXT     Database schema to use. Overrides the value specified for the connection.
│ --role,--rolename                              TEXT     Role to use. Overrides the value specified for the connection.
│ --warehouse                                    TEXT     Warehouse to use. Overrides the value specified for the connection.
│ --temporary-connection                 -x               Uses connection defined with command-line parameters, instead of one defined in config.
│ --mfa-passcode                                 TEXT     Token to use for multi-factor authentication (MFA).
│ --oauth-client-id                              TEXT     Value of the client ID provided by the identity provider for Snowflake integration.
│ --oauth-client-secret                          TEXT     Value of the client secret provided by the identity provider for Snowflake integration.
│ --oauth-authorization-url                      TEXT     Identity provider endpoint supplying the authorization code to the driver.
│ --oauth-token-request-url                      TEXT     Identity provider endpoint supplying the access tokens to the driver.
│ --oauth-redirect-uri                           TEXT     URI to use for the authorization code.
│ --oauth-scope                                  TEXT     Scope requested in the identity provider authorization request.
│ --oauth-disable-pkce                                    Disables Proof Key for Code Exchange (PKCE). Default: False.
│ --oauth-enable-refresh-tokens                           Enables a silent re-authentication when the actual access token becomes outdated. Default: False.
│ --oauth-enable-single-use-refresh-tokens                Whether to opt in to single-use refresh token semantics. Default: False.
│ --client-store-temporary-credential                     Store the temporary credential.
│ --enable-diag                                           Run the python connector diagnostic test.
│ --diag-log-path                                TEXT     Diagnostic report path.
│ --diag-allowlist-path                          TEXT     Diagnostic report path to optional allowlist.
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

```

Caution

For improved security, Snowflake strongly recommends using either `SNOWFLAKE_CONNECTIONS_<NAME>_PASSWORD` or `SNOWFLAKE_PASSWORD` environment variable.

## Import connections from SnowSQL[¶](#import-connections-from-snowsql ""Link to this heading"")

Snowflake CLI is an open-source command-line tool explicitly designed for developer-centric workloads in addition to SQL operations. Snowflake CLI is a more modern, robust, and efficient CLI client than legacy SnowSQL. In addition to executing SQL commands with Snowflake CLI, you can also execute commands for other Snowflake products like Streamlit in Snowflake, Snowpark Container Services, and Snowflake Native App Framework. Because new features and enhancements will be added only to Snowflake CLI, Snowflake recommends that you begin transitioning from SnowSQL to Snowflake CLI.

To import any existing connections defined in [SnowSQL](../../../user-guide/snowsql) into your Snowflake CLI `config.toml` configuration file, use the `snow helpers import-snowsql-connections` command.

To import SnowSQL connections, enter the `snow helpers import-snowsql-connections` command similar to the following code block that imports SnowSQL connections from the standard configuration file locations:

```
snow helpers import-snowsql-connections

```

Copy

As the command processes the SnowSQL configuration files, it shows the progress and prompts for confirmation when a connection with the same name is already defined in the Snowflake CLI `config.toml` file:

```
SnowSQL config file [/etc/snowsql.cnf] does not exist. Skipping.
SnowSQL config file [/etc/snowflake/snowsql.cnf] does not exist. Skipping.
SnowSQL config file [/usr/local/etc/snowsql.cnf] does not exist. Skipping.
Trying to read connections from [/Users/<user>/.snowsql.cnf].
Reading SnowSQL's connection configuration [connections.connection1] from [/Users/<user>/.snowsql.cnf]
Trying to read connections from [/Users/<user>/.snowsql/config].
Reading SnowSQL's default connection configuration from [/Users/<user>/.snowsql/config]
Reading SnowSQL's connection configuration [connections.connection1] from [/Users/<user>/.snowsql/config]
Reading SnowSQL's connection configuration [connections.connection2] from [/Users/<user>/.snowsql/config]
Connection 'connection1' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: Y
Connection 'connection2' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: n
Connection 'default' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: n
Saving [connection1] connection in Snowflake CLI's config.
Connections successfully imported from SnowSQL to Snowflake CLI.

```

For more information about this command, see the [snow helpers import-snowsql-connections](../command-reference/helpers-commands/import-snowsql-connections) command reference.

For help with migrating from SnowSQL to Snowflake CLI, see [Migrating from SnowSQL to Snowflake CLI](../../../user-guide/snowsql-migrate).

## Use a temporary connection[¶](#use-a-temporary-connection ""Link to this heading"")

You can also specify connection parameters from the command line using the `--temporary-connection [-x]` option. It ignores all definitions from the `config.toml`, using ones specified by command-line options instead. This approach can be helpful for CI/CD use cases when you don’t want to use a configuration file. When you use a temporary connection, Snowflake CLI ignores any connection variables defined in the `config.toml` file, but does still use any of the following [environment variables](#label-snowcli-environment-creds) you set:

*   `SNOWFLAKE_ACCOUNT`
    
*   `SNOWFLAKE_USER`
    
*   `SNOWFLAKE_PASSWORD`
    
*   `SNOWFLAKE_DATABASE`
    
*   `SNOWFLAKE_SCHEMA`
    
*   `SNOWFLAKE_ROLE`
    
*   `SNOWFLAKE_WAREHOUSE`
    
*   `SNOWFLAKE_AUTHENTICATOR`
    
*   `SNOWFLAKE_PRIVATE_KEY_FILE`
    
*   `SNOWFLAKE_PRIVATE_KEY_RAW`
    
*   `SNOWFLAKE_PRIVATE_KEY_PATH`
    
*   `SNOWFLAKE_SESSION_TOKEN`
    
*   `SNOWFLAKE_MASTER_TOKEN`
    
*   `SNOWFLAKE_TOKEN_FILE_PATH`
    
*   `WORKLOAD_IDENTITY_PROVIDER`
    

The following example shows how to create a temporary connection using a username and password. This example assumes you stored the password in the `SNOWFLAKE_PASSWORD` environment variable.

```
snow sql -q ""select 42;"" --temporary-connection \
                           --account myaccount \
                           --user jdoe

```

Copy

```
select 42;
+----+
| 42 |
|----|
| 42 |
+----+

```

Caution

For improved security, Snowflake strongly recommends using either `SNOWFLAKE_CONNECTIONS_<NAME>_PASSWORD` or `SNOWFLAKE_PASSWORD` environment variable.

For additional security, you can use a [private key file](#label-snowcli-private-key) and store the path to your private key file in the `SNOWFLAKE_PRIVATE_KEY_FILE` environment variable, as shown:

```
SNOWFLAKE_ACCOUNT = ""account""
SNOWFLAKE_USER = ""user""
SNOWFLAKE_PRIVATE_KEY_FILE = ""/path/to/key.p8""

```

Copy

You can then create a temporary connection without specifying the options, as shown:

```
snow sql -q ""select 42"" --temporary-connection

```

Copy

```
select 42;
+----+
| 42 |
|----|
| 42 |
+----+

```

When using CI/CD pipelines with key pair authentication, you might not be able to access local private key files (`SNOWFLAKE_PRIVATE_KEY_FILE`). In this situation, you can store the private key in the `SNOWFLAKE_PRIVATE_KEY_RAW` environment variable, as shown:

```
SNOWFLAKE_ACCOUNT = ""account""
SNOWFLAKE_USER = ""user""
SNOWFLAKE_PRIVATE_KEY_RAW = ""-----BEGIN PRIVATE KEY-----...""

```

Copy

You can then create a temporary connection without specifying the options, as shown:

```
snow sql -q ""select 42"" --temporary-connection

```

Copy

```
select 42;
+----+
| 42 |
|----|
| 42 |
+----+

```

Note

If you use the `SNOWFLAKE_PRIVATE_KEY_RAW` environment variable, you should not also define `SNOWFLAKE_PRIVATE_KEY_FILE`.

## Additional ways to authenticate your connection[¶](#additional-ways-to-authenticate-your-connection ""Link to this heading"")

You can also use the following methods to authenticate your connection to Snowflake:

*   [Use a private key file for authentication](#label-snowcli-private-key)
    
*   [Use OAuth authentication](#label-snowcli-oauth)
    
*   [Use the OAuth 2.0 Authorization Code flow](#label-snowcli-oauth-code-flow)
    
*   [Use the OAuth 2.0 Client Credentials flow](#label-snowcli-oauth-client-flow)
    
*   [Use multi-factor authentication (MFA)](#label-snowcli-mfa)
    
*   [Use MFA caching](#label-snowcli-mfa-caching)
    
*   [Use SSO (single sign-on)](#label-snowcli-sso)
    
*   [Use an external browser](#label-snowcli-externalbrowser)
    
*   [Use PAT (Programmatic Access Token)](#label-snowcli-pat)
    
*   [Use workload identity federation (WIF)](#label-snowcli-wif)
    

### Use a private key file for authentication[¶](#use-a-private-key-file-for-authentication ""Link to this heading"")

To use private key file for authentication, your connection configuration requires you to set the `authenticator` parameter to `SNOWFLAKE_JWT` and provide path to file with your private key similar to the following:

*   Specify the `--private_key-file` option in the `snow connection add` command, as shown:
    
    > ```
    > snow connection add \
    >    --connection-name jwt \
    >    --authenticator SNOWFLAKE_JWT \
    >    --private-key-file ~/.ssh/sf_private_key.p8
    > 
    > ```
    > 
    > Copy
    
*   Use the configuration file:
    
    > ```
    > [connections.jwt]
    > account = ""my_account""
    > user = ""jdoe""
    > authenticator = ""SNOWFLAKE_JWT""
    > private_key_file = ""~/sf_private_key.p8""
    > 
    > ```
    > 
    > Copy
    

For more details on configuring key pair authentication, see [Key-pair authentication and key-pair rotation](../../../user-guide/key-pair-auth).

Snowflake CLI looks for the private key in the connection parameters in the following order:

1.  If `private_key_file` is specified, Snowflake CLI reads the key from the specified file path.
    
2.  If `private_key_path` is specified, Snowflake CLI reads the key from the specified file path.
    
3.  If `private_key_file` or `private_key_path` are not specified, Snowflake CLI reads the key directly from the `private_key_raw` parameter.
    

Caution

If you specify your private key in the `private_key_raw` parameter, Snowflake recommends using either the `SNOWFLAKE_CONNECTIONS_<NAME>_PRIVATE_KEY_RAW` or the `SNOWFLAKE_PRIVATE_KEY_RAW` environment variables for improved security.

Note

If your private key is passphrase-protected, set the `PRIVATE_KEY_PASSPHRASE` environment variable to that passphrase.

### Use OAuth authentication[¶](#use-oauth-authentication ""Link to this heading"")

To use connect using OAuth, you can do either of the following:

*   Specify the `--token-file-path` option in the `snow connection add` command, as shown:
    
    ```
    snow connection add --token-file-path ""my-token.txt""
    
    ```
    
    Copy
    
*   In the `config.toml` file, set `authenticator = ""oauth""`, and add the `token_file_path` parameter to the connection definition, as shown:
    
    ```
    [connections.oauth]
    account = ""my_account""
    user = ""jdoe""
    authenticator = ""oauth""
    token_file_path = ""my-token.txt""
    
    ```
    
    Copy
    

### Use the OAuth 2.0 Authorization Code flow[¶](#use-the-oauth-2-0-authorization-code-flow ""Link to this heading"")

The OAuth 2.0 Authorization Code flow is a secure method for a client application to obtain an access token from an authorization server on behalf of a user, without revealing the user’s credentials. For more information about this flow and its parameters, see [Enable the OAuth 2.0 Authorization Code flow](../../python-connector/python-connector-connect.html#label-python-oauth-code-flow) in the Snowflake Connector for Python documentation.

To use the OAuth 2.0 Authorization Code flow, add a connection definition to your `config.toml` file similar to the following:

```
[connections.oauth]
authenticator = ""OAUTH_AUTHORIZATION_CODE""
user = ""user""
account = ""account""
oauth_client_id = ""client_id""
oauth_client_secret = ""client_secret""
oauth_redirect_uri = ""http://localhost:8001/snowflake/oauth-redirect""
oauth_scope = ""session:role:PUBLIC""

```

Copy

### Use the OAuth 2.0 Client Credentials flow[¶](#use-the-oauth-2-0-client-credentials-flow ""Link to this heading"")

The OAuth 2.0 Client Credentials flow provides a secure way for machine-to-machine (M2M) authentication, such as the Snowflake Connector for Python connecting to a backend service. Unlike the OAuth 2.0 Authorization Code flow, this method does not rely on any user-specific data. For more information about this flow and its parameters, see [Enable the OAuth 2.0 Client Credentials flow](../../python-connector/python-connector-connect.html#label-python-oauth-client-flow) in the Snowflake Connector for Python documentation.

To use the OAuth 2.0 Client Credentials flow, add a connection definition to your `config.toml` file similar to the following:

```
[connections.oauth]
authenticator = ""OAUTH_CLIENT_CREDENTIALS""
user = ""user""
account = ""account""
oauth_client_id = ""client_id""
oauth_client_secret = ""client_secret""
oauth_token_request_url = ""http://identity.provider.com/token""
oauth_scope = ""session:role:PUBLIC""

```

Copy

### Use multi-factor authentication (MFA)[¶](#use-multi-factor-authentication-mfa ""Link to this heading"")

To use MFA:

1.  Set up [multi-factor authentication](../../../user-guide/security-mfa) in Snowflake and set the `authenticator` parameter to `snowflake` (which is a default value).
    
2.  If you want to use a Duo-generated passcode instead of the push mechanism, use either the `--mfa-passcode <passcode>` option or set `passcode_in_password = true` in the `config.toml` file and include the passcode in your password as described in [Using MFA with Python](../../../user-guide/security-mfa.html#label-security-mfa-python).
    
    Note
    
    If you want use the passcode in the password for authentication, after executing the first `snow` command, you can no longer provide the passcode as long as the token in valid. You must do the following:
    
    *   Remove the passcode from the password.
        
    *   Remove or comment the `passcode_in_password = true` in the `config.toml` file.
        
    

### Use MFA caching[¶](#use-mfa-caching ""Link to this heading"")

MFA caching is a security feature that reduces the frequency of Multi-Factor Authentication (MFA) prompts during logins. Frequent MFA prompts can disrupt workflow and decrease productivity. MFA caching addresses this issue by securely storing MFA session information for a specified period. Using MFA caching lets you authenticate without repeatedly entering MFA codes, as long as they are within the cached session’s timeframe.

To enable MFA caching:

1.  For your account, set `ALLOW_CLIENT_MFA_CACHING = true`.
    
2.  In your `config.toml` file, add `authenticator = ""username_password_mfa""` to your connection.
    

For more information, see [Using MFA token caching to minimize the number of prompts during authentication — optional](../../../user-guide/security-mfa.html#label-mfa-token-caching).

### Use SSO (single sign-on)[¶](#use-sso-single-sign-on ""Link to this heading"")

If you have [configured Snowflake to use single sign-on (SSO)](../../../user-guide/admin-security-fed-auth-overview), you can configure your client application to use SSO for authentication. See [Using SSO with client applications that connect to Snowflake](../../../user-guide/admin-security-fed-auth-use.html#label-sso-with-command-line-clients) for details and configure your connection using the instructions for Python.

### Use an external browser[¶](#use-an-external-browser ""Link to this heading"")

You can use your browser to authenticate your Snowflake CLI connection with any SAML 2.0 compliant identity provider (IdP), such as Okta or Active Directory Federation Services.

Note

The `externalbrowser` authenticator is only supported in terminal windows that have web browser access. For example, a terminal window on a remote machine accessed through a SSH (Secure Shell) session might require additional setup to open a web browser.

If you don’t have access to a web browser, but your IdP is Okta, you can use native Okta by setting the authenticator to `https://<okta_account_name>.okta.com`.

To use external browser authentication, use one of the following methods:

*   Use the `snow connection add --authenticator` command option:
    
    ```
    snow connection add --authenticator externalbrowser
    
    ```
    
    Copy
    
*   Set `authenticator` to `externalbrowser` in your `config.toml` file:
    
    ```
    [connections.externalbrowser]
    account = ""my_account""
    user = ""jdoe""
    authenticator = ""externalbrowser""
    
    ```
    
    Copy
    

### Use PAT (Programmatic Access Token)[¶](#use-pat-programmatic-access-token ""Link to this heading"")

Programmatic Access Token (PAT) is a Snowflake-specific authentication method. The feature must be enabled for the account before usage (see the [Prerequisites](../../../user-guide/programmatic-access-tokens.html#label-pat-prerequisites) for more information). Authentication with PAT doesn’t involve any human interaction.

To use PAT with the connection, set `authenticator` to `PROGRAMMATIC_ACCESS_TOKEN` and `token_file_path` to point the file with token, as shown:

```
[connections.externalbrowser]
account = ""my_account""
user = ""jdoe""
authenticator = ""PROGRAMMATIC_ACCESS_TOKEN""
token_file_path = ""path-to-pat-token""

```

Copy

For more information about PATs, see [Using programmatic access tokens for authentication](../../../user-guide/programmatic-access-tokens).

### Use workload identity federation (WIF)[¶](#use-workload-identity-federation-wif ""Link to this heading"")

Workload identity federation (WIF) is a feature that allows you to use your CI/CD environment’s identity to authenticate to Snowflake without the need for static credentials. This is particularly useful in automated workloads, where you want to minimize the risk of credential exposure.

For more information, see [Workload identity federation](../../../user-guide/workload-identity-federation).

#### Set up WIF connections[¶](#set-up-wif-connections ""Link to this heading"")

To set up a WIF connection, you need to create a service account in Snowflake using the following steps:

1.  Create a service user in Snowflake with the proper WORKLOAD\_IDENTITY:
    

> ```
> CREATE USER <username>
> WORKLOAD_IDENTITY = (
>   TYPE = <WIF type>
>   // ...
> )
> TYPE = SERVICE
> DEFAULT_ROLE = PUBLIC;
> 
> ```
> 
> Copy

1.  Configure a connection in Snowflake CLI using either of the following methods
    
    *   Add the connection to the `config.toml` file
        
        > ```
        > [connections.my_wif_conn]
        > account = ""my_account""
        > authenticator = ""WORKLOAD_IDENTITY""
        > workload_identity_provider = ""<provider type>""
        > 
        > ```
        > 
        > Copy
        
    *   Use the `snow connection add` command:
        
        ```
        snow connection add \
         --connection-name my_wif_conn \
         --account <account>
         --authenticatior WORKLOAD_IDENTITY \
         --workload-identity-provider <provider type>
        
        ```
        
        Copy
        

where:

> `<provider type>` is one of the following:
> 
> *   AWS
>     
> *   AZURE
>     
> *   GCP
>     
> *   OIDC
>     

Note

When using OIDC as a provider, you need to retrieve the token from your environment and provide it to cli. You can provide retrieved token via

*   `--token` parameter
    
*   `SNOWFLAKE_TOKEN` environment variable
    
*   `SNOWFLAKE_CONNECTIONS_<connection_name>_TOKEN` environment variable
    
*   `token_file_path` in your `config.toml` file
    

For more information, see [Using Snowflake CLI actions](../cicd/integrate-ci-cd.html#label-cli-use-sf-actions).

#### Connect to Snowflake using a temporary WIF connection[¶](#connect-to-snowflake-using-a-temporary-wif-connection ""Link to this heading"")

To connect to Snowflake using a [temporary connection](#label-snowcli-temporary-connection), you can use the following command:

```
snow sql -x \
--authenticator WORKLOAD_IDENTITY \
--workload-identity-provider AWS \
--account <my_account> \
-q 'select current_user()'

select current_user();
+----------------+
| CURRENT_USER() |
|----------------|
| <user name>    |
+----------------+

```

Copy

On this page

1.  [Define connections](#define-connections)
2.  [Alternative configuration file](#alternative-configuration-file)
3.  [Manage or add your connections to Snowflake with the snow connection commands](#manage-or-add-your-connections-to-snowflake-with-the-snow-connection-commands)
4.  [Add a connection](#add-a-connection)
5.  [List defined connections](#list-defined-connections)
6.  [Test and diagnose a connection](#test-and-diagnose-a-connection)
7.  [Remove a connection](#remove-a-connection)
8.  [Set the default connection](#set-the-default-connection)
9.  [Use environment variables for Snowflake credentials](#use-environment-variables-for-snowflake-credentials)
10.  [Pass connection parameters to the snow command](#pass-connection-parameters-to-the-snow-command)
11.  [Import connections from SnowSQL](#import-connections-from-snowsql)
12.  [Use a temporary connection](#use-a-temporary-connection)
13.  [Additional ways to authenticate your connection](#additional-ways-to-authenticate-your-connection)
14.  [Use a private key file for authentication](#use-a-private-key-file-for-authentication)
15.  [Use OAuth authentication](#use-oauth-authentication)
16.  [Use the OAuth 2.0 Authorization Code flow](#use-the-oauth-2-0-authorization-code-flow)
17.  [Use the OAuth 2.0 Client Credentials flow](#use-the-oauth-2-0-client-credentials-flow)
18.  [Use multi-factor authentication (MFA)](#use-multi-factor-authentication-mfa)
19.  [Use MFA caching](#use-mfa-caching)
20.  [Use SSO (single sign-on)](#use-sso-single-sign-on)
21.  [Use an external browser](#use-an-external-browser)
22.  [Use PAT (Programmatic Access Token)](#use-pat-programmatic-access-token)
23.  [Use workload identity federation (WIF)](#use-workload-identity-federation-wif)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/connecting/../index)
2.  [Configuring Snowflake CLI and connecting to Snowflake](/developer-guide/snowflake-cli/connecting/connect)
3.  [Configuring Snowflake CLI](/developer-guide/snowflake-cli/connecting/configure-cli)
4.  [snow connection commands](/developer-guide/snowflake-cli/connecting/../command-reference/connection-commands/overview)",NULL,9c7a6a49f3090bde1dc76854207ff15db4c889d3d9567644e329c54d06bc2df6,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/bootstrap-commands/init,snow init¶,NULL,NULL,snow bootstrap,snow bootstrap init,"# snow init[¶](#snow-init ""Link to this heading"")

Creates project directory from template.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow init
  <path>
  --template <template>
  --template-source <template_source>
  --variable <variables>
  --no-interactive
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_path_`

Directory to be initialized with the project. This directory must not already exist.

## Options[¶](#options ""Link to this heading"")

`--template _TEXT_`

which template (subdirectory of –template-source) should be used. If not provided, whole source will be used as the template.

`--template-source _TEXT_`

local path to template directory or URL to git repository with templates. Default: [https://github.com/snowflakedb/snowflake-cli-templates](https://github.com/snowflakedb/snowflake-cli-templates).

`--variable, -D _TEXT_`

String in `key=value` format. Provided variables will not be prompted for.

`--no-interactive`

Disable prompting. Default: False.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow init` command initializes a directory specified in the `<path>` parameter with a chosen template. It renders all files mentioned in the `files_to_render` list in the `template.yml`, resolving all variables enclosed in `<! … !>`. If a `template.yml` file is not present in the template’s root directory, the command finishes with an error. For information about creating project templates, see [Bootstrapping a project from a template](../../bootstrap-project/bootstrap).

By default, the command interactively prompts you for each parameter defined in the `template.yml` file. You can bypass the interactive prompts in the following ways:

*   Use the `-D` option to specify the values for each parameter contained in the project template.
    
*   Use the `--no-interactive` option to use default values, if defined, for each template parameter in the `template.yml` file.
    
*   Use a combination of the `-D` and `--no-interactive` options to define values for some parameters and use the specified default values for the template.
    
    Note
    
    If you do not provide a value using the `-D` option that does not have a corresponding default value defined, the snow init command terminates with an error.
    

## Examples[¶](#examples ""Link to this heading"")

*   Bootstrap a Snowpark project that prompts for the parameters specified in the `example_snowpark` template contained in the [snowflake-cli-templates Git repository](https://github.com/snowflakedb/snowflake-cli-templates/).
    
    ```
    snow init new_snowpark_project --template example_snowpark
    
      Project identifier (used to determine artifacts stage path) [my_snowpark_project]:
      What stage should the procedures and functions be deployed to? [dev_deployment]: snowpark
    
    ```
    
    Copy
    
    ```
    Initialized the new project in new_snowpark_project
    
    ```
    
*   Bootstrap a Streamlit project by using the `-D` option to provide the values for some of the parameters specified in the local `../local_templates/example_streamlit` template and prompt for others.
    
    ```
    snow init new_streamlit_project --template-source ../local_templates/example_streamlit -D query_warehouse=dev_wareshouse -D stage=testing
    
      Name of the streamlit app [streamlit_app]: My streamlit
    
    ```
    
    Copy
    
    ```
    Initialized the new project in new_streamlit_project
    
    ```
    

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/bootstrap-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/bootstrap-commands/overview)",NULL,42da6217c6bd426d98c8ba8aa9cd22a4c8cd70c8d062da5d5f6dcb8d684347a3,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/specify-entities,Specify entities¶,NULL,NULL,NULL,NULL,"# Specify entities[¶](#specify-entities ""Link to this heading"")

In the `snowflake.yml` definition file, you can specify multiple entities. Each entity is identified by a unique key. The example below specifies two entities with the `entity_a` and `entity_b` keys:

```
entities:
  entity_a:
    ...
  entity_b:
    ...

```

Copy

Each entity has to specify a type. Currently supported types include:

*   [function](about.html#label-snowcli-func-proc-properties)
    
*   [procedure](about.html#label-snowcli-func-proc-properties)
    
*   [streamlit](../streamlit-apps/manage-apps/initialize-app.html#label-snowcli-streamlit-project-definition)
    
*   [application package](../native-apps/project-definitions)
    
*   [application](../native-apps/project-definitions)
    

## Entity identifiers[¶](#entity-identifiers ""Link to this heading"")

You can specify multiple entities of the same type in the `snowflake.yml` file. You can name entities in the following ways:

*   Use a unique key in the entities list.
    
    The following example shows using `entity_a` and `entity_b` as the unique keys:
    
    ```
    entities:
      entity_a:
        ...
      entity_b:
        ...
    
    ```
    
    Copy
    
*   Specify an `identifier` name to each entity.
    
    The following example adds identifier names to the `entity_a` and `entity_b` entities:
    
    ```
    entities:
      entity_a:
        identifier: entity_a_name
        ...
      entity_b:
        identifier:
          name: entity_a_name
    
    ```
    
    Copy
    
*   Add an `identifier` object to each entity.
    
    Using identifier objects allow to specify a name, database, and schema for each entity, as shown in the following example:
    
    ```
    entities:
      entity_b:
        identifier:
          name: entity_a_name
          schema: public
          database: DEV
    
    ```
    
    Copy
    

If you don’t specify an identifier, the entity key is used as the name of the object, without any database or schema qualification.

## Project mixins[¶](#project-mixins ""Link to this heading"")

In many cases you might find it useful to define project-wide default values. Mixins provide a way to extract common attributes out of individual entities. You can specify multiple mixins. You need to declare which mixins should be used by each entity using `meta.use_mixins` property.

When using mixins with an entity, you must ensure that all properties of a mixin can be applied to that entity. Applying a property that is not available on an entity causes an error. Consequently, in some cases you might need to use multiple mixins.

Note

Mixin values are overridden by explicitly-declared entity attributes.

The following example includes two mixins: `stage_mixin` and `snowpark_shared`. The `my_dashboard` entity uses only `stage_mixin`, while the `my_function` entity uses both of the mixins.

```
definition_version: 2
mixins:
  stage_mixin:
    stage: ""my_stage""
  snowpark_shared:
    artifacts: [""app/""]
    imports: [""@package_stage/package.zip""]

entities:
  my_function:
    type: ""function""
    ...
    meta:
      use_mixins:
        - ""stage_mixin""
        - ""snowpark_shared""
  my_dashboard:
    type: ""dashboard""
    ...
    meta:
      use_mixins:
        - ""stage_mixin""

```

Copy

If an entity uses multiple mixins that specify the same property, the entity uses the value of later mixin. In the following example, the value of key on the `foo` entity will be `mixin_2_value`.

```
mixins:
  mixin_1:
    key: mixin_1_value
  mixin_2:
    key: mixin_2_value

entities:
  foo:
    meta:
      use_mixin:
      - mixin_1
      - mixin_2

```

Copy

The behavior of applying mixins values depends on value type. For scalar values (strings, numbers, Booleans) values are overridden.

| Mixin notation | Explicit result |
| --- | --- |
| definition_version: 2
mixins:
  mix1:
    stage: A

  mix2:
    stage: B

entities:
  test_procedure:
    stage: C
    meta:
      use_mixins:
        - mix1
        - mix2
Copy | definition_version: 2
entities:
  test_procedure:
    stage: C
Copy |

In case of sequences, values are merged to create a new sequence. This implementation avoids creating duplicate entries in the sequence.

| Mixin notation | Explicit result |
| --- | --- |
| definition_version: 2
mixins:
  mix1:
    artifacts:
    - a.py

  mix2:
    artifacts:
    - b.py

entities:
  test_procedure:
    artifacts:
      - app/
    meta:
      use_mixins:
        - mix1
        - mix2
Copy | definition_version: 2
entities:
  test_procedure:
    artifacts:
      - a.py
      - b.py
      - app/
Copy |

For mapping values new keys are being added and existing values are updated. The update is recursive.

| Mixin notation | Explicit result |
| --- | --- |
| definition_version: 2
mixins:
  mix1:
    secrets:
      secret1: v1

  mix2:
    secrets:
      secret2: v2

entities:
  test_procedure:
    secrets:
      secret3: v3
    meta:
      use_mixins:
        - mix1
        - mix2
Copy | definition_version: 2
entities:
  test_procedure:
    secrets:
      secret1: v1
      secret2: v2
      secret3: v3
Copy |
| definition_version: 2
mixins:
  mix1:
    secrets:
      secret_name: v1

  mix2:
    secrets:
      secret_name: v2

entities:
  test_procedure:
    secrets:
      secret_name: v3
    meta:
      use_mixins:
        - mix1
        - mix2
Copy | definition_version: 2
entities:
  test_procedure:
    secrets:
      secret_name: v3
Copy |
| definition_version: 2
mixins:
  shared:
    identifier:
      schema: foo

entities:
  sproc1:
    identifier:
      name: sproc
    meta:
      use_mixins: [""shared""]
  sproc2:
    identifier:
      name: sproc
      schema: from_entity
    meta:
      use_mixins: [""shared""]
Copy | definition_version: 2
entities:
  sproc1:
    identifier:
      name: sproc
      schema: foo
  sproc2:
    identifier:
      name: sproc
      schema: from_entity
Copy |

On this page

1.  [Entity identifiers](#entity-identifiers)
2.  [Project mixins](#project-mixins)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",NULL,88a2a4636ba10665055c05b93dbae23b1b6f3a190335aa4a0db2c15013740f58,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/use-sql-variables,Use variables in SQL¶,NULL,NULL,NULL,NULL,"# Use variables in SQL[¶](#use-variables-in-sql ""Link to this heading"")

Note

Support for variables requires project definition version 1.1.

You can also use project files to define variables that other commands, such as `snow sql`, can use. The `env` section in the project definition file(typically, `snowflake.yml`) lets you define variables as shown:

```
definition_version: 2
env:
  database: ""dev""
  role: ""eng_rl""

```

Copy

After adding the `env` section to the project definition file, you can pass the variables to the `snow sql` command instead of specifying the variable and value on the command line.

Instead specifying the database and role on the command line with the `--variable` option, as shown:

```
snow sql \
-q ""grant usage on database <% database %> to <% role %>"" \
-D ""database=dev"" \
-D ""role=eng_rl""

```

Copy

you can specify the variables defined in the `env` section as shown:

```
snow sql -q ""grant usage on database <% ctx.env.database %> to <% ctx.env.role %>""

```

Copy

You can include the `env` section in addition to any other sections you include in the project definition file.

```
definition_version: 2
entities:
  test_function:
    type: ""function""
    stage: ""dev_deployment""
    artifacts: [""app/""]
    handler: ""functions.hello_function""
    signature: """"
    returns: string

  hello_procedure:
    type: ""procedure""
    stage: ""dev_deployment""
    artifacts: [""app/""]
    handler: ""procedures.hello_procedure""
    signature:
      - name: ""name""
        type: ""string""
    returns: string

env:
  database: ""dev""
  role: ""eng_rl""

```

Copy

Note

If your current project definition file uses `definition_version: 1`, you must update it to `definition_version: 1.1` if you want to take advantage of the variables feature. If you do not change the value, Snowflake CLI ignores the `env` section, but the other types of projects (`snowpark`, in this example) still work as expected.

You can override any variable defined the in `snowflake.yml` project definition file by setting a shell environment variable by the same name (case-sensitive). For example, to override the `database` value defined in the example, you can execute the following shell command:

```
export database=""other""

```

Copy

For more information about using `env` variables, see [Storing variables in the snowflake.yml project definition file](../sql/execute-sql.html#label-cli-sql-env-vars).

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)
2.  [snow sql](/developer-guide/snowflake-cli/project-definitions/../command-reference/sql-commands/sql)",NULL,4f0efda5bdc585befdc9e01bd06cddc22bdb02243f5ad5c36d254a9eb9997010,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/create-templates,Create project definition file templates¶,NULL,NULL,NULL,NULL,"# Create project definition file templates[¶](#create-project-definition-file-templates ""Link to this heading"")

In some situations, you might want to reference information already present in a project definition file in another place of the file. Snowflake CLI supports templating the project definition file.

Project definition file templates use the `<% … %>` syntax for specifying the templates. The following example uses the `env` section to define a name for a Streamlit application:

```
definition_version: 2
env:
  name: ""my-app""
entities:
  my_streamlit:
    type: ""streamlit""
    identifier: <% ctx.env.name %>

```

Copy

The `<% ctx.env.name %>` syntax references a global context object that provides access to the project definition. The `ctx` object has the same structure as the project definition. You can access attributes of defined objects using dot notation. Example uses include:

*   `<% ctx.entities.pkg.identifier %>` to access the name of a Native App package with ID `pkg`.
    
*   `<% ctx.entities.function.stage_name %>` to access the stage name for a snowpark UDFs and procedures.
    
*   `<% ctx.entities.my_streamlit.identifier %>` to access the Streamlit dashboard name.
    

You can override any variable defined in the `snowflake.yml` project definition file `env` section by setting a shell environment variable by the same case-sensitive name. For example, to override the name value defined in the example, you can execute the following shell command:

```
export name=""other""

```

Copy

## Access template defaults[¶](#access-template-defaults ""Link to this heading"")

Template defaults let you access default and automatically-generated fields from a project definition file, even if the fields are not explicitly defined. To illustrate, consider the following Snowflake Native App project definition file:

```
definition_version: 2
entities:
  pkg:
    type: application package
    artifacts:
      - src: app/*
        dest: ./
  app:
    type: application
    from:
      target: pkg

```

Copy

This definition provides enough information to create a Snowflake Native App, so the default values for the application package and application instance are automatically generated when you create the application. You can then access these values using the following syntax:

> ```
> <% ctx.entities.app.identifier %>
> <% ctx.entities.pkg.identifier %>
> 
> ```
> 
> Copy

On this page

1.  [Access template defaults](#access-template-defaults)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",NULL,e0c42261db6857d07d9ce115bbce759b530169353d6614ea86ef1eb46f8b6cc7,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/alter-with-templates,Alter command behavior using templates¶,NULL,NULL,NULL,NULL,"# Alter command behavior using templates[¶](#alter-command-behavior-using-templates ""Link to this heading"")

You can use templates to alter the definition using environment variables. For example, the following project definition templates the schema for a Streamlit dashboard:

```
definition_version: ""1.1""
env:
  schema: ""test""
streamlit:
  name: ""MY_APP""
  schema: <% ctx.env.schema %>

```

Copy

This feature lets you to alter the behavior of the `snow streamlit deploy` command by setting a `schema` environment variable. Using this approach, you can deploy the same dashboard to multiple different schemas by entering the following commands to deploy different schemas:

```
schema=""staging""; snow streamlit deploy
schema=""prod""; snow streamlit deploy

```

Copy

Note

The variables and environment variables are case-sensitive.

You can also use the template feature without defining variables in the `env` section. If a variable is not present in `env` section, Snowflake CLI looks for corresponding environment variables. For example, if you define a Streamlit application similar to the following, you can still alter the behavior of `snow streamlit deploy` by specifying a `schema` environment variable.

```
definition_version: ""1.1""
streamlit:
  name: ""MY_APP""
  schema: <% ctx.env.schema %>

```

Copy

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",NULL,2e4cd9286f9d613482411a7652143324fae50649210186fa7cb76ac64a2d7227,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/use-template-functions,Use template functions¶,NULL,NULL,NULL,NULL,"# Use template functions[¶](#use-template-functions ""Link to this heading"")

To enable the concatenation of SQL identifiers such as database names and schema names, and to provide flexibility in using quoted or unquoted identifiers in different contexts, Snowflake CLI provides the following set of utility functions you can use in project template definition templates:

*   [fn.concat\_ids()](#label-cli-fn-concat-ids)
    
*   [fn.str\_to\_id()](#label-cli-fn-str-to-id)
    
*   [fn.id\_to\_str()](#label-cli-fn-id-to-str)
    
*   [fn.get\_username()](#label-cli-fn-get-username)
    
*   [fn.sanitize\_id()](#label-cli-fn-sanitize-id)
    

## `fn.concat_ids()`[¶](#fn-concat-ids ""Link to this heading"")

*   Input: one or more string arguments (SQL ID or plain String)
    
*   Output: a valid SQL ID (quoted or unquoted)
    

The `fn.concat_ids()` function concatenates multiple string arguments into a single string representing a SQL ID (quoted or unquoted). If any of the input strings is a valid quoted identifier, it will be unescaped before the concatenation. The resulting string is then escaped and quoted if it contains non-SQL safe characters or if any of the input strings was a valid quoted identifier.

Examples:

*   Calling `fn.concat_ids('id1_', '""quoted_id2""')` outputs `""id1_quoted_id2""` because one of the input values is a quoted identifier.
    
*   Calling `fn.concat_ids('id1_', 'id2')` outputs `id1_id2` because none of the input values is a quoted identifier and none of the input values contains non SQL safe characters.
    

## `fn.str_to_id()`[¶](#fn-str-to-id ""Link to this heading"")

*   Input: one or more string arguments (SQL ID or plain String)
    
*   Output: a valid SQL ID (quoted or unquoted)
    

The `fn.str_to_id()` function returns a string as a an ID. If the input string contains a valid quoted or unquoted identifier, the function returns it as is. However, if the input string contains unsafe SQL characters that are not properly quoted, the function returns a quoted ID that escapes the unsafe characters.

Examples:

*   Calling `fn.str_to_id('id1')` returns `id1` because it is a valid unquoted identifier.
    
*   Calling `fn.str_to_id('unsafe""id')` returns `""unsafe""""id""` because it contains unsafe SQL characters.
    

## `fn.id_to_str()`[¶](#fn-id-to-str ""Link to this heading"")

*   Input: one string argument (SQL ID or plain String)
    
*   Output: a plain string
    

If the input is a valid SQL ID, the function returns an unescaped plain String. Otherwise, the function returns the input string as is.

Examples:

*   Calling `fn.id_to_str('id1')`, returns `id1` because it is already unquoted.
    
*   Calling `fn.id_to_str('""quoted""""id.example""')` returns `quoted""id.example`.
    

## `fn.get_username()`[¶](#fn-get-username ""Link to this heading"")

*   Input: one optional string containing the fallback value
    
*   Output: current username detected from the Operating System
    

Returns the current username from the operating system environment variables. If the current username is not found or is empty, it will either return an empty value or use the fallback value if one is provided.

Examples:

*   `fn.get_username('default_user')` returns the current username if found, otherwise, it returns `default_user`.
    

## `fn.sanitize_id()`[¶](#fn-sanitize-id ""Link to this heading"")

*   Input: one string argument
    
*   Output: a valid non-quoted SQL ID
    

The function `fn.sanitize_id()` removes any unsafe SQL characters from the input and returns it as a valid unquoted SQL ID. If the result does not start with a letter or an underscore, it appends an underscore to it. For very long strings, the function truncates the string to 255 characters.

Examples:

*   When using `fn.sanitize_id('Some.id""With_Special_Chars')` the output is `SomeidWith_Special_Chars`.
    
*   When using `fn.sanitize_id('1abc')` the output is `_1abc`.
    

## Sample use case[¶](#sample-use-case ""Link to this heading"")

The following example shows how to use these functions in `snowflake.yml` project definition files:

```
definition_version: 2
entities:
  pkg:
    type: application package
    identifier: <% fn.concat_ids(ctx.env.app_name, ctx.env.pkg_suffix) %>
    artifacts:
      - src: app/*
        dest: ./
  app:
    type: application
    identifier: <% fn.concat_ids(ctx.env.app_name, ctx.env.app_suffix) %>

env:
  app_name: myapp_base_name_<% fn.sanitize_id(fn.get_username()) %>
  app_suffix: _app_instance
  pkg_suffix: _pkg

```

Copy

The following example illustrates how to use the functions in a SQL file:

```
DESC APPLICATION <% fn.str_to_id(ctx.entities.app.identifier) %>;
DESC APPLICATION PACKAGE <% fn.str_to_id(ctx.entities.pkg.identifier) %>;

```

Copy

On this page

1.  [fn.concat\_ids()](#fn-concat-ids)
2.  [fn.str\_to\_id()](#fn-str-to-id)
3.  [fn.id\_to\_str()](#fn-id-to-str)
4.  [fn.get\_username()](#fn-get-username)
5.  [fn.sanitize\_id()](#fn-sanitize-id)
6.  [Sample use case](#sample-use-case)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",NULL,9970df5cc7b8365406e2913fc32d8d0f004a243c728862d9131f21347c0413e7,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/migrate-projects,Migrating project definition files from version 1.x to 2.0¶,NULL,NULL,NULL,NULL,"# Migrating project definition files from version 1.x to 2.0[¶](#migrating-project-definition-files-from-version-1-x-to-2-0 ""Link to this heading"")

To convert a version 1.x project definition file to the version 2 format, do the following:

1.  Go to your project directory that contains the version 1.x `snowflake.yml` file.
    
2.  Enter the `snow helpers v1-to-v2` command.
    
    *   If the version 1.x file conversion succeeds, the command displays a message similar to the following:
        
        > ```
        > cd <project-directory>
        > snow helpers v1-to-v2
        > 
        > ```
        > 
        > Copy
        > 
        > ```
        > Project definition migrated to version 2.
        > 
        > ```
        
    *   If your project definition file is already updated to version 2, the command displays the following message:
        
        > ```
        > cd <project-directory>
        > snow helpers v1-to-v2
        > 
        > ```
        > 
        > Copy
        > 
        > ```
        > Project definition is already at version 2.
        > 
        > ```
        

> *   If you try to convert a project file that contains a `snowflake.local.yml` file, without using the `--[no]-migrate-local-overrides` option, the command generates an error similar to the following:
>     
> 
> > *   If you try to convert a project file that contains templates, without using the `--accept-templates` option, the command generates an error similar to the following:
> >     
> >     > ```
> >     > cd <project-directory>
> >     > snow helpers v1-to-v2
> >     > 
> >     > ```
> >     > 
> >     > Copy
> >     > 
> >     > ```
> >     > +- Error-------------------------------------------------------------------+
> >     > | snowflake.local.yml file detected, please specify                        |
> >     > | --migrate-local-overrides to include or --no-migrate-local-overrides to  |
> >     > | exclude its values.                                                      |
> >     > +--------------------------------------------------------------------------+
> >     > 
> >     > ```
> >     
> > *   If you convert a project definition file that contains templates, and use the `--accept-templates` option, the command converts the file and displays a warning message similar to the following:
> >     
> >     > ```
> >     > cd <project-directory>
> >     > snow helpers v1-to-v2
> >     > 
> >     > ```
> >     > 
> >     > Copy
> >     > 
> >     > ```
> >     > WARNING  snowflake.cli._plugins.workspace.commands:commands.py:60 Your V1 definition contains templates. We cannot guarantee the correctness of the migration.
> >     > Project definition migrated to version 2
> >     > 
> >     > ```
> >     

## Convert Native App projects[¶](#convert-native-app-projects ""Link to this heading"")

This section shows an example from a V1 to V2 conversion of a Snowflake Native App project, lists the changes in property names, and offers some tips to help with migration.

### Snowflake Native App conversion example[¶](#native-app-conversion-example ""Link to this heading"")

| V1 project file | V2 project file |
| --- | --- |
| definition_version: 1
native_app:
  name: myapp
  source_stage: app_src.stage
  artifacts:
    - src: app/*
      dest: ./
      processors:
        - native app setup
        - name: templates
          properties:
            foo: bar
  package:
    role: pkg_role
    distribution: external
  application:
    name: myapp_app
    warehouse: app_wh
Copy | definition_version: 2
entities:
  pkg:
    type: application package
    meta:
      role: pkg_role
    identifier: <% fn.concat_ids('myapp', '_pkg_', fn.sanitize_id(fn.get_username('unknown_user')) \| lower) %>
    manifest: app/manifest.yml
    artifacts:
    - src: app/*
      dest: ./
      processors:
      - name: native app setup
      - name: templates
        properties:
          foo: bar
    stage: app_src.stage
  app:
    meta:
      warehouse: app_wh
    identifier: myapp_app
    type: application
    from:
      target: pkg
Copy |

### Native App project definition V1 to V2 property changes[¶](#native-app-project-definition-v1-to-v2-property-changes ""Link to this heading"")

| V1 property | V2 property |
| --- | --- |
| native_app.name | No equivalent. Use a template variable to port, if required. |
| native_app.deploy_root | <package entity>.deploy_root |
| native_app.generated_root | <package entity>.generated_root |
| native_app.bundle_root | <package entity>.bundle_root |
| native_app.source_stage | <package entity>.source_stage |
| native_app.scratch_stage | <package entity>.scratch_stage |
| native_app.artifacts | <package entity>.artifacts |
| native_app.application.debug | <application entity>.debug |
| native_app.application.name | <application entity>.identifier |
| native_app.application.post_deploy | <application entity>.meta.post_deploy (see above notes) |
| native_app.application.role | <application entity>.meta.role |
| native_app.application.warehouse | <application entity>.meta.warehouse |
| native_app.package.distribution | <package entity>.distribution |
| native_app.package.name | <package entity>.identifier |
| native_app.package.post_deploy | <package entity>.meta.post_deploy (see above notes) |
| native_app.package.role | <package entity>.meta.role |
| native_app.package.scripts | <package entity>.meta.post_deploy (see above notes) |
| native_app.package.warehouse | <package entity>.meta.warehouse |

### Migration tips[¶](#migration-tips ""Link to this heading"")

*   When migrating Snowflake Native App package scripts, the `v1-to-v2` command converts them to `package post-deploy` hooks and replaces `{{package_name}}` in the package script file with the equivalent template expression.
    
*   When migrating existing template expressions, `ctx.native_app`, `ctx.streamlit`, and `ctx.snowpark` variables are no longer accepted. The `v1-to-v2` command with equivalent template expressions that reference the specific entity name instead. For example, `ctx.native_app.package.name` could be replaced with `ctx.entities.pkg.identifier` if the package was migrated to an entity named `pkg` in the `snowflake.yml` file.
    

## Convert Streamlit projects[¶](#convert-streamlit-projects ""Link to this heading"")

This section shows an example from a V1 to V2 conversion of a Streamlit project, lists the changes in property names, and offers some tips to help with migration.

### Streamlit conversion example[¶](#streamlit-conversion-example ""Link to this heading"")

| V1 project file | V2 project file |
| --- | --- |
| definition_version: 1
streamlit:
  name: test_streamlit
  stage: streamlit
  query_warehouse: test_warehouse
  main_file: ""streamlit_app.py""
  title: ""My Fancy Streamlit""
Copy | definition_version: 2
entities:
  test_streamlit:
    identifier:
      name: test_streamlit
    type: streamlit
    title: My Fancy Streamlit
    query_warehouse: test_warehouse
    main_file: streamlit_app.py
    pages_dir: None
    stage: streamlit
    artifacts:
    - streamlit_app.py
Copy |

### Streamlit project definition V1 to V2 property changes[¶](#streamlit-project-definition-v1-to-v2-property-changes ""Link to this heading"")

| V1 property | V2 property |
| --- | --- |
| streamlit.name | <streamlit entity>.identifier.name |
| streamlit.schema | <streamlit entity>.identifier.schema |
| streamlit.database | <streamlit entity>.identifier.database |
| streamlit.comment | <streamlit entity>.comment |
| streamlit.title | <streamlit entity>.title |
| streamlit.query_warehouse | <streamlit entity>.query_warehouse |
| streamlit.main_file | <streamlit entity>.main_file and <streamlit entity>.artifacts |
| streamlit.stage | <streamlit entity>.stage |
| streamlit.env_file | <streamlit entity>.artifacts |
| streamlit.pages_dir | <streamlit entity>.pages_dir and <streamlit entity>.artifacts |
| streamlit.additional_source_files | <streamlit entity>.artifacts |

### Streamlit migration tips[¶](#streamlit-migration-tips ""Link to this heading"")

None.

## Convert Snowpark projects[¶](#convert-snowpark-projects ""Link to this heading"")

This section shows an example from a V1 to V2 conversion of a Snowpark project, lists the changes in property names, and offers some tips to help with migration.

### Snowpark conversion example[¶](#snowpark-conversion-example ""Link to this heading"")

| V1 project file | V2 project file |
| --- | --- |
| definition_version: 1
snowpark:
  project_name: ""my_snowpark_project""
  stage_name: ""dev_deployment""
  src: ""app/""
  functions:
    - name: func1
      handler: ""app.func1_handler""
      signature:
        - name: ""a""
          type: ""string""
          default: ""default value""
        - name: ""b""
          type: ""variant""
      returns: string
      runtime: 3.10
  procedures:
    - name: procedureName
      handler: ""hello""
      signature:
        - name: ""name""
          type: ""string""
      returns: string
Copy | definition_version: 2
entities:
  procedureName:
    imports: []
    external_access_integrations: []
    secrets: {}
    meta:
      use_mixins:
      - snowpark_shared
    identifier:
      name: procedureName
    handler: hello
    returns: string
    signature:
    - name: name
      type: string
    stage: dev_deployment
    artifacts:
    - src: app
      dest: my_snowpark_project
    type: procedure
    execute_as_caller: false
  func1:
    imports: []
    external_access_integrations: []
    secrets: {}
    meta:
      use_mixins:
      - snowpark_shared
    identifier:
      name: func1
    handler: app.func1_handler
    returns: string
    signature:
    - name: a
      type: string
      default: default value
    - name: b
      type: variant
    runtime: '3.10'
    stage: dev_deployment
    artifacts:
    - src: app
      dest: my_snowpark_project
    type: function
mixins:
  snowpark_shared:
    stage: dev_deployment
    artifacts:
    - src: app/
      dest: my_snowpark_project
Copy |

### Snowpark project definition V1 to V2 property changes[¶](#snowpark-project-definition-v1-to-v2-property-changes ""Link to this heading"")

| V1 property | V2 property |
| --- | --- |
| snowpark.project_name | <function or procedure entity>.artifacts.dest for each function and/or procedure migrated from the project. See above notes regarding Snowpark migration. Each function or procedure should declare an artifact with dest defined as the snowpark.project_name value, and src defined as the snowpark.src value. Use of a mixin is recommended. |
| snowpark.stage_name | <function or procedure entity>.stage for each function and/or procedure migrated from the project. |
| snowpark.src | <function or procedure entity>.artifacts.src for each function and/or procedure migrated from the project. (see snowpark.project_name above) |
| snowpark.functions (list) | <function entities> (top-level) |
| snowpark.procedures (list) | <procedure entities> (top-level) |

| V1 property | V2 property |
| --- | --- |
| name | identifier.name |
| schema | identifier.schema |
| database | identifier.database |
| handler | handler |
| returns | returns |
| signature | signature |
| runtime | runtime |
| external_access_integrations | external_access_integrations |
| secrets | secrets |
| imports | imports |
| execute_as_caller | execute_as_caller (only for procedures) |

### Snowpark migration tips[¶](#snowpark-migration-tips ""Link to this heading"")

*   When migrating Snowpark projects, each function (from the `snowpark.functions` array) or procedure (from the `snowpark.procedures` array) maps to a top-level entity.
    
*   All top-level Snowpark project properties (e.g. `src`) are now defined for each function and procedure. To reduce duplication, Snowflake recommends that you declare a `mixin` and include it in each of the migrated function and procedure entities.
    

On this page

1.  [Convert Native App projects](#convert-native-app-projects)
2.  [Convert Streamlit projects](#convert-streamlit-projects)
3.  [Convert Snowpark projects](#convert-snowpark-projects)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",NULL,7ae93e8fbddc4b96cff8c64c44323cebd9785bb85b9403b30e7cbff7dae05955,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/project-definitions,Project definition files¶,NULL,NULL,NULL,NULL,"# Project definition files[¶](#project-definition-files ""Link to this heading"")

A project definition file called `snowflake.yml` declares a directory as a Snowflake Native App project. It is a version-controlled file that resides at the root of a Snowflake Native App project directory and can either be created manually or by Snowflake CLI as part of project initialization. As long as you can provide this structured file in the directory but choose to use your own independent project structure, Snowflake CLI can discover the relevant files and carry out its functionality as usual.

For Native Apps, your `snowflake.yml` would look similar to the following:

```
definition_version: 2
entities:
  pkg:
    type: application package
    identifier: <name_of_app_pkg>
    stage: app_src.stage
    manifest: app/manifest.yml
    artifacts:
      - src: app/*
        dest: ./
      - src: src/module-add/target/add-1.0-SNAPSHOT.jar
        dest: module-add/add-1.0-SNAPSHOT.jar
      - src: src/module-ui/src/*
        dest: streamlit/
    meta:
      role: <your_app_pkg_owner_role>
      warehouse: <your_app_pkg_warehouse>
      post_deploy:
        - sql_script: scripts/any-provider-setup.sql
        - sql_script: scripts/shared-content.sql
  app:
    type: application
    identifier: <name_of_app>
    from:
      target: pkg
    debug: <true|false>
    meta:
      role: <your_app_owner_role>
      warehouse: <your_app_warehouse>

```

Copy

## Common entity properties[¶](#common-entity-properties ""Link to this heading"")

The following table describes common properties available for project definition entities for Native Apps. See [Specify entities](../project-definitions/specify-entities) for more information on project definition entities.

| Property | Definition |
| --- | --- |
| typerequired, string | The type of entity to manage. For Snowflake Native App, valid values include:application package. For more information about application package properties, see Application package entity properties.application. For more information about application properties, see Application entity properties. |
| identifieroptional, string | Optional Snowflake identifier for the entity, both unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (e.g. ’”My Native Application Package”’).If not specified, the entity ID in the project definition is used as the identifier. |
| meta.warehouseoptional, string | Warehouse used to run the scripts provided as part of meta.post_deploy, if any SQL commands within these scripts require use of warehouse.Default: Warehouse specified for the connection in the Snowflake CLI config.toml file.NoteIf you do not specify a warehouse, the application passes validation, but fails to install.Typically, you specify this value in the snowflake.local.yml as described in Project definition overrides. |
| meta.roleoptional, string | Role to use when creating the entity and provider-side objects.NoteIf you do not specify a role, Snowflake CLI attempts to use the default role assigned to your user in your Snowflake account.Typically, you specify this value in the snowflake.local.yml as described in Project definition overrides.Default: Role specified in the Snowflake CLI connection |
| meta.post_deployoptional, sequence | List of SQL scripts to execute after the entity has been created. The following example shows how to define these scripts in the project definition file:definition_version: 2
entities:
  myapp_pkg:
    type: application package
    ...
    meta:
      post_deploy:
        - sql_script: scripts/post_deploy1.sql
        - sql_script: scripts/post_deploy2.sql
CopyThese scripts are invoked by commands that create or update an entity. For example, running the snow app deploy command executes these scripts after creating or updating a package. They are also executed by snow app run if the application instance is not being directly installed from a version or release directive.You can also use templates in the post-deploy SQL scripts as well, as shown in the following sample script content:GRANT reference_usage on database provider_data to share in entity <% fn.str_to_id(ctx.entities.myapp_pkg.identifier) %>
Copy |
| meta.use_mixinsoptional, sequence | Names of mixins to apply to this entity. See Project mixins for more information |

## Application package entity properties[¶](#application-package-entity-properties ""Link to this heading"")

The following table describes common properties available for application package entities for Native Apps. See [Specify entities](../project-definitions/specify-entities) for more information on project definition entities.

| Property | Definition |
| --- | --- |
| typerequired, string | Must be application package. |
| manifestoptional, string | The location of the Snowflake Native App manifest.yml file in your project.NoteWith version 3.2, this property switched from required to optional. |
| deploy_rootoptional, string | Subdirectory at the root of your project where the build step copies the artifacts. Once copied to this location, you can deploy them to a Snowflake stage.Default: output/deploy |
| generated_rootoptional, string | Subdirectory of the deploy root where Snowflake CLI writes generated files.Default: __generated |
| stageoptional, string | Identifier of the stage that stores the application artifacts. The value uses the form <schema_name>.<stage_name>. The stage lives within the Application Package object. You can change the name to avoid name collisions.Default: app_src.stage |
| artifactsrequired, sequence | List of file source and destination pairs to add to the deploy root, as well as an optional Snowpark annotation processor. You can use the following artifact properties:src: Path to the code source file or filesdest: Path to the directory to deploy the artifacts.Destination paths that reference directories must end with a /. A glob pattern’s destination that does not end with a / results in an error. If omitted, dest defaults to the same string as src.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest.processors: Name of the processor to use to process the src code files. See More information about artifacts processors for more details.If src refers to just one file (not a glob), dest can refer to a target <path> or a <path/name>.You can also pass in a string for each item instead of a dict, which case, the value is treated as both src and dest.Example without a processor:pkg:
  artifacts:
    - src: app/*
      dest: ./
    - src: streamlit/*
      dest: streamlit/
    - src: src/resources/images/snowflake.png
      dest: streamlit/
CopyExample with a processor:pkg:
  artifacts:
    - src: qpp/*
      dest: ./
      processors:
          - name: snowpark
            properties:
              env:
                type: conda
                name: <conda_name>
Copy |
| distributionoptional, string | Distribution of the application package created by the Snowflake CLI. When running snow app commands, Snowflake CLI warns you if the application package you are working with has a different value for distribution than is set in your resolved project definition.Default: Internal |
| scratch_stageoptional, string | Identifier of the stage that stores temporary scratch data used by Snowflake CLI. The value uses the form <schema_name>.<stage_name>. The stage lives within the Application Package object. You can change the name to avoid name collisions.Default: app_src.stage_snowflake_cli_scratch |
| stage_subdirectoryoptional, string | Name of the folder for Snowflake CLI to add as a subdirectory under the stage to hold the artifacts specified in this Application Package Entity. If none are specified, the artifacts are uploaded to the root of the stage.Default: """" (empty string) |
| enable_release_channelsoptional, bool | Whether to enable publishing this application package in release channels.Default: Unset |

## Application entity properties[¶](#application-entity-properties ""Link to this heading"")

The following table describes common properties available for application entities for Native Apps. See [Specify entities](../project-definitions/specify-entities) for more information on project definition entities.

| Property | Definition |
| --- | --- |
| typerequired, string | Must be application. |
| from.targetrequired, string | Application package from which to create this application entity. In the following example, target defines the name of an entity in the snowflake.yml file.from:
  target: my_pkg
Copy |
| telemetry.share_mandatory_eventsoptional, boolean | Whether to enable event sharing at the application level. When this is set to true, all mandatory events are automatically shared with the application package provider.telemetry:
  share_mandatory_events: true
Copy |
| telemetry.optional_shared_eventsoptional, sequence | List of optional events to share with the provider in addition to the mandatory events. All events listed here must be declared in the configuration.telemetry_event_definitions section of the manifest.yml file. This field is supported only when share_mandatory_events is set to true.telemetry:
  share_mandatory_events: true
  optional_shared_events:
    - DEBUG_LOGS
Copy |
| debugoptional, boolean | Whether to enable debug mode when using a named stage to create an application.Default: True |

### Sharing events with providers[¶](#sharing-events-with-providers ""Link to this heading"")

Note

Snowflake CLI supports event sharing only in `snowflake.yml` files based on definition version 2 or later. If you currently use an earlier version, see [Migrating project definition files from version 1.x to 2.0](../project-definitions/migrate-projects).

[Event sharing](../../native-apps/event-definition) allows applications to send telemetry events back to application package owners. When testing an application with an application package requiring event sharing, you must explicitly enable event sharing for the application installation to succeed.

To enable sharing of specific events, you must also have the events configured in the `configuration.telemetry_event_definitions` section in the `manifest.yml` file for the application package. You must also have the MANAGE EVENT SHARING global privilege to authorize event sharing for the application.

After event sharing is enabled in your application’s manifest, you must add a `telemetry` section to your `snowflake.yml` file that specifies the events you want to share from your application. The following code shows a sample `telemetry` section:

```
definition_version: 2
entities:
  app:
    type: application
    from:
      target: pkg
    telemetry:
      share_mandatory_events: true
      optional_shared_events:
        - DEBUG_LOGS

...

```

Copy

The following examples illustrate different ways to share events in the `snowflake.yml` file. All of the examples are based on the following section in the application package’s `manifest.yml` file:

```
configuration:
    telemetry_event_definitions:
        - type: ERRORS_AND_WARNINGS
          sharing: MANDATORY
        - type: DEBUG_LOGS
          sharing: OPTIONAL

```

Copy

*   Authorize telemetry and share all mandatory events with the provider. In this case, only `ERRORS_AND_WARNINGS` events are shared.
    
    ```
    definition_version: 2
    entities:
      app:
        type: application
        from:
          target: pkg
        telemetry:
          share_mandatory_events: true
    
    ```
    
    Copy
    
*   Share both `DEBUG_LOGS` and `ERRORS_AND_WARNINGS` events with the application package provider. Setting `share_mandatory_events` to `true` enables sharing of mandatory `ERRORS_AND_WARNINGS` events, while the `optional_shared_events` section enables optional events like `DEBUG_LOGS`.
    
    ```
    definition_version: 2
    entities:
      app:
        type: application
        from:
          target: pkg
        telemetry:
          share_mandatory_events: true
          optional_shared_events:
            - DEBUG_LOGS
    
    ```
    
    Copy
    

## More information about artifacts processors[¶](#more-information-about-artifacts-processors ""Link to this heading"")

If you include the `artifacts.processors` field in the project definition file, the `snow app bundle` command invokes custom processing for Python code files in the `src` directory or file.

This section covers a list of supported processors.

### Snowpark processor[¶](#snowpark-processor ""Link to this heading"")

Note

The Snowpark processor has been deprecated and will be removed in a future release.

One of the processors supported by Snowflake CLI is `snowpark`, which applies Snowpark annotation processing to Python files. The following code examples show the basic structure and syntax for different processing environments:

*   To execute code in a conda environment, use the following:
    
    ```
    pkg:
      artifacts:
        - src: <some_src>
          dest: <some_dest>
          processors:
              - name: snowpark
                properties:
                  env:
                    type: conda
                    name: <conda_name>
    
    ```
    
    Copy
    
    where `<conda_name>` is the name of the conda environment containing the Python interpreter and the Snowpark library you want to use for Snowpark annotation processing.
    
*   To execute code in a Python virtual environment, use the following:
    
    ```
    pkg:
      artifacts:
        - src: <some_src>
          dest: <some_dest>
          processors:
              - name: snowpark
                properties:
                  env:
                    type: venv
                    path: <venv_path>
    
    ```
    
    Copy
    
    where `<venv_path>` is the path of the Python virtual environment containing the Python interpreter and the Snowpark library you want to use for Snowpark annotation processing. The path can be absolute or relative to the project directory.
    
*   To execute code in the currently active environment, use any of the following equivalent definitions:
    
    ```
    pkg:
      artifacts:
        - src: <some_src>
          dest: <some_dest>
          processors:
              - name: snowpark
                properties:
                  env:
                    type: current
    
    ```
    
    Copy
    
    or
    
    ```
    pkg:
      artifacts:
        - src: <some_src>
          dest: <some_dest>
          processors:
              - name: snowpark
    
    ```
    
    Copy
    
    or
    
    ```
    pkg:
      artifacts:
        - src: <some_src>
          dest: <some_dest>
          processors:
              - snowpark
    
    ```
    
    Copy
    

For more information about custom processing, see [Automatic SQL code generation](bundle-app.html#label-cli-nativeapp-bundle-codegen) and the [snow app bundle](../command-reference/native-apps-commands/bundle-app) command.

### Templates processor[¶](#templates-processor ""Link to this heading"")

Snowflake Native App projects support templates in arbitrary files, which lets you expand templates in all files in an artifact’s `src` directory. You can enable this feature by including a `templates` processor in the desired `artifacts` definition, as shown in the following example:

```
definition_version: 2
entities:
  pkg:
    type: application package
    identifier: myapp_pkg
    artifacts:
      - src: app/*
        dest: ./
        processors:
          - templates
    manifest: app/manifest.yml
  app:
    type: application
    identifier: myapp_<% fn.get_username() %>
    from:
      target: pkg

```

Copy

When Snowflake CLI uploads the files to a stage, it automatically expands the templates before uploading them. For example, suppose your application contained an `app/README.md` file with the following content that includes the `<% ctx.entities.pkg.identifier %>` template:

```
This is a README file for application package <% ctx.entities.pkg.identifier %>.

```

Copy

The template is then expanded to the following before uploading the file to a stage:

```
This is a README file for application package myapp_pkg.

```

Copy

## Project definition overrides[¶](#project-definition-overrides ""Link to this heading"")

Though your project directory must have a `snowflake.yml` file, you can choose to customize the behavior of the Snowflake CLI by providing local overrides to `snowflake.yml`, such as a new role to test out your own application package. These overrides must be put in the `snowflake.local.yml` file that lives beside the base project definition. Snowflake suggests that you add it to your `.gitignore` file so it won’t be version-controlled by git. All templates provided by Snowflake already include it in the `.gitignore` file.

This overrides file must live in the same location as your `snowflake.yml` file.

The `snowflake.local.yml` file shares the exact schema as `snowflake.yml`, except that every value that was required is now optional, in additional to the already optional ones. The following shows a sample `snowflake.local.yml` file:

```
entities:
  pkg:
    meta:
      role: <your_app_pkg_owner_role>
      name: <name_of_app_pkg>
      warehouse: <your_app_pkg_warehouse>
  app:
    debug: <true|false>
    meta:
      role: <your_app_owner_role>
      name: <name_of_app>
      warehouse: <your_app_warehouse>

```

Copy

Every `snow app` command prioritizes the parameters in this file over those set in base `snowflake.yml` configuration file. Sensible defaults already provide isolation between developers using the same Snowflake account to develop the same application project, so if you are just getting started we suggest not including an overrides file.

The final definition schema obtained after overriding `snowflake.yml` with `snowflake.local.yml` is called the resolved project definition.

### Limitations[¶](#limitations ""Link to this heading"")

Currently, Snowflake CLI does not support

*   Multiple override files.
    
*   A blank override file. Only create this file if you want to override a value from `snowflake.yml`.
    

On this page

1.  [Common entity properties](#common-entity-properties)
2.  [Application package entity properties](#application-package-entity-properties)
3.  [Application entity properties](#application-entity-properties)
4.  [Sharing events with providers](#sharing-events-with-providers)
5.  [More information about artifacts processors](#more-information-about-artifacts-processors)
6.  [Snowpark processor](#snowpark-processor)
7.  [Templates processor](#templates-processor)
8.  [Project definition overrides](#project-definition-overrides)
9.  [Limitations](#limitations)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)
3.  [About Snowflake Native App projects](/developer-guide/snowflake-cli/native-apps/about-projects)
4.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",NULL,d27fbcc7a454df0f0a3ad3e75270bbebe2d0e02144d1c37e512210b88f7edf6c,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/services/manage-images,Working with image registries and repositories¶,NULL,NULL,NULL,NULL,"# Working with image registries and repositories[¶](#working-with-image-registries-and-repositories ""Link to this heading"")

Snowpark Container Services provides an [OCIv2](https://github.com/opencontainers/distribution-spec/blob/main/spec.md)\-compliant image registry service and a storage unit call repository to store images. You can use the following Snowflake CLI commands to manage Snowpark Container Services image registries and repositories:

*   [Manage image registries](#label-sfcli-manage-img-registries)
    
*   [Manage image repositories](#label-sfcli-manage-img-repos)
    

For more information about Snowpark Container Services image registries and repositories, see [Snowpark Container Services: Working with an image registry and repository](../../snowpark-container-services/working-with-registry-repository).

## Manage image registries[¶](#manage-image-registries ""Link to this heading"")

Snowflake CLI lets you perform the following tasks with Snowpark Container Services image repositories:

*   [Get environment tokens for registry authentication](#label-sfcli-registry-tokens)
    
*   [Log in to an image registry](#label-sfcli-registry-login)
    
*   [Retrieve the URL for an image registry](#label-sfcli-registry-url)
    

For common operations, such as listing or dropping, Snowflake CLI uses `snow object` commands as described in [Managing Snowflake objects](../objects/manage-objects).

### Get environment tokens for registry authentication[¶](#get-environment-tokens-for-registry-authentication ""Link to this heading"")

You can use the [snow spcs image-registry token](../command-reference/spcs-commands/image-registry-commands/token) command to return the token associated with the specified connection that you can use to authenticate with the registry.

```
snow spcs image-registry token --connection mytest

```

Copy

```
+----------------------------------------------------------------------------------------------------------------------+
| key        | value                                                                                                   |
|------------+---------------------------------------------------------------------------------------------------------|
| token      | ****************************************************************************************************    |
|            | ****************************************************************************************************    |
| expires_in | 3600                                                                                                    |
+----------------------------------------------------------------------------------------------------------------------+

```

You can then use that token to log in to a Docker container by piping it to the `docker login` command, similar to the following:

```
snow spcs image-registry token --format=JSON | docker login <org>-<account>.registry.snowflakecomputing.com -u 0sessiontoken --password-stdin

```

Copy

### Log in to an image registry[¶](#log-in-to-an-image-registry ""Link to this heading"")

The [snow spcs image-registry login](../command-reference/spcs-commands/image-registry-commands/login) logs you into an image repository with the credentials specified for your connection. Before logging in, you must meet the following prerequisites:

*   [Docker Desktop](https://www.docker.com/products/docker-desktop/) must be installed because the command uses docker to log in to Snowflake.
    
*   The current role must have READ privileges for the image repository in the account to get the registry URL.
    

To log in to an image registry with your account credentials, use the following:

```
snow spcs image-registry login

```

Copy

```
Login Succeeded

```

### Retrieve the URL for an image registry[¶](#retrieve-the-url-for-an-image-registry ""Link to this heading"")

The [snow spcs image-registry url](../command-reference/spcs-commands/image-registry-commands/url) command returns a URL for an image repository. The current role must have READ privileges for the image repository in the account to get the registry URL.

To get the URL for a repository, do the following:

```
snow spcs image-registry url

```

Copy

```
<orgname-acctname>.registry.snowflakecomputing.com

```

## Manage image repositories[¶](#manage-image-repositories ""Link to this heading"")

Snowflake CLI lets you perform the following tasks with Snowpark Container Services image repositories:

*   [Create an image repository](#label-sfcli-repo-create)
    
*   [Create and deploy an image repository from a project definition](#label-sfcli-repo-pdf)
    
*   [Retrieve the URL for an image repository](#label-sfcli-repo-url)
    
*   [List tags and images in an image repository](#label-sfcli-repo-list)
    

For common operations, such as listing or dropping, Snowflake CLI uses `snow object` commands as described in [Managing Snowflake objects](../objects/manage-objects).

### Create an image repository[¶](#create-an-image-repository ""Link to this heading"")

The [snow spcs image-repository create](../command-reference/spcs-commands/image-repository-commands/create) command creates a new image repository in the current schema.

To create an image repository, enter a command similar to the following:

```
snow spcs image-repository create tutorial_repository

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

### Create and deploy an image repository from a project definition[¶](#create-and-deploy-an-image-repository-from-a-project-definition ""Link to this heading"")

You can deploy an image repository to a stage by creating a `snowflake.yml` project definition file and executing the `snow spcs image-repository deploy` command.

The following shows a sample `snowflake.yml` project definition file:

```
definition_version: 2
entities:
  my_image_repository:
    type: image-repository
    identifier: my_image_repository

```

Copy

The following table describes the properties of a compute pool project definition.

| Property | Definition |
| --- | --- |
| typerequired, string | Must be image-repository. |
| identifieroptional, string | Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-image-repository
CopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (for example, ""My Image Repository"").Objectidentifier:
  name: my-image-repository
  schema: my-schema # optional
  database: my-db # optional
CopyNoteAn error occurs if you specify a schema or database and use a fully qualified name in the name property (such as mydb.schema1.my-app). |

To create and deploy the image repository, do the following:

1.  Change your current directory to the directory containing the project definition file.
    
2.  Run a `snow spcs image-repository deploy` command similar to the following:
    
    ```
    snow spcs image-repository deploy
    
    ```
    
    Copy
    
    ```
    +---------------------------------------------------------------------+
    | key    | value                                                      |
    |--------+------------------------------------------------------------|
    | status | Image Repository MY_IMAGE_REPOSITORY successfully created. |
    +---------------------------------------------------------------------+
    
    ```
    

### Retrieve the URL for an image repository[¶](#retrieve-the-url-for-an-image-repository ""Link to this heading"")

The [snow spcs image-repository url](../command-reference/spcs-commands/image-repository-commands/url) command gets the URL for an image repository.

To get the URL, enter a command similar to the following:

```
snow spcs image-repository url tutorial_repository

```

Copy

```
<orgname-acctname>.registry.snowflakecomputing.com/tutorial_db/data_schema/tutorial_repository

```

### List tags and images in an image repository[¶](#list-tags-and-images-in-an-image-repository ""Link to this heading"")

The [snow spcs image-repository list-images](../command-reference/spcs-commands/image-repository-commands/list-images) command lets you get the images and tags for an image repository.

To list the images and tags in a repository, enter a command similar to the following, which lists the images in a repository named `images` in the `my_db` database:

```
snow spcs image-repository list-images images --database my_db

```

Copy

```
+----------------------------+---------------+---------+-------------------------------------------------+-----------------------------------------+
| created_on                 | image_name    | tags    | digest                                          | image_path                              |
|----------------------------+---------------+---------+-------------------------------------------------+-----------------------------------------|
| 2024-10-11 14:23:49-07:00  | echo_service  | latest  | sha256:a8a001fef406fdb3125ce8e8bf9970c35af7084  | my_db/test_schema/images/echo_service:  |
|                            |               |         | fc33b0886d7a8915d3082c781                       | latest                                  |
| 2024-10-14 22:21:14-07:00  | test_counter  | latest  | sha256:8cae96dac29a4a05f54bb5520003f964baf67fc  | my_db/test_schema/images/test_counter:  |
|                            |               |         | 38dcad3d2c85d6c5aa7381174                       | latest                                  |
+----------------------------+---------------+---------+-------------------------------------------------+-----------------------------------------+

```

On this page

1.  [Manage image registries](#manage-image-registries)
2.  [Get environment tokens for registry authentication](#get-environment-tokens-for-registry-authentication)
3.  [Log in to an image registry](#log-in-to-an-image-registry)
4.  [Retrieve the URL for an image registry](#retrieve-the-url-for-an-image-registry)
5.  [Manage image repositories](#manage-image-repositories)
6.  [Create an image repository](#create-an-image-repository)
7.  [Create and deploy an image repository from a project definition](#create-and-deploy-an-image-repository-from-a-project-definition)
8.  [Retrieve the URL for an image repository](#retrieve-the-url-for-an-image-repository)
9.  [List tags and images in an image repository](#list-tags-and-images-in-an-image-repository)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/services/../index)
2.  [Managing Snowpark Container Services in Snowflake CLI](/developer-guide/snowflake-cli/services/overview)
3.  [snow spcs image-registry commands](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/image-registry-commands/overview)
4.  [snow spcs image-repository commands](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/image-repository-commands/overview)
5.  [snow spcs image-repository deploy](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/image-repository-commands/deploy)",NULL,3cfc67fdd2a36c0939e4b998054a2c9c210c53ce5bba88bbdf08edef3a6f08e5,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/services/manage-compute-pools,Managing compute pools¶,NULL,NULL,NULL,NULL,"# Managing compute pools[¶](#managing-compute-pools ""Link to this heading"")

A compute pool is a collection of one or more virtual machine (VM) nodes on which Snowflake runs your Snowpark Container Services jobs and services.

For more information about compute pools, see [Snowpark Container Services: Working with compute pools](../../snowpark-container-services/working-with-compute-pool).

This topic shows how to do the following tasks with services:

*   [Create a compute pool](#label-sfcli-pool-create)
    
*   [Create a compute pool from a project definition](#label-sfcli-pool-pdf)
    
*   [Suspend and resume a compute pool](#label-sfcli-pool-suspend-resume)
    
*   [Set and unset a compute pool’s properties or parameters](#label-sfcli-pool-set-unset)
    
*   [Stop all services in a compute pool](#label-sfcli-pool-stop-all)
    

For common operations, such as listing or dropping, Snowflake CLI uses `snow object` commands as described in [Managing Snowflake objects](../objects/manage-objects).

## Create a compute pool[¶](#create-a-compute-pool ""Link to this heading"")

To create a compute pool named “pool\_1” composed of two CPUs with 4 GB of memory, enter a [spcs pool create](../command-reference/spcs-commands/compute-pool-commands/create) command similar to the following:

```
snow spcs compute-pool create ""pool_1"" --min-nodes 2 --max-nodes 2 --family ""CPU_X64_XS""

```

Copy

For more information about instance families, see the SQL `CREATE COMPUTE POOL` command.

## Create a compute pool from a project definition[¶](#create-a-compute-pool-from-a-project-definition ""Link to this heading"")

You can create a compute pool from a `snowflake.yml` project definition file and then executing the `snow spcs compute-pool deploy` command.

The following shows a sample `snowflake.yml` project definition file:

```
definition_version: 2
entities:
  my_compute_pool:
    type: compute-pool
    identifier:
      name: my_compute_pool
    min_nodes: 1
    max_nodes: 2
    instance_family: CPU_X64_XS
    auto_resume: true
    initially_suspended: true
    auto_suspend_seconds: 60
    comment: ""My compute pool""
    tags:
      - name: my_tag
        value: tag_value

```

Copy

The following table describes the properties of a compute pool project definition.

| Property | Definition |
| --- | --- |
| typerequired, string | Must be compute-pool. |
| identifieroptional, string | Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-compute-pool
CopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (for example, ""My Compute Pool"").Objectidentifier:
  name: my-compute-pool
  schema: my-schema # optional
  database: my-db # optional
CopyNoteAn error occurs if you specify a schema or database and use a fully qualified name in the name property (such as mydb.schema1.my-app). |
| instance_familyrequired, string | Name of the instance family. For a list of available instance families, see the CREATE COMPUTE POOL INSTANCE_FAMILY parameter. |
| min_nodesoptional, string | Minimum number of nodes for the compute pool. This value must be greater than 0.Default: 1 |
| max_nodesoptional, int | Maximum number of nodes for the compute pool. |
| auto_resumeoptional, boolean | Whether to automatically resume a compute pool when a service or job is submitted to it.Default: True |
| initially_suspendedoptional, boolean | Whether the compute pool is created initially in the suspended state. If true, Snowflake doesn’t provision any nodes requested for the compute pool at the compute pool creation time.Default: False |
| auto_suspend_secondsoptional, int | Number of seconds of inactivity after which you want Snowflake to automatically suspend the compute pool.Default: 3600 |
| commentoptional, string | Comments to associate with the compute pool. |
| tagsoptional, Tag sequence | Tag names and values for the compute pool. For more information, see Tag quotas |

To create and deploy the compute pool to a stage, do the following:

1.  Change your current directory to the directory containing the project definition file.
    
2.  Run a `snow spcs compute-pool deploy` command similar to the following:
    
    ```
    snow spcs compute-pool deploy
    
    ```
    
    Copy
    
    ```
    +---------------------------------------------------------------------+
    | key    | value                                                      |
    |--------+------------------------------------------------------------|
    | status | Compute pool MY_COMPUTE_POOL successfully created.         |
    +---------------------------------------------------------------------+
    
    ```
    

## Suspend and resume a compute pool[¶](#suspend-and-resume-a-compute-pool ""Link to this heading"")

Note

The current role must have OPERATE privilege on the compute pool to suspend or resume it.

To suspend a compute pool, enter a command similar to the following:

```
snow spcs compute-pool suspend tutorial_compute_pool

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

To resume a suspended compute pool, enter a command similar to the following:

```
snow spcs compute-pool resume tutorial_compute_pool

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

## Set and unset a compute pool’s properties or parameters[¶](#set-and-unset-a-compute-pool-s-properties-or-parameters ""Link to this heading"")

Note

The current role must have MODIFY privilege on the compute pool to set properties.

To set a property or parameter, enter a command similar to the following:

```
snow spcs compute-pool set tutorial_compute_pool --min-nodes 2 --max-nodes 4

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

To reset a property or parameter to its default value, enter a command similar to the following:

```
snow spcs compute-pool unset tutorial_compute_pool --auto-resume

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

## Stop all services in a compute pool[¶](#stop-all-services-in-a-compute-pool ""Link to this heading"")

Stopping a compute pool deletes all of the services running on the compute pool; however, it does not stop the compute pool itself.

To stop a compute pool, enter a [spcs compute-pool stop-all](../command-reference/spcs-commands/compute-pool-commands/stop-all) command similar to the following:

```
snow spcs compute-pool stop-all ""pool_1""

```

Copy

On this page

1.  [Create a compute pool](#create-a-compute-pool)
2.  [Create a compute pool from a project definition](#create-a-compute-pool-from-a-project-definition)
3.  [Suspend and resume a compute pool](#suspend-and-resume-a-compute-pool)
4.  [Set and unset a compute pool’s properties or parameters](#set-and-unset-a-compute-pool-s-properties-or-parameters)
5.  [Stop all services in a compute pool](#stop-all-services-in-a-compute-pool)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/services/../index)
2.  [Managing Snowpark Container Services in Snowflake CLI](/developer-guide/snowflake-cli/services/overview)
3.  [snow spcs compute-pool commands](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/compute-pool-commands/overview)
4.  [snow spcs compute-pool deploy](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/compute-pool-commands/deploy)
5.  [Snowpark Container Services: Working with compute pools](/developer-guide/snowflake-cli/services/../../snowpark-container-services/working-with-compute-pool)
6.  [CREATE COMPUTE POOL](/developer-guide/snowflake-cli/services/../../../sql-reference/sql/create-compute-pool)",NULL,e6839a435c09321fa4c53fe507e3d174748e60da1c4555a0e03c367c31ea2774,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/services/manage-services,Managing services¶,NULL,NULL,NULL,NULL,"# Managing services[¶](#managing-services ""Link to this heading"")

Snowpark Container Services enables you to easily deploy, manage, and scale containerized applications. After you upload your application image to a repository in your account, you run your application containers as a service or a job. This topic explains working with services.

A service is long-running, like a web service, and does not end on its own. Snowflake manages running services. For example, if a service container exits, for whatever reason, Snowflake restarts that container so the service runs uninterrupted. If your service needs more resources, such as more compute power, Snowflake provisions additional nodes in the compute pool.

For more information about working with container services, see [Snowpark Container Services: Working with services](../../snowpark-container-services/working-with-services).

This topic shows how to do the following tasks with services:

*   [Create a Snowpark Container Services service](#label-sfcli-service-create)
    
*   [Create and deploy a service from a project definition](#label-sfcli-service-pdf)
    
*   [Suspend and resume a service](#label-sfcli-service-suspend-resume)
    
*   [Get status information about a service](#label-sfcli-service-status)
    
*   [List the endpoints in a service](#label-sfcli-service-endpoints)
    
*   [Set and unset a service’s properties or parameters](#label-sfcli-service-set-unset)
    
*   [Display logs for a named service](#label-sfcli-service-logs)
    
*   [Upgrade a named service](#label-sfcli-service-upgrade)
    

For common operations, such as listing or dropping, Snowflake CLI uses `snow object` commands as described in [Managing Snowflake objects](../objects/manage-objects).

## Create a Snowpark Container Services service[¶](#create-a-snowpark-container-services-service ""Link to this heading"")

A Snowpark container service requires the following:

*   **A compute pool**: Snowflake runs your service in the specified compute pool.
    
*   **A service specification file**: This specification gives Snowflake the information needed to configure and run your service.
    

To create a service, enter a [snow spcs service create](../command-reference/spcs-commands/service-commands/create) command similar to the following:

```
snow spcs service create ""job_1"" --compute-pool ""pool_1"" --spec-path ""/some-dir/spec_file.yaml""

```

Copy

For more information, see [Managing Snowflake objects](../objects/manage-objects).

### Create and deploy a service from a project definition[¶](#create-and-deploy-a-service-from-a-project-definition ""Link to this heading"")

You can create a service from a `snowflake.yml` project definition file and then executing the `snow spcs service deploy` command.

The following shows a sample `snowflake.yml` project definition file:

```
definition_version: 2
entities:
  my_service:
    type: service
    identifier: my_service
    stage: my_stage
    compute_pool: my_compute_pool
    spec_file: spec.yml
    min_instances: 1
    max_instances: 2
    query_warehouse: my_warehouse
    auto_resume: true
    external_access_integrations:
      - my_external_access
    secrets:
        cred: my_cred_name
    artifacts:
      - spec.yml
    comment: ""My service""
    tags:
      - name: test_tag
        value: test_value

```

Copy

The following table describes the properties of a compute pool project definition.

| Property | Definition |
| --- | --- |
| typerequired, string | Must be service. |
| stagerequired, string | Stage where the service specification file is located. |
| compute_poolrequired, string | Compute pool where the service runs. |
| spec_filerequired, string | Path to service specification file on the stage. |
| identifieroptional, string | Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-service
CopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (for example, ’”My Image Repository"").Objectidentifier:
  name: my-service
  schema: my-schema # optional
  database: my-db # optional
CopyNoteAn error occurs if you specify a schema or database and use a fully qualified name in the name property (such as mydb.schema1.my-app). |
| min_instancesoptional, string | Minimum number of service instances to run.Default: 1 |
| max_instancesoptional, string | Maximum number of service instances to run. |
| query_warehouseoptional, string | Warehouse to use if a service container connects to Snowflake to execute a query without explicitly specifying a warehouse to use. |
| auto_resumeoptional, string | Whether to automatically resume when a service function or ingress is called.Default: True |
| external_access_integrationsoptional, string sequence | Names of external access integrations needed for this entity to access external networks. |
| secretsoptional, dictionary | Names and values of secrets variables so that you can use the variables to reference the secrets. |
| artifactsoptional, string sequence | List of file source and destination pairs to add to the deploy root. You can use the following artifact properties:src: Path to the code source file or filesdest: Path to the directory to deploy the artifacts.Destination paths that reference directories must end with a /. A glob pattern’s destination that does not end with a / results in an error. If omitted, dest defaults to the same string as src.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest.If src refers to just one file (not a glob), dest can refer to a target <path> or a <path/name>.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest. |
| commentoptional, string | Comments to associate with the compute pool. |
| tagsoptional, Tag sequence | Tag names and values for the compute pool. For more information, see Tag quotas |

To create and deploy a service, do the following:

1.  Change your current directory to the directory containing the project definition file.
    
2.  Run a `snow spcs service deploy` command similar to the following:
    
    ```
    snow spcs service deploy
    
    ```
    
    Copy
    
    ```
    +---------------------------------------------------------------------+
    | key    | value                                                      |
    |--------+------------------------------------------------------------|
    | status | Service MY_SERVICE successfully created.                   |
    +---------------------------------------------------------------------+
    
    ```
    

## Suspend and resume a service[¶](#suspend-and-resume-a-service ""Link to this heading"")

To suspend a named service, enter a [snow spcs service suspend](../command-reference/spcs-commands/service-commands/suspend) command similar to the following:

```
snow spcs service suspend echo_service

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

To resume a suspended service, enter a [snow spcs service resume](../command-reference/spcs-commands/service-commands/resume) command similar to the following:

```
snow spcs service resume echo_service

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

## Get status information about a service[¶](#get-status-information-about-a-service ""Link to this heading"")

Note

The current role must have MONITOR privilege on the service to get its status.

### List all services[¶](#list-all-services ""Link to this heading"")

The [snow spcs service list](../command-reference/spcs-commands/service-commands/list) command returns an overview of all services, including the runtime state of the services, such as PENDING or RUNNING, and the upgrading status. To get the status of all services, enter a command similar to the following:

```
snow spcs service list

```

Copy

```
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|        |        |        |        |        |        |        |        |        |        |        |         | extern |         |        |         |        |         |        |        |         |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         | al_acc |         |        |         |        |         |        |        |         |        | managin | managi |
|        |        | databa |        |        |        |        | curren | target | min_in | max_in |         | ess_in |         |        |         |        | owner_r | query_ |        |         |        | g_objec | ng_obj |
|        |        | se_nam | schema |        | comput | dns_na | t_inst | _insta | stance | stance | auto_re | tegrat | created | update | resumed | commen | ole_typ | wareho |        | spec_di | is_upg | t_domai | ect_na |
| name   | status | e      | _name  | owner  | e_pool | me     | ances  | nces   | s      | s      | sume    | ions   | _on     | d_on   | _on     | t      | e       | use    | is_job | gest    | rading | n       | me     |
|--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+--------+---------+--------+---------+--------+---------+--------+--------+---------+--------+---------+--------|
| ECHO_S | RUNNIN | TEST00 | TEST_S | SYSADM | TUTORI | echo-s | 1      | 1      | 1      | 1      | true    | None   | 2024-10 | 2024-1 | None    | This   | ROLE    | COMPUT | false  | 52e62d1 | false  | None    | None   |
| ERVICE | G      | _DB    | CHEMA  | IN     | AL_COM | ervice |        |        |        |        |         |        | -16     | 0-16   |         | is a   |         | E_WH   |        | f19c720 |        |         |        |
|        |        |        |        |        | PUTE_P | .imhd. |        |        |        |        |         |        | 15:09:3 | 15:09: |         | test   |         |        |        | 6b5f4ef |        |         |        |
|        |        |        |        |        | OOL    | svc.sp |        |        |        |        |         |        | 0.49300 | 31.905 |         | servic |         |        |        | c069557 |        |         |        |
|        |        |        |        |        |        | cs.int |        |        |        |        |         |        | 0-07:00 | 000-07 |         | e      |         |        |        | 8b6c2b3 |        |         |        |
|        |        |        |        |        |        | ernal  |        |        |        |        |         |        |         | :00    |         |        |         |        |        | 806ad76 |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 67d78cc |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | ce8b6ed |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 6501a8a |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 3       |        |         |        |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```

### Get the status of a named service[¶](#get-the-status-of-a-named-service ""Link to this heading"")

To get the status of an individual service, enter a [snow spcs service describe](../command-reference/spcs-commands/service-commands/describe) command similar to the following:

```
snow spcs service describe echo_service

```

Copy

```
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|        |        |        |        |        |        |        |        |        |        |        |         | extern |         |        |         |        |         |        |        |         |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         | al_acc |         |        |         |        |         |        |        |         |        | managin | managi |
|        |        | databa |        |        |        |        | curren | target | min_in | max_in |         | ess_in |         |        |         |        | owner_r | query_ |        |         |        | g_objec | ng_obj |
|        |        | se_nam | schema |        | comput | dns_na | t_inst | _insta | stance | stance | auto_re | tegrat | created | update | resumed | commen | ole_typ | wareho |        | spec_di | is_upg | t_domai | ect_na |
| name   | status | e      | _name  | owner  | e_pool | me     | ances  | nces   | s      | s      | sume    | ions   | _on     | d_on   | _on     | t      | e       | use    | is_job | gest    | rading | n       | me     |
|--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+--------+---------+--------+---------+--------+---------+--------+--------+---------+--------+---------+--------|
| ECHO_S | RUNNIN | TEST00 | TEST_S | SYSADM | TUTORI | echo-s | 1      | 1      | 1      | 1      | true    | None   | 2024-10 | 2024-1 | None    | This   | ROLE    | COMPUT | false  | 52e62d1 | false  | None    | None   |
| ERVICE | G      | _DB    | CHEMA  | IN     | AL_COM | ervice |        |        |        |        |         |        | -16     | 0-16   |         | is a   |         | E_WH   |        | f19c720 |        |         |        |
|        |        |        |        |        | PUTE_P | .imhd. |        |        |        |        |         |        | 15:09:3 | 15:09: |         | test   |         |        |        | 6b5f4ef |        |         |        |
|        |        |        |        |        | OOL    | svc.sp |        |        |        |        |         |        | 0.49300 | 31.905 |         | servic |         |        |        | c069557 |        |         |        |
|        |        |        |        |        |        | cs.int |        |        |        |        |         |        | 0-07:00 | 000-07 |         | e      |         |        |        | 8b6c2b3 |        |         |        |
|        |        |        |        |        |        | ernal  |        |        |        |        |         |        |         | :00    |         |        |         |        |        | 806ad76 |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 67d78cc |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | ce8b6ed |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 6501a8a |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 3       |        |         |        |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```

### List instances and containers[¶](#list-instances-and-containers ""Link to this heading"")

You can list service’s instances and containers with the `snow spcs service list-instances` and `snow spcs service list-containers` commands, respectively.

To get the list of instances in the `echo_service` service, enter the following [snow spcs service list-instances](../command-reference/spcs-commands/service-commands/list-instances) command:

```
snow spcs service list-instances echo_service

```

Copy

```
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| database_name | schema_name | service_name | instance_id | status | spec_digest                                                      | creation_time        | start_time           |
|---------------+-------------+--------------+-------------+--------+------------------------------------------------------------------+----------------------+----------------------|
| TEST00_DB     | TEST_SCHEMA | ECHO_SERVICE | 0           | READY  | 336c065739dd2b96e770f01804affdc7810e6df68a23b23052d851627abfbdf9 | 2024-10-10T06:06:30Z | 2024-10-10T06:06:30Z |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```

To get the list of containers in the `echo_service` service, enter the following [snow spcs service list-containers](../command-reference/spcs-commands/service-commands/list-containers) command:

```
snow spcs service list-containers echo_service

```

Copy

```
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| database_name | schema_name | service_name | instance_id | container_name | status | message | image_name                                | image_digest                              | restart_count | start_time           |
|---------------+-------------+--------------+-------------+----------------+--------+---------+-------------------------------------------+-------------------------------------------+---------------+----------------------|
| TEST00_DB     | TEST_SCHEMA | ECHO_SERVICE | 0           | main           | READY  | Running | org-test-account-00.registry.registry.sno | sha256:06c3d54edc24925abe398eda70d37eb6b8 | 0             | 2024-10-16T22:09:35Z |
|               |             |              |             |                |        |         | wflakecomputing.com/test00_db/test_schema | 7b1c4dd6211317592764e1e7d94498            |               |                      |
|               |             |              |             |                |        |         | /test00_repo/echo_service:latest          |                                           |               |                      |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```

### List the endpoints in a service[¶](#list-the-endpoints-in-a-service ""Link to this heading"")

To list the endpoints a named service, enter a [snow spcs service list-endpoints](../command-reference/spcs-commands/service-commands/list-endpoints) command similar to the following:

```
snow spcs service list-endpoints echo_service

```

Copy

```
+--------------+------+----------+-----------------+-----------------------------------------+
| name         | port | protocol | ingress_enabled | ingress_url                             |
|--------------+------+----------+-----------------+-----------------------------------------|
| echoendpoint | 8000 | TCP      | true            | org-id-acct-id.snowflakecomputing.app   |
+--------------+------+----------+-----------------+-----------------------------------------+

```

### List the service roles associated with a service[¶](#list-the-service-roles-associated-with-a-service ""Link to this heading"")

You can manage access to individual endpoints exposed by a service by defining service roles and permissions in the service specification. For more information about how to use service roles, see [GRANT SERVICE ROLE](../../../sql-reference/sql/grant-service-role).

To get a list of service roles created for a service, use the [snow spcs service list-roles](../command-reference/spcs-commands/service-commands/list-roles) command, as shown:

```
snow spcs service list-roles my_service

```

Copy

```
+------------------------------------------------------------------+
| created_on                       | name                | comment |
|----------------------------------+---------------------+---------|
| 2024-10-09 16:48:52.980000-07:00 | ALL_ENDPOINTS_USAGE | None    |
+------------------------------------------------------------------+

```

## Set and unset a service’s properties or parameters[¶](#set-and-unset-a-service-s-properties-or-parameters ""Link to this heading"")

Note

The current role must have OPERATE privilege on the service to set properties.

To set a service’s property or parameter, enter a [snow spcs service set](../command-reference/spcs-commands/service-commands/set) command similar to the following:

```
snow spcs service set echo_service --min-instances 2 --max-instances 4

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

To reset a service’s property or parameter to its default value, enter a command similar to the following:

```
snow spcs compute-pool unset tutorial_compute_pool --auto-resume

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

## Display logs for a named service[¶](#display-logs-for-a-named-service ""Link to this heading"")

Note

The current role must have MONITOR privilege on the service to display logs.

To display local logs for a named service, enter a [snow spcs service logs](../command-reference/spcs-commands/service-commands/logs) command similar to the following:

```
snow spcs service logs ""service_1"" --container-name ""container_1"" --instance-id ""0""

```

Copy

## Upgrade a named service[¶](#upgrade-a-named-service ""Link to this heading"")

Note

The current role must have OPERATE privilege on the service to upgrade it.

To upgrade a named service, enter a [snow spcs service upgrade](../command-reference/spcs-commands/service-commands/upgrade) command similar to the following:

```
snow spcs service upgrade echo_service --spec-path spec.yml

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

On this page

1.  [Create a Snowpark Container Services service](#create-a-snowpark-container-services-service)
2.  [Suspend and resume a service](#suspend-and-resume-a-service)
3.  [Get status information about a service](#get-status-information-about-a-service)
4.  [Set and unset a service’s properties or parameters](#set-and-unset-a-service-s-properties-or-parameters)
5.  [Display logs for a named service](#display-logs-for-a-named-service)
6.  [Upgrade a named service](#upgrade-a-named-service)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/services/../index)
2.  [Managing Snowpark Container Services in Snowflake CLI](/developer-guide/snowflake-cli/services/overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/overview)
4.  [snow spcs service commands](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/service-commands/overview)
5.  [snow spcs service deploy](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/service-commands/deploy)
6.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/services/../../snowpark-container-services/working-with-services)",NULL,330bf0cfc7fe5488b6bb28a48ae6e3045347e55a24c01478da6bedfa39e27eb0,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/initialize-app,Creating a Streamlit app¶,NULL,NULL,NULL,NULL,"# Creating a Streamlit app[¶](#creating-a-streamlit-app ""Link to this heading"")

## Prerequisites[¶](#prerequisites ""Link to this heading"")

Before creating a Streamlit app with Snowflake CLI, you should meet the following prerequisites:

*   Ensure that your account has the correct privileges as described in [Privileges required to create and use a Streamlit app](../../../streamlit/object-management/privileges).
    
*   Ensure that you can create or have access to a named stage where you can upload your Streamlit app files.
    

## Bootstrap a Streamlit app[¶](#bootstrap-a-streamlit-app ""Link to this heading"")

The `snow init` command creates a local directory with a sample set of files that help you get started creating a Streamlit app. When you execute this command, Snowflake CLI creates the following directory structure:

```
example_streamlit/            - project name (default: example_streamlit)
  snowflake.yml               - configuration for snow streamlit commands
  environment.yml             - additional config for Streamlit, for example installing packages
  streamlit_app.py            - entrypoint file of the app
  pages/                      - directory name for Streamlit pages (default pages)
  common/                     - example “shared library”

```

To initialize a Streamlit app, enter the following command:

```
snow init new_streamlit_project --template example_streamlit -D query_warehouse=dev_warehouse -D stage=testing

```

Copy

Caution

Files inside a project directory are processed by Snowflake CLI and could be uploaded to Snowflake when executing other `snow streamlit` commands. You should use caution when putting any sensitive information inside files in a project directory.

For more information about the file structure, see [Optional: Create the Streamlit files on your local file system](../../../streamlit/getting-started/create-streamlit-sql.html#label-streamlit-create-app-files).

## Create the project definition for a Streamlit app[¶](#create-the-project-definition-for-a-streamlit-app ""Link to this heading"")

Each Streamlit app in Snowflake must include a `snowflake.yml` project definition file. Streamlit is limited to one application per project definition file.

The following shows a sample `snowflake.yml` project definition file:

```
definition_version: 2
entities:
  my_streamlit:
    type: streamlit
    identifier: streamlit_app
    stage: my_streamlit_stage
    query_warehouse: my_streamlit_warehouse
    main_file: streamlit_app.py
    pages_dir: pages/
    external_access_integrations:
      - test_egress
    secrets:
      dummy_secret: ""db.schema.dummy_secret""
    imports:
      - ""@my_stage/foo.py""
    artifacts:
      - common/hello.py
      - environment.yml
    grants:
      - privilege: USAGE
        role: streamlit_role

```

Copy

The following table describes the properties of a Streamlit project definition.

| Property | Definition |
| --- | --- |
| identifieroptional, string | Optional Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-streamlit-id
CopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (e.g. ’”My Streamlit Application”’).Objectidentifier:
  name: my-streamlit-id
  schema: my-schema # optional
  database: my-db # optional
CopyNoteAn error occurs if you specify a schema or database and use a fully-qualified name in the name property (such as mydb.schema1.my-app). |
| typeoptional, string | Must be streamlit. |
| commentoptional, string | Comment for the Streamlit dashboard. |
| titleoptional, string | Human-readable title for the Streamlit dashboard. |
| stageoptional, string | Stage in which the app’s artifacts will be stored. Default: None. |
| query_warehouserequired, string | Snowflake warehouse to host the app. |
| main_fileoptional, string | Entrypoint file of the streamlit app. Default: “streamlit_app.py”. |
| pages_diroptional, string | Streamlit pages. Default: “pages”. |
| external_access_integrationsoptional, string sequence | Names of external access integrations needed for this Streamlit application code to access external networks. See the optional parameters for CREATE STREAMLIT for more details. |
| secretsoptional, dictionary | Assigns the names of secrets to variables so that you can use the variables to reference the secrets when retrieving information from secrets in application code. |
| importsoptional, string sequence | Stage and path to previously uploaded files you want to import. See the optional parameters for CREATE STREAMLIT for more details. |
| artifactsrequired, string sequence | List of file source and destination pairs to add to the deploy root. You can use the following artifact properties:src: Path to the code source file or files.dest: Path to the directory to deploy the artifacts.Destination paths that reference directories must end with a /. A glob pattern’s destination that does not end with a / results in an error. If omitted, dest defaults to the same string as src.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest.If src refers to just one file (not a glob), dest can refer to a target <path> or a <path/name>.You can also pass in a string for each item instead of a dict; in that case, the value is treated as both src and dest. |
| grantsoptional, grant sequence | Grants that should be given for the Streamlit app. Each grant must specify the privilege and target role. For more details, see the optional parameters for CREATE STREAMLIT. |

On this page

1.  [Prerequisites](#prerequisites)
2.  [Bootstrap a Streamlit app](#bootstrap-a-streamlit-app)
3.  [Create the project definition for a Streamlit app](#create-the-project-definition-for-a-streamlit-app)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../index)
2.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)
3.  [snow init](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/bootstrap-commands/init)",NULL,775ddc827880d39484e67b9f709d612d7af33b1a74f899fc26a5f10a521485d6,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/initialize,Initialize a Snowpark project¶,NULL,NULL,NULL,NULL,"# Initialize a Snowpark project[¶](#initialize-a-snowpark-project ""Link to this heading"")

The first step when creating Snowpark projects is to create a project boilerplate. The `snow init` command creates a fully-functional boilerplate with the following structure:

```
snowflake.yml      - project definition
requirements.txt   - project dependencies
app/               - code of functions and procedures
  __init__.py
  functions.py     - example functions
  procedures.py    - example procedures
  common.py        - example ""shared library""

```

*   The `snowflake.yml` file contains a [project definition](../project-definitions/about) that describes the project structure that the `snow snowpark` commands use.
    
*   The `app` directory stores the project code. You can think about it as a Python module. All functions and procedures must reside in this directory.
    
*   The `requirements.txt` file contains project dependencies. Snowflake CLI supports all requirement specifiers supported by `pip`, such as a package name, a URL for a package, or a local path.
    
    You can add more dependencies (such as previously deployed custom packages) as `imports` parameters in the function and procedure declarations in the [project definition](../project-definitions/about).
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)
3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)
4.  [snow init](/developer-guide/snowflake-cli/snowpark/../command-reference/bootstrap-commands/init)
5.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",NULL,69df207355f0123dc670ff1a15856b71cae8438c5696238996e2c424e5be383a,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/create,Create a Snowpark project definition¶,NULL,NULL,NULL,NULL,"# Create a Snowpark project definition[¶](#create-a-snowpark-project-definition ""Link to this heading"")

The `snowflake.yml` file contains the functions and procedures declarations for a Snowpark project.

Note

Currently, the Snowpark project definition file must be named `snowflake.yml`.

The following snippet shows a sample Snowpark project definition file: with two functions and two procedures. The `hello_function` function uses external capabilities of Snowpark.

```
definition_version: '2'

mixins:
  snowpark_shared:
    artifacts:
      - dest: my_snowpark_project
        src: app/
    stage: dev_deployment

entities:

  hello_function:
    type: function
    identifier:
      name: hello_function
    handler: functions.hello_function
    signature:
      - name: name
        type: string
    returns: string
    external_access_integrations:
      - my_external_access
    secrets:
        cred: my_cred_name
    meta:
      use_mixins:
        - snowpark_shared

  hello_procedure:
    type: procedure
    identifier:
      name: hello_procedure
    handler: procedures.hello_procedure
    signature:
      - name: name
        type: string
    returns: string
    meta:
      use_mixins:
        - snowpark_shared

  test_procedure:
    type: procedure
    identifier:
      name: test_procedure
    handler: procedures.test_procedure
    signature: ''
    returns: string
    meta:
      use_mixins:
        - snowpark_shared

```

Copy

Caution

Files inside a project directory are processed by Snowflake CLI and could be uploaded to Snowflake when executing other `snow snowpark` commands. You should use caution when putting any sensitive information inside files in a project directory.

## Function and procedure object properties[¶](#function-and-procedure-object-properties ""Link to this heading"")

The following table describes the properties used by functions and procedures.

| Property | Definition |
| --- | --- |
| identifieroptional, string | Optional Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-snowpark-id
CopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (e.g. ’”My Snowpark Function”’).Objectidentifier:
  name: my-snowpark-id
  schema: my-schema # optional
  database: my-db # optional
CopyNoteAn error occurs if you specify a schema or database and use a fully-qualified name in the name property (such as mydb.schema1.my-app). |
| typeoptional, string | Must be one of: function or procedure. |
| artifact_repositoryoptional, string | Name of the artifact repository. Snowflake has a default artifact repository called snowflake.snowpark.pypi_shared_repository that you use to connect and install PyPI packages within Snowpark UDFs and procedures. For more information, see Artifact Repository overview.The artifact_repository and packages parameters let you use non-anaconda packages, similar to the following:In the project’s app.py file, you can define a function like the following:from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

def udf():
  X, y = load_iris(return_X_y=True)
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

  model = RandomForestClassifier()
  model.fit(X_train, y_train)
  return model.score(X_test, y_test)
CopyIn the snowflake.yml file, you would then define it like the following:test_function:
  type: ""function""
  handler: ""app.udf""
  identifier:
    - name: ""udf""
  stage: ""dev_deployment""
  signature: """"
  returns: float
  artifact_repository: snowflake.snowpark.pypi_shared_repository
  packages:
    - ""scikit-learn""
  artifacts: ""app.py""
CopyFor packages that depend on specific architectures, you can define them in the resource_constraint parameter as follows:test_function:
   type: ""function""
   handler: ""app.udf""
   identifier:
     - name: ""udf""
   stage: ""dev_deployment""
   signature: """"
   returns: float
   artifact_repository: snowflake.snowpark.pypi_shared_repository
   packages:
     - ""scikit-learn""
   artifacts: ""app.py""
CopyFor more information, see Packages built only for x86. |
| artifact_repository_packagesoptional, string | NoteThis property has been deprecated in favor of the packages property. |
| packagesoptional, string | List of packages to install from the artifact_repository. For example:artifact_repository: snowflake.snowpark.pypi_shared_repository
packages:

  - Faker
  - rich
  - pytest
Copy |
| artifactsrequired, string sequence | List of file source and destination pairs to add to the deploy root. You can use the following artifact properties:src: Path to the code source file or filesdest: Path to the directory to deploy the artifacts.Destination paths that reference directories must end with a /. A glob pattern’s destination that does not end with a / results in an error. If omitted, dest defaults to the same string as src.NoteUsing glob patterns in Snowpark snowflake.yml files requires enabling the ENABLE_SNOWPARK_GLOB_SUPPORT feature flag.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest.If src refers to just one file (not a glob), dest can refer to a target <path> or a <path/name>.You can also pass in a string for each item instead of a dict, which case, the value is treated as both src and dest. |
| handlerrequired, string | Function’s or procedure’s implementation of the object inside module defined in snowpark.src. For example functions.hello_function refers to function hello_function from file <src>/functions.py. |
| returnsrequired, string | SQL type of the result. Check the list of available types. |
| signaturerequired, sequence | The signature parameter describes consecutive arguments passed to the object. Each should specify its name and type, for example:signature:
  - name: ""first_argument""
    type: int
  - name: ""second_argument""
    default: ""default value""
    type: string
CopyIf a function or procedure takes no arguments, set this value to an empty string (signature: """").Check the SQL Type column of available types. To learn more about the syntax of named and optional arguments, see Calling a UDF that has optional arguments. |
| runtimeoptional, string | Python version to use when executing the procedure or function. Default: “3.12”. |
| external_access_integrationsoptional, string sequence | Names of external access integrations needed for this procedure’s handler code to access external networks. See the EXTERNAL_ACCESS_INTEGRATIONS parameter in CREATE PROCEDURE for more details. |
| secretsoptional, dictionary | Assigns the names of secrets to variables so that you can use the variables to reference the secrets when retrieving information from secrets in handler code. See the SECRETS parameter in CREATE PROCEDURE for more details. |
| importsoptional, string sequence | Stage and path to previously uploaded files you want to import. See the IMPORT parameter in CREATE PROCEDURE for more details. |
| execute_as_calleroptional, bool | Available only for procedures. Determine whether the procedure is executed with the privileges of the owner (you) or with the privileges of the caller. Default: False (owner’s privileges). |

On this page

1.  [Function and procedure object properties](#function-and-procedure-object-properties)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)
3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)
4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",NULL,5b83183145bfea6a043003fdf056cc3406588df0135c04def6d03d6f88a0bb92,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/build,Build a Snowpark project¶,NULL,NULL,NULL,NULL,"# Build a Snowpark project[¶](#build-a-snowpark-project ""Link to this heading"")

The `snow snowpark build` command builds the Snowpark project as one or more `.zip` archive files that can be used by the `deploy` command. The cp,,amd builds the archives using only the `src` directory specified in the project file.

```
snow snowpark build

```

Copy

```
Resolving dependencies from requirements.txt
  No external dependencies.
Preparing artifacts for source code
  Creating: app.zip
Build done.

```

Additional options:

*   `--allow-shared-libraries`: Allows shared (`.so`/`.dll`) libraries, when using packages installed through `pip`.
    
*   `--ignore-anaconda`: Does not lookup packages on Snowflake Anaconda channel.
    
*   `--index-url`: Specifies the base URL of the Python Package Index to use for package lookup. This URL should point to a repository compliant with PEP 503 (the simple repository API) or a local directory laid out in the same format.
    
*   `--skip-version-check`: Skips comparing versions of dependencies between requirements and Anaconda.
    
*   `--project [-p]`: Specifies the path where the Snowpark project resides. Defaults to the current working directory.
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)
3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)
4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",NULL,4a7a12afa7e48bcc83a1cd53fb6ee3063bd58bcd3203195790efdd6189d51265,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/deploy,Deploy a Snowpark project¶,NULL,NULL,NULL,NULL,"# Deploy a Snowpark project[¶](#deploy-a-snowpark-project ""Link to this heading"")

The `snow snowpark deploy` command uploads local files to the specified stage and creates procedure and function objects defined in the project. Deploying the project alters all objects defined in it. By default, if any of the objects exist already the commands fails unless you provide the `--replace` option. All deployed objects use the same artifact, which is uploaded only once.

```
snow snowpark deploy

```

Copy

```
+-------------------------------------------------------------+
| object                       | type      | status           |
|------------------------------+-----------+------------------|
| hello_procedure(name string) | procedure | created          |
| test_procedure()             | procedure | packages updated |
| hello_function(name string)  | function  | created          |
+-------------------------------------------------------------+

```

When you run `snow snowpark deploy`, the command does the following:

1.  Snowflake CLI checks whether any of the defined objects (functions or procedures) already exists.
    
2.  If any exist and the `--replace` flag is not provided, the command exits. The reasoning behind this approach is to be “production-safe” by avoiding unintentional changes to existing objects.
    
3.  If all objects don’t exist or `--replace` is provided, the command:
    
    *   If the `--prune` flag is provided, all previous contents of the stages used by defined procedure and function objects are removed.
        
    *   Uploads the new zip artifacts.
        
    *   Updates definitions of every procedure.
        
    *   Updates definitions of every function.
        

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)
3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)
4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",NULL,c4089d6e64cf38fbe17810e68cafbee5af64296c06c361f40257ffcc5e6e192f,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/execute,Execute a Snowpark procedure or function¶,NULL,NULL,NULL,NULL,"# Execute a Snowpark procedure or function[¶](#execute-a-snowpark-procedure-or-function ""Link to this heading"")

To execute a Snowpark procedure or function, use the `snow snowpark execute OBJECT_TYPE EXECUTION_IDENTIFIER` command, where:

*   `OBJECT_TYPE` is one of `function` or `procedure`.
    
*   `EXECUTION_IDENTIFIER` is function or procedure signature, with all arguments provided.
    

The following example calls a Snowpark function called `hello_function`:

```
snow snowpark execute function ""hello_function('Olaf')""

```

Copy

```
+--------------------------------------+
| key                    | value       |
|------------------------+-------------|
| HELLO_FUNCTION('Olaf') | Hello Olaf! |
+--------------------------------------+

```

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)
3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)
4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",NULL,fb829181a2037c31a8bd380995e5bf00f21517ac56287088cbf3d7fbd5323945,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/upload,Upload an existing Python package¶,NULL,NULL,NULL,NULL,"# Upload an existing Python package[¶](#upload-an-existing-python-package ""Link to this heading"")

Snowflake CLI allows you to add existing Python packages to Snowpark imports using the `snow snowpark package` commands. You can use already implemented packages, such as those from PyPi, in your functions and procedures.

To add a Python package to Snowpark imports, do the following:

1.  [Check whether a package is already available](#label-snowcli-check-for-package).
    
2.  [Download a package and create a Snowflake artifact](#label-snowcli-download-package).
    
3.  [Upload the package to a Snowflake stage](#label-snowcli-upload-package).
    
4.  [Use the package in Snowpark procedures and functions](#label-snowcli-use-package).
    

## Check whether a package is already available[¶](#check-whether-a-package-is-already-available ""Link to this heading"")

To check whether a package is not already available use the `snow snowpark package lookup` command.

The following example illustrates looking up a package that is already available on the Snowflake Anaconda channel:

```
snow snowpark package lookup numpy

```

Copy

```
Package `numpy` is available in Anaconda. Latest available version: 1.26.4.

```

If a package is not available on the Snowflake Anaconda channel, you can get a message similar to the following:

```
snow snowpark package lookup july

```

Copy

```
Package `july` is not available in Anaconda. To prepare Snowpark compatible package run:

  snow snowpark package create july

```

For more information, see the [snowpark package lookup](../command-reference/snowpark-commands/package-commands/lookup) command.

## Download a package and create a Snowflake artifact[¶](#download-a-package-and-create-a-snowflake-artifact ""Link to this heading"")

To download a package and create a Snowflake artifact to upload use the `snow snowpark package create` command.

```
snow snowpark package create <name>

```

Copy

where:

*   `<name>` can be any requirement specifier supported by `pip`, such as a package name, an URL for a package, or a local file path.
    

Additional options:

*   `--allow-shared-libraries`: Allows shared (`.so`/`.dll`) libraries, when using packages installed through `pip`.
    
*   `--ignore-anaconda`: Does not lookup packages on Snowflake Anaconda channel.
    
*   `--index-url`: Specifies the base URL of the Python Package Index to use for package lookup. This URL should point to a repository compliant with PEP 503 (the simple repository API) or a local directory laid out in the same format.
    
*   `--skip-version-check`: Skips comparing versions of dependencies between requirements and Anaconda.
    

The following examples illustrate some different situations for creating Snowflake artifacts:

*   [Example: create a package with Anaconda dependencies](#label-snowcli-snowpark-anaconda)
    
*   [Example: create a package using the --ignore-anaconda option](#label-snowcli-snowpark-ignore-anaconda)
    
*   [Example: create a package already available in the Snowflake Anaconda channel](#label-snowcli-snowpark-existing-anaconda)
    

### Example: create a package with Anaconda dependencies[¶](#example-create-a-package-with-anaconda-dependencies ""Link to this heading"")

This example creates a Python package as a zip file that can be uploaded to a stage and later imported by a Snowpark Python app. Dependencies for “july” package are found on the Anaconda channel, so they were excluded from the `.zip` file. The command displays the packages you would need to include in `requirements.txt` of your Snowpark project.

```
snow snowpark package create july==0.1

```

Copy

```
Package july.zip created. You can now upload it to a stage using
snow snowpark package upload -f july.zip -s <stage-name>`
and reference it in your procedure or function.
Remember to add it to imports in the procedure or function definition.

The package july==0.1 is successfully created, but depends on the following
Anaconda libraries. They need to be included in project requirements,
as their are not included in .zip.
matplotlib
numpy

```

### Example: create a package using the `--ignore-anaconda` option[¶](#example-create-a-package-using-the-ignore-anaconda-option ""Link to this heading"")

This example creates the `july.zip` package that you can use in your Snowpark project without needing to add any dependencies to the `requirements.txt` file. The error messages indicate that some packages contain shared libraries, which might not work, such as when creating a package using Windows.

```
snow snowpark package create july==0.1 --ignore-anaconda --allow-shared-libraries

```

Copy

```
2024-05-09 15:34:02 ERROR Following dependencies utilise shared libraries, not supported by Conda:
2024-05-09 15:34:02 ERROR contourpy
numpy
pillow
kiwisolver
matplotlib
fonttools
2024-05-09 15:34:02 ERROR You may still try to create your package with --allow-shared-libraries, but the might not work.
2024-05-09 15:34:02 ERROR You may also request adding the package to Snowflake Conda channel
2024-05-09 15:34:02 ERROR at https://support.anaconda.com/

Package july.zip created. You can now upload it to a stage using
snow snowpark package upload -f july.zip -s <stage-name>`
and reference it in your procedure or function.
Remember to add it to imports in the procedure or function definition.

```

### Example: create a package already available in the Snowflake Anaconda channel[¶](#example-create-a-package-already-available-in-the-snowflake-anaconda-channel ""Link to this heading"")

This example fails to create the package because it already exists. You can still forcibly create the package by using the `--ignore-anaconda` option.

```
snow snowpark package create matplotlib

```

Copy

```
Package matplotlib is already available in Snowflake Anaconda Channel.

```

For more information about creating a package, see the [snowpark package create](../command-reference/snowpark-commands/package-commands/create) command.

## Upload the package to a Snowflake stage[¶](#upload-the-package-to-a-snowflake-stage ""Link to this heading"")

To upload your package, use the `snow snowpark package upload` command.

This command uploads a Python package zip file to a Snowflake stage so it can be referenced in the imports of a procedure or function.

```
snow snowpark package upload --file=""july.zip"" --stage=""packages""

```

Copy

```
Package july.zip UPLOADED to Snowflake @packages/july.zip.

```

## Use the package in Snowpark procedures and functions[¶](#use-the-package-in-snowpark-procedures-and-functions ""Link to this heading"")

To use the package in procedures or functions, add it to the `imports` parameter of [Snowpark definition](create.html#label-snowcli-func-proc-properties) section in `snowflake.yml`.

> ```
> get_custom_package_version:
>   handler: ""functions.get_custom_package_version""
>   signature: """"
>   returns: string
>   type: function
>   imports:
>     - ""@packages/july.zip""
>   meta:
>     use_mixins:
>       - snowpark_shared
> 
> ```
> 
> Copy
> 
> Then import your package in the function handler.
> 
> ```
> # functions.py
> import july
> 
> def get_custom_package_version():
>   return july.__VERSION__
> 
> ```
> 
> Copy

On this page

1.  [Check whether a package is already available](#check-whether-a-package-is-already-available)
2.  [Download a package and create a Snowflake artifact](#download-a-package-and-create-a-snowflake-artifact)
3.  [Upload the package to a Snowflake stage](#upload-the-package-to-a-snowflake-stage)
4.  [Use the package in Snowpark procedures and functions](#use-the-package-in-snowpark-procedures-and-functions)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)
3.  [snow snowpark package commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/package-commands/overview)
4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",NULL,22556be5ca464203f5e2b02ca83253a6f4298a8abec49325f1b6abe798a6a932,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/manage,Manage your Snowpark functions and procedures¶,NULL,NULL,NULL,NULL,"# Manage your Snowpark functions and procedures[¶](#manage-your-snowpark-functions-and-procedures ""Link to this heading"")

> *   Add and modify functions and procedures using the [Build a Snowpark project](build) and [Deploy a Snowpark project](deploy) processes.
>     
> *   List functions and procedures to which you have access using the `snow snowpark list functions` and `snow snowpark list procedures` commands. For more information, see [List all objects of a specific type](../objects/manage-objects.html#label-snowcli-object-list).
>     
> *   View details of a function or procedure using the `snow snowpark describe function [IDENTIFIER]` and `snow snowpark describe procedure [IDENTIFIER]` commands. For more information, see [Display the description for an object of a specified type](../objects/manage-objects.html#label-snowcli-object-describe).
>     
> *   Delete function/procedure using the `snow snowpark drop function [IDENTIFIER]` and `snow snowpark drop procedure [IDENTIFIER]` commands. For more information, see [Delete an object of a specified type](../objects/manage-objects.html#label-snowcli-object-drop).
>     
> *   Execute functions and procedures using the `snow snowpark execute` command. For more information, see [Execute a Snowpark procedure or function](execute).
>     

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)
3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)
4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",NULL,f97bba37be2255f608c2f3c092239db88fc3694ee8ffbd8c1bd4e0a1ef442567,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/create,snow notebook create¶,NULL,NULL,snow notebook,snow notebook create,"# snow notebook create[¶](#snow-notebook-create ""Link to this heading"")

Note

Beginning with version 3.4.0, Snowflake CLI added the [snow notebook deploy](deploy) command to replace the `snow notebook create` command. To support backward compatibility, you can still create a notebook using this command, but Snowflake recommends that you begin using the new [Deploy and create a notebook](../../notebooks/use-notebooks.html#label-cli-deploy-notebook) procedure.

Creates notebook from stage.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/create-notebook)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow notebook create
  <identifier>
  --notebook-file <notebook_file>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_identifier_`

Identifier of the notebook; for example: MY\_NOTEBOOK.

## Options[¶](#options ""Link to this heading"")

`--notebook-file, -f _TEXT_`

Stage path with notebook file. For example `@stage/path/to/notebook.ipynb`.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

By default, the command creates notebooks using the default warehouse provided in the connection. You can use the `--warehouse` parameter to specify a different warehouse or to specify one if the connection does not include a warehouse.

## Examples[¶](#examples ""Link to this heading"")

The following example creates `MY_NOTEBOOK` from the staged `@MY_STAGE/path/to/notebook.ipynb` notebook:

```
snow notebook create MY_NOTEBOOK -f @MY_STAGE/path/to/notebook.ipynb

```

Copy

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)
2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",NULL,084a77f1811eb100d58f1dda3a550e59f5e05eb0aac64e80f9e47a5ebed44d82,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/deploy,snow notebook deploy¶,NULL,NULL,snow notebook,snow notebook deploy,"# snow notebook deploy[¶](#snow-notebook-deploy ""Link to this heading"")

Uploads a notebook and required files to a stage and creates a Snowflake notebook.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow notebook deploy
  <entity_id>
  --replace
  --prune / --no-prune
  --project <project_definition>
  --env <env_overrides>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_entity_id_`

ID of notebook entity.

## Options[¶](#options ""Link to this heading"")

`--replace`

Replace notebook object if it already exists. It only uploads new and overwrites existing files, but does not remove any files already on the stage. Default: False.

`--prune / --no-prune`

Delete files that exist in the stage, but not in the local filesystem. Default: False.

`-p, --project _TEXT_`

Path where the Snowflake project is stored. Defaults to the current working directory.

`--env _TEXT_`

String in the format key=value. Overrides variables from the env section used for templates. Default: \[\].

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow notebook deploy` command uploads local files to a stage and creates a new Notebook object inside your chosen database and schema. Your [project definition file](../../notebooks/use-notebooks.html#label-cli-deploy-notebook) should specify the main notebook file and query warehouse. The `--replace` option replaces the specified Notebook object if it already exists.

## Examples[¶](#examples ""Link to this heading"")

The following example uploads the files specified in your project definition file and creates a new notebook named `my_notebook`:

```
snow notebook deploy my_notebook

```

Copy

```
Uploading artifacts to @notebooks/my_notebook
  Creating stage notebooks if not exists
  Uploading artifacts
Creating notebook my_notebook
Notebook successfully deployed and available under https://snowflake.com/provider-deduced-from-connection/#/notebooks/DB.SCHEMA.MY_NOTEBOOK

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)
2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",NULL,e3e0aaf41bf29ce68b6b18ca8e3b4467a2b84ca359c4e7e6a6ee8b50bb16045b,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/execute,snow notebook execute¶,NULL,NULL,snow notebook,snow notebook execute,"# snow notebook execute[¶](#snow-notebook-execute ""Link to this heading"")

Executes a notebook in a headless mode.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/execute-notebook)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow notebook execute
  <identifier>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_identifier_`

Identifier of the notebook; for example: MY\_NOTEBOOK.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow notebook execute` command executes a notebook in headless mode. Currently, the command only returns a message indicating whether the notebook executed successfully. It doesn’t return any result data from the notebook.

## Examples[¶](#examples ""Link to this heading"")

The following example executes the `MY_NOTEBOOK` notebook:

```
snow notebook execute MY_NOTEBOOK

```

Copy

```
Notebook MY_NOTEBOOK executed.

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)
2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",NULL,ad74fdd29ff445e4c5903c2be4ff7852d103091952978a3463fa95c786f55309,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/get-url,snow notebook get-url¶,NULL,NULL,snow notebook,snow notebook get url,"# snow notebook get-url[¶](#snow-notebook-get-url ""Link to this heading"")

Return a url to a notebook.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow notebook get-url
  <identifier>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_identifier_`

Identifier of the notebook; for example: MY\_NOTEBOOK.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The notebook get-url command returns a url link to an existing notebooks. Note the following requirements:

*   The notebook must already be deployed.
    
*   If your notebook is running under a different database and schema than specified in the connection, you must provide them in name as a fully-qualified name, such as `database.schema.name`.
    

## Examples[¶](#examples ""Link to this heading"")

This example gets a URL for an notebook using a fully-qualified database and schema name:

```
snow notebook get-url database.schema.my_notebook

```

Copy

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)
2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",NULL,d246715049d8b29f4615aba75689645ca635224ee29d4ea7e7e34a2d9d6074ac,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/open,snow notebook open¶,NULL,NULL,snow notebook,snow notebook open,"# snow notebook open[¶](#snow-notebook-open ""Link to this heading"")

Opens a notebook in default browser

## Syntax[¶](#syntax ""Link to this heading"")

```
snow notebook open
  <identifier>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_identifier_`

Identifier of the notebook; for example: MY\_NOTEBOOK.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The notebook open command opens existing notebooks in your default browser. Note the following requirements:

*   The notebook must already be deployed.
    
*   If your notebook is running under a different database and schema than specified in the connection, you must provide them in name as a fully-qualified name, such as `database.schema.name`.
    

## Examples[¶](#examples ""Link to this heading"")

This example opens a notebook using a fully-qualified database and schema name:

```
snow notebook open database.schema.my_notebook

```

Copy

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)
2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",NULL,cdc476ccaf9919ec58e83acd1784ff4c55e14c413d77bc9b7f22b97a02612c87,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/deploy-app,Deploying a Streamlit app¶,NULL,NULL,NULL,NULL,"# Deploying a Streamlit app[¶](#deploying-a-streamlit-app ""Link to this heading"")

The [snow streamlit deploy](../../command-reference/streamlit-commands/deploy) command creates a new Streamlit object inside your chosen database and schema. By default, this command looks for a main file called `streamlit_app.py` in your current working directory.

## Prerequisites[¶](#prerequisites ""Link to this heading"")

Before deploying a Streamlit app with Snowflake CLI, you should meet the following prerequisites:

*   Ensure that you have a local Streamlit app with the correct directory structure and `snowflake.yml` project definition file must exist.
    
*   Ensure that your account has the correct privileges as described in [Privileges required to create and use a Streamlit app](../../../streamlit/object-management/privileges).
    
*   Ensure that you can create or have access to a named stage where you can upload your Streamlit app files.
    

## How to deploy a Streamlit app[¶](#how-to-deploy-a-streamlit-app ""Link to this heading"")

Note

With the release of Snowflake CLI 3.14.0, the `snow streamlit deploy` command now uses the updated CREATE STREAMLIT syntax (FROM _source\_location_) instead of the deprecated syntax (ROOT\_LOCATION = ‘<stage\_path\_and\_root\_directory>’). To continue using the deprecated syntax, you can use the `--legacy` option.

The `snow streamlit deploy` command uploads local files to a stage and creates a new Streamlit object inside your chosen database and schema. Your [project definition file](initialize-app.html#label-snowcli-streamlit-project-definition) should specify the main Python file and query warehouse. You can also specify the following options:

*   `--replace`: Replaces the specified Streamlit app, if it already exists.
    
*   `--open`: Opens the Streamlit app in your default browser after deploying the app.
    
*   `--prune`: Removes files that exist in the stage, but not files in the local filesystem (by default no files are removed).
    
*   `--legacy`: Uses the deprecated SQLsyntax (ROOT\_LOCATION = ‘<stage\_path\_and\_root\_directory>’).
    

By default the command automatically deploys the `environment.yml` file and the content of the `pages/` directory, if any of those exists. You can use different files by using [command-line options](../../command-reference/streamlit-commands/deploy).

For more information about creating Streamlit apps, see the CLI [snow streamlit deploy](../../command-reference/streamlit-commands/deploy) and SQL [CREATE STREAMLIT](../../../../sql-reference/sql/create-streamlit) commands.

On this page

1.  [Prerequisites](#prerequisites)
2.  [How to deploy a Streamlit app](#how-to-deploy-a-streamlit-app)

Related content

1.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)
2.  [Creating a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/initialize-app)
3.  [Retrieving the URL for a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/get-url)
4.  [Share a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/share-app)
5.  [snow streamlit deploy](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/streamlit-commands/deploy)
6.  [SQL: CREATE STREAMLIT](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../../../sql-reference/sql/create-streamlit)",NULL,8846d547d3af5a31f9c14ec865baa455acf93ee393a2c99836b1a425a037a7f6,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/get-url,Retrieving the URL for a Streamlit app¶,NULL,NULL,NULL,NULL,"# Retrieving the URL for a Streamlit app[¶](#retrieving-the-url-for-a-streamlit-app ""Link to this heading"")

## Prerequisites[¶](#prerequisites ""Link to this heading"")

*   The Streamlit app must already be uploaded to a stage in the connection you are currently using.
    
*   Your current ROLE must have access to the app.
    

## How to get the URL for a deployed Streamlit app[¶](#how-to-get-the-url-for-a-deployed-streamlit-app ""Link to this heading"")

The `snow streamlit get-url` command returns a URL for a deployed Streamlit app that you can then use to open the app in a browser.

To get an app URL, do the following:

1.  Ensure your connection specifies the database and schema where your app is deployed.
    
2.  Enter a command similar to the following:
    
    ```
    snow streamlit get-url my_streamlit_app
    
    ```
    
    Copy
    
    ```
    https://snowflake.com/provider-deduced-from-connection/#/streamlit-apps/DB.SCHEMA.MY_STREAMLIT_APP
    
    ```
    

You can use the command to return the URL and open the app automatically in your default browser by using the `--open` option, similar to the following:

```
snow streamlit get-url my_streamlit_app --open

```

Copy

## How to resolve common errors[¶](#how-to-resolve-common-errors ""Link to this heading"")

*   If the command fails because your ROLE does not have access to the Streamlit app, try the following:
    
    *   Verify you are using the same ROLE in your browser that was used to deploy the app.
        
    *   Switch to a ROLE that has access to the app. If you don’t have access to the ROLE used to create the app, the app developer can grant access to another ROLE with the `snow streamlit share` command.
        
*   If the command fails because it could not find the Streamlit app, try the following:
    
    *   Check the app name.
        
    *   Verify you generated the URL using the same connection (host, account, database, and schema) that was used to deploy the app.
        
    *   Ensure the database and schema are correct. If you specified the database and schema as a fully-qualified name, it overrides the values for them in the connection.
        

On this page

1.  [Prerequisites](#prerequisites)
2.  [How to get the URL for a deployed Streamlit app](#how-to-get-the-url-for-a-deployed-streamlit-app)
3.  [How to resolve common errors](#how-to-resolve-common-errors)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../index)
2.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)
3.  [Deploying a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/deploy-app)
4.  [Creating a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/initialize-app)
5.  [Share a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/share-app)
6.  [snow streamlit get-url](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/streamlit-commands/get-url)
7.  [snow streamlit share](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/streamlit-commands/share)",NULL,87c2c6745995eba3cee32325ef768b2670a28afb7efd4431215d1bd9cab6a892,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/share-app,Share a Streamlit app¶,NULL,NULL,NULL,NULL,"# Share a Streamlit app[¶](#share-a-streamlit-app ""Link to this heading"")

## Prerequisites[¶](#prerequisites ""Link to this heading"")

Before sharing a Streamlit app with Snowflake CLI, you should meet the following prerequisites:

*   Ensure that your account has the correct privileges as described in [Privileges required to create and use a Streamlit app](../../../streamlit/object-management/privileges).
    
*   Ensure that the app is already deployed in your connection.
    
*   Ensure that your connection has the right ROLE and that the connection uses the correct database and schema.
    

## How to share a Streamlit app[¶](#how-to-share-a-streamlit-app ""Link to this heading"")

To share a Streamlit app from the stage, enter the following command:

```
snow streamlit share my-app some-role

```

Copy

For more information about sharing Streamlit apps, see the CLI [snow streamlit share](../../command-reference/streamlit-commands/share) command.

On this page

1.  [Prerequisites](#prerequisites)
2.  [How to share a Streamlit app](#how-to-share-a-streamlit-app)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../index)
2.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)
3.  [Deploying a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/deploy-app)
4.  [Retrieving the URL for a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/get-url)
5.  [CLI: streamlit share](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/streamlit-commands/share)
6.  [SQL: DROP STREAMLIT](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../../../sql-reference/sql/drop-streamlit)",NULL,cc5a6cac7cb1dcca24fd7f6f2f889321acb26c258bbf9742b227ace7de137df5,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/manage-app,Managing Streamlit apps¶,NULL,NULL,NULL,NULL,"# Managing Streamlit apps[¶](#managing-streamlit-apps ""Link to this heading"")

After you have created a Streamlit app, you can use the following commands to manage the app:

*   To retrieve the URL of your Streamlit app, use the `snow streamlit get-url NAME` command. See [snow streamlit get-url](../../command-reference/streamlit-commands/get-url) for more information.
    
*   To share your app to other roles, use the snow `streamlit share NAME TO_ROLE` command. See [snow streamlit share](../../command-reference/streamlit-commands/share) for more information.
    
*   To list the Streamlit apps for which you have access, use the `snow streamlit list` command. See [snow streamlit list](../../command-reference/streamlit-commands/list) for more information.
    
*   To display details about a Streamlit app, use the `snow streamlit describe NAME` command. See [snow streamlit describe](../../command-reference/streamlit-commands/describe) for more information.
    
*   To delete a Streamlit app, use the `snow streamlit drop NAME` command. See [snow streamlit drop](../../command-reference/streamlit-commands/drop) for more information.
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../index)
2.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)",NULL,587a62503ae2e6ecde8fc3f45d745260900ad14ca77a9bbd2940df585e2e2658,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/list-contents,Listing the contents of a repository¶,NULL,NULL,NULL,NULL,"# Listing the contents of a repository[¶](#listing-the-contents-of-a-repository ""Link to this heading"")

Snowflake CLI supports the following ways to list the contents of a Git repository:

*   [List branches in a repository](#label-snowcli-git-list-branches)
    
*   [List tags in a repository](#label-snowcli-git-list-tags)
    
*   [List files in a repository](#label-snowcli-git-list-files)
    

## List branches in a repository[¶](#list-branches-in-a-repository ""Link to this heading"")

The `snow git list-branches` command lists all of the branches in a repository.

```
snow git list-branches <REPO_NAME>

```

Copy

where:

*   `<REPO_NAME>` is the ID of the repository stage.
    

For example, to list all of the branches in a repository named `my_snow_git`, enter the following command:

```
snow git list-branches my_snow_git

```

Copy

```
show git branches in my_snow_git
+--------------------------------------------------------------------------------------------------------------------------------------------+
| name                                     | path                                     | checkouts | commit_hash                              |
|------------------------------------------+------------------------------------------+-----------+------------------------------------------|
| SNOW-1011750-service-create-options      | /branches/SNOW-1011750-service-create-op |           | 729855df0104c8d0ef1c7a3e8f79fe50c6c8d2fa |
|                                          | tions                                    |           |                                          |
| SNOW-1011775-containers-to-spcs-int-test | /branches/SNOW-1011775-containers-to-spc |           | e81b00de6b0eb73a99a7baaa39b0afa5ea1202d0 |
| s                                        | s-int-tests                              |           |                                          |
| SNOW-1105629-git-integration-tests       | /branches/SNOW-1105629-git-integration-t |           | 712b07b5e692624c34caabe07d64801615ce5f0f |
+--------------------------------------------------------------------------------------------------------------------------------------------+

```

## List tags in a repository[¶](#list-tags-in-a-repository ""Link to this heading"")

The `snow git list-tabs` command lists all of the tags in a repository.

```
snow git list-tags <REPO_NAME>

```

Copy

where:

*   `<REPO_NAME>` is the ID of the repository stage you want to create. Note that if the repository stage already exists, the command fails.
    

For example, to list all of the tags in a repository named `my_snow_git`, enter the following command:

```
snow git list-tags my_snow_git

```

Copy

```
show git tags in my_snow_git
+--------------------------------------------------------------------------------------------------------------+
| name           | path                 | commit_hash                 | author                       | message |
|----------------+----------------------+-----------------------------+------------------------------+---------|
| v2.0.0rc3      | /tags/v2.0.0rc3      | 2b019d2841da823d8001f23c6f3 | None                         | None    |
|                |                      | 064e5899142a0               |                              |         |
| v2.1.0-rc0     | /tags/v2.1.0-rc0     | 829887b758b43b86959611dd612 | None                         | None    |
|                |                      | 7638da75cf871               |                              |         |
| v2.1.0-rc1     | /tags/v2.1.0-rc1     | b7efe1fe9c0925b95ba214e233b | None                         | None    |
|                |                      | 18924fa0404b3               |                              |         |
+--------------------------------------------------------------------------------------------------------------+

```

## List files in a repository[¶](#list-files-in-a-repository ""Link to this heading"")

The `snow git list-files` command lists all of the files on a specified repository state (a specific branch, tag or commit).

```
snow git list-files <REPO_PATH>

```

Copy

where:

*   `<REPO_PATH>` is a stage path with a specific scope where the value is the repository name is followed by a suffix specifying which branch, tag or commit. The following lists some different types of values:
    
    *   `@snowcli_git/branches/main/` refers to last commit of the `main` branch.
        
    *   `@snowcli_git/tags/v2.1.0/` refers to a commit tagged `v2.1.0`.
        
    *   `@snowcli_git/commits/1e939d69ca6fd0f89074e7e97c9fd1/` refers to a specific commit. Commit hashes should be between 6 and 40 characters long.
        
    
    A repository path can also be a subdirectory or file in the repository, but still must be preceded with a scope prefix.
    

The following example lists all of the files in the `my_snow_git` repository marked with the `v2.0.0` tag:

```
snow git list-files @my_snow_git/tags/v2.0.0/

```

Copy

```
ls @snowcli_git/tags/v2.0.0/
+---------------------------------------------------------------------------------------------------------------------------------+
| name                                    | size | md5  | sha1                                     | last_modified                |
|-----------------------------------------+------+------+------------------------------------------+------------------------------|
| snowcli_git/tags/v2.0.0/CONTRIBUTING.md | 5472 | None | 1cc437b88d20afe4d5751bd576114e3b20be27ea | Mon, 5 Feb 2024 13:16:25 GMT |
| snowcli_git/tags/v2.0.0/LEGAL.md        | 251  | None | 4453da50b7a2222006289ff977bfb23583657214 | Mon, 5 Feb 2024 13:16:25 GMT |
| snowcli_git/tags/v2.0.0/README.md       | 1258 | None | bdc918baae93467c258c6634c872ca6bd4ee1e9c | Mon, 5 Feb 2024 13:16:25 GMT |
| snowcli_git/tags/v2.0.0/SECURITY.md     | 308  | None | 27e7e1b2fd28a86943b3f4c0a35a931577422389 | Mon, 5 Feb 2024 13:16:25 GMT |
| ...
+---------------------------------------------------------------------------------------------------------------------------------+

```

The following example lists all of the files in the `tests/` directory of the `my_snow_git` repository marked with the `v2.0.0` tag:

```
snow git list-files @my_snow_git/tags/v2.0.0/tests --pattern "".*\.toml""

```

Copy

```
ls @snowcli_git/tags/v2.0.0/tests pattern = '.*\.toml'
+-----------------------------------------------------------------------------------------------------------------------------------------+
| name                                            | size | md5  | sha1                                     | last_modified                |
|-------------------------------------------------+------+------+------------------------------------------+------------------------------|
| snowcli_git/tags/v2.0.0/tests/empty_config.toml | 0    | None | e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 | Mon, 5 Feb 2024 13:16:25 GMT |
| snowcli_git/tags/v2.0.0/tests/test.toml         | 381  | None | 45f1c00f16eba1b7bc7b4ab2982afe95d0161e7f | Mon, 5 Feb 2024 13:16:25 GMT |
+-----------------------------------------------------------------------------------------------------------------------------------------+

```

On this page

1.  [List branches in a repository](#list-branches-in-a-repository)
2.  [List tags in a repository](#list-tags-in-a-repository)
3.  [List files in a repository](#list-files-in-a-repository)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)
2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)
3.  [snow git list-branches](/developer-guide/snowflake-cli/git/../command-reference/git-commands/list-branches)
4.  [snow git list-files](/developer-guide/snowflake-cli/git/../command-reference/git-commands/list-files)
5.  [snow git list-tags](/developer-guide/snowflake-cli/git/../command-reference/git-commands/list-tags)",NULL,d62154f08fd972ebd51ff2653d13b9150324d17018942bdd167eda9f5db98e6d,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/about-projects,About Snowflake Native App projects¶,NULL,NULL,NULL,NULL,"# About Snowflake Native App projects[¶](#about-native-app-projects ""Link to this heading"")

From the point of view of Snowflake Native App, a project encompasses a codebase that can be added to an application package in a Snowflake account. It includes references to all the extension code that app functionality needs, references to external databases for shared content, as well as required files such as [manifest.yml](../../native-apps/manifest-overview), an [environment.yml](../../streamlit/getting-started/create-streamlit-sql.html#label-streamlit-install-packages-manual) (for a Streamlit app), and any code artifacts such as JAR files and images. It also includes a configuration to describe how the application package can be built from the files in the project folder.

A Snowflake Native App project is simply a set of files in a directory; like other code repositories, these files can be version-controlled using technologies like git and shared on platforms like Github.

To give you an idea of what a Snowflake Native App project should look like, Snowflake has created a few templates that are available for you to clone through Snowflake CLI commands. You can access these publicly available templates from the [Snowflake Git repository](https://github.com/snowflakedb/snowflake-cli-templates) and even create projects directly from them using Snowflake CLI. You can also create and share your own templates. For more information, see [Bootstrapping a project from a template](../bootstrap-project/bootstrap).

Caution

Snowflake CLI processes the files inside a project directory. These files can be uploaded to Snowflake by other `snow app` commands, so you should use caution when putting any sensitive information inside files in a project directory.

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)
3.  [Project definition files](/developer-guide/snowflake-cli/native-apps/project-definitions)
4.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)
5.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)
6.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",NULL,bbebd7be2f973e0a7db971d52d5e65501bd85052c7f271f9422f8815c7b18f78,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/create-manage-apps,Creating and managing Snowflake Native App objects¶,NULL,NULL,NULL,NULL,"# Creating and managing Snowflake Native App objects[¶](#creating-and-managing-native-app-objects ""Link to this heading"")

You can perform the following operations when creating and managing Snowflake Native App objects:

*   [Creating a Snowflake Native App project](initiate-app)
    
*   [Preparing a local folder with configured Snowflake Native App artifacts](bundle-app)
    
*   [Validating an application package](validate-app)
    
*   [Creating and installing your application](create-package)
    
*   [Creating an application package with a version (or patch)](create-app-package-version)
    
*   [Listing all versions defined in an application package](list-app-package-version)
    
*   [Opening an app in a browser](open-app)
    
*   [Publishing a Snowflake Native App to customers](publish-app)
    
*   [Dropping an existing version of an app in an application package](drop-app-package-version)
    
*   [Dropping Snowflake Native App objects](drop-objects)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)
3.  [About Snowflake Native App projects](/developer-guide/snowflake-cli/native-apps/about-projects)
4.  [Project definition files](/developer-guide/snowflake-cli/native-apps/project-definitions)
5.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)
6.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)
7.  [Opening an app in a browser](/developer-guide/snowflake-cli/native-apps/open-app)
8.  [Publishing a Snowflake Native App to customers](/developer-guide/snowflake-cli/native-apps/publish-app)
9.  [Dropping Snowflake Native App objects](/developer-guide/snowflake-cli/native-apps/drop-objects)
10.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",NULL,9e5e97ab3a36b0ce27d807d2898bfe77c7b3cb80bc05b3a44799de9743727ec1,NULL
NULL,https://docs.snowflake.com/developer-guide/snowflake-cli/native-apps/initiate-app,Creating a Snowflake Native App project¶,NULL,NULL,NULL,NULL,"# Creating a Snowflake Native App project[¶](#creating-a-native-app-project ""Link to this heading"")

You can use the `snow init` command to bootstrap a Snowflake Native App project, and get the project up and running quickly.

To create a Snowflake Native App project from a Snowflake provided Snowflake Native App template:

*   Enter a `snow init` command, similar to the following:
    
    ```
    snow init --template app_basic my_app
    
    ```
    
    Copy
    
    When successful, the command returns a confirmation message similar to the following:
    
    ```
    Initialized the new project in my_app
    
    ```
    

Caution

Files inside a project directory are processed by Snowflake CLI and could be uploaded to Snowflake when executing other `snow app` commands. You should use caution when putting any sensitive information inside files in a project directory.

For more information about creating a Snowflake Native App project, see the snow init command as well as the [Snowflake CLI templates](https://github.com/snowflakedb/snowflake-cli-templates) repository.

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)
3.  [About Snowflake Native App projects](/developer-guide/snowflake-cli/native-apps/about-projects)
4.  [Project definition files](/developer-guide/snowflake-cli/native-apps/project-definitions)
5.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)
6.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",NULL,421b4ca0524f24f4df6b8f6538f542c048e2b84b0330aa71a9089f92e15eccad,NULL
NULL,https://docs.snowflake.com/developer-guide/snowflake-cli/native-apps/create-package,Creating and installing your application¶,NULL,NULL,NULL,NULL,"# Creating and installing your application[¶](#creating-and-installing-your-application ""Link to this heading"")

## Prerequisites[¶](#prerequisites ""Link to this heading"")

*   You must have an existing connection in your `config.toml` file.
    
*   You must have a `snowflake.yml` file in your native app project.
    

## How to create an application package and an application object together[¶](#how-to-create-an-application-package-and-an-application-object-together ""Link to this heading"")

The [snow app run](../command-reference/native-apps-commands/run-app) command brings all the different code files together, creates an application package, uploads code to a Snowflake stage in this application package, [validates the setup script SQL](../command-reference/native-apps-commands/validate-app), and also installs or upgrades an application in the same account from this application package. This command is driven by the values specified in your resolved project definition for determining which stage to upload files to, which files to upload, and the names of the objects to be created.

To create an application object, do the following:

1.  [Create a connection](../connecting/connect), if necessary.
    
2.  Make relevant changes to your code files, including `snowflake.yml`, `manifest.yml`, any setup scripts and extension code files.
    
3.  Execute the `snow app run` command from within your project, similar to the following:
    
    ```
    snow app run --connection=""dev""
    
    ```
    
    Copy
    

> When successful, the command displays a message similar to the following:
> 
> ```
> Your application (""my_app_admin"") is now live:
> https://app.snowflake.com/data_org/data_acct/#/apps/application/my_app_admin
> 
> ```

Using the `snow app run --connection=""dev""` command creates an application using the files on a named stage that is automatically managed by Snowflake CLI. You can also use the command to create or update your application even if your application package already exists. In this case, the command issues an UPGRADE on your application object, which will execute your setup script. For information about how to avoid re-running the setup script, see the next section.

To create an application using a version (and patch) of an existing application package, execute the following:

```
snow app run --version v1 --patch 12 --connection=""dev""

```

Copy

Here, version `V1` and patch `12` are used as an example only. For more information about creating Snowflake Native App objects, see the [snow app run](../command-reference/native-apps-commands/run-app) command.

## How to create an application package[¶](#how-to-create-an-application-package ""Link to this heading"")

The `snow app deploy` command performs a subset of the steps `snow app run` takes to deploy your code to Snowflake. While it still brings all the different code files together, creates an application package, and uploads code to a named stage in this application package, and [validates the setup script SQL](../command-reference/native-apps-commands/validate-app), the `snow app deploy` command does not attempt to create or upgrade an application object.

The `snow app deploy` command is particularly useful in the following situations:

*   Deploying only the application package and stage files, for situations where an application object is not required (such as part of a Continuous Delivery pipeline).
    
*   Updating the stage files linked to the application object. For example, if you only changed python code files, you do not need to re-create the PROCEDURE, FUNCTION, and STREAMLIT objects that point to it when using stage development mode. This approach saves time and reduces cost, as you do not need to use a warehouse to re-execute the setup script to use the updated python code.
    

To create an application package without a corresponding application object, do the following:

1.  [Create a connection](../connecting/connect), if necessary.
    
2.  Make relevant changes to your code files, including `snowflake.yml`, `manifest.yml`, any setup scripts, and extension code files.
    
3.  Execute the `snow app deploy` command from within your project, similar to the following:
    
    ```
    snow app deploy --connection=""dev""
    
    ```
    
    Copy
    

> When successful, the command displays a message similar to the following:
> 
> ```
> Checking if stage exists, or creating a new one if none exists.
> Performing a diff between the Snowflake stage and your local deploy_root
> ...
> Deployed successfully. Application package and stage are up-to-date.
> 
> ```

You can also use the `snow app deploy` command to restrict which files it synchronizes to a stage by listing paths as positional arguments after the `snow app deploy` command. For more information about this and other advanced functionality, see the [snow app deploy](../command-reference/native-apps-commands/deploy-app) command.

On this page

1.  [Prerequisites](#prerequisites)
2.  [How to create an application package and an application object together](#how-to-create-an-application-package-and-an-application-object-together)
3.  [How to create an application package](#how-to-create-an-application-package)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)
3.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)
4.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)
5.  [snow app deploy](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/deploy-app)
6.  [snow app run](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/run-app)
7.  [snow app validate](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/validate-app)",NULL,d44af1e54f8562a095b6e237cfa4cdd55e6896189f143bcbd3fffe3f4679b77f,NULL
NULL,https://docs.snowflake.com/developer-guide/snowflake-cli/native-apps/open-app,Opening an app in a browser¶,NULL,NULL,NULL,NULL,"# Opening an app in a browser[¶](#opening-an-app-in-a-browser ""Link to this heading"")

## Prerequisites[¶](#prerequisites ""Link to this heading"")

*   You must have an existing connection in your `config.toml` file.
    
*   You must have a `snowflake.yml` file in your Snowflake Native App project.
    

## How to open a Snowflake Native App application in your default browser[¶](#how-to-open-a-native-app-application-in-your-default-browser ""Link to this heading"")

The `snow app open` command opens the app specified in the resolved project definition of your Snowflake Native App project.

1.  [Create a connection](../connecting/connect), if necessary.
    
2.  Execute the `snow app open` command from within your project, similar to the following:
    
    > ```
    > snow app open --connection=""dev""
    > 
    > ```
    > 
    > Copy
    
    When successful, the command returns the following message:
    
    > ```
    > Application opened in browser.
    > 
    > ```
    
    If you have not yet installed an application as part of the `snow app run`, the following error message is displayed:
    
    > ```
    > Application not yet deployed! Please run ""snow app run"" first.
    > 
    > ```
    

For more information about opening a Snowflake Native App in a browser, see the CLI [snow app open](../command-reference/native-apps-commands/open-app) command.

On this page

1.  [Prerequisites](#prerequisites)
2.  [How to open a Snowflake Native App application in your default browser](#how-to-open-a-native-app-application-in-your-default-browser)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)
3.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)
4.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)
5.  [Opening an app in a browser](/developer-guide/snowflake-cli/native-apps/#)
6.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",NULL,3d01d3e868fe20ae37d60693f36d1e1dc0c69b43d2e529f7b52ed524c2864c6e,NULL
NULL,https://docs.snowflake.com/developer-guide/snowflake-cli/native-apps/drop-objects,Dropping Snowflake Native App objects¶,NULL,NULL,NULL,NULL,"# Dropping Snowflake Native App objects[¶](#dropping-native-app-objects ""Link to this heading"")

## Prerequisites[¶](#prerequisites ""Link to this heading"")

*   You must have an existing connection in your `config.toml` file.
    
*   You must have a `snowflake.yml` file in your Snowflake Native App project.
    

## How to drop Snowflake Native App application packages and application objects[¶](#how-to-drop-native-app-application-packages-and-application-objects ""Link to this heading"")

The `snow app teardown` drops both the application object and the application package defined in the resolved project definition. This command succeeds even if one or both of these objects do not exist.

1.  [Create a connection](../connecting/connect), if necessary.
    
2.  Execute the `snow app teardown` command from within your project, similar to the following:
    
    > ```
    > snow app teardown --connection=""dev""
    > 
    > ```
    > 
    > Copy
    > 
    > When successful, the command returns the following message:
    > 
    > ```
    > Teardown is now complete.
    > 
    > ```
    

Note

When dropping applications that own objects outside of the application object, such as compute pools, Snowflake CLI shows a list of these dependent objects and asks whether you would like to drop them in addition to the application object and package.

> You can choose this option non-interactively by passing in the `--cascade` option.

If Snowflake CLI is unable to drop the application, it does note drop the application package either. For more information about dropping Snowflake Native App objects, see the [snow app teardown](../command-reference/native-apps-commands/teardown-app) command.

On this page

1.  [Prerequisites](#prerequisites)
2.  [How to drop Snowflake Native App application packages and application objects](#how-to-drop-native-app-application-packages-and-application-objects)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)
3.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",NULL,290a01607fee0a322aef1dbec66a8f045b7dbad3d2e045cea923a46e20ed288e,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snow,snow¶,NULL,NULL,NULL,snow,"# snow[¶](#snow ""Link to this heading"")

Snowflake CLI tool for developers.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow [<resource-commands>]
  --version
  --info
  --config-file <configuration_file>
  --install-completion
  --show-completion
  --help

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`[_resource-commands_]`

Optional commands for managing Snowflake CLI resources.

## Options[¶](#options ""Link to this heading"")

`--version`

Shows the version of the Snowflake CLI.

`--info`

Shows information about the Snowflake CLI.

`--config-file _configuration_file_`

Specifies Snowflake CLI configuration file that should be used.

`--install-completion`

Install completion for the current shell.

`--show-completion`

Show completion for the current shell, to copy it or customize the installation.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The **snow** command supports the following commands to manage Snowflake resources:

*   [snow app commands](native-apps-commands/overview)
    
*   [snow connection commands](connection-commands/overview)
    
*   [snow git commands](git-commands/overview)
    
*   [snow helpers commands](helpers-commands/overview)
    
*   [snow notebook commands](notebook-commands/overview)
    
*   [snow object commands](object-commands/overview)
    
*   [snow snowpark commands](snowpark-commands/overview)
    
*   [snow spcs service commands](spcs-commands/service-commands/overview)
    
*   [snow sql commands](sql-commands/overview)
    
*   [snow stage commands](stage-commands/overview)
    
*   [snow streamlit commands](streamlit-commands/overview)
    

## Examples[¶](#examples ""Link to this heading"")

*   To display the Snowflake CLI version, run the following command:
    
    ```
    snow --version
    
    ```
    
    Copy
    
    ```
    Snowflake CLI version: 3.0.0
    
    ```
    
*   To display information about Snowflake CLI, run the following command:
    
    ```
    snow --info
    
    ```
    
    Copy
    
    ```
    [
      {
          ""key"": ""version"",
          ""value"": ""3.2.0""
      },
      {
          ""key"": ""default_config_file_path"",
          ""value"": ""<user-home>/.snowflake/config.toml""
      },
      {
          ""key"": ""python_version"",
          ""value"": ""3.11.6 (v3.11.6:8b6ee5ba3b, Oct  2 2023, 11:18:21) [Clang 13.0.0 (clang-1300.0.29.30)]""
      },
      {
          ""key"": ""system_info"",
          ""value"": ""macOS-14.4.1-x86_64-i386-64bit""
      },
      {
          ""key"": ""feature_flags"",
          ""value"": {}
      },
      {
          ""key"": ""SNOWFLAKE_HOME"",
          ""value"": null
      }
    ]
    
    ```
    
*   To display command-line help for the `snow` command, run the following command:
    
    ```
    snow --help
    
    ```
    
    Copy
    
    ```
    Usage: snow [OPTIONS] COMMAND [ARGS]...
    
    Snowflake CLI tool for developers.
    
    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ --version                           Shows version of the Snowflake CLI                                                                   │
    │ --info                              Shows information about the Snowflake CLI                                                            │
    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │
    │ --install-completion                Install completion for the current shell.                                                            │
    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │
    │ --help                -h            Show this message and exit.                                                                          │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ app          Manages a Snowflake Native App                                                                                              │
    │ connection   Manages connections to Snowflake.                                                                                           │
    │ cortex       Provides access to Snowflake Cortex.                                                                                        │
    │ git          Manages git repositories in Snowflake.                                                                                      │
    │ notebook     Manages notebooks in Snowflake.                                                                                             │
    │ object       Manages Snowflake objects like warehouses and stages                                                                        │
    │ snowpark     Manages procedures and functions.                                                                                           │
    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │
    │ sql          Executes Snowflake query.                                                                                                   │
    │ stage        Manages stages.                                                                                                             │
    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    
*   To display command-line help resource commands, run a command similar to the following that displays help for the `snow spcs` commands:
    
    ```
    snow spcs --help
    
    ```
    
    Copy
    
    ```
    Usage: snow spcs [OPTIONS] COMMAND [ARGS]...
    
    Manages Snowpark Container Services compute pools, services, image registries, and image repositories.
    
    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ --help  -h        Show this message and exit.                                                                        │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────╮
    │ compute-pool       Manages compute pools.                                                                            │
    │ image-registry     Manages image registries.                                                                         │
    │ image-repository   Manages image repositories.                                                                       │
    │ service            Manages services.                                                                                 │
    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/overview)
3.  [SQL command reference](/developer-guide/snowflake-cli/command-reference/overview)",NULL,cc5b4c62b457089613189790cb85f834fc6901b413e3d7a743a05840256a9891,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/logs-commands/overview,snow logs commands¶,NULL,NULL,snow logs,snow logs overview,"# snow logs commands[¶](#snow-logs-commands ""Link to this heading"")

Snowflake CLI supports the following commands for accessing logs for various entities:

*   [snow logs](logs)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/logs-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/logs-commands/../overview)",NULL,80e7bb2e0b48ca3dd79922a2ff82315bb543371c02b4923f9a4a758a2c373356,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/sql-commands/sql,snow sql¶,NULL,NULL,snow sql,snow sql sql,"# snow sql[¶](#snow-sql ""Link to this heading"")

Executes Snowflake query. Use either query, filename or input option. Query to execute can be specified using query option, filename option (all queries from file will be executed) or via stdin by piping output from other command. For example `cat my.sql | snow sql -i`. The command supports variable substitution that happens on client-side.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow sql
  --query <query>
  --filename <files>
  --stdin
  --variable <data_override>
  --retain-comments
  --single-transaction / --no-single-transaction
  --enable-templating <enabled_templating>
  --project <project_definition>
  --env <env_overrides>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

None

## Options[¶](#options ""Link to this heading"")

`--query, -q _TEXT_`

Query to execute.

`--filename, -f _FILE_`

File to execute. Default: \[\].

`--stdin, -i`

Read the query from standard input. Use it when piping input to this command. Default: False.

`--variable, -D _TEXT_`

String in format of key=value. If provided the SQL content will be treated as template and rendered using provided data.

`--retain-comments`

Retains comments in queries passed to Snowflake. Default: False.

`--single-transaction / --no-single-transaction`

Connects with autocommit disabled. Wraps BEGIN/COMMIT around statements to execute them as a single transaction, ensuring all commands complete successfully or no change is applied. Default: False.

`--enable-templating [LEGACY|STANDARD|JINJA|ALL|NONE]`

Syntax used to resolve variables before passing queries to Snowflake. Default: \[<\_EnabledTemplating.LEGACY: ‘LEGACY’>, <\_EnabledTemplating.STANDARD: ‘STANDARD’>\].

`-p, --project _TEXT_`

Path where the Snowflake project is stored. Defaults to the current working directory.

`--env _TEXT_`

String in the format key=value. Overrides variables from the env section used for templates. Default: \[\].

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

You can specify the SQL query to execute using one of the following options:

*   Specify the query string using the `--query` option.
    
*   Use the `--filename` option to execute one or more files containing a SQL query or queries. For example:
    
    *   `snow sql -f myfile.sql`
        
    *   `snow sql -f file1.sql -f file2.sql`
        
*   Specify the query as `stdin` and pipe it to the `snow sql` command, such as `cat my.sql | snow sql`.
    
*   If your query contains special characters, such as the dollar sign in [SYSTEM functions](../../../../sql-reference/functions-system), that you do not want the shell to interpret, you can do either of the following:
    
    *   Enclose the query in single quotes instead of double quotes, as in:
        
        `snow sql -q 'SELECT SYSTEM$CLIENT_VERSION_INFO()'`
        
    *   Escape the special character, as in:
        
        `snow sql -q ""SELECT SYSTEM\$CLIENT_VERSION_INFO()""`
        
*   Use variables for templating SQL queries with a combination of a `<% variable_name %>` placeholder in your SQL queries and a `-D` command-line option, in the form:
    
    ```
    snow sql -q ""select * from my-database order by <% column_name %>"" -D ""column_name=Country""
    
    ```
    
    Copy
    
    Note
    
    You can currently use the SnowSQL `&variable_name` and `<% variable_name %>` syntax for templates. However, Snowflake recommends using the `<% variable_name %>` syntax.
    
*   Specify a scripting block in queries. For example:
    
    ```
    EXECUTE IMMEDIATE $$
    -- Snowflake Scripting code
    DECLARE
      radius_of_circle FLOAT;
      area_of_circle FLOAT;
    BEGIN
      radius_of_circle := 3;
      area_of_circle := pi() * radius_of_circle * radius_of_circle;
      RETURN area_of_circle;
    END;
    $$
    ;
    
    ```
    
    Copy
    
    Note
    
    When specifying the scripting block directly on the Snowflake CLI command line, the `$$` delimiters might not work for some shells because they interpret that delimiter as something else. For example, the bash and zsh shells interpret it as the process ID (PID). To address this limitation, you can use the following alternatives:
    
    *   If you still want to specify the scripting block on the command line, you can escape the `$$` delimiters, as in `\$\$`.
        
    *   You can also put the scripting block with the default `$$` delimiters into a separate file and call it with the `snow sql -f <filename>` command.
        
    

### Formatting JSON output[¶](#formatting-json-output ""Link to this heading"")

The `--format` option provides two ways to display JSON:

*   `JSON`: Returns JSON as quoted strings, similar to the following:
    
    ```
    snow sql --format json -q ""SELECT PARSE_JSON('{""name"": ""Alice"", ""age"": 30}') as json_col""
    
    ```
    
    Copy
    
    ```
    [
      {
          ""JSON_COL"": ""{\""name\"": \""Alice\"", \""age\"": 30}""
      }
    ]
    
    ```
    
*   `JSON_EXT`: Returns JSON as JSON objects, similar to the following:
    
    ```
    snow sql --format JSON_EXT -q ""SELECT PARSE_JSON('{""name"": ""Alice"", ""age"": 30}') as json_col""
    
    ```
    
    Copy
    
    ```
    [
      {
        ""JSON_COL"": {
        ""name"": ""Alice"",
        ""age"": 30
      }
    ]
    
    ```
    

### Enhanced error codes[¶](#enhanced-error-codes ""Link to this heading"")

The `--enhanced-exit-codes` option provides information that helps identify whether problems result from query execution or from invalid command options. With this option, the `snow sql` command provides the following return codes:

*   `0`: Successful execution
    
*   `2`: Command parameter issues
    
*   `5`: Query execution issues
    
*   `1`: Other types of issues
    

After the command executes, you can use the `echo $?` shell command to see the return code.

In this example, the command contains both a query parameter (`-q 'select 1'`) and a query file parameter (`-f my.query`), which is an invalid parameter combination:

```
snow sql --enhanced-exit-codes -q 'select 1' -f my.query

echo $?

```

Copy

```
2

```

The following examples show the effect of the `--enhanced-exit-codes` option when the command contains an invalid query (slect is misspelled):

*   With the `--enhanced-exit-codes` option, the command returns a `5` exit code to indicate a query error:
    
    ```
    snow sql --enhanced-exit-codes -q 'slect 1'
    
    echo $?
    
    ```
    
    Copy
    
    ```
    5
    
    ```
    
*   Without the `--enhanced-exit-codes` option, the command returns a `1` exit code to indicate a generic (other) error:
    
    ```
    snow sql --enhanced-exit-codes -q 'slect 1'
    
    echo $?
    
    ```
    
    Copy
    
    ```
    1
    
    ```
    

Alternatively, you can set the `SNOWFLAKE_ENHANCED_EXIT_CODES` environment variable to `1` to send the enhanced return codes for all `snow sql` commands.

### Interactive mode[¶](#interactive-mode ""Link to this heading"")

The `snow sql` command supports an interactive mode that lets you enter SQL commands one at a time. Interactive mode provides the following features:

*   Syntax highlighting
    
    ![Interactive mode syntax highlighting](../../../../_images/interactive-sql-syntax-highlight.png)
    
*   Code completion while typing
    
    ![Interactive mode code completion](../../../../_images/interactive-sql-code-completion.png)
    
*   Searchable history
    
    To search your command history, press CTRL\-R:
    
    ![Interactive mode searchable history](../../../../_images/interactive-sql-history.png)
    
*   Multi-line input
    
    Pressing ENTER on a line that does not end with a semicolon (`;`) moves the cursor to the next line for more commands until a statement ends with a semi-colon.
    
    ![Interactive mode multi-line input](../../../../_images/interactive-sql-multiline.png)
    

To use interactive mode, enter the `snow sql` command followed by ENTER, as shown:

```
snow sql

```

Copy

The command opens a sub-shell with a `>` prompt where you can enter SQL commands interactively:

```
$ snow sql
  ╭───────────────────────────────────────────────────────────────────────────────────╮
  │ Welcome to Snowflake-CLI REPL                                                   │
  │ Type 'exit' or 'quit' to leave                                                  │
  ╰───────────────────────────────────────────────────────────────────────────────────╯
  >

```

You can then enter SQL commands, as shown:

```
> create table my_table (c1 int);

```

Copy

```
+-------------------------------------+
| status                              |
|-------------------------------------|
| Table MY_TABLE successfully created.|
+-------------------------------------+

```

Note

You must end each SQL statement with a semicolon (`;`).

To exit interactive mode, enter `exit`, `quit`, or CTRL\-D.

### Multiple commands in a single transaction[¶](#multiple-commands-in-a-single-transaction ""Link to this heading"")

The `--single-transaction` option lets you enter multiple SQL commands to execute as an all-or-nothing set of commands. By executing commands in a single transaction, you can ensure that all of the commands complete successfully before committing any of the changes. If any of the commands fail, none of the changes from the successful commands persist.

The following examples show successful and unsuccessful transactions:

*   Successful command execution
    
    ```
    snow sql -q ""insert into my_tbl values (123); insert into my_tbl values (124);"" --single-transaction
    
    ```
    
    Copy
    
    ```
    BEGIN;
    +----------------------------------+
    | status                           |
    |----------------------------------|
    | Statement executed successfully. |
    +----------------------------------+
    
    insert into my_tbl values (123);
    +-------------------------+
    | number of rows inserted |
    |-------------------------|
    | 1                       |
    +-------------------------+
    
    insert into my_tbl values (124);
    +-------------------------+
    | number of rows inserted |
    |-------------------------|
    | 1                       |
    +-------------------------+
    
    COMMIT
    +----------------------------------+
    | status                           |
    |----------------------------------|
    | Statement executed successfully. |
    +----------------------------------+
    
    ```
    
    You can then verify that the commands were committed to the database:
    
    ```
    snow sql -q ""select count(*) from my_tbl""
    
    ```
    
    Copy
    
    ```
    select count(*) from my_tbl
    +----------+
    | COUNT(*) |
    |----------|
    | 2        |
    +----------+
    
    ```
    
*   Unsuccessful single transaction
    
    ```
    snow sql -q ""insert into my_tbl values (123); insert into my_tbl values (124); select BAD;"" --single-transaction
    
    ```
    
    Copy
    
    ```
    BEGIN;
    +----------------------------------+
    | status                           |
    |----------------------------------|
    | Statement executed successfully. |
    +----------------------------------+
    
    insert into my_tbl values (123);
    +-------------------------+
    | number of rows inserted |
    |-------------------------|
    | 1                       |
    +-------------------------+
    
    insert into my_tbl values (124);
    +-------------------------+
    | number of rows inserted |
    |-------------------------|
    | 1                       |
    +-------------------------+
    
    select BAD;
    ╭─ Error ───────────────────────────────────────────────────────────────────────────────╮
    │ 000904 (42000): 01bc3b84-0810-0247-0001-c1be14ee11ce: SQL compilation error: error    │
    │ line 1 at position 7                                                                  │
    │ invalid identifier 'BAD'                                                              │
    ╰───────────────────────────────────────────────────────────────────────────────────────╯
    
    ```
    

> You can then verify that the commands were not committed to the database:
> 
> > ```
> > snow sql -q ""select count(*) from my_tbl""
> > 
> > ```
> > 
> > Copy
> > 
> > ```
> > select count(*) from my_tbl
> > +----------+
> > | COUNT(*) |
> > |----------|
> > | 0        |
> > +----------+
> > 
> > ```

## Examples[¶](#examples ""Link to this heading"")

*   The following example uses the SQL [SYSTEM$CLIENT\_VERSION\_INFO](../../../../sql-reference/functions/system_client_version_info) system function to return version information about the clients and drivers.
    
    ```
    snow sql --query 'SELECT SYSTEM$CLIENT_VERSION_INFO();'
    
    ```
    
    Copy
    
    ```
    select current_version();
    +-------------------+
    | CURRENT_VERSION() |
    |-------------------|
    | 8.25.1            |
    +-------------------+
    
    ```
    
*   The following example shows how you can specify a database using a client-side variable:
    
    ```
    snow sql -q ""select * from <% database %>.logs"" -D ""database=dev""
    
    ```
    
    Copy
    
    When executed, the command substitutes the value `dev` in the `<% database %>` variable to create the `dev.logs` identifier and then sends the `select * from dev.logs` SQL query to Snowflake for processing.
    
    Note
    
    You can currently use the SnowSQL `&variable_name` and &\`\`{ variable\_name }\`\` syntax for templates. However, Snowflake recommends using the `<% variable_name %>` syntax.
    
*   This example shows how to pass in environment variables using the `--env` option:
    
    ```
    snow sql -q ""select '<% ctx.env.test %>'"" --env test=value_from_cli
    
    ```
    
    Copy
    
*   By default, Snowflake CLI removes comments in SQL query from the output. The following example uses the `--retain-comments` option to include the comments in the query results.
    
    Assume the `example.sql` file contains the following statements and comment:
    
    ```
    select 'column1';
    -- My comment
    select 'column2';
    
    ```
    
    Copy
    
    When you execute the following command, `-- My comment` appears in the query results.
    
    ```
    snow sql -f example.sql --retain-comments
    
    ```
    
    Copy
    
    ```
    select 'column1';
    +-----------+
    | 'COLUMN1' |
    |-----------|
    | ABC       |
    +-----------+
    
    -- My comment
    select 'bar';
    +-----------+
    | 'COLUMN2' |
    |-----------|
    | 123       |
    +-----------+
    
    ```
    
    Copy
    

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/sql-commands/../../index)
2.  [Executing SQL statements](/developer-guide/snowflake-cli/command-reference/sql-commands/../../sql/execute-sql)
3.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/sql-commands/../overview)
4.  [SQL command reference](/developer-guide/snowflake-cli/command-reference/sql-commands/overview)",NULL,2fdec66703b71d9791b27e75c8db94e05b00ff6ad2f5da92af13823fee6e9ebf,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/setup-git,Setting up a Git repository¶,NULL,NULL,NULL,NULL,"# Setting up a Git repository[¶](#setting-up-a-git-repository ""Link to this heading"")

You can integrate your remote Git repository with Snowflake so that files from the repository are synchronized to a special kind of stage called a _repository stage_. The repository stage acts as a local Git repository with a full clone of the remote repository, including branches, tags, and commits.

For more information, see [Using a Git repository in Snowflake](../../git/git-overview).

## Before you start[¶](#before-you-start ""Link to this heading"")

Before setting a Git repository, you need the following information:

*   URL of the for the remote repository (also called the `origin` in Git).
    
*   Optional credentials for connecting to Git, including a secret, username, and password.
    
*   Optional API integration ID.
    
*   Role or user with privileges to create API integrations, if you do not already have an API integration.
    

For more information, see [Setting up Snowflake to use Git](../../git/git-setting-up).

## Set up a Git repository[¶](#set-up-a-git-repository ""Link to this heading"")

To clone a Git repository into Git repository stage, use the `snow git setup` command, as shown:

```
snow git setup <REPO_NAME>

```

Copy

where:

*   `<REPO_NAME>` is the ID of the repository stage you want to create. Note that if the repository stage already exists, the command fails.
    

The `snow git setup` command provide a series of prompts to collect the necessary information, as shown in the following examples:

*   Create a repository that requires a secret and credentials:
    
    ```
    $ snow git setup snowcli_git
    Origin url: https://github.com/snowflakedb/snowflake-cli.git
    Use secret for authentication? [y/N]: y
    Secret identifier (will be created if not exists) [snowcli_git_secret]: new_secret
    Secret 'new_secret' will be created
    username: john_doe
    password/token: ****
    API integration identifier (will be created if not exists) [snowcli_git_api_integration]:
    
    ```
    
    Copy
    
    ```
    Secret 'new_secret' successfully created.
    API integration snowcli_git_api_integration successfully created.
    +------------------------------------------------------+
    | status                                               |
    |------------------------------------------------------|
    | Git Repository SNOWCLI_GIT was successfully created. |
    +------------------------------------------------------+
    
    ```
    
*   Create a repository without a secret and an existing API integration ID:
    
    ```
    $ snow git setup snowcli_git
    Origin url: https://github.com/snowflakedb/snowflake-cli.git
    Use secret for authentication [y/N]: n
    API integration identifier (will be created if not exists) [snowcli_git_api_integration]: EXISTING_INTEGRATION
    
    ```
    
    Copy
    
    ```
    Using existing API integration 'EXISTING_INTEGRATION'.
    +------------------------------------------------------+
    | status                                               |
    |------------------------------------------------------|
    | Git Repository SNOWCLI_GIT was successfully created. |
    +------------------------------------------------------+
    
    ```
    

If the role or user specified in your [connection](../connecting/configure-connections) has not been granted, executing this command generates an error similar to the following:

```
003001 (42501): 01b2f095-0508-c66d-0001-c1be009a66ee: SQL access control error: Insufficient privileges to operate on account XXX

```

Copy

In this situation, you should check your connection configuration or ask your account administrator to give you the necessary privileges or to create the integration for you. For more information, see [Setting up Snowflake to use Git](../../git/git-setting-up)

On this page

1.  [Before you start](#before-you-start)
2.  [Set up a Git repository](#set-up-a-git-repository)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)
2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)
3.  [snow git setup](/developer-guide/snowflake-cli/git/../command-reference/git-commands/setup)",NULL,653f19de0dd9ff142a9c1812e389cc5d996fb8bc76a7f985a95de44baae541fd,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/refresh-repo,Refreshing a repository¶,NULL,NULL,NULL,NULL,"# Refreshing a repository[¶](#refreshing-a-repository ""Link to this heading"")

The `snow git fetch` command updates a repository stage with all branches, tags, and new commits from a remote repository.

To fetch changes in a repository, use the following command:

```
snow git fetch <REPO_NAME>

```

Copy

where:

*   `<REPO_NAME>` is the ID of the repository stage.
    

The following example refreshes a repository named `my_snow_git`:

```
snow git fetch my_snow_git

```

Copy

```
alter Git repository my_snow_git fetch
+-------------------------------------------------------------------+
| status                                                            |
|-------------------------------------------------------------------|
| Git Repository MY_SNOW_GIT is up to date. No change was fetched.. |
+-------------------------------------------------------------------+

```

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)
2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)
3.  [snow git fetch](/developer-guide/snowflake-cli/git/../command-reference/git-commands/fetch)",NULL,7275cfef7606019b53e183b83fe31ee714d1b0956ff10183dd3ccd2cbd04cfef,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/copy-files,Copying files in Git¶,NULL,NULL,NULL,NULL,"# Copying files in Git[¶](#copying-files-in-git ""Link to this heading"")

The `snow git copy` command copies files from given state of the repository (specific branch, tag, or commit) into another stage or local file system.

```
snow git copy <REPO_PATH> <DEST_PATH> [--parallel INT]

```

Copy

where:

*   `<REPO_PATH>` is a stage path with a specific scope where the value is the repository name followed by a suffix specifying which branch, tag, or commit to copy. The following lists some different types of values:
    
    *   `@snowcli_git/branches/main/` refers to last commit of the “main” branch
        
    *   `@snowcli_git/tags/v2.1.0/` refers to a commit tagged `v2.1.0`.
        
    *   `@snowcli_git/commits/1e939d69ca6fd0f89074e7e97c9fd1/` refers to a specific commit. Commit hashes should be between 6 and 40 characters long.
        
    
    A repository path can also be a subdirectory or file in the repository, but still must be preceded with a scope prefix.
    
*   `<DEST_PATH>` is a path to a local directory or to a remote directory on the Snowflake stage.
    
*   `--parallel` specifies the number of threads to use when downloading files.
    

When `<DEST_PATH>` specifies a stage, the command operates differently based on its suffix format, as follows:

*   If the source ends with a `/`, such as `@my_snow_git/branches/main/tests/plugin/`, the command copies the contents of the `plugin` directory into the destination.
    
*   If the source does not end with a `/`, such as `@my_snow_git/branches/main/tests/plugin`, the command copies the entire `plugin` directory.
    

## Example: Copy files from a commit to a directory in a stage[¶](#example-copy-files-from-a-commit-to-a-directory-in-a-stage ""Link to this heading"")

This example creates a `snowcli2.0/` directory on stage `@public` and copies all files from the commit marked with tag `v2.0.0` into that directory:

```
snow git copy @my_snow_git/tags/v2.0.0/ @public/snowcli2.0/

```

Copy

## Example: Copy files from inside a directory to a directory in a stage[¶](#example-copy-files-from-inside-a-directory-to-a-directory-in-a-stage ""Link to this heading"")

The following example creates a `plugin_tests` directory on the `test_stage` stage and copies the contents of the `tests/plugin/` directory into it.

```
snow git copy @my_snow_git/branches/main/tests/plugin/ @test_stage/plugin_tests/

```

Copy

## Example: Copy an entire directory to a directory in a stage[¶](#example-copy-an-entire-directory-to-a-directory-in-a-stage ""Link to this heading"")

This example creates a `plugin_tests` directory on the `test_stage` stage and copies the entire `tests/plugin` directory into it. Because `tests/plugin` does note end with a /, the command copies all of the files to `@test_stage/plugin_tests/plugin`.

```
snow git copy @snowcli_git/branches/main/tests/plugin @test_stage/plugin_tests

```

Copy

## Example: Copy files from a directory in a stage to the local file system[¶](#example-copy-files-from-a-directory-in-a-stage-to-the-local-file-system ""Link to this heading"")

The following example creates a `plugin_tests` directory in the local file system and downloads the contents of the `tests/plugin` directory into it.

```
snow git copy @snowcli_git/branches/main/tests/plugin plugin_tests/

```

Copy

On this page

1.  [Example: Copy files from a commit to a directory in a stage](#example-copy-files-from-a-commit-to-a-directory-in-a-stage)
2.  [Example: Copy files from inside a directory to a directory in a stage](#example-copy-files-from-inside-a-directory-to-a-directory-in-a-stage)
3.  [Example: Copy an entire directory to a directory in a stage](#example-copy-an-entire-directory-to-a-directory-in-a-stage)
4.  [Example: Copy files from a directory in a stage to the local file system](#example-copy-files-from-a-directory-in-a-stage-to-the-local-file-system)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)
2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)
3.  [snow git copy](/developer-guide/snowflake-cli/git/../command-reference/git-commands/copy)",NULL,df890eb1849394680e965d80a4dd3b51db138f74ae35d692588016b0a5f5f297,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/execute-sql,Executing files from a repository¶,NULL,NULL,NULL,NULL,"# Executing files from a repository[¶](#executing-files-from-a-repository ""Link to this heading"")

Note

Snowflake CLI does not support executing Python files for Python versions 3.12 and above.

You can use the `snow git execute` command for all `.sql` and `.py` files in a repository path. The command searches for all SQL and Python files and then executes the [EXECUTE IMMEDIATE](../../../sql-reference/sql/execute-immediate) command on each of them.

```
snow git execute <REPO_PATH> [--silent]

```

Copy

where:

*   `<REPO_PATH>` can be any of the following:
    
    *   A repository stage, such as `@snowcli_git/branches/main/`, to execute commands from all `.sql` files in the stage.
        
    *   A glob-like pattern, such as `@snowcli_git/branches/main/scripts/*`, to execute commands from all `.sql` files in the `scripts` directory.
        
    *   A specific `.sql` file, such as `@snowcli_git/branches/main/scripts/script.sql`, to execute commands contained only the `script.sql` file.
        
*   `--silent` hides intermediate messages with file execution results.
    

Note

The `snow git execute` command does not display the output of any of the SQL commands it processes.

The following example shows how to execute SQL commands in all files within the `project` directory that match a regular expression.

```
snow git execute ""@git_test/branches/main/projects/script?.sql""

```

Copy

```
SUCCESS - git_test/branches/main/projects/script1.sql
SUCCESS - git_test/branches/main/projects/script2.sql
SUCCESS - git_test/branches/main/projects/script3.sql
+---------------------------------------------------------------+
| File                                        | Status  | Error |
|---------------------------------------------+---------+-------|
| git_test/branches/main/projects/script1.sql | SUCCESS | None  |
| git_test/branches/main/projects/script2.sql | SUCCESS | None  |
| git_test/branches/main/projects/script3.sql | SUCCESS | None  |
+---------------------------------------------------------------+

```

Adding the `--silent` option to the same command hides the intermediate messages showing the progression of the files processed.

```
snow git execute ""@git_test/branches/main/projects/script?.sql"" --silent

```

Copy

```
+---------------------------------------------------------------+
| File                                        | Status  | Error |
|---------------------------------------------+---------+-------|
| git_test/branches/main/projects/script1.sql | SUCCESS | None  |
| git_test/branches/main/projects/script2.sql | SUCCESS | None  |
| git_test/branches/main/projects/script3.sql | SUCCESS | None  |
+---------------------------------------------------------------+

```

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)
2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)
3.  [snow git execute](/developer-guide/snowflake-cli/git/../command-reference/git-commands/execute)",NULL,7b5209505422da408b9c73de078c7ac901b74bafaa6e3bb15d946a576ecb0dd5,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/data-pipelines/dbt-projects,Managing dbt Projects on Snowflake using Snowflake CLI¶,NULL,NULL,NULL,NULL,"# Managing dbt Projects on Snowflake using Snowflake CLI[¶](#managing-sf-dbt-using-sf-cli ""Link to this heading"")

Note

The dbt Projects on Snowflake features in Snowflake CLI are available only in version 3.13.0 or later.

You can use Snowflake CLI to manage dbt projects with the following operations:

*   [Deploying a dbt project object](#label-snowcli-snow-dbt-deploy)
    
*   [Listing all available dbt project objects](#label-snowcli-snow-dbt-list)
    
*   [Executing a dbt project object command](#label-snowcli-snow-dbt-execute)
    
*   [Describing a dbt project object](#label-snowcli-snow-dbt-describe)
    
*   [Dropping a dbt project object](#label-snowcli-snow-dbt-drop)
    

## Deploying a dbt project object[¶](#deploying-a-dbt-project-object ""Link to this heading"")

The [snow dbt deploy](../command-reference/dbt-commands/deploy) command uploads local files to a temporary stage and creates a new dbt project object, updates it by making a new version, or completely recreates it. A valid dbt project must contain two files:

*   `dbt_project.yml`: A standard dbt configuration file that specifies the profile to use.
    
*   `profiles.yml`: A dbt connection profile definition referenced in `dbt_project.yml`. `profiles.yaml` must define the database, role, schema, and type.
    
    *   By default, dbt Projects on Snowflake uses your target schema (`target.schema`) specified from your dbt environment or profile. Unlike dbt Core behavior, the target schema specified in the `profiles.yml` file must exist before you create your dbt Project in order for it to compile or execute successfully.
        
    
    ```
    <profile_name>:
    target: dev
    outputs:
      dev:
        database: <database_name>
        role: <role_name>
        schema: <schema_name>
        type: snowflake
    
    ```
    
    Copy
    

The following examples illustrate how to use the `snow dbt deploy` command:

*   Deploy a dbt project object named `jaffle_shop`:
    
    ```
    snow dbt deploy jaffle_shop
    
    ```
    
    Copy
    
*   Deploy a project named `jaffle_shop` from a specified directory and create or add a new version depending on whether the dbt project object already exists:
    
    ```
    snow dbt deploy jaffle_shop --source /path/to/dbt/directory --profiles-dir ~/.dbt/ --force
    
    ```
    
    Copy
    
*   Deploy a project named `jaffle_shop` from a specified directory using a custom profiles directory and enabling [external access integrations](../../external-network-access/creating-using-external-network-access):
    
    ```
    snow dbt deploy jaffle_shop --source /path/to/dbt/directory
    --profiles-dir ~/.dbt/ --default-target dev
    --external-access-integration dbthub-integration
    --external-access-integration github-integration
    --force
    
    ```
    
    Copy
    

## Listing all available dbt project objects[¶](#listing-all-available-dbt-project-objects ""Link to this heading"")

The [snow dbt list](../command-reference/dbt-commands/list) command lists all available dbt project objects on Snowflake.

The following examples illustrate how to use the `snow dbt list` command:

*   List all available dbt project objects:
    
    ```
    snow dbt list
    
    ```
    
    Copy
    
*   List dbt project objects in the `product` database whose names begin with `JAFFLE`:
    
    ```
    snow dbt list --like JAFFLE% --in database product
    
    ```
    
    Copy
    

## Executing a dbt project object command[¶](#executing-a-dbt-project-object-command ""Link to this heading"")

The [snow dbt execute](../command-reference/dbt-commands/execute/overview) command executes one of the following [dbt commands](https://docs.getdbt.com/reference/dbt-commands) on a Snowflake dbt project object:

*   [build](https://docs.getdbt.com/reference/commands/build)
    
*   [compile](https://docs.getdbt.com/reference/commands/compile)
    
*   [deps](https://docs.getdbt.com/reference/commands/deps)
    
*   [list](https://docs.getdbt.com/reference/commands/list)
    
*   [parse](https://docs.getdbt.com/reference/commands/parse)
    
*   [retry](https://docs.getdbt.com/reference/commands/retry)
    
*   [run](https://docs.getdbt.com/reference/commands/run)
    
*   [run-operation](https://docs.getdbt.com/reference/commands/run-operation)
    
*   [seed](https://docs.getdbt.com/reference/commands/seed)
    
*   [show](https://docs.getdbt.com/reference/commands/show)
    
*   [snapshot](https://docs.getdbt.com/reference/commands/snapshot)
    
*   [test](https://docs.getdbt.com/reference/commands/test)
    

For more information about using dbt commands, see the [dbt Command reference](https://docs.getdbt.com/reference/dbt-commands).

The following examples illustrate how to use the `snow dbt execute` command:

*   Execute the dbt `test` command:
    
    ```
    snow dbt execute jaffle_shop test
    
    ```
    
    Copy
    
*   Execute the `run` dbt command asynchronously:
    
    ```
    snow dbt execute --run-async jaffle_shop run --select @source:snowplow,tag:nightly models/export
    
    ```
    
    Copy
    

## Describing a dbt project object[¶](#describing-a-dbt-project-object ""Link to this heading"")

The [snow dbt describe](../command-reference/dbt-commands/describe) command describes a dbt project object on Snowflake.

The following example describes the dbt project object named `my_dbt_project` on Snowflake:

```
snow dbt describe my_dbt_project

```

Copy

## Dropping a dbt project object[¶](#dropping-a-dbt-project-object ""Link to this heading"")

The [snow dbt drop](../command-reference/dbt-commands/drop) command deletes a dbt project object on Snowflake.

The following example deletes the dbt project object named `my_dbt_project` on Snowflake:

```
snow dbt drop my_dbt_project

```

Copy

## Use `snow dbt` commands in a CI/CD workflow[¶](#use-snow-dbt-commands-in-a-ci-cd-workflow ""Link to this heading"")

Note

When building CI/CD workflows, you only need your git server, such as Github, and Snowflake CLI. A Git repository object is not required.

You can run dbt commands with Snowflake CLI to build CI/CD pipelines. These pipelines are commonly used to test new code, such as new pull requests, or to update production applications whenever something is merged to the main branch.

To build a CI/CD workflow with `snow dbt` commands, follow these steps:

1.  Prepare your dbt project:
    
    1.  Download your dbt project or start a new one.
        
        *   Ensure that the main project directory contains the `dbt_project.yml` and `profiles.yml` files.
            
        *   Verify that the profile name referenced in `dbt_project.yml` is defined in `profiles.yml`.
            
            Note
            
            Snowflake’s dbt project objects don’t need passwords, so if `profiles.yml` contains any, deployment stops until they are removed.
            
2.  Set up Snowflake CLI GitHub Action.
    
    Follow the guidelines for [setting up GitHub Action for Snowflake CLI](../cicd/integrate-ci-cd) and [verify your connection](../connecting/configure-connections.html#label-cli-test-connection) to Snowflake.
    
3.  Define your workflow.
    
    Determine which commands your workflow needs to run based on your organization’s needs. The following example illustrates a CI workflow that updates the version of the dbt project object named `product_pipeline` with new files, runs the transformations, and finally runs tests:
    
    ```
    - name: Execute Snowflake CLI command
      run: |
        snow dbt deploy product_pipeline
        snow dbt execute product_pipeline run
        snow dbt execute product_pipeline test
    
    ```
    
    Copy
    

On this page

1.  [Deploying a dbt project object](#deploying-a-dbt-project-object)
2.  [Listing all available dbt project objects](#listing-all-available-dbt-project-objects)
3.  [Executing a dbt project object command](#executing-a-dbt-project-object-command)
4.  [Describing a dbt project object](#describing-a-dbt-project-object)
5.  [Dropping a dbt project object](#dropping-a-dbt-project-object)
6.  [Use snow dbt commands in a CI/CD workflow](#use-snow-dbt-commands-in-a-ci-cd-workflow)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/data-pipelines/../index)
2.  [snow dbt commands](/developer-guide/snowflake-cli/data-pipelines/../command-reference/dbt-commands/overview)
3.  [dbt Projects on Snowflake](/developer-guide/snowflake-cli/data-pipelines/../../../user-guide/data-engineering/dbt-projects-on-snowflake)",NULL,826a9e155857b724114f6435440202aed0e16576c1ec080a7678b291bb6c5a46,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/auth-commands/overview,snow auth oidc commands¶,NULL,NULL,NULL,NULL,"# snow auth oidc commands[¶](#snow-auth-oidc-commands ""Link to this heading"")

The `snow auth oidc` commands enable secure, password-less authentication to Snowflake. It leverages OpenID Connect (OIDC) tokens from CI/CD environments like GitHub Actions. This feature supports workload identity federation (WIF), enabling automated systems to access Snowflake without static credentials, which aligns with security best practices.

The following Snowflake CLI `snow auth oidc` commands let you manage authentication for your Snowflake projects:

*   [snow auth oidc read-token](read-token)
    

Note the following:

*   The `snow auth oidc` commands are currently limited to GitHub Actions as the provider.
    
*   The OIDC token is only available when running inside a supported CI/CD environment, such as a GitHub Actions runner.
    
*   Short-lived OIDC tokens are detected dynamically; Snowflake CLI does not store any OIDC tokens.
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/auth-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/auth-commands/../overview)",NULL,7c830269bc0b8f46f8dbb1be9798f1eab53a3fb340a46eb17b8099891417f6aa,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/bootstrap-commands/overview,snow bootstrap commands¶,NULL,NULL,snow bootstrap,snow bootstrap overview,"# snow bootstrap commands[¶](#snow-bootstrap-commands ""Link to this heading"")

The Snowflake CLI bootstrap commands provide developers the ability to instantiate projects from templates.

*   [snow init](init)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/bootstrap-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/bootstrap-commands/../overview)",NULL,72d29036916f9b0b09cd8ce7f966560f2a0a1bf8a68f04e330613ad83330337f,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/connection-commands/overview,snow connection commands¶,NULL,NULL,snow connection,snow connection overview,"# snow connection commands[¶](#snow-connection-commands ""Link to this heading"")

Snowflake CLI supports the following commands for managing Snowflake connections:

> *   [snow connection add](add-connection)
>     
> *   [snow connection generate-jwt](generate-jwt)
>     
> *   [snow connection list](list-connections)
>     
> *   [snow connection remove](remove-connection)
>     
> *   [snow connection set-default](set-default-connection)
>     
> *   [snow connection test](test-connection)
>     

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/connection-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/connection-commands/../overview)
3.  [snow connection add](/developer-guide/snowflake-cli/command-reference/connection-commands/add-connection)
4.  [snow connection list](/developer-guide/snowflake-cli/command-reference/connection-commands/list-connections)
5.  [snow connection set-default](/developer-guide/snowflake-cli/command-reference/connection-commands/set-default-connection)
6.  [snow connection test](/developer-guide/snowflake-cli/command-reference/connection-commands/test-connection)",NULL,5912f1d05142239bafa058abe5525e2a34b52c2468f5e9da207491d8764242fc,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/cortex-commands/overview,snow cortex commands¶,NULL,NULL,snow cortex,snow cortex overview,"# snow cortex commands[¶](#snow-cortex-commands ""Link to this heading"")

Snowflake CLI provides the following commands to access [Snowflake Cortex](../../../../user-guide/snowflake-cortex/aisql) features:

*   [snow cortex complete](complete)
    
*   [snow cortex extract-answer](extract-answer)
    
*   [snow cortex sentiment](sentiment)
    
*   [snow cortex summarize](summarize)
    
*   [snow cortex translate](translate)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/cortex-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/cortex-commands/../overview)
3.  [Snowflake Cortex](/developer-guide/snowflake-cli/command-reference/cortex-commands/../../../../user-guide/snowflake-cortex/aisql)",NULL,7865971c086c5d17b07a5590d86ae038e7efbd7a7c120907d04c1bd219d0946d,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/dbt-commands/overview,snow dbt commands¶,NULL,NULL,NULL,NULL,"# snow dbt commands[¶](#snow-dbt-commands ""Link to this heading"")

Snowflake CLI supports the following commands for managing Snowflake dbt project objects:

*   [snow dbt describe](describe)
    
*   [snow dbt deploy](deploy)
    
*   [snow dbt drop](drop)
    
*   [snow dbt execute commands](execute/overview)
    
*   [snow dbt list](list)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/dbt-commands/../../index)
2.  [Managing dbt Projects on Snowflake using Snowflake CLI](/developer-guide/snowflake-cli/command-reference/dbt-commands/../../data-pipelines/dbt-projects)",NULL,a46b78abd54423935411d6d0a97399e008a417b7a2feefcbae697d96de5317a5,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/git-commands/overview,snow git commands¶,NULL,NULL,snow git,snow git overview,"# snow git commands[¶](#snow-git-commands ""Link to this heading"")

Snowflake CLI supports the following commands to support Git integration:

*   [snow git copy](copy)
    
*   [snow git describe](describe)
    
*   [snow git drop](drop)
    
*   [snow git execute](execute)
    
*   [snow git fetch](fetch)
    
*   [snow git list](list)
    
*   [snow git list-branches](list-branches)
    
*   [snow git list-files](list-files)
    
*   [snow git list-tags](list-tags)
    
*   [snow git setup](setup)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/git-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/git-commands/../overview)",NULL,ed1895d783146a08daf345425074e1cc09b0ac4df85c58728d560e7b6b7dffbd,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/helpers-commands/overview,snow helpers commands¶,NULL,NULL,snow helpers,snow helpers overview,"# snow helpers commands[¶](#snow-helpers-commands ""Link to this heading"")

Snowflake CLI supports the following workspace commands:

*   [snow helpers check-snowsql-env-vars](check-snowsql-env-vars)
    
*   [snow helpers import-snowsql-connections](import-snowsql-connections)
    
*   [snow helpers v1-to-v2](v1-to-v2)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/helpers-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/helpers-commands/../overview)",NULL,dbe4f882f5ef24c36df67144618e8d77b899a71772c549f489f43a94f4874b62,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/overview,snow notebook commands¶,NULL,NULL,snow notebook,snow notebook overview,"# snow notebook commands[¶](#snow-notebook-commands ""Link to this heading"")

Snowflake CLI supports the following commands for managing Snowflake notebooks:

*   [snow notebook create](create)
    
*   [snow notebook deploy](deploy)
    
*   [snow notebook execute](execute)
    
*   [snow notebook get-url](get-url)
    
*   [snow notebook open](open)
    

You can get a list of all available notebooks by running the `snow object list notebook` command. For more information, see [snow object list](../object-commands/list).

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)
2.  [Using Snowflake Notebooks](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../notebooks/use-notebooks)",NULL,aa4d1bdede1c9fe814339bc78040466fe3a89e37b82817b2e6fc431fbc5ad2a0,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/native-apps-commands/overview,snow app commands¶,NULL,NULL,snow app,snow app overview,"# snow app commands[¶](#snow-app-commands ""Link to this heading"")

Snowflake CLI supports the following commands for managing Snowflake Native App apps:

> *   [snow app bundle](bundle-app)
>     
> *   [snow app deploy](deploy-app)
>     
> *   [snow app events](retrieve-app-events)
>     
> *   [snow app open](open-app)
>     
> *   [snow app publish](publish-app)
>     
> *   [snow app release-channel commands](release-channel/overview)
>     
> *   [snow app release-directive commands](release-directive/overview)
>     
> *   [snow app run](run-app)
>     
> *   [snow app teardown](teardown-app)
>     
> *   [snow app validate](validate-app)
>     
> *   [snow app version commands](version/overview)
>     

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../overview)
3.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../native-apps/overview)",NULL,8b176338147bef15f41c69af709e6af34a9ba6ae9f2c7678674b17eb1bb217b7,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/overview,snow object commands¶,NULL,NULL,snow object,snow object overview,"# snow object commands[¶](#snow-object-commands ""Link to this heading"")

Snowflake CLI supports the following commands to support Snowflake objects:

*   [snow object create](create)
    
*   [snow object describe](describe)
    
*   [snow object drop](drop)
    
*   [snow object list](list)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)",NULL,e40c688f29200052961f262b48c70123636ba88f7a75286cf8ceaefe58a2f1df,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snowpark-commands/overview,snow snowpark commands¶,NULL,NULL,snow snowpark,snow,"# snow snowpark commands[¶](#snow-snowpark-commands ""Link to this heading"")

Snowflake CLI supports the following Snowpark commands:

*   [snow snowpark build](build)
    
*   [snow snowpark deploy](deploy)
    
*   [snow snowpark describe](describe)
    
*   [snow snowpark drop](drop)
    
*   [snow snowpark execute](execute)
    
*   [snow snowpark list](list)
    
*   [snow snowpark package commands](package-commands/overview)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/snowpark-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/../overview)",NULL,8e4e1bd660e3d327834579437119ebe430ffaf9175aefbc74abb64c3b3f4a0c7,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/overview,Snowpark Container Services (spcs) commands¶,NULL,NULL,snow spcs,snow spcs overview,"# Snowpark Container Services (`spcs`) commands[¶](#snowpark-container-services-spcs-commands ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Snowflake CLI supports the following commands to support Snowpark Container Services:

> *   [snow spcs image-registry commands](image-registry-commands/overview)
>     
> *   [snow spcs image-repository commands](image-repository-commands/overview)
>     
> *   [snow spcs compute-pool commands](compute-pool-commands/overview)
>     
> *   [snow spcs service commands](service-commands/overview)
>     

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/../overview)",NULL,3882213b547dbf26af543e434ffdceb035c8ccacfbec2ce6609e2c7617c39e2d,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/sql-commands/overview,snow sql commands¶,NULL,NULL,snow sql,snow sql overview,"# snow sql commands[¶](#snow-sql-commands ""Link to this heading"")

SQL commands provide developers the ability to execute SQL queries with Snowflake CLI.

*   [snow sql](sql)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/sql-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/sql-commands/../overview)",NULL,e7e947812fd94802c361d37a623bf7127e8b24ed6e47cf269bf5ba2768d569bd,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/overview,snow stage commands¶,NULL,NULL,snow stage,snow stage overview,"# snow stage commands[¶](#snow-stage-commands ""Link to this heading"")

Snowflake CLI supports the following commands to support Snowflake stage objects:

*   [snow stage copy](copy)
    
*   [snow stage create](create)
    
*   [snow stage describe](describe)
    
*   [snow stage drop](drop)
    
*   [snow stage execute](execute)
    
*   [snow stage list](list)
    
*   [snow stage list-files](list-files)
    
*   [snow stage remove](remove)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)
3.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",NULL,c5d41c4d5e1602fee36db4ac137887d57f4e9854e3977c2564a68afa27360cb7,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/streamlit-commands/overview,snow streamlit commands¶,NULL,NULL,snow streamlit,snow streamlit overview,"# snow streamlit commands[¶](#snow-streamlit-commands ""Link to this heading"")

Snowflake CLI supports the following commands for managing Streamlit apps:

*   [snow streamlit deploy](deploy)
    
*   [snow streamlit describe](describe)
    
*   [snow streamlit drop](drop)
    
*   [snow streamlit execute](execute)
    
*   [snow streamlit get-url](get-url)
    
*   [snow streamlit list](list)
    
*   [snow streamlit share](share)
    

For more information about Streamlit apps, refer to [About Streamlit in Snowflake](../../../streamlit/about-streamlit) and [Add a Streamlit app](../../../native-apps/adding-streamlit).

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../overview)",NULL,8efe77900fe4228a88756343ca00fd27937ad27e7d0e926b63f32df988b271aa,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/overview,snow snowpark package commands¶,NULL,NULL,snow snowpark,snow,"# snow snowpark package commands[¶](#snow-snowpark-package-commands ""Link to this heading"")

Snowflake CLI supports the following commands to support Snowpark packages:

*   [snow package create](create)
    
*   [snow package lookup](lookup)
    
*   [snow package upload](upload)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../overview)
3.  [snow snowpark commands](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../overview)",NULL,5b8de12ee55ca836f798b8d8cab7dbcd833b5dce5fcf54dce380afec193b10b0,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/overview,snow spcs image-registry commands¶,NULL,NULL,snow spcs,snow spcs image registry commands,"# snow spcs image-registry commands[¶](#snow-spcs-image-registry-commands ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Snowflake CLI provides the following commands for managing image registries:

*   [snow spcs image-registry login](login)
    
*   [snow spcs image-registry token](token)
    
*   [snow spcs image-registry url](url)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../overview)",NULL,f291273c11b1dc9fb9f1230baf262d9d399d0648fc6ad122257db88ae1131e3d,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview,snow spcs image-repository commands¶,NULL,NULL,snow spcs,snow spcs image repository commands,"# snow spcs image-repository commands[¶](#snow-spcs-image-repository-commands ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Snowflake CLI provides the following commands to manage image repositories:

*   [snow spcs image-repository create](create)
    
*   [snow spcs image-repository deploy](deploy)
    
*   [snow spcs image-repository drop](drop)
    
*   [snow spcs image-repository list](list)
    
*   [snow spcs image-repository list-images](list-images)
    
*   [snow spcs image-repository list-tags](list-tags)
    
*   [snow spcs image-repository url](url)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)
4.  [image-registry command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../image-registry-commands/overview)",NULL,bad3d24fdbfdf51ef1ff4e9427734057df68abd6b025aba0930dc46965e349c7,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/overview,snow spcs compute-pool commands¶,NULL,NULL,snow spcs,snow spcs compute pool commands,"# snow spcs compute-pool commands[¶](#snow-spcs-compute-pool-commands ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Snowflake CLI supports the following commands to support compute pools:

*   [snow spcs compute-pool create](create)
    
*   [snow spcs compute-pool deploy](deploy)
    
*   [snow spcs compute-pool describe](describe)
    
*   [snow spcs compute-pool drop](drop)
    
*   [snow spcs compute-pool resume](resume)
    
*   [snow spcs compute-pool set](set)
    
*   [snow spcs compute-pool status](status)
    
*   [snow spcs compute-pool stop-all](stop-all)
    
*   [snow spcs compute-pool suspend](suspend)
    
*   [snow spcs compute-pool unset](unset)
    

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../overview)",NULL,399fbb236a7d33f7b8139b1d7e177a24e1d3a7dbf8d1861f16ce1804ef78a153,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview,snow spcs service commands¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service commands[¶](#snow-spcs-service-commands ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Snowflake CLI supports the following commands for managing services:

> *   [snow spcs service create](create)
>     
> *   [snow spcs service deploy](deploy)
>     
> *   [snow spcs service describe](describe)
>     
> *   [snow spcs service drop](drop)
>     
> *   [snow spcs service events](events)
>     
> *   [snow spcs service execute-job](execute-job)
>     
> *   [snow spcs service list](list)
>     
> *   [snow spcs service list-containers](list-containers)
>     
> *   [snow spcs service list-endpoints](list-endpoints)
>     
> *   [snow spcs service list-instances](list-instances)
>     
> *   [snow spcs service list-roles](list-roles)
>     
> *   [snow spcs service logs](logs)
>     
> *   [snow spcs service metrics](metrics)
>     
> *   [snow spcs service resume](resume)
>     
> *   [snow spcs service set](set)
>     
> *   [snow spcs service status](status)
>     
> *   [snow spcs service suspend](suspend)
>     
> *   [snow spcs service unset](unset)
>     
> *   [snow spcs service upgrade](upgrade)
>     

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [Snowpark Container Services (spcs) commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../overview)",NULL,133b6f19e72eea675d632386183007efc683c1ed2f3bffde8a00c7b43beb5154,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/helpers-commands/import-snowsql-connections,snow helpers import-snowsql-connections¶,NULL,NULL,snow helpers,snow helpers import snowsql connections,"# snow helpers import-snowsql-connections[¶](#snow-helpers-import-snowsql-connections ""Link to this heading"")

Import your existing connections from your SnowSQL configuration.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow helpers import-snowsql-connections
  --snowsql-config-file <custom_snowsql_config_files>
  --default-connection-name <default_cli_connection_name>
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

None

## Options[¶](#options ""Link to this heading"")

`--snowsql-config-file _FILE_`

Specifies file paths to custom SnowSQL configuration. The option can be used multiple times to specify more than 1 file.

`--default-connection-name _TEXT_`

Specifies the name which will be given in Snowflake CLI to the default connection imported from SnowSQL. Default: default.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow helpers import-snowsql-connections` command imports existing connection definitions from SnowSQL into your `config.toml` configuration file.

By default, the command reads the SnowSQL configuration files in the order described in the [Configuring SnowSQL](../../../../user-guide/snowsql-config.html#label-configuring-snowsql) topic. If more than one of these configurations define the same connection, this command overwrites the previously imported connection definition with the most recent one. To illustrate, assume the same `[connections.example]` connection is defined with different parameters in the following locations:

| Location of the configuration file | Connection definition |
| --- | --- |
| /etc/snowsql.cnf | [connections]

[connections.example]
username=user1
Copy |
| <HOME_DIR>/.snowsql/config | [connections]

[connections.example]
username=user2
password=<my-pwd>
Copy |

After you run the command, your Snowflake CLI `config.toml` file contains the following `[connections.example]` definition (from the file with the higher precedence):

```
[connections]

[connections.example]
username=user2
password=<my-pwd>

```

Copy

You can use the `--snowsql-config-file` option to override this default behavior and import from one or more specific SnowSQL configuration files instead.

The `snow helpers import-snowsql-connections` command also imports the default connection from SnowSQL, which is not a named connection. It is defined directly in the `[connections]` section of the configuration file. Because Snowflake CLI requires all connections to be named, the command defines a connection named `[default]`. If you want to use another name for the default connection, you can specify it with the `--default-connection-name` option.

If a SnowSQL connection matches the name of an existing Snowflake CLI connection, the command prompt asks whether you want to overwrite the existing connection or skip importing that SnowSQL connection.

## Examples[¶](#examples ""Link to this heading"")

The following example imports SnowSQL connections from the standard configuration file locations:

```
snow helpers import-snowsql-connections

```

Copy

As the command processes the SnowSQL configuration files, it shows the progress and prompts for confirmation when a connection with the same name is already defined in the Snowflake CLI `config.toml` file.

```
SnowSQL config file [/etc/snowsql.cnf] does not exist. Skipping.
SnowSQL config file [/etc/snowflake/snowsql.cnf] does not exist. Skipping.
SnowSQL config file [/usr/local/etc/snowsql.cnf] does not exist. Skipping.
Trying to read connections from [/Users/<user>/.snowsql.cnf].
Reading SnowSQL's connection configuration [connections.connection1] from [/Users/<user>/.snowsql.cnf]
Trying to read connections from [/Users/<user>/.snowsql/config].
Reading SnowSQL's default connection configuration from [/Users/<user>/.snowsql/config]
Reading SnowSQL's connection configuration [connections.connection1] from [/Users/<user>/.snowsql/config]
Reading SnowSQL's connection configuration [connections.connection2] from [/Users/<user>/.snowsql/config]
Connection 'connection1' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: Y
Connection 'connection2' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: n
Connection 'default' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: n
Saving [connection1] connection in Snowflake CLI's config.
Connections successfully imported from SnowSQL to Snowflake CLI.

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/helpers-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/helpers-commands/../overview)
3.  [snow helpers commands](/developer-guide/snowflake-cli/command-reference/helpers-commands/overview)
4.  [Import connections from SnowSQL](/developer-guide/snowflake-cli/command-reference/helpers-commands/../../connecting/configure-connections#label-snowcli-import-connections-snowsql)",NULL,3820b1f1bb5f33fa8d467a5213e2a47539018de3e3ebb0b07379d43eae9af101,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/publish-app.html,Publishing a Snowflake Native App to customers¶,NULL,NULL,NULL,NULL,"# Publishing a Snowflake Native App to customers[¶](#publishing-a-native-app-to-customers ""Link to this heading"")

## Prerequisites[¶](#prerequisites ""Link to this heading"")

*   You must have an existing connection in your `config.toml` file.
    
*   You must have a `snowflake.yml` file in your Snowflake Native App project.
    
*   You must have an existing listing if you are publishing a Snowflake Native App to the [Snowflake Marketplace](../../../collaboration/collaboration-marketplace-about).
    

## How to publish a Snowflake Native App to customers[¶](#how-to-publish-a-native-app-to-customers ""Link to this heading"")

In Snowflake, publishing a Snowflake Native App to customers is done by setting release directives. Release directives are a set of rules that determine which version and patch of the Snowflake Native App is available to which customers.

Release channels provide a way to manage separate release processes for different types of customers. For example, early access customers can use the ALPHA channel, the internal QA team can use the QA channel, and general customers can use the DEFAULT channel.

If release channels are enabled for an application package, the release directives are tied to the release channels; otherwise, the release directives are tied directly to the application package.

Note

The release channels feature might not be available in all regions. Please contact Snowflake Support for more information.

### Process with release channels enabled[¶](#process-with-release-channels-enabled ""Link to this heading"")

To explicitly enable release channels, add `enable_release_channels=true` to the [application package definition](project-definitions.html#label-cli-app-pkg-entity-props) in your `snowflake.yml` file. You need to update or recreate your application package after enabling release channels.

Note

After enabling, release channels cannot be disabled

To confirm that release channels have been enabled, run the [snow app release-channel list](../command-reference/native-apps-commands/release-channel/list) command. A list of release channels in the application package is then displayed:

```
snow app release-channel list

```

Copy

The simplest way to publish an existing version and patch to all customers on the default release channel is to use the [snow app publish](../command-reference/native-apps-commands/publish-app) command with the `--version` and `--patch` options:

```
snow app publish --version v1 --patch 1

```

Copy

To automatically create a new version and patch, use the `--create-version` option:

```
snow app publish --version v1 --create-version

```

Copy

To publish a Snowflake Native App to a non-default release channel, use the `--channel` option:

```
snow app publish --version v1 --patch 1 --channel ALPHA

```

Copy

To publish a Snowflake Native App to a custom release directive targeting specific customers, use the `--directive` option:

```
snow app publish --version v1 --patch 1 --channel ALPHA --directive customers_group_1

```

Copy

The `snow app publish` command adds the version to the release channel. If the release channel already has the maximum number of versions allowed, this command first attempts to remove from the channel one of the versions not referenced by any release directive.

After adding the version to the release channel, the command sets the default release directive of that release channel to the specified version and patch.

For more control over what is happening, replace the previous command with the following commands:

```
snow app release-channel add-version --version v1 ALPHA
snow app release-directive set customers_group_1 --version v1 --patch 1

```

Copy

For more information on managing release channels and release directives, see the [snow app release-channel](../command-reference/native-apps-commands/release-channel/overview) and [snow app release-directive](../command-reference/native-apps-commands/release-directive/overview) command references.

### Process with release channels disabled[¶](#process-with-release-channels-disabled ""Link to this heading"")

If release channels are not enabled for an application package, the release directives are tied directly to the application package.

The simplest way to publish an existing version and patch to all customers is to use the [snow app publish](../command-reference/native-apps-commands/publish-app) command with the `--version` and `--patch` options.

```
snow app publish --version v1 --patch 1

```

Copy

This command sets the default release directive of the application package to the specified version and patch. In this case, release channels are not enabled, so no release channel is involved in this process.

If you want the publish command to automatically create a new version and patch, use the `--create-version` option:

```
snow app publish --version v1 --create-version

```

Copy

To publish a Snowflake Native App to a custom release directive targeting specific customers, use the `--directive` option:

```
snow app publish --version v1 --patch 1 --directive customers_group_1

```

Copy

These `snow app publish` commands continue to work even if release channels are enabled in the future. When release channels are enabled, the command starts using the default release channel.

On this page

1.  [Prerequisites](#prerequisites)
2.  [How to publish a Snowflake Native App to customers](#how-to-publish-a-native-app-to-customers)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)
3.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)
4.  [snow app version commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/version/overview)
5.  [snow app release-channel commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/release-channel/overview)
6.  [snow app release-directive commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/release-directive/overview)
7.  [snow app publish](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/publish-app)",NULL,3a4aec93330d00a5372a04bc956ccaa3cc179cebd2f45a8e9e3480098bcc9f64,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/bundle-app.html,Preparing a local folder with configured Snowflake Native App artifacts¶,NULL,NULL,NULL,NULL,"# Preparing a local folder with configured Snowflake Native App artifacts[¶](#preparing-a-local-folder-with-configured-native-app-artifacts ""Link to this heading"")

## Create a local folder with configured artifacts[¶](#create-a-local-folder-with-configured-artifacts ""Link to this heading"")

The `snow app bundle` command creates a local directory in your project, populates it with the file structure you specified in the project definition file, and generates CREATE FUNCTION or CREATE PROCEDURE declarations in Snowflake Native App setup scripts from Snowpark Python code that includes decorators (such as `@sproc` or `@udaf`). For more information, see the Snowpark Python documentation corresponding to your chosen function decorator, such as [snowflake.snowpark.functions.udaf](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.udaf).

The `snow app deploy` and `snow app run` commands already use this functionality. However, now with an explicit `snow app bundle` command at your disposal, you can explore this directory before it gets uploaded to the stage, to verify the artifacts were created as expected.

To create a local folder with the configured artifacts, do the following:

1.  Create or verify your Snowflake `snowflake.yml` project definition file, such as:
    
    ```
    definition_version: 2
    entities:
      codegen_nativeapp_pkg:
        type: application package
        manifest: root_files/_manifest.yml
        artifacts:
          - src: root_files/README.md
            dest: README.md
          - src: root_files/_manifest.yml
            dest: manifest.yml
          - src: root_files/setup_scripts/*
            dest: setup_scripts/
          - src: python/user_gen/echo.py
            dest: user_gen/echo.py
          - src: python/cli_gen/*
            dest: cli_gen/
            processors:
              - snowpark
      codegen_nativeapp:
        type: application
        from:
          target: codegen_nativeapp_pkg
    
    ```
    
    Copy
    
2.  From your project directory, run the `snow app bundle` command to create the temporary `output/deploy` directory that contains your configured artifacts.
    
    ```
    snow app bundle
    
    ```
    
    Copy
    
3.  Verify the contents of the output or deploy directory match the rules you specified in the snowflake.yml. file. If you invoked Snowpark annotation processing in your Python files, you can see the generated code in the amended setup script in the directory.
    

For more information, see the [snow app bundle](../command-reference/native-apps-commands/bundle-app) command.

## Generate SQL code using Snowpark annotation processing[¶](#generate-sql-code-using-snowpark-annotation-processing ""Link to this heading"")

As a Snowflake Native App developer with a limited SQL background, you might find it cumbersome to write and maintain [setup scripts](../../native-apps/creating-setup-script), which can get quite large and complicated over time. Setup scripts contain all the application logic that a customer can use with their data, and hence are a required part of developing a Snowflake Native App. One of the core components of setup scripts is your ability to use Snowpark Python extension functions for functions and stored procedures. In addition to writing Snowpark code in Python, Java, or other Snowpark supported languages, you need to write the corresponding portions of those functions and procedures using SQL in the setup script.

For example, you could create a basic function and stored procedure using Snowpark Python, as shown:

```
# Example python file ""echo.py"" that a developer writes

def echo_fn(data):
    return 'echo_fn: ' + data

def echo_proc(session, data):
    return 'echo_proc: ' + data

```

Copy

You would then need to upload the file to a stage and refer to it from the setup script SQL code, similar to the following:

```
-- Sample setup_script.sql SQL file for a Snowflake Native App

CREATE APPLICATION ROLE IF NOT EXISTS app_instance_role;

CREATE OR ALTER VERSIONED SCHEMA ext_code_schema;
GRANT USAGE ON SCHEMA ext_code_schema TO APPLICATION ROLE app_instance_role;

CREATE OR REPLACE PROCEDURE ext_code_schema.py_echo_proc(DATA string)
  RETURNS STRING
  LANGUAGE PYTHON
  RUNTIME_VERSION = 3.12
  PACKAGES=('snowflake-snowpark-python')
  HANDLER='echo.echo_proc'
  IMPORTS=('/echo.py');

    GRANT USAGE ON PROCEDURE ext_code_schema.py_echo_proc(string)
      TO APPLICATION ROLE app_instance_role;

-- Wraps a function from a python file
CREATE OR REPLACE FUNCTION ext_code_schema.py_echo_fn(string)
RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = 3.12
PACKAGES=('snowflake-snowpark-python')
HANDLER='echo.echo_fn'
IMPORTS=('/echo.py');

GRANT USAGE ON FUNCTION ext_code_schema.py_echo_fn(DATA string)
  TO APPLICATION ROLE app_instance_role;

```

Copy

### Automatic SQL code generation[¶](#automatic-sql-code-generation ""Link to this heading"")

Note

To take advantage of automatic SQL code generation, you must use Snowpark Python version 1.15.0 and above.

To help alleviate this extra work, Snowflake CLI can automatically generate the necessary SQL for your setup scripts. Snowpark Python supports a feature called extension function decorators (`@udf`, `@sproc`, `@udtf`, and `@udaf`) that let you annotate your Python code, such as using the [snowflake.snowpark.functions.udf](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.udf) function decorator. Snowflake CLI can use these decorators to automatically create and validate the necessary SQL code for your setup scripts.

For example, you can use the `@udf` decorator for the function in the previous example:

```
# some python file echo.py
@udf(name=""echo_fn"")
def echo_fn(data) -> str:
  return 'echo_fn: ' + str

```

Copy

Using the `@udf` decorator tells the Snowflake CLI [snow app bundle](../command-reference/native-apps-commands/bundle-app) (and other commands that internally invoke the `snow app bundle` command) to process the Snowpark Python decorators, generate the corresponding SQL commands, and include them in the setup script automatically, as shown. You can, therefore, minimize the amount of SQL code you need to write for your setup script.

```
-- Sample setup_script.sql SQL file for a Snowflake Native App

-- User-written code
CREATE OR REPLACE APPLICATION ROLE app_instance_role;

CREATE OR ALTER VERSIONED SCHEMA ext_code_schema;
GRANT USAGE ON SCHEMA ext_code_schema TO APPLICATION ROLE app_instance_role;

-- Snowflake CLI generated code
CREATE OR REPLACE FUNCTION ext_code_schema.py_echo_fn(DATA string)
  RETURNS STRING
  LANGUAGE PYTHON
  RUNTIME_VERSION = 3.12
  PACKAGES=('snowflake-snowpark-python')
  HANDLER='echo.echo_fn'
  IMPORTS=('/echo.py');

  GRANT USAGE ON FUNCTION ext_code_schema.py_echo_fn(string)
    TO APPLICATION ROLE app_instance_role;

```

Copy

## Using the Snowpark Python decorators[¶](#using-the-snowpark-python-decorators ""Link to this heading"")

While the Snowpark decorators in Snowflake CLI work the same as regular Snowpark Python decorators, you should be aware of the following differences when writing Python code files specifically for a Snowflake Native App:

*   You can’t use any `Session` objects in these files, as Snowflake CLI executes these Python files in a sandbox environment with no connection to Snowflake. As a result, any reference of a Snowpark `Session` results in an error.
    
*   You can use only the `@udf`, `@sproc`, `@udaf` and `@udtf` Snowpark Python decorators.
    
*   You can’t use these decorators as regular functions to register your code as a Snowflake object. Only code explicitly annotated with the supported decorators is recognized. Therefore, the Python function must be a named function. Lambda functions are not supported.
    
*   Snowflake CLI always generates CREATE OR REPLACE statements, as recommended by Snowflake, for creating functions and procedures in your setup scripts.
    

### More about decorator properties[¶](#more-about-decorator-properties ""Link to this heading"")

The following table lists the Python decorator properties and explains how Snowflake CLI uses them.

| Property | Details |
| --- | --- |
| nameOptional | Name of the function or stored procedure Snowflake CLI uses to generate the SQL statements.If you omit this property, Snowflake CLI reuses the Python function name to generate the SQL statements. |
| input_typesRequired | Types for each input parameter for this function or stored procedure.You must provide this information either in this decorator parameter or provide type annotations directly in your code. If this information is not available in either location, Snowflake CLI does not generate SQL statements for this function or stored procedure. |
| return_typeRequired | Type for the return value for this function or stored procedure.You must provide this information either in this decorator parameter or provide type annotation directly in your code. If this information is not available in either location, Snowflake CLI does not generate SQL statements for this function or stored procedure. |
| packagesOptional | List of packages. You can specify snowflake-snowpark-python with or without a version number. If you provide a version number for this package, Snowflake CLI does not use the version as part of its SQL generation, but does retain the version number for any other packages in the list.If you omit this property, Snowflake CLI automatically adds snowflake-snowpark-python as the only package and reflects it in the generated SQL statements. |
| importsOptional | List of files your Snowflake function or stored procedure needs to import from the stage. You can specify them either as a string or a tuple of strings. If you specify a tuple, Snowflake CLI only uses the string at the 0th index. For an example of using a tuple, see Use external Python files.If you do not specify any imports, Snowflake CLI automatically adds an import for the Python file that contains the function or stored procedure for which it generates SQL. The path of the import is determined by the dest parameter of the Python file in the deploy root directory, based on the project definition file. |
| execute_asOptional | Persona to use when executing a stored procedure. Values include: caller and owner. If unspecified, Snowflake CLI defaults to owner. Note that this property does not apply to functions. |
| handlerN/A | Handler for the function or stored procedure. Snowflake CLI automatically populates this field. |
| replaceUnused | Snowflake CLI assumes true for code generation. |
| sessionRequired | Must be None. If omitted, Snowflake CLI throws an error. |
| is_permanentUnused | Snowflake CLI does not use this field for SQL generation. |
| stage_locationUnused | Snowflake CLI does not use this field for SQL generation. |
| if_not_existsUnused | Snowflake CLI does not use this field for SQL generation. |
| strictUnused | Snowflake CLI does not use this field for SQL generation. |
| secureUnused | Snowflake CLI does not use this field for SQL generation. |
| immutableUnused | Snowflake CLI does not use this field for SQL generation. |
| native_app_paramsOptional | (For a Snowflake Native App only)Python dictionary containing the following Snowflake Native App parameters:schema: Name of the schema to contain the Snowpark function or stored procedure. This schema must already be defined in your setup script. Snowflake recommends setting the value to the name of a versioned schema in your setup script file. Snowflake CLI prefixes this value to the name of the Snowpark function or procedure name in the generated SQL statement. Note that Snowflake CLI does not create the schema for you.application_roles: List of application roles to be granted USAGE privileges on the generated Snowpark function or procedure. Snowflake CLI does not create the application roles; it only creates SQL statements like GRANT USAGE ON FUNCTION <schema_name.func_name> TO APPLICATION ROLE <app_role> and adds them to the setup script.While technically optional, not specifying the native_app_params property in your project definition file might result in an invalid setup script. |

When uploading your Python files to a destination stage, Snowflake CLI converts the decorators to comments so these UDFs and stored procedures are not created in your current session. The original source files are not changed so that the `snow app bundle` command remains idempotent. Only Python files in the deploy root directory are changed to contain the comments, as the deploy root is recreated every time you run the `snow app bundle` command. The following example illustrates how Snowflake CLI comments decorators.

```
# output/deploy/dest_dir1/dest_dir2/echo.py
#: @sproc(
#:    return_type=IntegerType(),
#:    input_types=[IntegerType(), IntegerType()],
#:    packages=[""snowflake-snowpark-python==1.15.0""],
#:    native_app_params={
#:        ""schema"": ""ext_code_schema"",
#:        ""application_roles"": [""app_instance_role""],
#:    },
#: )
def add_sp(session_, x, y):
    return x + y

```

Copy

Also, only the Python files with a `processors` property in the project definition file are affected.

On this page

1.  [Create a local folder with configured artifacts](#create-a-local-folder-with-configured-artifacts)
2.  [Generate SQL code using Snowpark annotation processing](#generate-sql-code-using-snowpark-annotation-processing)
3.  [Using the Snowpark Python decorators](#using-the-snowpark-python-decorators)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)
2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)
3.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)
4.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)
5.  [snow app bundle](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/bundle-app)",NULL,f72ec4912c9b40f4e8a54e7734e358163f441c13aeda20a910fc1d42ae2d9e68,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/native-apps-commands/bundle-app,snow app bundle¶,NULL,NULL,snow app,snow app bundle app,"# snow app bundle[¶](#snow-app-bundle ""Link to this heading"")

Prepares a local folder with configured app artifacts.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow app bundle
  --package-entity-id <package_entity_id>
  --app-entity-id <app_entity_id>
  --project <project_definition>
  --env <env_overrides>
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

None

## Options[¶](#options ""Link to this heading"")

`--package-entity-id _TEXT_`

The ID of the package entity on which to operate when the definition\_version is 2 or higher.

`--app-entity-id _TEXT_`

The ID of the application entity on which to operate when the definition\_version is 2 or higher.

`-p, --project _TEXT_`

Path where the Snowflake project is stored. Defaults to the current working directory.

`--env _TEXT_`

String in the format key=value. Overrides variables from the env section used for templates. Default: \[\].

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow app bundle` command creates a temporary local directory that contains all of the Snowflake Native App artifacts. It can also automatically generate SQL scripts from your Snowpark Python code. This command is called automatically by the [snow app deploy](deploy-app), [snow app run](run-app), and [snow app version create](version/app-version-create) commands. If, however, you want to see the setup script, artifacts, and generated SQL, before uploading them to a stage, you can run this command manually. For more information about generating SQL code, see [Preparing a local folder with configured Snowflake Native App artifacts](../../native-apps/bundle-app).

*   The command uses the [project definition file](../../native-apps/project-definitions) to determine the name of the temporary folder to create within your project directory.
    
    *   By default, it will be `<project_directory>/output/deploy`. This directory, which is also known as the deploy root, mirrors what the structure of the stage will be, once files are uploaded to stage in subsequent commands.
        
    *   If you want Snowflake CLI to create a folder with a custom name instead of `output/deploy`, you can do so by providing the `deploy_root` field on the `application package` entity in the [project definition file](../../native-apps/project-definitions).
        
        Note
        
        You must provide a relative path for the deploy root; absolute paths are rejected. The deploy root path is created inside the project directory.
        
    *   The deploy root is a temporary directory because it gets deleted and recreated every you `run snow app bundle` or another command invokes the `bundle` functionality.
        
*   Because `snow app bundle` is automatically called as part of he [snow app deploy](deploy-app), [snow app run](run-app), and [snow app version create](version/app-version-create) commands, you should make changes to the source files only, outside the deploy root. If you modify files in the deploy root, the files are overwritten by the most recent state of your source files the next time you call one of these commands.
    
*   If using a version control system such as `git`, you can choose to not to track the deploy root, as it can change frequently.
    
*   `snow app bundle` does not build or compile your artifacts for you, such as creating jar files from your Java files. It only copies the artifacts specified in the project definition file and adds them to the deploy root to mimic the stage’s directory structure.
    
*   `snow app bundle` does not need access to your Snowflake account; it only affects your local filesystem.
    
*   The command has the following copying and symlinking behavior for any `artifacts` of the `application package` entity in the [project definition file](../../native-apps/project-definitions):
    
    *   All directory names in a source path are also created in the deploy root.
        
    *   All files in a source path are symlinked within these directories in the deploy root.
        
    *   Some symlinked files in the deploy root can become hard links if you invoke SQL generation from those files. For more information, see [Preparing a local folder with configured Snowflake Native App artifacts](../../native-apps/bundle-app).
        
    
    Consider the following `artifacts` list example from a project definition file:
    
    ```
    entities:
      pkg:
        type: application package
        ...
        artifacts:
          - src: dir1/dir2/*
            dest: dest_dir1/dest_dir2/
          - src: dir8/dir9/file.txt
            dest: dest_dir8/dest_file.txt
      ...
    
    ```
    
    Copy
    
    where `dir1/dir2` in the project root could have other subdirectories, such as `dir3` and `dir4`, and some files, such as `file3.txt` and `file4.txt`.
    
    After running the `snow app bundle` command, your deploy root should look like the following:
    
    ```
    -- deploy_root
          -- dest_dir1
                -- dest_dir2
                      -- dir3
                          -- ... <entire directory tree of dir3>
                      -- dir4
                          -- ... <entire directory tree of dir4>
                      -- file3.txt
                      -- file4.txt
          -- dest_dir8
                -- dest_file.txt
    
    ```
    
    Copy
    

### Snowpark annotation processing[¶](#snowpark-annotation-processing ""Link to this heading"")

Beginning with Snowflake CLI version 2.5.0 and [Snowpark Python API](../../../snowpark/python/index) version 1.15.0, you can leverage the Snowpark annotation processing feature with the `snow app bundle` command. This feature lets you annotate your Python code files with Snowpark Python decorators, such as `@udf`, `@sproc`, `@udaf`, and `@udtf` to let Snowflake CLI automatically the corresponding CREATE FUNCTION or CREATE PROCEDURE SQL statements in setup script files in the project directory. For a better understanding of these decorators, please refer to corresponding Python decorators documentation.

Snowpark annotation processing involves the following:

*   It reads all Python files you marked with a `processor` field in the project definition file.
    
*   It creates a separate temporary sandbox Python environment using the environment information provided in the processor’s `properties` sub-field.
    
*   It executes those Python files in the sandboxed environment.
    
*   It collects all decorated functions from those files.
    
*   With the collected information, Snowflake CLI generates the necessary SQL statements and adds them to the setup script whose location is specified in your `manifest.yaml` file.
    

You no longer need to repeat boilerplate SQL code for writing Snowpark extension functions for your Snowflake Native App apps.

For more information about enabling this feature in your project definition files, see [Using the Snowpark Python decorators](../../native-apps/bundle-app.html#label-cli-sf-annotation-processing).

For more information about all supported artifact processors, see [More information about artifacts processors](../../native-apps/project-definitions.html#label-cli-na-artifacts-processors).

## Examples[¶](#examples ""Link to this heading"")

This example assumes you have made the necessary changes to your code files and added them to your `snowflake.yml` or `snowflake.local.yml` files, and also built or compiled any relevant artifacts.

```
cd my_app_project
snow app bundle

```

Copy

The command displays information about the various steps that occur while the command runs and creates a new directory a the location specified in your project definition file (default: `my_app_project/output/deploy`).

To see a simple use case in action, you can leverage the ready-to-use templates using the following commands:

```
snow init my_app_bundle_project --template app_basic
cd ""my_app_bundle_project""
snow app bundle
ls my_app_bundle_project/output/deploy

```

Copy

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../overview)
3.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../native-apps/overview)
4.  [Preparing a local folder with configured Snowflake Native App artifacts](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../native-apps/bundle-app)
5.  [snow app commands](/developer-guide/snowflake-cli/command-reference/native-apps-commands/overview)
6.  [snow app deploy](/developer-guide/snowflake-cli/command-reference/native-apps-commands/deploy-app)
7.  [snow app run](/developer-guide/snowflake-cli/command-reference/native-apps-commands/run-app)
8.  [snow app version create](/developer-guide/snowflake-cli/command-reference/native-apps-commands/version/app-version-create)",NULL,5279f0b9dc3c4410f1dab61618f83b8765b7ce704f721a8417ef37cec943ff9e,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/create,snow spcs compute-pool create¶,NULL,NULL,snow spcs,snow spcs compute pool commands,"# snow spcs compute-pool create[¶](#snow-spcs-compute-pool-create ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Creates a new compute pool.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/create-compute-pool)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs compute-pool create
  <name>
  --family <instance_family>
  --min-nodes <min_nodes>
  --max-nodes <max_nodes>
  --auto-resume
  --no-auto-resume
  --init-suspend / --no-init-suspend
  --auto-suspend-secs <auto_suspend_secs>
  --tag <tags>
  --comment <comment>
  --if-not-exists
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the compute pool; for example: my\_compute\_pool.

## Options[¶](#options ""Link to this heading"")

`--family _TEXT_`

Name of the instance family. For more information about instance families, refer to the SQL CREATE COMPUTE POOL command.

`--min-nodes _INTEGER RANGE_`

Minimum number of nodes for the compute pool. Default: 1.

`--max-nodes _INTEGER RANGE_`

Maximum number of nodes for the compute pool.

`--auto-resume`

The compute pool will automatically resume when a service or job is submitted to it. Default: False.

`--no-auto-resume`

The compute pool will automatically resume when a service or job is submitted to it. Default: False.

`--init-suspend / --no-init-suspend`

Starts the compute pool in a suspended state. Default: False.

`--auto-suspend-secs _INTEGER RANGE_`

Number of seconds of inactivity after which you want Snowflake to automatically suspend the compute pool. Default: 3600.

`--tag _NAME=VALUE_`

Tag for the compute pool.

`--comment _TEXT_`

Comment for the compute pool.

`--if-not-exists`

Only apply this operation if the specified object does not already exist. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

The following example creates a compute pool named “pool\_1” using the minimal CPU\_X64\_XS family, which comprises two CPUs with 4GB of memory.

```
snow spcs compute-pool create ""pool_1"" --min-nodes 2 --max-nodes 2 --family ""CPU_X64_XS""

```

Copy

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../overview)
4.  [compute-pool commands reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/overview)
5.  [snow spcs compute-pool stop-all](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/stop-all)",NULL,57e4caa9650e89db4a9956ea5c3dcd958c3bd98768bd02bef8ea27bb1335427e,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/stop-all,snow spcs compute-pool stop-all¶,NULL,NULL,snow spcs,snow spcs compute pool commands,"# snow spcs compute-pool stop-all[¶](#snow-spcs-compute-pool-stop-all ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Deletes all services running on the compute pool.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/alter-compute-pool)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs compute-pool stop-all
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the compute pool; for example: my\_compute\_pool.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

The following example stops a compute pool named “pool1” and deletes all services running on it:

```
snow spcs compute-pool stop-all ""pool1""

```

Copy

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../overview)
4.  [compute-pool commands reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/overview)
5.  [snow spcs compute-pool create](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/create)",NULL,2d263608bddc86540f5c0d274e8b668985d72f2ddc5f1dc983d085f14f0721e0,NULL
NULL,https://docs.snowflake.com/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/deploy,snow spcs compute-pool deploy¶,NULL,NULL,snow spcs,snow spcs compute pool commands,"# snow spcs compute-pool deploy[¶](#snow-spcs-compute-pool-deploy ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Deploys a compute pool from the project definition file.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs compute-pool deploy
  <entity_id>
  --upgrade
  --project <project_definition>
  --env <env_overrides>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_entity_id_`

ID of compute-pool entity.

## Options[¶](#options ""Link to this heading"")

`--upgrade`

Updates the existing compute pool. Can update min\_nodes, max\_nodes, auto\_resume, auto\_suspend\_seconds and comment. Default: False.

`-p, --project _TEXT_`

Path where the Snowflake project is stored. Defaults to the current working directory.

`--env _TEXT_`

String in the format key=value. Overrides variables from the env section used for templates. Default: \[\].

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow spcs compute pool deploy` command reads a `snowflake.yml` project definition file that defines a compute pool. If your project definition has precisely one compute pool entity, you can omit the `<entity_id>` argument. However, if your project definition has multiple compute pool entities, you must specify the compute pool name in the `<entity_id>` argument. For more information, see [Compute pools project definition](../../../services/manage-compute-pools.html#label-sfcli-pool-pdf).

The `--upgrade` option updates an existing service. You can update only the following project definition parameters:

*   `min_instances`
    
*   `max_instances`
    
*   `query_warehouse`
    
*   `auto_resume`
    
*   `external_access_integrations`
    
*   `comment`
    

## Examples[¶](#examples ""Link to this heading"")

The following example creates and deploys a compute pool defined in the `snowflake.yml` file in the current directory.

```
snow spcs compute-pool deploy

```

Copy

```
+---------------------------------------------------------------------+
| key    | value                                                      |
|--------+------------------------------------------------------------|
| status | Compute pool MY_COMPUTE_POOL successfully created.         |
+---------------------------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../overview)
4.  [compute-pool commands reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/overview)
5.  [snow spcs compute-pool stop-all](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/stop-all)",NULL,2bd0fba56540317520c3d3b8e597b70f2be9b895c7ba2d92510115da40f301a7,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/token,snow spcs image-registry token¶,NULL,NULL,snow spcs,snow spcs image registry commands,"# snow spcs image-registry token[¶](#snow-spcs-image-registry-token ""Link to this heading"")

Retrieves a registry authentication token based on your current connection. Note that this token is specific to your current user and will not grant access to any repositories that your current user cannot access.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs image-registry token
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

None

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

The following example shows how to return the token associated with the specified connection that you can use to authenticate with the registry.

```
snow spcs image-registry token --connection mytest

```

Copy

```
+----------------------------------------------------------------------------------------------------------------------+
| key        | value                                                                                                   |
|------------+---------------------------------------------------------------------------------------------------------|
| token      | ****************************************************************************************************    |
|            | ****************************************************************************************************    |
| expires_in | 3600                                                                                                    |
+----------------------------------------------------------------------------------------------------------------------+

```

Example usage with docker:

```
snow spcs image-registry token --format=JSON | docker login YOUR_HOST -u 0sessiontoken --password-stdin

```

Copy

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../overview)
4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/overview)
5.  [Working with image registries and repositories](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../services/manage-images)",NULL,9ff3a835ebb3fa7255163cab5102f9fa784c380a31dae5e42db437996cabbabc,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/login,snow spcs image-registry login¶,NULL,NULL,snow spcs,snow spcs image registry commands,"# snow spcs image-registry login[¶](#snow-spcs-image-registry-login ""Link to this heading"")

Logs in to the account image registry with the current user’s credentials through Docker. Must be called from a role that can view at least one image repository in the image registry.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs image-registry login
  --private-link
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

None

## Options[¶](#options ""Link to this heading"")

`--private-link`

Get the private link URL instead of the public URL. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

*   [Docker Desktop](https://www.docker.com/products/docker-desktop/) must be installed because the command uses docker to log in to Snowflake.
    
*   The current role must have READ privileges for the image repository in the account to get the registry URL.
    

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs image-registry login

```

Copy

```
Login Succeeded

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../overview)
4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/overview)
5.  [Working with image registries and repositories](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../services/manage-images)",NULL,a3953d5845870639ca9fed862bd635f4867744b50224e5d09af504e623b6f649,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/url,snow spcs image-registry url¶,NULL,NULL,snow spcs,snow spcs image registry commands,"# snow spcs image-registry url[¶](#snow-spcs-image-registry-url ""Link to this heading"")

Gets the image registry URL for the current account. Must be called from a role that can view at least one image repository in the image registry.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs image-registry url
  --private-link
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

None

## Options[¶](#options ""Link to this heading"")

`--private-link`

Get the private link URL instead of the public URL. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The current role must have READ privileges for the image repository in the account to get the registry URL.

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs image-registry url

```

Copy

```
<orgname-acctname>.registry.snowflakecomputing.com

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../overview)
4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/overview)
5.  [Working with image registries and repositories](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../services/manage-images)",NULL,5060df02594064e54a008bb812bfc147b83af2721e4ca3235fa2b532379572ee,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/create,snow spcs image-repository create¶,NULL,NULL,snow spcs,snow spcs image repository commands,"# snow spcs image-repository create[¶](#snow-spcs-image-repository-create ""Link to this heading"")

Creates a new image repository in the current schema.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/create-image-repository)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs image-repository create
  <name>
  --replace
  --if-not-exists
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the image repository; for example: my\_repository.

## Options[¶](#options ""Link to this heading"")

`--replace`

Replace this object if it already exists. Default: False.

`--if-not-exists`

Only apply this operation if the specified object does not already exist. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs image-repository create tutorial_repository

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)
4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview)",NULL,0a50fda054b5d2e8e91bac38169700e4454c467934de74f3e5ed9e8b9053b70d,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/url,snow spcs image-repository url¶,NULL,NULL,snow spcs,snow spcs image repository commands,"# snow spcs image-repository url[¶](#snow-spcs-image-repository-url ""Link to this heading"")

Returns the URL for the given repository.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs image-repository url
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the image repository; for example: my\_repository.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

*   The current role must have READ privileges for the image repository in the account to get the registry URL.
    
*   The URL is returned as a text string, so you can store it in an environment variable for convenience. For example:
    
    ```
    export REPO_URL = $(snow spcs image-repository url <name>)
    
    ```
    
    Copy
    

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs image-repository url tutorial_repository

```

Copy

```
<orgname-acctname>.registry.snowflakecomputing.com/tutorial_db/data_schema/tutorial_repository

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)
4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview)",NULL,fc073565c66ddef2c7c6332b2930e2b6023ad427d8ad4ff92c2b1e8e472db233,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/list-images,snow spcs image-repository list-images¶,NULL,NULL,snow spcs,snow spcs image repository commands,"# snow spcs image-repository list-images[¶](#snow-spcs-image-repository-list-images ""Link to this heading"")

Lists images in the given repository.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/show-images-in-image-repository)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs image-repository list-images
  <name>
  --like <like_option>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the image repository; for example: my\_repository.

## Options[¶](#options ""Link to this heading"")

`--like, -l _TEXT_`

SQL LIKE pattern for filtering objects by name. For example, `--like ""my%""` lists all image repositories that begin with “my”.. Default: %%.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

The following example lists the images and tags in a repository named `images` in the `my_db` database:

```
snow spcs image-repository list-images images --database my_db

```

Copy

```
+--------------------------------------------------------------------------------------------------------------------------------------------------------+
| created_on                | image_name            | tags   | digest                                         | image_path                               |
|---------------------------+-----------------------+--------+------------------------------------------------+------------------------------------------|
| 2024-10-11 14:23:49-07:00 | echo_service          | latest | sha256:a8a001fef406fdb3125ce8e8bf9970c35af7084 | my_db/test_schema/images/echo_service:   |
|                           |                       |        | fc33b0886d7a8915d3082c781                      | latest                                   |
| 2024-10-14 22:21:14-07:00 | test_counter          | latest | sha256:8cae96dac29a4a05f54bb5520003f964baf67fc | my_db/test_schema/images/test_counter:   |
|                           |                       |        | 38dcad3d2c85d6c5aa7381174                      | latest                                   |
+--------------------------------------------------------------------------------------------------------------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)
4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview)",NULL,26c220f58556f27cd085892904a2b460a5fbed3a172fd73754fd676f9f85df81,NULL
NULL,https://docs.snowflake.com/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/deploy,snow spcs image-repository deploy¶,NULL,NULL,snow spcs,snow spcs image repository commands,"# snow spcs image-repository deploy[¶](#snow-spcs-image-repository-deploy ""Link to this heading"")

Deploys a new image repository from snowflake.yml file.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs image-repository deploy
  <entity_id>
  --replace
  --project <project_definition>
  --env <env_overrides>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_entity_id_`

ID of image-repository entity.

## Options[¶](#options ""Link to this heading"")

`--replace`

Replace the image repository if it already exists. Default: False.

`-p, --project _TEXT_`

Path where the Snowflake project is stored. Defaults to the current working directory.

`--env _TEXT_`

String in the format key=value. Overrides variables from the env section used for templates. Default: \[\].

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow spcs image repository deploy` command creates an image repository from its definition in a `snowflake.yml` project definition file. For more information, see [Image repository project definition file](../../../services/manage-images.html#label-sfcli-repo-pdf).

## Examples[¶](#examples ""Link to this heading"")

The following example creates an image repository defined in the `snowflake.yml` file in the current directory.

```
snow spcs image-repository deploy

```

Copy

```
+---------------------------------------------------------------------+
| key    | value                                                      |
|--------+------------------------------------------------------------|
| status | Image Repository MY_IMAGE_REPOSITORY successfully created. |
+---------------------------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)
4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview)",NULL,3cea9a37e1f0df9d5ab11d063ee74cebf5386171bc8b286f6d98c186bd339e56,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/create,snow spcs service create¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service create[¶](#snow-spcs-service-create ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Creates a new service in the current schema.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/create-service)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service create
  <name>
  --compute-pool <compute_pool>
  --spec-path <spec_path>
  --min-instances <min_instances>
  --max-instances <max_instances>
  --auto-resume / --no-auto-resume
  --eai-name <external_access_integrations>
  --query-warehouse <query_warehouse>
  --tag <tags>
  --comment <comment>
  --if-not-exists
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--compute-pool _TEXT_`

Compute pool to run the service on.

`--spec-path _FILE_`

Path to service specification file.

`--min-instances _INTEGER RANGE_`

Minimum number of service instances to run. Default: 1.

`--max-instances _INTEGER RANGE_`

Maximum number of service instances to run.

`--auto-resume / --no-auto-resume`

The service will automatically resume when a service function or ingress is called. Default: True.

`--eai-name _TEXT_`

Identifies external access integrations (EAI) that the service can access. This option may be specified multiple times for multiple EAIs.

`--query-warehouse _TEXT_`

Warehouse to use if a service container connects to Snowflake to execute a query without explicitly specifying a warehouse to use.

`--tag _NAME=VALUE_`

Tag for the service.

`--comment _TEXT_`

Comment for the service.

`--if-not-exists`

Only apply this operation if the specified object does not already exist. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

You can optionally choose to run more than one instance of your service. Each service instance is a collection of containers, as defined in the service specification file, that run together on a node in your compute pool. If you choose to run multiple instances of a service, a load balancer manages incoming traffic.

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs service create ""my-service"" --compute-pool ""pool_1"" --spec-path ""/some-dir/echo-speck.yaml""

```

Copy

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",NULL,45408d2ed2f4c62ff946dc67f27dcd9f04d595b9d840224c621e29318da40a43,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/suspend,snow spcs service suspend¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service suspend[¶](#snow-spcs-service-suspend ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Suspends the service, shutting down and deleting all its containers.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/alter-service)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service suspend
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The current role must have OPERATE privilege on the service to suspend a service.

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs service suspend echo_service

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",NULL,f59bb355a43071f15467c8cd0ad06d642e531dd7c801ec18310c8bd6c0eb1b9f,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/resume,snow spcs service resume¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service resume[¶](#snow-spcs-service-resume ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Resumes the service from a SUSPENDED state.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/alter-service)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service resume
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The current role must have OPERATE privilege on the service to resume a service.

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs service resume echo_service

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",NULL,a69176cbc8f204e08feb585f1c50a8c79fa6eb235d2baf299e969afcd6c148ca,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list,snow spcs service list¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service list[¶](#snow-spcs-service-list ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Lists all available services.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/show-services)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service list
  --like <like>
  --in <scope>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

None

## Options[¶](#options ""Link to this heading"")

`--like, -l _TEXT_`

SQL LIKE pattern for filtering objects by name. For example, `list --like ""my%""` lists all services that begin with “my”.. Default: %%.

`--in _<TEXT TEXT>..._`

Specifies the scope of this command using ‘–in <scope> <name>’, for example `list --in compute-pool my_pool`. Default: (None, None).

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

The following command lists the services and their statuses:

```
snow spcs service list

```

Copy

```
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|        |        |        |        |        |        |        |        |        |        |        |         | extern |         |        |         |        |         |        |        |         |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         | al_acc |         |        |         |        |         |        |        |         |        | managin | managi |
|        |        | databa |        |        |        |        | curren | target | min_in | max_in |         | ess_in |         |        |         |        | owner_r | query_ |        |         |        | g_objec | ng_obj |
|        |        | se_nam | schema |        | comput | dns_na | t_inst | _insta | stance | stance | auto_re | tegrat | created | update | resumed | commen | ole_typ | wareho |        | spec_di | is_upg | t_domai | ect_na |
| name   | status | e      | _name  | owner  | e_pool | me     | ances  | nces   | s      | s      | sume    | ions   | _on     | d_on   | _on     | t      | e       | use    | is_job | gest    | rading | n       | me     |
|--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+--------+---------+--------+---------+--------+---------+--------+--------+---------+--------+---------+--------|
| ECHO_S | RUNNIN | TEST00 | TEST_S | SYSADM | TUTORI | echo-s | 1      | 1      | 1      | 1      | true    | None   | 2024-10 | 2024-1 | None    | This   | ROLE    | COMPUT | false  | 52e62d1 | false  | None    | None   |
| ERVICE | G      | _DB    | CHEMA  | IN     | AL_COM | ervice |        |        |        |        |         |        | -16     | 0-16   |         | is a   |         | E_WH   |        | f19c720 |        |         |        |
|        |        |        |        |        | PUTE_P | .imhd. |        |        |        |        |         |        | 15:09:3 | 15:09: |         | test   |         |        |        | 6b5f4ef |        |         |        |
|        |        |        |        |        | OOL    | svc.sp |        |        |        |        |         |        | 0.49300 | 31.905 |         | servic |         |        |        | c069557 |        |         |        |
|        |        |        |        |        |        | cs.int |        |        |        |        |         |        | 0-07:00 | 000-07 |         | e      |         |        |        | 8b6c2b3 |        |         |        |
|        |        |        |        |        |        | ernal  |        |        |        |        |         |        |         | :00    |         |        |         |        |        | 806ad76 |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 67d78cc |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | ce8b6ed |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 6501a8a |        |         |        |
|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 3       |        |         |        |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [SHOW SERVICES](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/show-services)",NULL,3c82af51645917a6a1728f98cf61944af9b81c2573c32b1832426b90b46e34fa,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/describe,snow spcs service describe¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service describe[¶](#snow-spcs-service-describe ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Provides description of service.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/desc-service)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service describe
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

None.

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [DESCRIBE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/desc-service)",NULL,24ff13044640494af0a51f81f34b7d1e122df90125ac39aeec8494f4c6690dc6,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list-instances,snow spcs service list-instances¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service list-instances[¶](#snow-spcs-service-list-instances ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Lists all service instances in a service.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/show-service-instances-in-service)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service list-instances
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

This example lists the instances in the `echo_service` service:

```
snow spcs service list-instances echo_service

```

Copy

```
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| database_name | schema_name | service_name | instance_id | status | spec_digest                                                      | creation_time        | start_time           |
|---------------+-------------+--------------+-------------+--------+------------------------------------------------------------------+----------------------+----------------------|
| TEST00_DB     | TEST_SCHEMA | ECHO_SERVICE | 0           | READY  | 336c065739dd2b96e770f01804affdc7810e6df68a23b23052d851627abfbdf9 | 2024-10-10T06:06:30Z | 2024-10-10T06:06:30Z |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [DROP SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/drop-service)",NULL,8dc9aa27ef16daa22449145595c111a29963b5dc296268316cb136d7ef8aeaa7,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list-containers,snow spcs service list-containers¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service list-containers[¶](#snow-spcs-service-list-containers ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Lists all service containers in a service.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/show-service-containers-in-service)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service list-containers
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

This example lists containers in the `echo_service` service:

```
snow spcs service list-containers echo_service

```

Copy

```
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| database_name | schema_name | service_name | instance_id | container_name | status | message | image_name                                | image_digest                              | restart_count | start_time           |
|---------------+-------------+--------------+-------------+----------------+--------+---------+-------------------------------------------+-------------------------------------------+---------------+----------------------|
| TEST00_DB     | TEST_SCHEMA | ECHO_SERVICE | 0           | main           | READY  | Running | org-test-account-00.registry.registry.sno | sha256:06c3d54edc24925abe398eda70d37eb6b8 | 0             | 2024-10-16T22:09:35Z |
|               |             |              |             |                |        |         | wflakecomputing.com/test00_db/test_schema | 7b1c4dd6211317592764e1e7d94498            |               |                      |
|               |             |              |             |                |        |         | /test00_repo/echo_service:latest          |                                           |               |                      |
+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [DROP SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/drop-service)",NULL,fe969ef7b246355c91a8b24b4b5aaf8dd7f5d0051fb087a165b07f7c190af16b,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list-endpoints,snow spcs service list-endpoints¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service list-endpoints[¶](#snow-spcs-service-list-endpoints ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Lists the endpoints in a service.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/show-endpoints)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service list-endpoints
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs service list-endpoints echo_service

```

Copy

```
+--------------+------+----------+-----------------+-----------------------------------------+
| name         | port | protocol | ingress_enabled | ingress_url                             |
|--------------+------+----------+-----------------+-----------------------------------------|
| echoendpoint | 8000 | TCP      | true            | org-id-acct-id.snowflakecomputing.app   |
+--------------+------+----------+-----------------+-----------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [SHOW ENDPOINTS](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/show-endpoints)",NULL,add841b1078155d7381c95dd12df0279c21d988b209a3a709b55b59b5b815873,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list-roles,snow spcs service list-roles¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service list-roles[¶](#snow-spcs-service-list-roles ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Lists all service roles in a service.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/show-roles)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service list-roles
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

The following example gets a list of service roles created for a service:

```
snow spcs service list-roles my_service

```

Copy

```
+------------------------------------------------------------------+
| created_on                       | name                | comment |
|----------------------------------+---------------------+---------|
| 2024-10-09 16:48:52.980000-07:00 | ALL_ENDPOINTS_USAGE | None    |
+------------------------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [DROP SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/drop-service)",NULL,426d9fa510a0f41149e743f78da5436c2ed277bb0d4606282294725722973ec8,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/set,snow spcs service set¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service set[¶](#snow-spcs-service-set ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Sets one or more properties for the service.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/alter-service)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service set
  <name>
  --min-instances <min_instances>
  --max-instances <max_instances>
  --query-warehouse <query_warehouse>
  --auto-resume / --no-auto-resume
  --auto-suspend-secs <auto_suspend_secs>
  --eai-name <external_access_integrations>
  --comment <comment>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--min-instances _INTEGER RANGE_`

Minimum number of service instances to run.

`--max-instances _INTEGER RANGE_`

Maximum number of service instances to run.

`--query-warehouse _TEXT_`

Warehouse to use if a service container connects to Snowflake to execute a query without explicitly specifying a warehouse to use.

`--auto-resume / --no-auto-resume`

The service will automatically resume when a service function or ingress is called.

`--auto-suspend-secs _INTEGER RANGE_`

Number of seconds of inactivity after which the service will be automatically suspended.

`--eai-name _TEXT_`

Identifies external access integrations (EAI) that the service can access. This option may be specified multiple times for multiple EAIs.

`--comment _TEXT_`

Comment for the service.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The current role must have OPERATE privilege on the service to set properties.

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs service set echo_service --min-instances 2 --max-instances 4

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [UNSET](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/unset)",NULL,4baa115c4b292e09355d8715370bf7ea2e2e7c9b98d3daac89e6752e417e37d0,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/logs,snow spcs service logs¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service logs[¶](#snow-spcs-service-logs ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Retrieves local logs from a service container.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/call)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service logs
  <name>
  --container-name <container_name>
  --instance-id <instance_id>
  --num-lines <num_lines>
  --previous-logs
  --since <since_timestamp>
  --include-timestamps
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--container-name _TEXT_`

Name of the container.

`--instance-id _TEXT_`

ID of the service instance, starting with 0.

`--num-lines _INTEGER_`

Number of lines to retrieve. Default: 500.

`--previous-logs`

Retrieve logs from the last terminated container. Default: False.

`--since _TEXT_`

Start log retrieval from a specified UTC timestamp.

`--include-timestamps`

Include timestamps in logs. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

*   The current role must have the MONITOR privilege on the service to access the container logs.
    
*   The function returns a container log as a string.
    
*   When using the `--follow` option for real-time log streaming, the `--num-lines` and `--previous-logs` options are not supported.
    

## Examples[¶](#examples ""Link to this heading"")

*   The following example displays the last three lines of the `echo_service` logs:
    
    ```
    snow spcs service logs echo_service --container-name echo --instance-id 0 --num-lines 3
    
    ```
    
    Copy
    
    ```
    10.18.94.31 - - [22/Nov/2024 09:16:47] ""GET /healthcheck HTTP/1.1"" 200 -
    10.18.94.31 - - [22/Nov/2024 09:16:52] ""GET /healthcheck HTTP/1.1"" 200 -
    10.18.94.31 - - [22/Nov/2024 09:16:57] ""GET /healthcheck HTTP/1.1"" 200 -
    
    ```
    
*   This example streams the logs for the `echo_service` service and updates them every 10 seconds:
    
    ```
    snow spcs service logs echo_service --container-name echo --instance-id 0 --follow --follow-interval 10
    
    ```
    
    Copy
    
*   The following example displays the log entries since 9:30 UTC, 21 Nov 2024:
    
    ```
    snow spcs service logs echo_service --container-name echo --instance-id 0 --since 2024-11-21T09:30:00Z
    
    ```
    
    Copy
    
*   The following example retrieves logs from the last-terminated container:
    
    ```
    snow spcs service logs example_job_service --container-name main --instance-id 0 --previous-logs
    
    ```
    
    Copy
    

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../overview)
4.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
5.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
6.  [SYSTEM$GET\_SERVICE\_LOGS](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/functions/system_get_service_logs)",NULL,d3e8e37e5bec184fb39b841a9f9d43ec3d77313953a65eaa858b139485d955e2,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/upgrade,snow spcs service upgrade¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service upgrade[¶](#snow-spcs-service-upgrade ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Updates an existing service with a new specification file.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/alter-service)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service upgrade
  <name>
  --spec-path <spec_path>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the service; for example: my\_service.

## Options[¶](#options ""Link to this heading"")

`--spec-path _FILE_`

Path to service specification file.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The current role must have OPERATE privilege on the service to upgrade a service.

## Examples[¶](#examples ""Link to this heading"")

```
snow spcs service upgrade echo_service --spec-path spec.yml

```

Copy

```
+-------------------------------------------+
| key    | value                            |
|--------+----------------------------------|
| status | Statement executed successfully. |
+-------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",NULL,8a70f67b4ab58377881723b0079b9c6bcb64ac59237cd815b39b1b2e38d0c86b,NULL
NULL,https://docs.snowflake.com/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/deploy,snow spcs service deploy¶,NULL,NULL,snow spcs,snow spcs service commands,"# snow spcs service deploy[¶](#snow-spcs-service-deploy ""Link to this heading"")

Note

You can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.

Deploys a service defined in the project definition file.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow spcs service deploy
  <entity_id>
  --upgrade
  --project <project_definition>
  --env <env_overrides>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_entity_id_`

ID of service entity.

## Options[¶](#options ""Link to this heading"")

`--upgrade`

Updates the existing service. Can update min\_instances, max\_instances, query\_warehouse, auto\_resume, auto\_suspend\_secs, external\_access\_integrations and comment. Default: False.

`-p, --project _TEXT_`

Path where the Snowflake project is stored. Defaults to the current working directory.

`--env _TEXT_`

String in the format key=value. Overrides variables from the env section used for templates. Default: \[\].

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow spcs service deploy` command reads a `snowflake.yml` project definition file that defines a service, then creates and deploys the compute pool to a stage named in the `snowflake.yml` file. If your project definition has precisely one service entity, you can omit the `<entity_id>` argument. However, if your project definition has multiple service entities, you must specify the service name in the `<entity_id>` argument. For more information, see [Services project definition](../../../services/manage-services.html#label-sfcli-service-pdf).

You can optionally choose to run more than one instance of your service. Each service instance is a collection of containers, as defined in the service specification file, that run together on a node in your compute pool. If you choose to run multiple instances of a service, a load balancer manages incoming traffic.

The `--upgrade` option updates an existing service. You can update only the following project definition parameters:

*   `min_instances`
    
*   `max_instances`
    
*   `query_warehouse`
    
*   `auto_resume`
    
*   `external_access_integrations`
    
*   `comment`
    

## Examples[¶](#examples ""Link to this heading"")

The following example creates and deploys a service defined in the `snowflake.yml` file in the current directory.

```
snow spcs service deploy

```

Copy

```
+---------------------------------------------------------------------+
| key    | value                                                      |
|--------+------------------------------------------------------------|
| status | Service MY_SERVICE successfully created.                   |
+---------------------------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)
3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)
4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)
5.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",NULL,a59428147934da18ba194381a4c0f81bce32e522e8b7aeaf051419929d09b800,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/create,snow object create¶,NULL,NULL,snow object,snow object create,"# snow object create[¶](#snow-object-create ""Link to this heading"")

Create an object of a given type. Check documentation for the list of supported objects and parameters.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow object create
  <object_type>
  <object_attributes>
  --json <object_json>
  --if-not-exists
  --replace
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_object_type_`

Type of object. For example table, database, compute-pool.

`_object_attributes..._`

Object attributes provided as a list of key=value pairs, for example name=my\_db comment=’created with Snowflake CLI’. Check documentation for the full list of available parameters for every object. .

## Options[¶](#options ""Link to this heading"")

`--json _TEXT_`

Object definition in JSON format, for example ‘{“name”: “my\_db”, “comment”: “created with Snowflake CLI”}’. Check documentation for the full list of available parameters for every object.

`--if-not-exists`

Only apply this operation if the specified object does not already exist. Default: False.

`--replace`

Replace this object if it already exists. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow object create` command creates one of the following types Snowflake objects, based on the provided object attributes or definitions:

*   `account`
    
*   `catalog-integration`
    
*   `compute-pool`
    
*   `database`
    
*   `database-role`
    
*   `dynamic-table`
    
*   `event-table`
    
*   `external-volume`
    
*   `function`
    
*   `image-repository`
    
*   `managed-account`
    
*   `network-policy`
    
*   `notebook`
    
*   `notification-integration`
    
*   `pipe`
    
*   `procedure`
    
*   `role`
    
*   `schema`
    
*   `service`
    
*   `stage`
    
*   `stream`
    
*   `table`
    
*   `task`
    
*   `user-defined-function`
    
*   `view`
    
*   `warehouse`
    

For each object, you must specify the appropriate object details using either the object attributes or the object definitions.

*   Use the `object_attributes` parameter specifies the object details as a series of `<key>=<value>` pairs, such as:
    
    ```
    snow object create database name=my_db comment=""Created with Snowflake CLI""
    
    ```
    
    Copy
    
*   Use the `--json object_definition` option to specify the object details as JSON, such as:
    
    ```
    snow object create table name=my_table columns='[{""name"":""col1"",""datatype"":""number"", ""nullable"":false}]' constraints='[{""name"":""prim_key"", ""column_names"":[""col1""], ""constraint_type"":""PRIMARY KEY""}]' --database my_db --schema public
    
    ```
    
    Copy
    
*   See [Examples](#label-cli-create-examples) for more examples.
    

Note

The following object types require a database to be identified in the connection configuration, such as `config.toml`, or passed to the command using the `--database` option.

*   image-repository
    
*   schema
    
*   service
    
*   table
    
*   task
    

The following sections describe the attributes that Snowflake CLI supports for selected object types.

*   [compute-pool](#label-cli-object-attrs-compute-pool)
    
*   [database](#label-cli-object-attrs-database)
    
*   [image-repository](#label-cli-object-attrs-image-repository)
    
*   [schema](#label-cli-object-attrs-schema)
    
*   [service](#label-cli-object-attrs-service)
    
*   [table](#label-cli-object-attrs-table)
    
*   [task](#label-cli-object-attrs-task)
    
*   [warehouse](#label-cli-object-attrs-database)
    

You can find attributes for other types of objects by checking their corresponding SQL CREATE command references, such as [CREATE ACCOUNT](../../../../sql-reference/sql/create-account).

### Compute pool object attributes[¶](#compute-pool-object-attributes ""Link to this heading"")

| Attribute | Description |
| --- | --- |
| namerequired, string | Snowflake object identifier. |
| min_nodesrequired, integer | Minimum number of nodes for the compute pool. |
| max_nodesrequired, integer | Maximum number of nodes for the compute pool. |
| instance_familyrequired, string | Name of the instance family. For more information about instance families, refer to the SQL CREATE COMPUTE POOL command. |
| auto_resumeoptional, string | Whether to resume the compute pool automatically when any statement that requires the compute pool is submitted. |
| commentoptional, string | Comment describing the compute pool. |
| auto_suspend_secsoptional, string | Number of seconds of inactivity after which you want Snowflake to automatically suspend the compute pool. |

### Database object attributes[¶](#database-object-attributes ""Link to this heading"")

| Attribute | Description |
| --- | --- |
| namerequired, string | Snowflake object identifier. |
| commentoptional, string | Comment describing the database. |
| data_retention_time_in_daysoptional, integer | Number of days for which Time Travel actions (CLONE and UNDROP) can be performed on the schema, as well as the default Time Travel retention time for all tables created in the schema. |
| default_ddl_collationoptional, string | Default collation specification for all schemas and tables added to the database. You can override this default at the schema and individual table level. |
| max_data_extension_time_in_daysoptional, integer | Maximum number of days for which Snowflake can extend the data retention period for tables in the database to prevent streams on the tables from becoming stale. |
| suspend_task_after_num_failuresoptional, integer | Number of consecutive failed task runs after which the current task is suspended automatically. |
| user_task_managed_initial_warehouse_sizeoptional, integer | Size of the compute resources to provision for the first run of the task, before a task history is available for Snowflake to determine an ideal size. Possible values include: XSMALL, SMALL, MEDIUM, LARGE, and XLARGE. |
| user_task_timeout_msoptional, integer | Time limit, in milliseconds, for a single run of the task before it times out. For information, see USER_TASK_TIMEOUT_MS. |

### Image repository object attributes[¶](#image-repository-object-attributes ""Link to this heading"")

| Attribute | Description |
| --- | --- |
| namerequired, string | Snowflake object identifier. |

### Schema object attributes[¶](#schema-object-attributes ""Link to this heading"")

| Attribute | Description |
| --- | --- |
| namerequired, string | Snowflake object identifier. |
| commentoptional, string | Comment describing the schema. |
| data_retention_time_in_daysoptional, integer | Number of days for which Time Travel actions (CLONE and UNDROP) can be performed on the schema, as well as the default Time Travel retention time for all tables created in the schema. |
| default_ddl_collationoptional, string | Default collation specification for all schemas and tables added to the database. You can override this default at the schema and individual table level. |
| max_data_extension_time_in_daysoptional, integer | Maximum number of days for which Snowflake can extend the data retention period for tables in the database to prevent streams on the tables from becoming stale. |
| suspend_task_after_num_failuresoptional, integer | Number of consecutive failed task runs after which the current task is suspended automatically. |
| user_task_managed_initial_warehouse_sizeoptional, integer | Size of the compute resources to provision for the first run of the task, before a task history is available for Snowflake to determine an ideal size. |
| user_task_timeout_msoptional, integer | Time limit, in milliseconds, for a single run of the task before it times out. For information, see USER_TASK_TIMEOUT_MS. |

### Service object attributes[¶](#service-object-attributes ""Link to this heading"")

| Attribute | Description |
| --- | --- |
| namerequired, string | Snowflake object identifier. |
| compute_poolrequired, string | Name of the compute pool in your account on which to run the service. |
| specrequired, object | Service specification. See service specification table for details. |
| external_access_integrationsoptional, string list | Names of the external access integrations that allow your service to access external sites. |
| auto_resumeoptional, boolean | Whether to automatically resume a service when a service function or ingress is called. |
| min_instancesoptional, integer | Minimum number of service instances to run. |
| max_instancesoptional, integer | Maximum number of service instances to run. |
| query_warehouseoptional, string | Warehouse to use if a service container connects to Snowflake to execute a query but does not explicitly specify a warehouse to use. |
| commentoptional, string | Comment for the service. |

**Service specification attributes**

| Attribute | Description |
| --- | --- |
| spec_typerequired, string | Type of the service specification. Possible values include from_file or from_inline. |
| spec_textrequired, string | (Valid only for spec_type=""from_inline"")Service specification. You can use a pair of dollar signs ($$) to delimit the beginning and ending of the specification string. |
| stagerequired, string | (Valid only for spec_type=""from_inline"")Snowflake internal stage where the specification file is stored, such as @tutorial_stage. |
| namerequired, string | (Valid only for spec_type=""from_inline"")Path to the service specification file on the stage, such as some-dir/echo_spec.yaml. |

### Table object attributes[¶](#table-object-attributes ""Link to this heading"")

| Attribute | Description |
| --- | --- |
| namerequired, string | Snowflake object identifier. The name must be unique for the schema in which the table is created. |
| kindoptional, string | Table type. Possible values include: TABLE for permanent tables, TEMPORARY, and TRANSIENT. |
| commentoptional, string | Description of the table. |
| cluster_by[]optional, string list | List of one or more columns or column expressions in the table as the clustering key. |
| enable_schema_evolutionoptional, boolean | Whether to enable or disable schema evolution for the table. |
| change_trackingoptional, boolean | Whether to enable or disable change tracking for the table. |
| data_retention_time_in_daysoptional, integer | Retention period, in days, for the table so that Time Travel actions SELECT, CLONE, UNDROP can be performed on historical data in the table. |
| max_data_extension_time_in_daysoptional, integer | Maximum number of days Snowflake can extend the data retention period to prevent streams on the table from becoming stale. |
| default_ddl_collationoptional, string | Default collation specification for the columns in the table, including columns added to the table in the future. |
| columnsrequired, column list | List of column definitions. See Column definition attributes. |
| constraintsoptional, constraint list | List of constraint definitions. See Constrain definition attributes. |

**Column definition attributes**

| Attribute | Description |
| --- | --- |
| namerequired, string | Column name. |
| datatyperequired, string | Type of data contained in the column. |
| nullableoptional, boolean | Whether the column allows NULL values. |
| collateoptional, string | Collation to use for column operations such as string comparison. |
| defaultoptional, string | Whether to automatically insert a default value in the column if a value is not explicitly specified with an INSERT or CREATE TABLE AS SELECT statement. |
| autoincrementoptional, boolean | Whether to automatically increment and include the number in successive columns. |
| autoincrement_startoptional, integer | Staring value for the column. |
| autoincrement_incrementoptional, integer | Increment for determining the next auto-incremented number. |
| commentoptional, string | Column description. |

**Constraint definition attributes**

| Attribute | Description |
| --- | --- |
| namerequired, string | Constraint name. |
| column_namesrequired, string list | Names of columns to apply the constraint. |
| constraint_typerequired, string | Type of the constraint. Possible values include: UNIQUE, PRIMARY KEY and FOREIGN KEY. |
| referenced_table_namerequired, string | (Valid only for constraint_type=""FOREIGN KEY"")Name of table referenced by foreign key |
| referenced_column_namesoptional, string | (Valid only for constraint_type=""FOREIGN KEY"")Names of columns referenced by foreign key |

### Task attributes[¶](#task-attributes ""Link to this heading"")

| Attribute | Description |
| --- | --- |
| namerequired, string | Snowflake object identifier. |
| definitionrequired, string | SQL definition for the task. It can be a single SQL statement, a call to a stored procedure, or procedural logic using Snowflake scripting. |
| warehouseoptional, string | Virtual warehouse that provides compute resources for task runs. |
| scheduleoptional, string | Schedule for periodically running the task. See Task schedule attributes for details. |
| commentoptional, string | Comment description for the task. |
| predecessorsoptional, string list | One or more predecessor tasks for the current task. |
| user_task_managed_initial_warehouse_sizeoptional, string | Size of the compute resources to provision for the first run of the task. |
| user_task_timeout_msoptional, string | Time limit, in milliseconds, on a single run of the task before it times out. For information, see USER_TASK_TIMEOUT_MS. |
| suspend_task_after_num_failuresoptional, integer | Number of consecutive failed task runs after which the current task is suspended automatically. |
| conditionoptional, string | Boolean SQL expression condition; multiple conditions joined with AND/OR are supported. |
| allow_overlapping_executionoptional, boolean | Whether to allow multiple instances of the DAG to run concurrently. |

**Task schedule attributes**

| Attribute | Description |
| --- | --- |
| schedule_typeoptional, string | Type of the schedule. Possible values include CRON_TYPE or MINUTES_TYPE. |
| cron_exproptional, string | (Valid only for schedule_type=""CRON_TYPE"")A cron expression for the task execution, such as “* * * * ? *”. |
| timezoneoptional, string | (Valid only for schedule_type=""CRON_TYPE"")Time zone for the schedule, for example ""america/los_angeles"". |
| minutesoptional, string | (Valid only for schedule_type=""MINUTES_TYPE"")Number of minutes between each task run. |

### Warehouse attributes[¶](#warehouse-attributes ""Link to this heading"")

| Attribute | Description |
| --- | --- |
| namerequired, string | Snowflake object identifier. |
| commentoptional, string | Description of the warehouse. |
| warehouse_typeoptional, string | Type of warehouse. Possible values include: STANDARD and SNOWPARK-OPTIMIZED. |
| warehouse_sizeoptional, string | Size of warehouse. Possible values include: XSMALL, SMALL, MEDIUM, LARGE, XLARGE, XXLARGE, XXXLARGE, X4LARGE, X5LARGE, and X6LARGE. |
| auto_suspendoptional, string | Time, in seconds, before the warehouse automatically suspends itself. |
| auto_resumeoptional, string | Whether to automatically resume a warehouse when a SQL statement is submitted to it. Possible values include: “true” and “false”. |
| max_concurrency_leveloptional, integer | Concurrency level for SQL statements executed by a warehouse cluster. |
| statement_queued_timeout_in_secondsoptional, integer | Time, in seconds, a SQL statement can be queued on a warehouse before it is canceled by the system. |
| statement_timeout_in_secondsoptional, integer | Time, in seconds, after which a running SQL statement is canceled by the system. |
| resource_monitoroptional, string | Name of a resource monitor that is explicitly assigned to the warehouse. When a resource monitor is explicitly assigned to a warehouse, the monitor controls the monthly credits used by the warehouse. |

## Examples[¶](#examples ""Link to this heading"")

*   Create a database object using the `option-attributes` parameter:
    
    ```
    snow object create database name=my_db comment='Created with Snowflake CLI'
    
    ```
    
    Copy
    
*   Create a table object using the `option-attributes` parameter:
    
    ```
    snow object create table name=my_table columns='[{""name"":""col1"",""datatype"":""number"", ""nullable"":false}]' constraints='[{""name"":""prim_key"", ""column_names"":[""col1""], ""constraint_type"":""PRIMARY KEY""}]' --database my_db --schema public
    
    ```
    
    Copy
    
*   Create a database using the `--json object-definition` option:
    
    ```
    snow object create database --json '{""name"":""my_db"", ""comment"":""Created with Snowflake CLI""}'
    
    ```
    
    Copy
    
*   Create a table using the `--json object-definition` option:
    
    ```
    snow object create table --json ""$(cat table.json)"" --database my_db
    
    ```
    
    Copy
    
    where `table.json` contains the following:
    
    ```
    {
      ""name"": ""my_table"",
      ""columns"": [
        {
          ""name"": ""col1"",
          ""datatype"": ""number"",
          ""nullable"": false
        }
      ],
      ""constraints"": [
        {
          ""name"": ""prim_key"",
          ""column_names"": [""col1""],
          ""constraint_type"": ""PRIMARY KEY""
        }
      ]
    }
    
    ```
    
    Copy
    

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Compute pool object attributes](#compute-pool-object-attributes)
6.  [Database object attributes](#database-object-attributes)
7.  [Image repository object attributes](#image-repository-object-attributes)
8.  [Schema object attributes](#schema-object-attributes)
9.  [Service object attributes](#service-object-attributes)
10.  [Table object attributes](#table-object-attributes)
11.  [Task attributes](#task-attributes)
12.  [Warehouse attributes](#warehouse-attributes)
13.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)
3.  [snow object commands](/developer-guide/snowflake-cli/command-reference/object-commands/overview)",NULL,8881ae6dd183b5047508cbe1a83e8c009f6871fe2e402257a7daf9922d9805b9,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/describe,snow object describe¶,NULL,NULL,snow object,snow object describe,"# snow object describe[¶](#snow-object-describe ""Link to this heading"")

Provides description of an object of given type. Supported types: compute-pool, database, external-access-integration, function, git-repository, integration, network-rule, notebook, procedure, role, schema, secret, service, stage, stream, streamlit, table, task, user, view, warehouse

## Syntax[¶](#syntax ""Link to this heading"")

```
snow object describe
  <object_type>
  <object_name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_object_type_`

Type of object. For example table, database, compute-pool.

`_object_name_`

Name of the object.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `IDENTIFIER` for procedures and functions must specify argument types, such as `""hello(int,string)""`.

## Examples[¶](#examples ""Link to this heading"")

To describe a function, run a command similar to the following:

```
snow object describe function ""hello_function(string)""

```

Copy

```
describe function hello_function(string)
+---------------------------------------------------------------------
| property           | value
|--------------------+------------------------------------------------
| signature          | (NAME VARCHAR)
| returns            | VARCHAR(16777216)
| language           | PYTHON
| null handling      | CALLED ON NULL INPUT
| volatility         | VOLATILE
| body               | None
| imports            |
| handler            | functions.hello_function
| runtime_version    | 3.12
| packages           | ['snowflake-snowpark-python']
| installed_packages | ['_libgcc_mutex==0.1','_openmp_mutex==5.1',...
+---------------------------------------------------------------------

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)",NULL,66dd939ade942cdd7fcc60175a9fbc4655ecdd6bdb8addad6359f372cbcf1e1a,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/drop,snow object drop¶,NULL,NULL,snow object,snow object drop,"# snow object drop[¶](#snow-object-drop ""Link to this heading"")

Drops Snowflake object of given name and type. Supported types: compute-pool, database, external-access-integration, function, git-repository, image-repository, integration, network-rule, notebook, procedure, role, schema, secret, service, stage, stream, streamlit, table, task, user, view, warehouse

## Syntax[¶](#syntax ""Link to this heading"")

```
snow object drop
  <object_type>
  <object_name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_object_type_`

Type of object. For example table, database, compute-pool.

`_object_name_`

Name of the object.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `IDENTIFIER` for procedures and functions must specify argument types, such as `""hello(int,string)""`.

## Examples[¶](#examples ""Link to this heading"")

To delete a procedure, run a command similar to the following:

```
snow object drop procedure ""test_procedure()""

```

Copy

```
drop procedure test_procedure()
+--------------------------------------+
| status                               |
|--------------------------------------|
| TEST_PROCEDURE successfully dropped. |
+--------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)",NULL,5af42a609ad1a044d7a2bb53d95249cbf34ca5766e4616d80066ccb0fe68487b,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/list,snow object list¶,NULL,NULL,snow object,snow object list,"# snow object list[¶](#snow-object-list ""Link to this heading"")

Lists all available Snowflake objects of given type. Supported types: compute-pool, database, external-access-integration, function, git-repository, image-repository, integration, network-rule, notebook, procedure, role, schema, secret, service, stage, stream, streamlit, table, task, user, view, warehouse

## Syntax[¶](#syntax ""Link to this heading"")

```
snow object list
  <object_type>
  --like <like>
  --in <scope>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_object_type_`

Type of object. For example table, database, compute-pool.

## Options[¶](#options ""Link to this heading"")

`--like, -l _TEXT_`

SQL LIKE pattern for filtering objects by name. For example, `list function --like ""my%""` lists all functions that begin with “my”. Default: %%.

`--in _<TEXT TEXT>..._`

Specifies the scope of this command using ‘–in <scope> <name>’, for example `list table --in database my_db`. Some object types have specialized scopes (e.g. list service –in compute-pool my\_pool). Default: (None, None).

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `--like [-l] <pattern>` option lets you specify a SQL LIKE pattern for filtering objects by name. For example, `snow object list function --like ""my%""` lists all functions that begin with **my**. For more information about SQL patterns syntax, see [SQL LIKE Keyword](https://www.w3schools.com/sql/sql_ref_like.asp).

## Examples[¶](#examples ""Link to this heading"")

The following example lists all roles beginning with **public**. The `--like` option

```
snow object list role --like public%

```

Copy

```
show roles like 'public%'
+-------------------------------------------------------------------------------
| created_on                       | name        | is_default | is_current | ...
|----------------------------------+-------------+------------+------------+----
| 2023-02-01 15:25:04.105000-08:00 | PUBLIC      | N          | N          | ...
| 2024-01-15 12:55:05.840000-08:00 | PUBLIC_TEST | N          | N          | ...
+-------------------------------------------------------------------------------

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)
3.  [snow object commands](/developer-guide/snowflake-cli/command-reference/object-commands/overview)",NULL,deb395039a58fe702a1606efd6c8f288513013df72a398731889a89822333fea,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/copy,snow stage copy¶,NULL,NULL,snow stage,snow stage copy,"# snow stage copy[¶](#snow-stage-copy ""Link to this heading"")

Copies all files from source path to target directory. This works for uploading to and downloading files from the stage, and copying between named stages.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/copy-into-table)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow stage copy
  <source_path>
  <destination_path>
  --overwrite / --no-overwrite
  --parallel <parallel>
  --recursive / --no-recursive
  --auto-compress / --no-auto-compress
  --refresh / --no-refresh
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_source_path_`

Source path for copy operation. Can be either stage path or local. You can use a glob pattern for local files but the pattern has to be enclosed in quotes.

`_destination_path_`

Target directory path for copy operation.

## Options[¶](#options ""Link to this heading"")

`--overwrite / --no-overwrite`

Overwrites existing files in the target path. Default: False.

`--parallel _INTEGER_`

Number of parallel threads to use when uploading files. Default: 4.

`--recursive / --no-recursive`

Copy files recursively with directory structure. Default: False.

`--auto-compress / --no-auto-compress`

Specifies whether Snowflake uses gzip to compress files during upload. Ignored when downloading. Default: False.

`--refresh / --no-refresh`

Specifies whether ALTER STAGE {name} REFRESH should be executed after uploading. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

*   One of `SOURCE_PATH` or `DESTINATION_PATH` must be a local directory, while the other should be a directory in the Snowflake stage. The stage path must start with “@”. For example:
    
    *   `snow stage copy @my_stage dir/` - copies files from `my_stage` stage to the local `dir` directory.
        
    *   `snow stage copy dir/ @my_stage` - copies files from the local `dir` directory to `my_stage`.
        
*   You can specify multiple files matching a regular expression by using a glob pattern for the `source_path` argument. You must enclose the glob pattern in single or double quotes.
    

## Examples[¶](#examples ""Link to this heading"")

*   To copy files from the local machine to a stage, use a command similar to the following:
    
    ```
    snow stage copy local_example_app @example_app_stage/app
    
    ```
    
    Copy
    
    ```
    put file:///.../local_example_app/* @example_app_stage/app4 auto_compress=false parallel=4 overwrite=False
    +--------------------------------------------------------------------------------------
    | source           | target           | source_size | target_size | source_compression...
    |------------------+------------------+-------------+-------------+--------------------
    | environment.yml  | environment.yml  | 62          | 0           | NONE             ...
    | snowflake.yml    | snowflake.yml    | 252         | 0           | NONE             ...
    | streamlit_app.py | streamlit_app.py | 109         | 0           | NONE             ...
    +--------------------------------------------------------------------------------------
    
    ```
    
*   To download files from a stage to a local directory, use a command similar to the following:
    
    ```
    mkdir local_app_backup
    snow stage copy @example_app_stage/app local_app_backup
    
    ```
    
    Copy
    
    ```
    get @example_app_stage/app file:///.../local_app_backup/ parallel=4
    +------------------------------------------------+
    | file             | size | status     | message |
    |------------------+------+------------+---------|
    | environment.yml  | 62   | DOWNLOADED |         |
    | snowflake.yml    | 252  | DOWNLOADED |         |
    | streamlit_app.py | 109  | DOWNLOADED |         |
    +------------------------------------------------+
    
    ```
    
*   The following example copies all `.txt` files in a directory to a stage.
    
    ```
    snow stage copy ""testdir/*.txt"" @TEST_STAGE_3
    
    ```
    
    Copy
    
    ```
    put file:///.../testdir/*.txt @TEST_STAGE_3 auto_compress=false parallel=4 overwrite=False
    +------------------------------------------------------------------------------------------------------------+
    | source | target | source_size | target_size | source_compression | target_compression | status   | message |
    |--------+--------+-------------+-------------+--------------------+--------------------+----------+---------|
    | b1.txt | b1.txt | 3           | 16          | NONE               | NONE               | UPLOADED |         |
    | b2.txt | b2.txt | 3           | 16          | NONE               | NONE               | UPLOADED |         |
    +------------------------------------------------------------------------------------------------------------+
    
    ```
    

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)
3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)
4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",NULL,6ca1cb5389dc2294de1cdcdc04fd0c8afa188025cc2ac6e681d95a90bf28aa73,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/create,snow stage create¶,NULL,NULL,snow stage,snow stage create,"# snow stage create[¶](#snow-stage-create ""Link to this heading"")

Creates a named stage if it does not already exist.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/create-stage)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow stage create
  <stage_name>
  --encryption <encryption>
  --enable-directory
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_stage_name_`

Identifier of the stage; for example: @my\_stage.

## Options[¶](#options ""Link to this heading"")

`--encryption [SNOWFLAKE_FULL|SNOWFLAKE_SSE]`

Type of encryption supported for all files stored on the stage. Default: SNOWFLAKE\_FULL.

`--enable-directory`

Specifies whether directory support is enabled for the stage. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `stage create` command creates a named stage if it does not already exist. The stage name can be a fully qualified name or just a stage name. In the later case, the stage is created in the database and schema specified in the connection details.

## Examples[¶](#examples ""Link to this heading"")

The following example creates a stage called `new_stage` in the `bar` database:

```
snow stage create new_stage --database=bar --schema=public

```

Copy

```
+-----------------------------------------------------+
| key    | value                                      |
|--------+--------------------------------------------|
| status | Stage area NEW_STAGE successfully created. |
+-----------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)
3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)
4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",NULL,eb8b878c992a8b6bfbf7264aa4449b813388922d94ec14c93ee80463c23f443b,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/describe,snow stage describe¶,NULL,NULL,snow stage,snow stage describe,"# snow stage describe[¶](#snow-stage-describe ""Link to this heading"")

Provides description of stage.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/desc-stage)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow stage describe
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the stage; for example: @my\_stage.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

None.

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)
3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)
4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",NULL,5fdf780c329173ed1e41afd746da9e1c50e7dece8d30acfb140dfdafe626744f,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/drop,snow stage drop¶,NULL,NULL,snow stage,snow stage drop,"# snow stage drop[¶](#snow-stage-drop ""Link to this heading"")

Drops stage with given name.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/drop-stage)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow stage drop
  <name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the stage; for example: @my\_stage.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

None.

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)
3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)
4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",NULL,5cd160ae25bfc0807d003a6ff4fcdc2e51893d070c9950cdf9e5b037933a03f0,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/execute,snow stage execute¶,NULL,NULL,snow stage,snow stage execute,"# snow stage execute[¶](#snow-stage-execute ""Link to this heading"")

Execute immediate all files from the stage path. Files can be filtered with a glob-like pattern, e.g. `@stage/*.sql`, `@stage/dev/*`. Only files with `.sql` extension will be executed.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow stage execute
  <stage_path>
  --on-error <on_error>
  --variable <variables>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_stage_path_`

Stage path with files to be execute. For example `@stage/dev/*`.

## Options[¶](#options ""Link to this heading"")

`--on-error [break|continue]`

What to do when an error occurs. Defaults to break. Default: break.

`--variable, -D _TEXT_`

Variables for the execution context; for example: `-D ""<key>=<value>""`. For SQL files, variables are used to expand the template, and any unknown variable will cause an error (consider embedding quoting in the file).For Python files, variables are used to update the os.environ dictionary. Provided keys are capitalized to adhere to best practices. In case of SQL files string values must be quoted in `''` (consider embedding quoting in the file).

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

Note

Snowflake CLI does not support executing Python files for Python versions 3.12 and above.

*   The command searches for files with a `.sql` extension in the specified `STAGE_PATH` and executes `EXECUTE IMMEDIATE` on each of them. `STAGE_PATH` can be:
    
    *   Only a stage name, such as `@scripts`, which executes all `.sql` files from the stage.
        
    *   Glob-like pattern, such as `@scripts/dir/*`, which executes `.sql` files from the `dir` directory.
        
    *   Direct file path, such as `@scripts/script.sql`, which executes only the `script.sql` file from the `scripts`.
        

The `--silent` options hides intermediate messages with file execution results.

When using Jinja templates for the SQL files, you can pass template variables using `-D` (or `--variable`) option, such as `-D ""<key>=<value>""`. You must enclose string values in single quotes (`''`).

## Examples[¶](#examples ""Link to this heading"")

*   Specify only a stage name to execute all `.sql` files in the stage:
    
    ```
    snow stage execute ""@scripts""
    
    ```
    
    Copy
    
    ```
    SUCCESS - scripts/script1.sql
    SUCCESS - scripts/script2.sql
    SUCCESS - scripts/dir/script.sql
    +------------------------------------------+
    | File                   | Status  | Error |
    |------------------------+---------+-------|
    | scripts/script1.sql    | SUCCESS | None  |
    | scripts/script2.sql    | SUCCESS | None  |
    | scripts/dir/script.sql | SUCCESS | None  |
    +------------------------------------------+
    
    ```
    
*   Specify a glob-like pattern to execute all `.sql` files in the `dir` directory:
    
    ```
    snow stage execute ""@scripts/dir/*""
    
    ```
    
    Copy
    
    ```
    SUCCESS - scripts/dir/script.sql
    +------------------------------------------+
    | File                   | Status  | Error |
    |------------------------+---------+-------|
    | scripts/dir/script.sql | SUCCESS | None  |
    +------------------------------------------+
    
    ```
    
*   Specify a glob-like pattern to execute only `.sql` files in the `dir` directory that begin with “script”, followed by one character:
    
    ```
    snow stage execute ""@scripts/script?.sql""
    
    ```
    
    Copy
    
    ```
    SUCCESS - scripts/script1.sql
    SUCCESS - scripts/script2.sql
    +---------------------------------------+
    | File                | Status  | Error |
    |---------------------+---------+-------|
    | scripts/script1.sql | SUCCESS | None  |
    | scripts/script2.sql | SUCCESS | None  |
    +---------------------------------------+
    
    ```
    
*   Specify a direct file path with the `--silent` option:
    
    ```
    snow stage execute ""@scripts/script1.sql"" --silent
    
    ```
    
    Copy
    
    ```
    +---------------------------------------+
    | File                | Status  | Error |
    |---------------------+---------+-------|
    | scripts/script1.sql | SUCCESS | None  |
    +---------------------------------------+
    
    ```
    

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)
3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)
4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",NULL,b927889d5d526a236df7fdadfcc4fd63066fdacb02a070799837e9a3c43d6211,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/list,snow stage list¶,NULL,NULL,snow stage,snow stage list,"# snow stage list[¶](#snow-stage-list ""Link to this heading"")

Lists all available stages.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/show-stages)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow stage list
  --like <like>
  --in <scope>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

None

## Options[¶](#options ""Link to this heading"")

`--like, -l _TEXT_`

SQL LIKE pattern for filtering objects by name. For example, `list --like ""my%""` lists all stages that begin with “my”. Default: %%.

`--in _<TEXT TEXT>..._`

Specifies the scope of this command using ‘–in <scope> <name>’, for example `list --in database my_db`. Default: (None, None).

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

None.

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)
3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)
4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",NULL,d0b8edf1e1f39c59cb5f1e2a1ddb5b3d936ba244163f9f5476ebbc75b01c9e62,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/list-files,snow stage list-files¶,NULL,NULL,snow stage,snow stage list files,"# snow stage list-files[¶](#snow-stage-list-files ""Link to this heading"")

Lists the stage contents.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/list)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow stage list-files
  <stage_name>
  --pattern <pattern>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_stage_name_`

Identifier of the stage; for example: @my\_stage/path.

## Options[¶](#options ""Link to this heading"")

`--pattern _TEXT_`

Regex pattern for filtering files by name. For example –pattern “.\*.txt” will filter only files with .txt extension.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

The following example lists the contents of the `jdoe.public.test` stage:

```
snow stage list-files jdoe.public.test

```

Copy

```
ls @jdoe.public.test
+------------------------------------------------------------------------------+
| name            | size    | md5              | last_modified                 |
|-----------------+---------+------------------+-------------------------------|
| test/file.csv   | 195424  | 4fc596b5e00681d8 | Mon, 11 Mar 2024 17:09:01 GMT |
| test/data.csv   | 133248  | c0ddc25c1d3745d6 | Mon, 11 Mar 2024 17:08:57 GMT |
+------------------------------------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)
3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)
4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",NULL,582cc33ff336fb1e6c2547417c4faa7ed52ea7ac619326d4efd21e6c77982cd0,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/remove,snow stage remove¶,NULL,NULL,snow stage,snow stage remove,"# snow stage remove[¶](#snow-stage-remove ""Link to this heading"")

Removes a file from a stage.

### For more information

Go to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.

[View](/sql-reference/sql/remove)

## Syntax[¶](#syntax ""Link to this heading"")

```
snow stage remove
  <stage_name>
  <file_name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_stage_name_`

Identifier of the stage; for example: @my\_stage.

`_file_name_`

Name of the file to remove.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

None.

## Examples[¶](#examples ""Link to this heading"")

The following example removes the `app/pages/my_page.py` file from a stage:

```
snow stage remove example_app_stage app/pages/my_page.py

```

Copy

```
+-------------------------------------------------+
| key    | value                                  |
|--------+----------------------------------------|
| name   | example_app_stage/app/pages/my_page.py |
| result | removed                                |
+-------------------------------------------------+

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)
3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)
4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",NULL,9e4aac29130d15297135526cfa6f886d66bb27d6a137fbc013e8b81dd5f902b1,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/lookup,snow package lookup¶,NULL,NULL,snow snowpark,snow,"# snow package lookup[¶](#snow-package-lookup ""Link to this heading"")

Checks if a package is available on the Snowflake Anaconda channel.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow snowpark package lookup
  <package_name>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_package_name_`

Name of the package.

## Options[¶](#options ""Link to this heading"")

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snow snowpark lookup` command checks to see whether a package is available on the Snowflake Anaconda channel.

## Examples[¶](#examples ""Link to this heading"")

The following example illustrates looking up a package that is already available on the Snowflake Anaconda channel:

```
snow snowpark package lookup numpy

```

Copy

```
Package `numpy` is available in Anaconda. Latest available version: 1.26.4.

```

If a package is not available on the Snowflake Anaconda channel, you can get a message similar to the following:

```
snow snowpark package lookup july

```

Copy

```
Package `july` is not available in Anaconda. To prepare Snowpark compatible package run:

  snow snowpark package create july

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../overview)
3.  [Package command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/overview)
4.  [snow package create](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/create)
5.  [snow package upload](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/upload)",NULL,062fb3b78e7e4d3fdde5eb729e13aa6467de0bf76a128fae0635455589c148f3,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/create,snow package create¶,NULL,NULL,snow snowpark,snow,"# snow package create[¶](#snow-package-create ""Link to this heading"")

Creates a Python package as a zip file that can be uploaded to a stage and imported for a Snowpark Python app.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow snowpark package create
  <name>
  --ignore-anaconda
  --index-url <index_url>
  --skip-version-check
  --allow-shared-libraries
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Name of the package to create.

## Options[¶](#options ""Link to this heading"")

`--ignore-anaconda`

Does not lookup packages on Snowflake Anaconda channel. Default: False.

`--index-url _TEXT_`

Base URL of the Python Package Index to use for package lookup. This should point to a repository compliant with PEP 503 (the simple repository API) or a local directory laid out in the same format.

`--skip-version-check`

Skip comparing versions of dependencies between requirements and Anaconda. Default: False.

`--allow-shared-libraries`

Allows shared (.so) libraries, when using packages installed through PIP. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `snowpark package create` command does the following:

*   Creates an artifact ready to upload to a stage.
    
*   Checks for native libraries and asks if you want to continue. If the native libraries are present in the downloaded packages, this command works the same as the `snowpark package build` command.
    

## Examples[¶](#examples ""Link to this heading"")

*   This example creates a Python package as a zip file that can be uploaded to a stage and later imported by a Snowpark Python app. Dependencies for the “july” package are found on the Anaconda channel, so they were excluded from the `.zip` file. The command displays the packages you would need to include in `requirements.txt` of your Snowpark project.
    
    ```
    snow snowpark package create july==0.1
    
    ```
    
    Copy
    
    ```
    Package july.zip created. You can now upload it to a stage using
    snow snowpark package upload -f july.zip -s <stage-name>`
    and reference it in your procedure or function.
    Remember to add it to imports in the procedure or function definition.
    
    The package july is successfully created, but depends on the following
    Anaconda libraries. They need to be included in project requirements,
    as their are not included in .zip.
    matplotlib
    contourpy >=1.0.1
    numpy>=1.20
    bokeh
    selenium
    mypy==1.8.0
    Pillow
    pytest-xdist
    wurlitzer
    cycler >=0.10
    fonttools >=4.22.0
    kiwisolver >=1.3.1
    pyparsing >=2.3.1
    jinja2
    python-dateutil >=2.7
    six >=1.5
    importlib-resources >=3.2.0
    
    ```
    
*   This example creates the `july.zip` package that you can use in your Snowpark project without needing to add any dependencies to the `requirements.txt` file. The error messages indicate that some packages contain shared libraries, which might not work, such as when creating a package using Windows.
    
    ```
    snow snowpark package create july==0.1 --ignore-anaconda --allow-shared-libraries
    
    ```
    
    Copy
    
    ```
    2024-04-11 16:24:56 ERROR Following dependencies utilise shared libraries, not supported by Conda:
    2024-04-11 16:24:56 ERROR numpy
    contourpy
    fonttools
    kiwisolver
    matplotlib
    pillow
    2024-04-11 16:24:56 ERROR You may still try to create your package with --allow-shared-libraries, but the might not work.
    2024-04-11 16:24:56 ERROR You may also request adding the package to Snowflake Conda channel
    2024-04-11 16:24:56 ERROR at https://support.anaconda.com/
    
    Package july.zip created. You can now upload it to a stage using
    snow snowpark package upload -f july.zip -s <stage-name>`
    and reference it in your procedure or function.
    Remember to add it to imports in the procedure or function definition.
    
    ```
    
*   This example fails to create the package because it already exists. You can still forcibly create the package by using the `--ignore-anaconda` option.
    
    ```
    snow snowpark package create matplotlib
    
    ```
    
    Copy
    
    ```
    Package matplotlib is already available in Snowflake Anaconda Channel.
    
    ```
    

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../overview)
3.  [Package command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/overview)
4.  [snow package lookup](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/lookup)
5.  [snow package upload](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/upload)",NULL,c137c1aca1fd8d4c33dcb5fb1e7f63fc0b44856d505d68a82d7c88a9b30fd318,NULL
NULL,https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/streamlit-commands/deploy,snow streamlit deploy¶,NULL,NULL,snow streamlit,snow streamlit deploy,"# snow streamlit deploy[¶](#snow-streamlit-deploy ""Link to this heading"")

Deploys a Streamlit app defined in the project definition file (snowflake.yml). By default, the command uploads environment.yml and any other pages or folders, if present. If you don’t specify a stage name, the `streamlit` stage is used. If the specified stage does not exist, the command creates it. If multiple Streamlits are defined in snowflake.yml and no entity\_id is provided then command will raise an error.

## Syntax[¶](#syntax ""Link to this heading"")

```
snow streamlit deploy
  <entity_id>
  --replace
  --prune / --no-prune
  --open
  --legacy
  --project <project_definition>
  --env <env_overrides>
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_entity_id_`

ID of streamlit entity.

## Options[¶](#options ""Link to this heading"")

`--replace`

Replaces the Streamlit app if it already exists. It only uploads new and overwrites existing files, but does not remove any files already on the stage. Default: False.

`--prune / --no-prune`

Delete files that exist in the stage, but not in the local filesystem. Default: False.

`--open`

Whether to open the Streamlit app in a browser. Default: False.

`--legacy`

Use legacy ROOT\_LOCATION SQL syntax. Default: False.

`-p, --project _TEXT_`

Path where the Snowflake project is stored. Defaults to the current working directory.

`--env _TEXT_`

String in the format key=value. Overrides variables from the env section used for templates. Default: \[\].

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified. \[env var: SNOWFLAKE\_DECIMAL\_PRECISION\].

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

This command creates a Streamlit app object in the database and a schema configured in the specified `connection`.

The command uploads local files to a specified stage and creates a Streamlit app using those files. You must specify the main Python file and query warehouse. By default, the command uploads the `environment.yml` and `pages/` folder if present. The Streamlit app is created in the database and schema configured in the specified `connection`.

If you don’t specify a stage name, the `streamlit` stage is used. If the specified stage does not exist, the command creates it. You can modify the behavior by using [command-line options](#).

If you specify the `--replace` option, the command uploads new files and overwrites existing files. It does not remove any files already on the stage.

If you specify the `--prune` option, the command removes files that exist in the stage, but not files in the local filesystem.

## Examples[¶](#examples ""Link to this heading"")

```
snow streamlit deploy demo_app --replace

```

Copy

```
Streamlit successfully deployed and available under https://app.snowflake.com/myorg/myacc/#/streamlit-apps/JDOE.PUBLIC.DEMO_APP

```

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../overview)
3.  [Streamlit commands](/developer-guide/snowflake-cli/command-reference/streamlit-commands/overview)",NULL,06d07049743110896fc358cdc8b7da59238e5a30c9bf1a170dc4f98e946eb197,NULL
NULL,https://docs.snowflake.com/developer-guide/snowflake-cli/command-reference/streamlit-commands/get-url,snow streamlit get-url¶,NULL,NULL,snow streamlit,snow streamlit get url,"# snow streamlit get-url[¶](#snow-streamlit-get-url ""Link to this heading"")

Returns a URL to the specified Streamlit app

## Syntax[¶](#syntax ""Link to this heading"")

```
snow streamlit get-url
  <name>
  --open
  --connection <connection>
  --host <host>
  --port <port>
  --account <account>
  --user <user>
  --password <password>
  --authenticator <authenticator>
  --workload-identity-provider <workload_identity_provider>
  --private-key-file <private_key_file>
  --token <token>
  --token-file-path <token_file_path>
  --database <database>
  --schema <schema>
  --role <role>
  --warehouse <warehouse>
  --temporary-connection
  --mfa-passcode <mfa_passcode>
  --enable-diag
  --diag-log-path <diag_log_path>
  --diag-allowlist-path <diag_allowlist_path>
  --oauth-client-id <oauth_client_id>
  --oauth-client-secret <oauth_client_secret>
  --oauth-authorization-url <oauth_authorization_url>
  --oauth-token-request-url <oauth_token_request_url>
  --oauth-redirect-uri <oauth_redirect_uri>
  --oauth-scope <oauth_scope>
  --oauth-disable-pkce
  --oauth-enable-refresh-tokens
  --oauth-enable-single-use-refresh-tokens
  --client-store-temporary-credential
  --format <format>
  --verbose
  --debug
  --silent
  --enhanced-exit-codes
  --decimal-precision <decimal_precision>

```

Copy

## Arguments[¶](#arguments ""Link to this heading"")

`_name_`

Identifier of the Streamlit app; for example: my\_streamlit.

## Options[¶](#options ""Link to this heading"")

`--open`

Whether to open the Streamlit app in a browser. Default: False.

`--connection, -c, --environment _TEXT_`

Name of the connection, as defined in your `config.toml` file. Default: `default`.

`--host _TEXT_`

Host address for the connection. Overrides the value specified for the connection.

`--port _INTEGER_`

Port for the connection. Overrides the value specified for the connection.

`--account, --accountname _TEXT_`

Name assigned to your Snowflake account. Overrides the value specified for the connection.

`--user, --username _TEXT_`

Username to connect to Snowflake. Overrides the value specified for the connection.

`--password _TEXT_`

Snowflake password. Overrides the value specified for the connection.

`--authenticator _TEXT_`

Snowflake authenticator. Overrides the value specified for the connection.

`--workload-identity-provider _TEXT_`

Workload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.

`--private-key-file, --private-key-path _TEXT_`

Snowflake private key file path. Overrides the value specified for the connection.

`--token _TEXT_`

OAuth token to use when connecting to Snowflake.

`--token-file-path _TEXT_`

Path to file with an OAuth token to use when connecting to Snowflake.

`--database, --dbname _TEXT_`

Database to use. Overrides the value specified for the connection.

`--schema, --schemaname _TEXT_`

Database schema to use. Overrides the value specified for the connection.

`--role, --rolename _TEXT_`

Role to use. Overrides the value specified for the connection.

`--warehouse _TEXT_`

Warehouse to use. Overrides the value specified for the connection.

`--temporary-connection, -x`

Uses a connection defined with command-line parameters, instead of one defined in config. Default: False.

`--mfa-passcode _TEXT_`

Token to use for multi-factor authentication (MFA).

`--enable-diag`

Whether to generate a connection diagnostic report. Default: False.

`--diag-log-path _TEXT_`

Path for the generated report. Defaults to system temporary directory. Default: <system\_temporary\_directory>.

`--diag-allowlist-path _TEXT_`

Path to a JSON file that contains allowlist parameters.

`--oauth-client-id _TEXT_`

Value of client id provided by the Identity Provider for Snowflake integration.

`--oauth-client-secret _TEXT_`

Value of the client secret provided by the Identity Provider for Snowflake integration.

`--oauth-authorization-url _TEXT_`

Identity Provider endpoint supplying the authorization code to the driver.

`--oauth-token-request-url _TEXT_`

Identity Provider endpoint supplying the access tokens to the driver.

`--oauth-redirect-uri _TEXT_`

URI to use for authorization code redirection.

`--oauth-scope _TEXT_`

Scope requested in the Identity Provider authorization request.

`--oauth-disable-pkce`

Disables Proof Key for Code Exchange (PKCE). Default: `False`.

`--oauth-enable-refresh-tokens`

Enables a silent re-authentication when the actual access token becomes outdated. Default: `False`.

`--oauth-enable-single-use-refresh-tokens`

Whether to opt-in to single-use refresh token semantics. Default: `False`.

`--client-store-temporary-credential`

Store the temporary credential.

`--format [TABLE|JSON|JSON_EXT|CSV]`

Specifies the output format. Default: TABLE.

`--verbose, -v`

Displays log entries for log levels `info` and higher. Default: False.

`--debug`

Displays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.

`--silent`

Turns off intermediate output to console. Default: False.

`--enhanced-exit-codes`

Differentiate exit error codes based on failure type. Default: False.

`--decimal-precision _INTEGER_`

Number of decimal places to display for decimal values. Uses Python’s default precision if not specified.

`--help`

Displays the help text for this command.

## Usage notes[¶](#usage-notes ""Link to this heading"")

The `streamlit get-url` command returns a url link to an existing Streamlit application. You can also use the `--open` option to automatically open the Streamlit in a new tab in your browser.

Note the following requirements:

*   The app must already be deployed.
    
*   You must use the same connection that was used to deploy the app.
    
*   If your app is running under different database and schema than specified in the connection, you must provide them in name as a fully-qualified name, such as `database.schema.name`.
    

## Examples[¶](#examples ""Link to this heading"")

*   Get a URL for an app using the database and schema specified in the default connection and opens it in your browser:
    
    ```
    snow streamlit get-url my_streamlit_app --open
    
    ```
    
    Copy
    
    ```
    https://snowflake.com/provider-deduced-from-connection/#/streamlit-apps/DB.PUBLIC.MY_STREAMLIT_APP
    
    ```
    
*   Get a URL for an app using a fully-qualified database and schema name:
    
    ```
    snow streamlit get-url database.schema.my_streamlit_app
    
    ```
    
    Copy
    
    ```
    https://snowflake.com/provider-deduced-from-connection/#/streamlit-apps/DATABASE.SCHEMA.MY_STREAMLIT_APP
    
    ```
    

On this page

1.  [Syntax](#syntax)
2.  [Arguments](#arguments)
3.  [Options](#options)
4.  [Usage notes](#usage-notes)
5.  [Examples](#examples)

Related content

1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../../index)
2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../overview)
3.  [Streamlit commands](/developer-guide/snowflake-cli/command-reference/streamlit-commands/overview)",NULL,fada8cff6a197c92d4f74a6fc3ed242d66b157c2a2910ffd1f0c04be9d0ccb9b,NULL
