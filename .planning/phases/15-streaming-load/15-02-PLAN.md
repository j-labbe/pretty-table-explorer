---
phase: 15-streaming-load
plan: 02
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - src/main.rs
  - src/render.rs
autonomous: false

must_haves:
  truths:
    - "User sees first rows on screen within 1 second of piping data"
    - "User sees loading indicator showing row count during streaming"
    - "User can navigate and scroll through partially-loaded data while loading continues"
    - "User can press Ctrl+C to cancel a long-running load without application crash"
    - "Loading indicator disappears when loading completes"
    - "Application behaves normally after streaming finishes (all features work)"
  artifacts:
    - path: "src/main.rs"
      provides: "Streaming integration in stdin path and event loop"
      contains: "StreamingParser"
    - path: "src/render.rs"
      provides: "Loading indicator rendering function"
      contains: "loading"
  key_links:
    - from: "src/main.rs"
      to: "src/streaming.rs"
      via: "Creates StreamingParser for stdin mode, polls with try_recv_batch in event loop"
      pattern: "StreamingParser::from_stdin|try_recv_batch"
    - from: "src/main.rs"
      to: "src/render.rs"
      via: "Passes loading state to render for indicator display"
      pattern: "loading|is_complete"
    - from: "src/main.rs"
      to: "workspace"
      via: "Extends tab data rows with newly received rows"
      pattern: "data\\.rows\\.extend|append"
---

<objective>
Integrate the StreamingParser into the main event loop so the UI displays data immediately while loading continues in the background, with a loading indicator and Ctrl+C cancellation.

Purpose: This connects the streaming infrastructure (Plan 01) to the actual application, delivering the user-visible behavior: immediate data display, loading progress, interactive navigation during load, and graceful cancellation.

Output: Modified src/main.rs (streaming integration), modified src/render.rs (loading indicator)
</objective>

<execution_context>
@/home/jlabbe/.claude/get-shit-done/workflows/execute-plan.md
@/home/jlabbe/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/15-streaming-load/15-RESEARCH.md
@.planning/phases/15-streaming-load/15-01-SUMMARY.md
@src/main.rs
@src/render.rs
@src/streaming.rs
@src/workspace.rs
@src/state.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate StreamingParser into main.rs event loop</name>
  <files>src/main.rs, src/render.rs</files>
  <action>
This task modifies the stdin loading path in main.rs to use StreamingParser instead of read_to_string + parse_psql, and adds a loading indicator to the UI.

**Step 1: Replace blocking stdin read with StreamingParser**

In main.rs, find the `else` branch of the stdin mode (around line 175-195) that currently does:
```rust
let mut input = String::new();
io::stdin().read_to_string(&mut input)?;
match parser::parse_psql(&input) { ... }
```

Replace with:
```rust
use pretty_table_explorer::streaming::StreamingParser;

match StreamingParser::from_stdin() {
    Ok(Some(loader)) => {
        // Create initial TableData from headers (rows will stream in)
        let initial_data = TableData {
            headers: loader.headers().to_vec(),
            rows: Vec::with_capacity(100_000),
        };
        // Return data + loader as Option for event loop to poll
        (initial_data, None, ViewMode::PipeData, Some(loader))
    }
    Ok(None) => {
        eprintln!("Error: Invalid or empty input. Expected psql table format.");
        eprintln!("Usage: psql -c 'SELECT ...' | pretty-table-explorer");
        std::process::exit(1);
    }
    Err(e) => {
        eprintln!("Error reading stdin: {}", e);
        std::process::exit(1);
    }
}
```

Update the destructuring to capture the optional loader:
```rust
let (table_data, mut db_client, initial_view_mode, mut streaming_loader) = ...
```

For the database mode branch, add `None` as the fourth tuple element (no streaming loader).

**Step 2: Add streaming poll to event loop**

BEFORE the `terminal.draw()` call (but after building tab_bar and before building render data), add a streaming poll section:

```rust
// Poll streaming loader for new rows
let mut is_loading = false;
let mut loaded_count: usize = 0;
if let Some(ref loader) = streaming_loader {
    is_loading = !loader.is_complete();
    loaded_count = loader.total_rows_parsed();

    // Non-blocking receive of new rows
    let new_rows = loader.try_recv_batch(5000);
    if !new_rows.is_empty() {
        // Append to the first tab's data (streaming always uses tab 0)
        if let Some(tab) = workspace.tabs.get_mut(0) {
            // Reserve capacity in larger chunks to minimize reallocations
            let new_total = tab.data.rows.len() + new_rows.len();
            if new_total > tab.data.rows.capacity() {
                let additional = (new_total - tab.data.rows.capacity()).max(50_000);
                tab.data.rows.reserve(additional);
            }
            tab.data.rows.extend(new_rows);
        }
    }

    // Clean up loader when complete and channel is drained
    if loader.is_complete() {
        // Check if channel still has data
        let remaining = loader.try_recv_batch(5000);
        if remaining.is_empty() {
            // All data consumed, drop the loader
            streaming_loader = None;
        } else {
            // Still draining, append these rows too
            if let Some(tab) = workspace.tabs.get_mut(0) {
                tab.data.rows.extend(remaining);
            }
        }
    }
}
```

**Step 3: Add loading indicator to render**

In `src/render.rs`, add a helper function:
```rust
/// Format loading status text for display in status area
pub fn format_loading_status(is_loading: bool, loaded_count: usize) -> Option<String> {
    if is_loading {
        Some(format!("Loading... {} rows", loaded_count))
    } else if loaded_count > 0 {
        None
    } else {
        None
    }
}
```

In main.rs, integrate the loading status into the status display. Before the `terminal.draw()` call, after the streaming poll:
```rust
// Show loading indicator as status message during streaming
if is_loading {
    status_message = Some(format!("Loading... {} rows", loaded_count));
    // Don't set status_message_time -- we don't want it to auto-clear during loading
    status_message_time = None;
}
```

This reuses the existing status_message infrastructure to display loading progress. When loading completes, the status_message will be naturally cleared on the next iteration.

Track loading completion with a flag:
- Add `let mut prev_loading = false;` before the loop
- At end of streaming poll: if `prev_loading && !is_loading && streaming_loader.is_none()` then show "Loaded X rows" with timer
- Set `prev_loading = is_loading;`

**Step 4: Handle Ctrl+C cancellation during streaming**

Implement "cancel but keep browsing" approach. In the KeyAction::Quit match arm:

```rust
KeyAction::Quit => {
    if let Some(loader) = streaming_loader.take() {
        // Cancel loading but keep app running with partial data
        loader.cancel();
        // Drop loader (triggers join via Drop impl)
        drop(loader);
        status_message = Some("Loading cancelled".to_string());
        status_message_time = Some(Instant::now());
        // Do NOT break -- let user browse partial data
    } else {
        break; // No streaming -- normal quit
    }
}
```

This way:
- First Ctrl+C during loading = cancel loading, keep browsing
- Second Ctrl+C (or 'q') = quit the app (since streaming_loader is now None)

**Step 5: Remove the `use std::io::Read;` import at the top of main.rs** since we no longer use `read_to_string`. Keep `use std::io::IsTerminal;` which is still needed (move it to the stdin block where it's used).

**Important implementation notes:**
- The `streaming_loader` variable must be `Option<StreamingParser>` and declared at the same scope level as other state variables
- Do NOT try to access tab.data.rows inside the draw closure for appending -- the borrow checker won't allow it. Append rows BEFORE the draw call.
- The column_config for the streaming tab is initialized from the header count at tab creation time, which is correct since headers are known immediately
- When new rows are appended, column widths may need recalculation. The existing render path already calls calculate_auto_widths each frame via build_pane_render_data, so this is handled automatically.
- Keep the batch size at 5000 rows per poll iteration (larger than the research's 1000 because we want to drain the channel quickly and avoid buffering too much in the channel)
  </action>
  <verify>
1. `cargo build` succeeds
2. `cargo clippy` has no warnings
3. `cargo test` passes all tests (unit + integration)
4. Manual test: `seq 1 100 | awk 'BEGIN{print " id | val"; print "----+-----"} {printf " %d  | test%d\n", $1, $1}' | cargo run --` displays data immediately
5. Manual test: Run the above with a larger dataset and verify loading indicator appears
  </verify>
  <done>
Application uses StreamingParser for stdin mode. Data appears immediately (headers visible before all rows loaded). Loading indicator shows row count during streaming. Rows continue appending in background. All existing features (navigation, search, export, column controls) work with partially-loaded data.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify streaming load with real data</name>
  <files>src/main.rs</files>
  <action>
Human verification checkpoint. All implementation is complete from Task 1. This task verifies the streaming load behavior with real data of various sizes.
  </action>
  <verify>
1. **Quick test (small data):**
   ```bash
   seq 1 50 | awk 'BEGIN{print " id | value"; print "----+-------"} {printf " %-2d | test%-2d\n", $1, $1}' | cargo run --
   ```
   Expected: Table appears instantly with 50 rows. No loading indicator (too fast).

2. **Streaming test (large data):**
   ```bash
   seq 1 500000 | awk 'BEGIN{print " id | value | extra"; print "----+-------+------"} {printf " %-6d | val%-6d | extra%d\n", $1, $1, $1}' | cargo run --
   ```
   Expected: Table appears within 1 second. Loading indicator shows "Loading... X rows" updating every ~250ms. Row count increases progressively. After loading completes, shows "Loaded 500000 rows" briefly then clears.

3. **Navigation during load:**
   While the 500k dataset is still loading, try arrow keys, j/k, /, l/h -- all should be responsive.

4. **Ctrl+C cancellation:**
   ```bash
   yes "1 | test" | head -n 10000000 | (echo " id | val"; echo "----+-----"; cat) | cargo run --
   ```
   Press Ctrl+C while loading. Expected: Loading stops, status shows "Loading cancelled", app remains usable. Press 'q' to quit normally.

5. **Normal quit:** Press 'q' after any test -- app should exit cleanly.
  </verify>
  <done>
All five verification scenarios pass: instant small data display, streaming large data with loading indicator, responsive navigation during load, Ctrl+C cancellation keeps app usable, clean exit.
  </done>
</task>

</tasks>

<verification>
1. `cargo build` succeeds with no errors
2. `cargo clippy` has no warnings
3. `cargo test` passes all existing + new tests
4. Manual verification: small data appears instantly
5. Manual verification: large data streams with loading indicator
6. Manual verification: navigation works during loading
7. Manual verification: Ctrl+C cancels loading, app stays usable
8. Manual verification: 'q' exits cleanly after streaming
</verification>

<success_criteria>
- LOAD-01: First rows visible within 1 second of piping data (even for 1.8M+ row datasets)
- LOAD-02: Loading indicator shows "Loading... X rows" during streaming, updates every ~250ms
- LOAD-03: Navigation, search, column controls all work while loading continues
- LOAD-04: Ctrl+C cancels loading without crash, partial data remains browsable
- All existing features (export, tabs, split view, search) work correctly after streaming completes
- No regressions in database connection mode (--connect flag still works identically)
</success_criteria>

<output>
After completion, create `.planning/phases/15-streaming-load/15-02-SUMMARY.md`
</output>
