[
  {
    "full_command": "NULL",
    "title": "Snowflake CLI¶",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/index",
    "parent_command": "NULL",
    "raw_content": "# Snowflake CLI[¶](#sf-cli \"Link to this heading\")\n\n## What is Snowflake CLI?[¶](#what-is-sf-cli \"Link to this heading\")\n\nSnowflake CLI is an open-source command-line tool explicitly designed for developer-centric workloads in addition to SQL operations. It is a flexible and extensible tool that can accommodate modern development practices and technologies.\n\nWith Snowflake CLI, developers can create, manage, update, and view apps running on Snowflake across workloads such as Streamlit in Snowflake, the Snowflake Native App Framework, Snowpark Container Services, and Snowpark. It supports a range of Snowflake features, including user-defined functions, stored procedures, Streamlit in Snowflake, and SQL execution.\n\n## What’s in this guide?[¶](#what-s-in-this-guide \"Link to this heading\")\n\nThis guide introduces and explains how to install and use Snowflake CLI. It includes the following sections:\n\n*   [Introducing Snowflake CLI](introduction/introduction)\n    \n*   [Installing Snowflake CLI](installation/installation)\n    \n*   [Configuring Snowflake CLI and connecting to Snowflake](connecting/connect)\n    \n*   [Bootstrapping a project from a template](bootstrap-project/bootstrap)\n    \n*   [About project definition files](project-definitions/about)\n    \n*   [Managing Snowflake objects](objects/manage-objects)\n    \n*   [Managing Snowflake stages](stages/manage-stages)\n    \n*   [Managing Snowpark Container Services in Snowflake CLI](services/overview)\n    \n*   [Using Snowpark in Snowflake CLI](snowpark/overview)\n    \n*   [Using Snowflake Notebooks](notebooks/use-notebooks)\n    \n*   [Managing Streamlit apps with Snowflake CLI](streamlit-apps/overview)\n    \n*   [Using Snowflake Native App in Snowflake CLI](native-apps/overview)\n    \n*   [Executing SQL statements](sql/execute-sql)\n    \n*   [Managing Git repositories](git/overview)\n    \n*   [Snowflake CLI command reference](command-reference/overview)\n    \n\nFor more information about supported Snowflake products, see the following:\n\n*   [Snowflake Cortex](../../user-guide/snowflake-cortex/aisql) documentation\n    \n*   [Native App Framework](../native-apps/native-apps-about) documentation\n    \n*   [Snowflake notebooks](../../user-guide/ui-snowsight/notebooks) documentation\n    \n*   [Snowpark Container Services](../snowpark-container-services/overview) documentation\n    \n*   [Snowpark](../snowpark/index) documentation\n    \n*   [SQL](../../reference) documentation\n    \n*   [Git](../git/git-overview) documentation\n    \n*   [Streamlit](../streamlit/about-streamlit) documentation\n    \n\nTo see what changed in this release, see the [Snowflake CLI release notes](../../release-notes/clients-drivers/snowflake-cli).\n\nSnowflake CLI is an open-source project available in the [Snowflake CLI Git repository](https://github.com/snowflakedb/snowflake-cli).\n\nOn this page\n\n1.  [What is Snowflake CLI?](#what-is-sf-cli)\n2.  [What’s in this guide?](#what-s-in-this-guide)\n\nRelated content\n\n1.  [Introducing Snowflake CLI](/developer-guide/snowflake-cli/introduction/introduction)\n2.  [Git in Snowflake](/developer-guide/snowflake-cli/../git/git-overview)\n3.  [Native App Framework](/developer-guide/snowflake-cli/../native-apps/native-apps-about)\n4.  [Snowflake Notebooks](/developer-guide/snowflake-cli/../../user-guide/ui-snowsight/notebooks)\n5.  [Snowpark Container Services](/developer-guide/snowflake-cli/../snowpark-container-services/overview)\n6.  [Snowpark](/developer-guide/snowflake-cli/../snowpark/index)\n7.  [SQL](/developer-guide/snowflake-cli/../../reference)\n8.  [Streamlit](/developer-guide/snowflake-cli/../streamlit/about-streamlit)\n9.  [Snowflake CLI release notes](/developer-guide/snowflake-cli/../../release-notes/clients-drivers/snowflake-cli)\n10.  [Snowflake CLI Git repository](https://github.com/snowflakedb/snowflake-cli)",
    "last_scraped": "NULL",
    "content_hash": "f739a843f76e222c9380af7bf1db5f386e31c683859c3753c01aebd88516a114",
    "category": "NULL",
    "id": "NULL",
    "metadata": "NULL"
  },
  {
    "raw_content": "# Introducing Snowflake CLI[¶](#introducing-sf-cli \"Link to this heading\")\n\nSnowflake CLI’s open-source nature means that developers can leverage the community’s collective knowledge and contributions to improve and enhance the tool. By using Snowflake CLI, developers can expect a streamlined, efficient experience that empowers them to work with Snowflake in new and innovative ways. Snowflake CLI is a powerful and flexible tool that helps developers streamline their workflow and optimize their Snowflake experience.\n\nAs a command-line interface (CLI), Snowflake CLI provides several benefits for developers, such as:\n\n*   Speed and efficiency\n    \n    A CLI allows developers to perform tasks quickly and efficiently by executing commands from the terminal without needing a graphical user interface. This can save developers significant time and effort, especially when performing repetitive or complex tasks.\n    \n*   Automation\n    \n    A CLI can automate tasks and workflows, such as building, testing, CI/CD, and deploying applications. CLI can help developers streamline their development process and reduce the risk of errors or inconsistencies.\n    \n*   Portability\n    \n    A CLI is often platform-independent and can be used across different operating systems and environments. Developers can work more easily on multiple projects or collaborate with others who use different systems.\n    \n*   Version control\n    \n    A CLI can be integrated with version control systems like Git to manage changes and track code history, which can help developers collaborate more effectively, resolve conflicts, and document changes appropriately.\n    \n*   Customization\n    \n    A CLI can be customized and extended by using modules and scripts, so developers can tailor it to their needs and preferences. Automating common tasks and workflows can help developers work more efficiently and effectively.\n    \n*   Accessibility\n    \n    CLI can be accessed remotely, so developers can work on servers and other remote systems without a graphical interface.\n    \n\n## How does Snowflake CLI differ from SnowSQL?[¶](#how-does-sf-cli-differ-from-snowsql \"Link to this heading\")\n\nSnowSQL is the command-line client for connecting to Snowflake to execute SQL queries and perform all DDL and DML operations, including loading data into and unloading data out of database tables.\n\nThe Snowflake CLI command-line client, in contrast, focuses primarily on managing workloads and applications that connect to Snowflake. Snowflake CLI lets you locally run and debug Snowflake apps, with the following benefits:\n\n*   You can search, create, and upload Python packages that might not be supported in Anaconda yet.\n    \n*   Snowflake CLI supports Snowpark Python user-defined functions and stored procedures, warehouses, and Streamlit apps.\n    \n*   You can define packages by using `requirements.txt`, with dependencies automatically added through integration with Anaconda at deployment time.\n    \n*   Snowflake CLI can include packages that are identified in `requirements.txt`—but aren’t yet in Anaconda—in the application package deployed to Snowflake. (This feature only works with packages that don’t rely on native libraries).\n    \n*   When you update existing applications, code and dependencies are automatically altered as needed.\n    \n*   Deployment artifacts are automatically managed and uploaded to Snowflake stages.\n    \n\nSnowflake plans to continue enhancing Snowflake CLI to provide developers a robust tool for leveraging all of the SnowSQL capabilities in a new open source CLI.\n\nOn this page\n\n1.  [How does Snowflake CLI differ from SnowSQL?](#how-does-sf-cli-differ-from-snowsql)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/introduction/../index)",
    "title": "Introducing Snowflake CLI¶",
    "full_command": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/introduction/introduction",
    "id": "NULL",
    "category": "NULL",
    "command_group": "NULL",
    "parent_command": "NULL",
    "content_hash": "564c14d7c971c06cb75f9c38dd6f77179e2a0d0f8e2ebbb8db8f2ac774c512c3",
    "metadata": "NULL",
    "last_scraped": "NULL"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/installation/installation",
    "title": "Installing Snowflake CLI¶",
    "id": "NULL",
    "raw_content": "# Installing Snowflake CLI[¶](#installing-sf-cli \"Link to this heading\")\n\nThis topic explains how to install Snowflake CLI on [supported platforms](../../../release-notes/requirements.html#label-client-operating-system-support). Note that Snowflake CLI is not currently available for AIX systems.\n\nSnowflake recommends using binary installation methods, such as package managers, to install Snowflake CLI on your system. You can download the binary installers from the official [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).\n\n## Requirements[¶](#requirements \"Link to this heading\")\n\n*   Before using Snowflake CLI, you must have a valid Snowflake account.\n    \n*   To run Streamlit in Snowflake using Snowflake CLI, you must have a Snowflake account with permission to use Streamlit.\n    \n*   To run Snowpark Container Services in Snowflake using Snowflake CLI, you must have a Snowflake account with privileges to use Snowpark Container Services.\n    \n\nTip\n\nIf your Snowflake account requires MFA (multi-factor authentication), Snowflake CLI requires approval for every command. You can use MFA caching to require authentication only once every four hours. For more information, see [Use multi-factor authentication (MFA)](../connecting/configure-connections.html#label-snowcli-mfa).\n\n## Install Snowflake CLI using package managers[¶](#install-sf-cli-using-package-managers \"Link to this heading\")\n\nTo install Snowflake CLI using platform-specific package managers, use one of the following procedures:\n\n*   [Install using Linux package managers (rpm, deb)](#label-snowcli-install-linux-package-managers).\n    \n*   [Install using MacOS installer](#label-snowcli-install-macos-installer).\n    \n*   [Install using Windows installer](#label-snowcli-install-windows-installer).\n    \n*   [Install using Homebrew](#label-snowcli-install-homebrew).\n    \n\n### Install with Linux package managers[¶](#install-with-linux-package-managers \"Link to this heading\")\n\nIf you use a Linux operating system, you can install Snowflake CLI with package managers that support the following:\n\n*   `deb` packages,\n    \n*   `rpm` packages.\n    \n\nTo install Snowflake CLI using the `deb` package manager:\n\n1.  Download the Snowflake CLI `deb` from the [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).\n    \n2.  Install the package by running the following command:\n    \n    ```\n    sudo dpkg -i snowflake-cli-<version>.deb\n    \n    ```\n    \n    Copy\n    \n\nTo install Snowflake CLI using the `rpm` package manager:\n\n1.  Download the Snowflake CLI `rpm` package from the [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).\n    \n2.  Install the package by running the following command:\n    \n    ```\n    sudo rpm -i snowflake-cli-<version>.rpm\n    \n    ```\n    \n    Copy\n    \n3.  To verify that the software was installed successfully, run the following command:\n    \n    ```\n    snow --help\n    \n    ```\n    \n    Copy\n    \n    ```\n    Usage: snow [OPTIONS] COMMAND [ARGS]...\n    \n    Snowflake CLI tool for developers.\n    \n    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ --version                           Shows version of the Snowflake CLI                                                                   │\n    │ --info                              Shows information about the Snowflake CLI                                                            │\n    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │\n    │ --install-completion                Install completion for the current shell.                                                            │\n    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │\n    │ --help                -h            Show this message and exit.                                                                          │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ app          Manages a Snowflake Native App                                                                                              │\n    │ connection   Manages connections to Snowflake.                                                                                           │\n    │ cortex       Provides access to Snowflake Cortex.                                                                                        │\n    │ git          Manages git repositories in Snowflake.                                                                                      │\n    │ notebook     Manages notebooks in Snowflake.                                                                                             │\n    │ object       Manages Snowflake objects like warehouses and stages                                                                        │\n    │ snowpark     Manages procedures and functions.                                                                                           │\n    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │\n    │ sql          Executes Snowflake query.                                                                                                   │\n    │ stage        Manages stages.                                                                                                             │\n    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n4.  [Configure the Snowflake connection](../connecting/connect).\n    \n\n### Install with the MacOS package installer[¶](#install-with-the-macos-package-installer \"Link to this heading\")\n\nTo install Snowflake CLI on MacOS, do the following:\n\n1.  Download the Snowflake CLI installer from the [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).\n    \n2.  Run the installer and follow the instructions to install Snowflake CLI.\n    \n3.  To verify that the software was installed successfully, open new terminal and run the following command:\n    \n    ```\n    snow --help\n    \n    ```\n    \n    Copy\n    \n    ```\n    Usage: snow [OPTIONS] COMMAND [ARGS]...\n    \n    Snowflake CLI tool for developers.\n    \n    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ --version                           Shows version of the Snowflake CLI                                                                   │\n    │ --info                              Shows information about the Snowflake CLI                                                            │\n    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │\n    │ --install-completion                Install completion for the current shell.                                                            │\n    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │\n    │ --help                -h            Show this message and exit.                                                                          │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ app          Manages a Snowflake Native App                                                                                              │\n    │ connection   Manages connections to Snowflake.                                                                                           │\n    │ cortex       Provides access to Snowflake Cortex.                                                                                        │\n    │ git          Manages git repositories in Snowflake.                                                                                      │\n    │ notebook     Manages notebooks in Snowflake.                                                                                             │\n    │ object       Manages Snowflake objects like warehouses and stages                                                                        │\n    │ snowpark     Manages procedures and functions.                                                                                           │\n    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │\n    │ sql          Executes Snowflake query.                                                                                                   │\n    │ stage        Manages stages.                                                                                                             │\n    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n4.  [Configure the Snowflake connection](../connecting/connect).\n    \n\n### Install with the Windows installer[¶](#install-with-the-windows-installer \"Link to this heading\")\n\nTo install Snowflake CLI on Windows, do the following:\n\n1.  Download the Snowflake CLI installer from the [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html).\n    \n2.  Run the installer and follow the instructions to install Snowflake CLI.\n    \n3.  To verify that the software was installed successfully, open new terminal and run the following command:\n    \n    ```\n    snow --help\n    \n    ```\n    \n    Copy\n    \n    ```\n    Usage: snow [OPTIONS] COMMAND [ARGS]...\n    \n    Snowflake CLI tool for developers.\n    \n    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ --version                           Shows version of the Snowflake CLI                                                                   │\n    │ --info                              Shows information about the Snowflake CLI                                                            │\n    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │\n    │ --install-completion                Install completion for the current shell.                                                            │\n    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │\n    │ --help                -h            Show this message and exit.                                                                          │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ app          Manages a Snowflake Native App                                                                                              │\n    │ connection   Manages connections to Snowflake.                                                                                           │\n    │ cortex       Provides access to Snowflake Cortex.                                                                                        │\n    │ git          Manages git repositories in Snowflake.                                                                                      │\n    │ notebook     Manages notebooks in Snowflake.                                                                                             │\n    │ object       Manages Snowflake objects like warehouses and stages                                                                        │\n    │ snowpark     Manages procedures and functions.                                                                                           │\n    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │\n    │ sql          Executes Snowflake query.                                                                                                   │\n    │ stage        Manages stages.                                                                                                             │\n    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n4.  [Configure the Snowflake connection](../connecting/connect).\n    \n\n### Install with Homebrew[¶](#install-with-homebrew \"Link to this heading\")\n\nIf you use a Mac operating system, you can install Snowflake CLI with [Homebrew](https://brew.sh/).\n\n1.  Install [Homebrew](https://brew.sh/), if necessary.\n    \n2.  To give Homebrew access to the Snowflake CLI repository, run the following command:\n    \n    ```\n    brew tap snowflakedb/snowflake-cli\n    brew update\n    \n    ```\n    \n    Copy\n    \n3.  To install Snowflake CLI, run the following command:\n    \n    ```\n    brew install snowflake-cli\n    \n    ```\n    \n    Copy\n    \n4.  To verify that the software was installed successfully, run the following command:\n    \n    ```\n    snow --help\n    \n    ```\n    \n    Copy\n    \n    ```\n    Usage: snow [OPTIONS] COMMAND [ARGS]...\n    \n    Snowflake CLI tool for developers.\n    \n    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ --version                           Shows version of the Snowflake CLI                                                                   │\n    │ --info                              Shows information about the Snowflake CLI                                                            │\n    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │\n    │ --install-completion                Install completion for the current shell.                                                            │\n    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │\n    │ --help                -h            Show this message and exit.                                                                          │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ app          Manages a Snowflake Native App                                                                                              │\n    │ connection   Manages connections to Snowflake.                                                                                           │\n    │ cortex       Provides access to Snowflake Cortex.                                                                                        │\n    │ git          Manages git repositories in Snowflake.                                                                                      │\n    │ notebook     Manages notebooks in Snowflake.                                                                                             │\n    │ object       Manages Snowflake objects like warehouses and stages                                                                        │\n    │ snowpark     Manages procedures and functions.                                                                                           │\n    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │\n    │ sql          Executes Snowflake query.                                                                                                   │\n    │ stage        Manages stages.                                                                                                             │\n    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n5.  [Configure the Snowflake connection](../connecting/connect).\n    \n\n## Advanced local installations[¶](#advanced-local-installations \"Link to this heading\")\n\nYou can also install Snowflake CLI as a Python package using either of the following:\n\n*   [pip (PyPi)](#label-snowcli-install-pip)\n    \n*   [pipx](#label-snowcli-install-pipx)\n    \n\nSnowflake recommends installing as a Python package only for development purposes or when installing binaries isn’t possible in your environment.\n\n### Install with pip (PyPi)[¶](#install-with-pip-pypi \"Link to this heading\")\n\nNote\n\nThis method modifies the Python environment where you install Snowflake CLI. Consider using [pipx](#label-snowcli-install-pipx) instead to avoid dependency conflicts.\n\nTo install Snowflake CLI using `pip`, you must have [Python](https://python.org) version 3.10 or later installed.\n\n1.  Run the following shell command:\n    \n    ```\n    pip install snowflake-cli\n    \n    ```\n    \n    Copy\n    \n2.  To verify that the software was installed successfully, run the following command:\n    \n    ```\n    snow --help\n    \n    ```\n    \n    Copy\n    \n    ```\n    Usage: snow [OPTIONS] COMMAND [ARGS]...\n    \n    Snowflake CLI tool for developers.\n    \n    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ --version                           Shows version of the Snowflake CLI                                                                   │\n    │ --info                              Shows information about the Snowflake CLI                                                            │\n    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │\n    │ --install-completion                Install completion for the current shell.                                                            │\n    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │\n    │ --help                -h            Show this message and exit.                                                                          │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ app          Manages a Snowflake Native App                                                                                              │\n    │ connection   Manages connections to Snowflake.                                                                                           │\n    │ cortex       Provides access to Snowflake Cortex.                                                                                        │\n    │ git          Manages git repositories in Snowflake.                                                                                      │\n    │ notebook     Manages notebooks in Snowflake.                                                                                             │\n    │ object       Manages Snowflake objects like warehouses and stages                                                                        │\n    │ snowpark     Manages procedures and functions.                                                                                           │\n    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │\n    │ sql          Executes Snowflake query.                                                                                                   │\n    │ stage        Manages stages.                                                                                                             │\n    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n3.  [Configure the Snowflake connection](../connecting/connect).\n    \n\n### Install with pipx[¶](#install-with-pipx \"Link to this heading\")\n\n[pipx](https://github.com/pypa/pipx) provides an alternative to `pip` that installs and executes Python packages into isolated virtual environments. Installing Snowflake CLI with `pipx` does not, therefore, modify your current Python environment.\n\nTo install Snowflake CLI using `pipx`, you must have [pipx](https://github.com/pypa/pipx) installed.\n\n1.  Run the following shell command:\n    \n    ```\n    pipx install snowflake-cli\n    \n    ```\n    \n    Copy\n    \n2.  To verify that the software was installed successfully, run the following command:\n    \n    ```\n    snow --help\n    \n    ```\n    \n    Copy\n    \n    ```\n    Usage: snow [OPTIONS] COMMAND [ARGS]...\n    \n    Snowflake CLI tool for developers.\n    \n    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ --version                           Shows version of the Snowflake CLI                                                                   │\n    │ --info                              Shows information about the Snowflake CLI                                                            │\n    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │\n    │ --install-completion                Install completion for the current shell.                                                            │\n    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │\n    │ --help                -h            Show this message and exit.                                                                          │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ app          Manages a Snowflake Native App                                                                                              │\n    │ connection   Manages connections to Snowflake.                                                                                           │\n    │ cortex       Provides access to Snowflake Cortex.                                                                                        │\n    │ git          Manages git repositories in Snowflake.                                                                                      │\n    │ notebook     Manages notebooks in Snowflake.                                                                                             │\n    │ object       Manages Snowflake objects like warehouses and stages                                                                        │\n    │ snowpark     Manages procedures and functions.                                                                                           │\n    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │\n    │ sql          Executes Snowflake query.                                                                                                   │\n    │ stage        Manages stages.                                                                                                             │\n    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n3.  [Configure the Snowflake connection](../connecting/connect).\n    \n\n## Installing Snowflake CLI in FIPS-compliant environments[¶](#installing-sf-cli-in-fips-compliant-environments \"Link to this heading\")\n\nYou can use a Docker image to install Snowflake CLI in an environment that is compliant with FIPS (Federal Information Processing Standards).\n\n### Prerequisites[¶](#prerequisites \"Link to this heading\")\n\nBefore installing Snowflake CLI in a FIPS-compliant environment, ensure that you meet the following prerequisites:\n\n*   **FIPS-compliant Python**: Python must be preinstalled, built, and configured for FIPS compliance. This typically means Python is linked against a FIPS-enabled OpenSSL library.\n    \n*   **FIPS-enabled OpenSSL**: The system’s OpenSSL libraries must be FIPS-compliant and available to Python at runtime.\n    \n*   **Build tools**: Standard build tools (such as a C compiler and Python development headers) must be available, as dependencies will be built from source.\n    \n*   **Network Access**: The environment must allow access to PyPI or your internal package index for downloading source distributions.\n    \n\n### Install Snowflake CLI in a FIPS-compliant Dockerfile[¶](#install-sf-cli-in-a-fips-compliant-dockerfile \"Link to this heading\")\n\nTo install Snowflake CLI in a FIPS-compliant environment, follow these steps:\n\n1.  Create a Python virtual environment in the container, as shown in the following example:\n    \n    ```\n    python -m venv .venv\n    \n    ```\n    \n    Copy\n    \n2.  Activate the Python virtual environment in the container, as shown in the following example:\n    \n    ```\n    source ~/.venv/bin/activate\n    \n    ```\n    \n    Copy\n    \n3.  Upgrade `pip` and `setuptools` in the container, as shown in the following example:\n    \n    ```\n    pip install -U setuptools pip\n    \n    ```\n    \n    Copy\n    \n4.  Install the cryptography, Python connector, and Snowflake CLI dependencies from source in the container, as shown in the following example. Note that all dependencies must be installed from source to ensure they are built against your FIPS-compliant libraries.\n    \n    ```\n    pip install cryptography==44.0.3 --no-binary cryptography\n    pip install -U snowflake-connector-python[secure-local-storage] --no-binary snowflake-connector-python[secure-local-storage]\n    pip install -U snowflake-cli --no-binary snowflake-cli\n    \n    ```\n    \n    Copy\n    \n    The `--no-binary` option forces installation from source, ensuring that the builds use FIPS-ready libraries.\n    \n\n### Validate the Docker image[¶](#validate-the-docker-image \"Link to this heading\")\n\nTo confirm that your Python environment uses a FIPS-enabled OpenSSL library, enter the following command in the running container:\n\n```\npython -c \"import ssl; print(ssl.OPENSSL_VERSION)\"\n\n```\n\nCopy\n\nAfter installing Snowflake CLI and validating the Docker image, you can use Snowflake CLI in the container.\n\n```\nsnow <your-command>\n\n```\n\nCopy\n\nwhere <_your-command_\\> is any valid Snowflake CLI command, such as `snow --help`.\n\n## Install command auto-completion functionality[¶](#install-command-auto-completion-functionality \"Link to this heading\")\n\nSnowflake CLI supports standard shell tab completion functionality.\n\nTo install auto-completion into Snowflake CLI, perform the following steps:\n\n1.  Run the `snow --install-completion` command:\n    \n    ```\n    snow --install-completion\n    \n    ```\n    \n    Copy\n    \n    ```\n    zsh completion installed in <user home>/.zfunc/_snow\n    Completion will take effect once you restart the terminal\n    \n    ```\n    \n2.  Run the `snow --show-completion` command to generate the commands you need to add to your shell profile (`.bashrc`, `.bash_profile`, `.zshrc`, and others):\n    \n    ```\n    snow --show-completion\n    \n    ```\n    \n    Copy\n    \n    ```\n    _snow_completion() {\n       local IFS=$'\n    '\n       COMPREPLY=( $( env COMP_WORDS=\"${COMP_WORDS[*]}\" \\\n                      COMP_CWORD=$COMP_CWORD \\\n                      _SNOW_COMPLETE=complete_bash $1 ) )\n       return 0\n    }\n    \n    complete -o default -F _snow_completion snow\n    \n    ```\n    \n3.  Select and copy the command output text.\n    \n4.  Open your shell profile file, `.bashrc` in this example, and paste the copied text:\n    \n    ```\n    export SHELL=/bin/bash\n    \n    ...\n    \n    _snow_completion() {\n       local IFS=$'\n    '\n       COMPREPLY=( $( env COMP_WORDS=\"${COMP_WORDS[*]}\" \\\n                      COMP_CWORD=$COMP_CWORD \\\n                      _SNOW_COMPLETE=complete_bash $1 ) )\n       return 0\n    }\n    \n    complete -o default -F _snow_completion snow\n    \n    ```\n    \n5.  Save the file.\n    \n6.  To activate the tab-completion functionality, restart your shell or `source` your shell profile file, such as:\n    \n    ```\n    source ~/.bashrc\n    \n    ```\n    \n    Copy\n    \n7.  To test the feature, enter a snow command followed by a `TAB`, as shown:\n    \n    ```\n    snow app [TAB]\n    \n    ```\n    \n    Copy\n    \n    ```\n    deploy    init      open      run       teardown  version\n    \n    ```\n    \n\nOn this page\n\n1.  [Requirements](#requirements)\n2.  [Install Snowflake CLI using package managers](#install-sf-cli-using-package-managers)\n3.  [Install with Linux package managers](#install-with-linux-package-managers)\n4.  [Install with the MacOS package installer](#install-with-the-macos-package-installer)\n5.  [Install with the Windows installer](#install-with-the-windows-installer)\n6.  [Install with Homebrew](#install-with-homebrew)\n7.  [Advanced local installations](#advanced-local-installations)\n8.  [Install with pip (PyPi)](#install-with-pip-pypi)\n9.  [Install with pipx](#install-with-pipx)\n10.  [Installing Snowflake CLI in FIPS-compliant environments](#installing-sf-cli-in-fips-compliant-environments)\n11.  [Prerequisites](#prerequisites)\n12.  [Install Snowflake CLI in a FIPS-compliant Dockerfile](#install-sf-cli-in-a-fips-compliant-dockerfile)\n13.  [Validate the Docker image](#validate-the-docker-image)\n14.  [Install command auto-completion functionality](#install-command-auto-completion-functionality)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/installation/../index)\n2.  [Snowflake CLI repository](https://sfc-repo.snowflakecomputing.com/snowflake-cli/index.html)",
    "category": "NULL",
    "parent_command": "NULL",
    "last_scraped": "NULL",
    "content_hash": "e0249aa57ae417f58b757a27170f25b2214ed4e5b87e5c9bf659411a39ea2e33",
    "command_group": "NULL",
    "full_command": "NULL",
    "metadata": "NULL"
  },
  {
    "metadata": "NULL",
    "command_group": "NULL",
    "title": "Configuring Snowflake CLI and connecting to Snowflake¶",
    "full_command": "NULL",
    "content_hash": "022416edf88df83a916e1df5d187e4b2ebf18e0d5f7f61a6c039ceeab7e9f687",
    "raw_content": "# Configuring Snowflake CLI and connecting to Snowflake[¶](#configuring-sf-cli-and-connecting-to-snowflake \"Link to this heading\")\n\nThis section explains how to configure, test, and manage your Snowflake connections.\n\n*   [Configuring Snowflake CLI](configure-cli)\n    \n*   [Managing Snowflake connections](configure-connections)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/connecting/../index)",
    "parent_command": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/connecting/connect",
    "id": "NULL",
    "category": "NULL",
    "last_scraped": "NULL"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/connecting/configure-cli",
    "title": "Configuring Snowflake CLI¶",
    "command_group": "NULL",
    "full_command": "NULL",
    "raw_content": "# Configuring Snowflake CLI[¶](#configuring-sf-cli \"Link to this heading\")\n\nSnowflake CLI uses a global configuration file called `config.toml` to configure connections and logs for Snowflake CLI. If the file does not exist, running any `snow` command for the first time automatically creates an empty `config.toml` file that you can then populate with the desired connections. For more information about `toml` file formats, see [TOML (Tom’s Obvious Minimal Language)](https://toml.io/en/). Snowflake Python libraries currently support TOML version 1.0.0.\n\nThe `config.toml` supports the following sections:\n\n*   `[connections]` for defining and managing connections\n    \n*   `[logs]` for configuring which types of messages are saved to log files\n    \n\nA Snowflake CLI configuration file has the following structure:\n\n```\ndefault_connection_name = \"myconnection\"\n\n[connections]\n[connections.myconnection]\naccount = \"myorganization-myaccount\"\nuser = \"jdoe\"\n...\n\n[connections.testingconnection]\naccount = \"myorganization-myaccount\"\nuser = \"jdoe\"\n...\n\n[cli.logs]\nsave_logs = true\nlevel = \"info\"\npath = \"/home/<username>/.snowflake/logs\"\n\n```\n\nCopy\n\nYou can generate the basic settings for the TOML configuration file in Snowsight. For information, see [Configuring a client, driver, library, or third-party application to connect to Snowflake](../../../user-guide/gen-conn-config).\n\nNote\n\nIf a `connection.toml` file exists, Snowflake CLI uses the connections defined in it instead of those defined in the `config.toml` file.\n\n## Location of the `.toml` configuration file[¶](#location-of-the-toml-configuration-file \"Link to this heading\")\n\nBy default Snowflake CLI looks for the `config.toml` file in the `~/.snowflake` directory or, in case this directory does not exist, in a system-specific location, as listed below. You can also specify which configuration file should be used using `--config-file` flag or `SNOWFLAKE_HOME` environment variable.\n\n*   If you specify the `--config-file` option (such as, `snow --config-file ./my-config-file-path`), Snowflake CLI uses the specified configuration file.\n    \n*   If the `SNOWFLAKE_HOME` environment variable is set, Snowflake CLI uses the location specified by this variable.\n    \n*   If a `~/.snowflake` directory exists on your machine, Snowflake CLI uses the `~/.snowflake/config.toml` file.\n    \n*   Otherwise, Snowflake CLI uses the `config.toml` file in the one of the following locations, based on your operating system:\n    \n    > *   Linux: `~/.config/snowflake/config.toml`, but you can update it with XDG vars\n    >     \n    > *   Windows: `%USERPROFILE%\\AppData\\Local\\snowflake\\config.toml`\n    >     \n    > *   Mac: `~/Library/Application Support/snowflake/config.toml`\n    >     \n    \n\nNote\n\nFor MacOS and Linux systems, Snowflake CLI requires the `config.toml` file to limit its file permissions to read and write for the file owner only. To set the file required file permissions execute the following commands:\n\n```\nchown $USER config.toml\nchmod 0600 config.toml\n\n```\n\nCopy\n\n### Choose a different configuration file[¶](#choose-a-different-configuration-file \"Link to this heading\")\n\nIn some situations, such as a continuous integration and continuous deployment (CI/CD) environments, you might prefer to create dedicated configuration files for testing and deployment pipelines instead of defining all of the possible configurations in a single Snowflake default configuration file.\n\nTo use a different configuration file that your default file, you can use the `--config-file` option for the `snow` command, as shown:\n\n```\nsnow --config-file=\"my_config.toml\" connection test\n\n```\n\nCopy\n\n### Support for system environment variables[¶](#support-for-system-environment-variables \"Link to this heading\")\n\nSnowflake CLI supports using system environment variables to override parameter values defined in your `config.toml` file, using the following format:\n\n```\nSNOWFLAKE_<config-section>_<variable>=<value>\n\n```\n\nCopy\n\nwhere:\n\n*   `<config_section>` is the name of a section in the configuration file with periods (`.`) replaced with underscores (`_`), such as `CLI_LOGS`.\n    \n*   variable is the name of a variable defined in that section, such as `path`.\n    \n\nSome examples include:\n\n*   Override the `path` parameter in the `[cli.logs]` section in the `config.toml` file:\n    \n    ```\n    export SNOWFLAKE_CLI_LOGS_PATH=\"/Users/jondoe/snowcli_logs\"\n    \n    ```\n    \n    Copy\n    \n*   Set the password for the `myconnection` connection:\n    \n    ```\n    export SNOWFLAKE_CONNECTIONS_MYCONNECTION_PASSWORD=\"*******\"\n    \n    ```\n    \n    Copy\n    \n*   Set the default connection name:\n    \n    ```\n    export SNOWFLAKE_DEFAULT_CONNECTION_NAME=\"myconnection\"\n    \n    ```\n    \n    Copy\n    \n\n## Add an authentication policy that limits access to Snowflake CLI only[¶](#add-an-authentication-policy-that-limits-access-to-sf-cli-only \"Link to this heading\")\n\nUsers can create an [authentication policy](../../../user-guide/authentication-policies) that limits access permission to drivers, as well as Snowflake CLI. If you want to allow access to Snowflake CLI only (and exclude the drivers), you can do the following:\n\n*   Create a new authentication policy that limits access strictly to Snowflake CLI.\n    \n*   Enable the policy in the `config.toml` file.\n    \n\n### Create an authentication policy limited to Snowflake CLI[¶](#create-an-authentication-policy-limited-to-sf-cli \"Link to this heading\")\n\nTo create a new authentication policy for only Snowflake CLI, follow these steps:\n\n1.  Execute the [CREATE AUTHENTICATION POLICY](../../../sql-reference/sql/create-authentication-policy) SQL command, setting the CLIENT\\_TYPES parameter to include `'SNOWFLAKE_CLI'`.\n    \n    ```\n    CREATE AUTHENTICATION POLICY snowflake_cli_only\n      CLIENT_TYPES = ('SNOWFLAKE_CLI');\n    \n    ```\n    \n    Copy\n    \n2.  Add the policy to the user, as shown:\n    \n    ```\n    ALTER USER user1\n      SET AUTHENTICATION POLICY snowflake_cli_only;\n    \n    ```\n    \n    Copy\n    \n\n### Enable the policy in the Snowflake CLI configuration[¶](#enable-the-policy-in-the-sf-cli-configuration \"Link to this heading\")\n\nThe `enable_separate_authentication_policy_id` configuration parameter lets you enable access to Snowflake CLI separately from the drivers. When this access is enabled, specified users can access Snowflake CLI but not the other Snowflake drivers.\n\nWarning\n\nIf you already have an authentication policy that allows access only to drivers and don’t have one that allows access to Snowflake CLI only, enabling the `enable_separate_authentication_policy_id` parameter will cause the users to lose access to Snowflake CLI if you don’t create the new policy first. Make sure to add SNOWFLAKE\\_CLI to your authentication policy before enabling the configuration parameter.\n\nTo enable the SNOWFLAKE\\_CLI policy, add the `enable_separate_authentication_policy_id` parameter to the `[cli.features]` section in the `config.toml` file, as shown:\n\n```\n[cli.features]\nenable_separate_authentication_policy_id = true\n\n```\n\nCopy\n\nNote\n\nEnabling this parameter affects all connections made by Snowflake CLI.\n\n## Use a proxy server[¶](#use-a-proxy-server \"Link to this heading\")\n\nTo use a proxy server, configure the following environment variables:\n\n*   HTTP\\_PROXY\n    \n*   HTTPS\\_PROXY\n    \n*   NO\\_PROXY\n    \n\nFor example:\n\nLinux or macOS:\n\n```\nexport HTTP_PROXY='http://username:password@proxyserver.example.com:80'\nexport HTTPS_PROXY='http://username:password@proxyserver.example.com:80'\n\n```\n\nCopy\n\nWindows:\n\n```\nset HTTP_PROXY=http://username:password@proxyserver.example.com:80\nset HTTPS_PROXY=http://username:password@proxyserver.example.com:80\n\n```\n\nCopy\n\nTip\n\nSnowflake’s security model does not allow Secure Sockets Layer (SSL) proxies (using an HTTPS certificate). Your proxy server must use a publicly-available Certificate Authority (CA), reducing potential security risks such as a MITM (Man In The Middle) attack through a compromised proxy.\n\nIf you must use your SSL proxy, we strongly recommend that you update the server policy to pass through the Snowflake certificate such that no certificate is altered in the middle of communications.\n\nOptionally `NO_PROXY` can be used to bypass the proxy for specific communications. For example, access to Amazon S3 can bypass the proxy server by specifying `NO_PROXY=\".amazonaws.com\"`.\n\n`NO_PROXY` does not support wildcards. Each value specified should be one of the following:\n\n*   The end of a hostname (or a complete hostname), for example:\n    \n    *   .amazonaws.com\n        \n    *   myorganization-myaccount.snowflakecomputing.com\n        \n*   An IP address, for example:\n    \n    *   192.196.1.15\n        \n\nIf more than one value is specified, values should be separated by commas, for example:\n\n> ```\n> localhost,.example.com,.snowflakecomputing.com,192.168.1.15,192.168.1.16\n> \n> ```\n> \n> Copy\n\n## Configure logging[¶](#configure-logging \"Link to this heading\")\n\nBy default, Snowflake CLI automatically saves `INFO`, `WARNING`, and `ERROR` level messages to log files. To disable or customize logging, create a `[cli.logs]` section in your `config.toml` file:\n\n```\n[cli.logs]\nsave_logs = true\nlevel = \"info\"\npath = \"/home/<username>/.snowflake/logs\"\n\n```\n\nCopy\n\nwhere:\n\n*   `save_logs` indicates whether to save logs to files. Default: `true`.\n    \n*   `level` specifies which levels of messages to save to log files. Choose from the following levels, which includes all levels below the selected one:\n    \n    *   `debug`\n        \n        Warning\n        \n        Switching to the `debug` logging level can expose sensitive information, such as executed SQL queries. Use caution when enabling this level.\n        \n    *   `info`\n        \n    *   `warning`\n        \n    *   `error`\n        \n    \n    Default: `info`\n    \n*   `path` specifies the absolute path to save the log files. The format of the path varies based on your operating system, as shown:\n    \n    *   Linux: `path = \"/home/<your_username>/.config/snowflake/logs\"`\n        \n    *   MacOS: `path = \"/Users/<your_username>/Library/Application Support/snowflake/logs\"`\n        \n    *   Windows: `path = \"C:\\\\Users\\\\<your_username>\\\\AppData\\\\Local\\\\snowflake\\\\logs\"`\n        \n    \n    If not specified, the command creates a `logs` directory in the default `config.toml` file location.\n    \n\nIf your `config.toml` was created automatically, the `config.toml` file contains the `|cli.logs|` section filled with default values.\n\nLogs from a single day are appended to file `snowflake-cli.log`, which is later renamed to `snowflake-cli.log.YYYY-MM-DD`, as shown.\n\n```\nls logs/\n\n```\n\nCopy\n\n```\nsnowflake-cli.log            snowflake-cli.log.2024-10-22\n\n```\n\n## Suppress version update notifications[¶](#suppress-version-update-notifications \"Link to this heading\")\n\nBy default, Snowflake CLI checks for newer versions and displays a notification message when a newer version is available. You can suppress these notifications using either a configuration file setting or an environment variable, as follows:\n\n*   Add the `ignore_new_version_warning` setting to the `config.toml` file:\n    \n    ```\n    [cli]\n    ignore_new_version_warning = true\n    \n    ```\n    \n    Copy\n    \n*   Set the `SNOWFLAKE_CLI_IGNORE_NEW_VERSION_WARNING` environment variable:\n    \n    ```\n    export SNOWFLAKE_CLI_IGNORE_NEW_VERSION_WARNING=true\n    \n    ```\n    \n    Copy\n    \n\nOn this page\n\n1.  [Location of the .toml configuration file](#location-of-the-toml-configuration-file)\n2.  [Add an authentication policy that limits access to Snowflake CLI only](#add-an-authentication-policy-that-limits-access-to-sf-cli-only)\n3.  [Use a proxy server](#use-a-proxy-server)\n4.  [Configure logging](#configure-logging)\n5.  [Suppress version update notifications](#suppress-version-update-notifications)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/connecting/../index)\n2.  [Managing Snowflake connections](/developer-guide/snowflake-cli/connecting/configure-connections)",
    "last_scraped": "NULL",
    "id": "NULL",
    "parent_command": "NULL",
    "category": "NULL",
    "content_hash": "6bee41caf2348ad0a6abc4723b5fc31d2c464a9b1bd8d8c57c27e77a1b2507ab",
    "metadata": "NULL"
  },
  {
    "metadata": "NULL",
    "last_scraped": "NULL",
    "raw_content": "# Bootstrapping a project from a template[¶](#bootstrapping-a-project-from-a-template \"Link to this heading\")\n\nTo make it easier for you to instantiate projects, Snowflake CLI implements project templating. You can [create your own project templates](#label-cli-project-templating-custom-templates) or use samples provided by Snowflake in the [Snowflake CLI templates](https://github.com/snowflakedb/snowflake-cli-templates/) public Git repository.\n\nThe [snow init](../command-reference/bootstrap-commands/init) command creates a project directory and populates it with file structure defined in the specified template.\n\n*   If you don’t provide the `--no-interactive` option, the command prompts for each variable specified by the template (`template.yml`) that you don’t provide with the `-D` (or `--variable`) option.\n    \n*   If you do provide the `--no-interactive` option, the command uses the default values of variables (defined by the template). If the template does not define a default value for a variable and you don’t use the `-D` option to provide it, the command exits with an error.\n    \n\nThe `snow init` command uses the following syntax:\n\n```\nsnow init PATH [--template-source SOURCE] [--template NAME] [-D key1=value1 -D key2=value2...] [--no-interactive]\n\n```\n\nCopy\n\nwhere:\n\n*   `PATH` is a new directory where the command initializes the project. If you specify an existing directory, the command exits with an error.\n    \n*   `[--template-source SOURCE]` is one of the following:\n    \n    *   A local file path of the template directory.\n        \n    *   A valid Git URL to the directory containing the project template. If not specified, the command defaults to the [Snowflake CLI templates](https://github.com/snowflakedb/snowflake-cli-templates/) Git repository.\n        \n*   `[--template NAME]` specifies which subdirectory of `SOURCE` to use as a template (useful for remote sources). If not provided, `SOURCE` is treated as a single template.\n    \n*   `[-D key1=value1 -D key2=value2...]` is a list of one or more name-value pairs, providing values for variables defined in the template (in `template.yml`). The command does not prompt for variables you provide with this option.\n    \n*   `[--no-interactive]` disables prompts for user input. If you use this option, you must provide all of the required values with the `[-D key1=value1 -D key2=value2...]` options; otherwise, the command exists with an error.\n    \n\nFor more information, see the [snow init](../command-reference/bootstrap-commands/init) command reference.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   Initialize project from `example_snowpark` template from default repository:\n    \n    ```\n    snow init my_snowpark_test_app --template example_snowpark\n    \n    ```\n    \n    Copy\n    \n    The command prompts for (default values are shown in square brackets):\n    \n    ```\n    Project identifier (used to determine artifacts stage path) [my_snowpark_project]:\n    What stage should the procedures and functions be deployed to? [dev_deployment]: snowpark\n    Initialized the new project in my_snowpark_test_app\n    \n    ```\n    \n*   Initialize the project from the local template.\n    \n    ```\n    snow init new_streamlit_project --template-source ../local_templates/example_streamlit -D query_warehouse=dev_wareshouse -D stage=testing\n    \n    ```\n    \n    Copy\n    \n    In this example, `query_warehouse` and `stage` variables are specified with the `-D` option, so the command only prompts for the following:\n    \n    ```\n    Name of the streamlit app [streamlit_app]:\n    Initialized the new project in new_streamlit_project\n    \n    ```\n    \n\n## Creating custom templates[¶](#creating-custom-templates \"Link to this heading\")\n\n### Template layout[¶](#template-layout \"Link to this heading\")\n\nA project template requires a `template.yml` file that contains data that explains how the `snow init` command should render the template. If the file is not present in the template’s root directory, `snow init` finishes with an error. For more information, see [template.yml syntax.](#label-cli-project-templating-template-yml)\n\n### Template syntax[¶](#template-syntax \"Link to this heading\")\n\nTemplate variables and expressions should be enclosed in `<! ... !>`. Snowflake CLI also supports basic jinja2 expressions and filters, for example:\n\n> ```\n> some_file_spec:\n>   filename: <! file_name !>\n>   size: \"<! [ max_file_size_mb, 4 ] | max !> MB\"\n> \n> ```\n> \n> Copy\n\nSnowflake CLI project templates also support the following reserved variable and filter:\n\n*   `project_dir_name` variable, which automatically resolves to the root directory of the created project.\n    \n    For example, suppose your `snowflake.yml` file contains the following:\n    \n    ```\n    definition_version: \"1.1\"\n    snowpark:\n      project_name: <! project_dir_name !>\n      ...\n    \n    ```\n    \n    Copy\n    \n    If you then execute the following command to initialize the project from your custom template:\n    \n    ```\n    snow init examples/new_snowpark_project --template-source my_example_template/\n    \n    ```\n    \n    Copy\n    \n    The `snow init` command renders the `snowflake.yml` file as follows:\n    \n    ```\n    definition_version: \"1.1\"\n    snowpark:\n      project_name: new_snowpark_project\n      ...\n    \n    ```\n    \n    Copy\n    \n*   `to_snowflake_identifier` filter, which formats user-provided strings into to correctly-formatted Snowflake identifiers.\n    \n    Snowflake strongly recommends using this filter when a variable references a Snowflake object.\n    \n    For example, suppose your `snowflake.yml` file contains the following:\n    \n    ```\n    definition_version: \"1.1\"\n    streamlit:\n      name: <! name | to_snowflake_identifier !>\n      ...\n    \n    ```\n    \n    Copy\n    \n    If you then execute the following command to initialize a project from your custom template:\n    \n    ```\n    snow init examples/streamlit --template-source my_example_template2/ -D name='My test streamlit'\n    \n    ```\n    \n    Copy\n    \n    The `snow init` command renders the `snowflake.yml` file as follows:\n    \n    ```\n    definition_version: \"1.1\"\n    streamlit:\n      name: My_test_streamlit\n      ...\n    \n    ```\n    \n    Copy\n    \n    If a string cannot be converted into a valid Snowflake identifier, the `snow init` command exits with an error, as shown:\n    \n    ```\n    snow init examples/streamlit --template-source my_example_template2/ -D name=1234567890\n    \n    ```\n    \n    Copy\n    \n    ```\n    ╭─ Error ────────────────────────────────────────────────────────────────────────╮\n    │ Value '123456789' cannot be converted to valid Snowflake identifier.         │\n    │ Consider enclosing it in double quotes: \"\"                                   │\n    ╰────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n\n### About the `template.yml` project template file[¶](#about-the-template-yml-project-template-file \"Link to this heading\")\n\nThe `template.yml` project template file stores all of the data needed to render the project. For example:\n\n```\nminimum_cli_version: \"2.7.0\"\nfiles_to_render:\n  - snowflake.yml\nvariables:\n  - name: name\n    default: streamlit_app\n    prompt: \"Name of the streamlit app\"\n    type: string\n  - name: stage\n    default: my_streamlit_stage\n    prompt: \"What stage should the app be deployed to?\"\n    type: string\n  - name: query_warehouse\n    default: my_streamlit_warehouse\n    prompt: \"On which warehouse SQL queries issued by the application are run\"\n    type: string\n\n```\n\nCopy\n\nThe following table lists the properties in a `template.yml` project template file.\n\n| Property | Definition |\n| --- | --- |\n| minimum_cli_versionoptional, string (default:None) | Minimum Snowflake CLI version. If specified, the snow init command checks the version of Snowflake CLI installed and exits with an error if the installed version is lower than the specified version. |\n| files_to_renderoptional, string list (default: []) | List of files to be rendered by the snow init command. Each path should be relative to the templates root.NoteTemplate files not included in this list are added to the new project, but their content remains unchanged. |\n| variablesoptional, variable list (default: []) | List of template variables. It supports customizing prompts, providing default values for optional variables and basic type checking. See the Variables property parameters table below for more details. Variable values are determined in order from this list.If you omit any variable used in the snowflake.yml file from this list, the snow init command exits with the following error.╭─ Error ─────────────────────────────────────────────────────────╮\n│ Cannot determine value of variable undefined_variable         │\n╰─────────────────────────────────────────────────────────────────╯ |\n\nThe following table lists the parameters of a variable property.\n\n| Property | Definition |\n| --- | --- |\n| namerequired, string | Name of the variable. It is used in the template files, such as <! name !> and in -D option, such as -D name=value. |\n| promptoptional, string | Prompt to display to the user to get a value. If you don’t set this parameter, the command displays the name of the parameter as the prompt text.If you define the prompt as follows:variables:\n  - name: project_id\n    prompt: The identifier for the project\nCopysnow init displays this prompt for the project_id variable.The identifier for the project: |\n| defaultoptional, string/int/float | Default value of the variable. If not provided, the variable is treated as required, so a user needs to provide the value after a prompt or by specifying it with the -D command-line option.The following example defines two variables with default values:variables:\n  - name: max_file_size_mb\n    default: 16\n  - name: file_name\n    default: 'default_file_name.zip'\nCopyWhen executed, the snow init command displays the following prompts for these two variables:file_name [default_file_name.zip]:\nmax_file_size_mb [16]: 5\nCopyIn this example, the command uses the default value (default_file_name.zip) for the file_name variable has a default value, and sets max_file_size_mb to the value provided by the user (5). |\n| typeoptional, string | Data type of the variable. Valid values include: string, int, and float. If not specified, the command assumes the value is a string.The following example defines a variable as an int data type:variables:\n  - name: max_file_size_mb\n    type: int\nCopyWhen executed, the snow init command displays the following errors if the user enters a value of the wrong data type:max_file_size_mb: not an int\nError: 'not an int' is not a valid integer.\nmax_file_size_mb: 14.5\nError: '14.5' is not a valid integer.\nmax_file_size_mb: 6\nInitialized the new project in example_dir |\n\nOn this page\n\n1.  [Examples](#examples)\n2.  [Creating custom templates](#creating-custom-templates)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/bootstrap-project/../index)\n2.  [snow init](/developer-guide/snowflake-cli/bootstrap-project/../command-reference/bootstrap-commands/init)\n3.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/bootstrap-project/../streamlit-apps/overview)\n4.  [Using Snowpark in Snowflake CLI](/developer-guide/snowflake-cli/bootstrap-project/../snowpark/overview)",
    "id": "NULL",
    "full_command": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/bootstrap-project/bootstrap",
    "parent_command": "NULL",
    "command_group": "NULL",
    "title": "Bootstrapping a project from a template¶",
    "category": "NULL",
    "content_hash": "15b05ab882bddcbf662e632cd97ba61a4efd99d2a0a73cb43b61dbb12f11a103"
  },
  {
    "title": "About project definition files¶",
    "category": "NULL",
    "command_group": "NULL",
    "parent_command": "NULL",
    "raw_content": "# About project definition files[¶](#about-project-definition-files \"Link to this heading\")\n\nWhen developing Streamlit or Snowpark applications you often work with multiple files and objects, be it python file or stored procedures. Organizing this in a clear and concise way is very important for smooth development experience. That’s the reason why Snowflake CLI is using the concept of _project definition files_.\n\nA project definition file (usually named `snowflake.yml`) is a file containing information about the Snowflake objects you are developing. The following `snowflake.yml` example shows a project with a Snowpark UDF and a stored procedure.\n\n```\ndefinition_version: 2\nentities:\n  test_function:\n    type: \"function\"\n    stage: \"dev_deployment\"\n    artifacts: [\"app/\"]\n    handler: \"functions.hello_function\"\n    signature: \"\"\n    returns: string\n\n  hello_procedure:\n    type: \"procedure\"\n    stage: \"dev_deployment\"\n    artifacts: [\"app/\"]\n    handler: \"procedures.hello_procedure\"\n    signature:\n      - name: \"name\"\n        type: \"string\"\n    returns: string\n\n```\n\nCopy\n\n## Project definition properties[¶](#project-definition-properties \"Link to this heading\")\n\nThe following table describes the project definition properties used by all projects.\n\n| Property | Definition |\n| --- | --- |\n| definition_versionrequired, int | Version of the project definition schema, which is currently 2. |\n| entitiesoptional, string | List of entity definitions, such as procedures, functions, and so on. For more information, see Specify entities. |\n| envoptional, string sequence | List of default environment specifications to be used in project templates. For more information, see Create project definition file templates. |\n| mixinsoptional, string sequence | List of common values for entity properties. For more information, see Project mixins. |\n\nEach project requires specific information about what you are building. Snowflake CLI currently supports the following entity definitions from the following Snowflake domains:\n\n*   [Native App Framework](../native-apps/project-definitions)\n    \n*   [Notebooks](../notebooks/use-notebooks)\n    \n*   [Snowpark](../snowpark/create.html#label-snowcli-create-snowpark)\n    \n*   Snowpark Container Services (SPCS)\n    \n    *   [Compute pools](../services/manage-compute-pools.html#label-sfcli-pool-pdf)\n        \n    *   [Image repositories](../services/manage-images.html#label-sfcli-repo-pdf)\n        \n    *   [Services](../services/manage-services.html#label-sfcli-service-pdf)\n        \n*   [Streamlit](../streamlit-apps/manage-apps/initialize-app.html#label-snowcli-streamlit-project-definition)\n    \n*   [SQL](../sql/execute-sql.html#label-cli-sql-env-vars)\n    \n\nCaution\n\nFiles inside a project directory are processed by Snowflake CLI and could be uploaded to Snowflake when executing other `snow` commands. You should use caution when putting any sensitive information inside files in a project directory.\n\nOn this page\n\n1.  [Project definition properties](#project-definition-properties)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",
    "full_command": "NULL",
    "content_hash": "4f202f9eebb65c4569207b5c04db9477171e30d95e1564815fa051281ecbfcd1",
    "id": "NULL",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/about",
    "metadata": "NULL"
  },
  {
    "category": "NULL",
    "title": "Managing Snowflake objects¶",
    "command_group": "NULL",
    "parent_command": "NULL",
    "full_command": "NULL",
    "id": "NULL",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "raw_content": "# Managing Snowflake objects[¶](#managing-snowflake-objects \"Link to this heading\")\n\nThe `snow object` commands provide you with a convenient way of managing most Snowflake objects, such as stages, Snowpark functions, or Streamlit apps. Instead of using separate commands for each type of object, you can use these commands to perform common tasks, including the following:\n\n*   [Create an object of a specific type](#label-snowcli-object-create)\n    \n*   [List available objects of a specified type](#label-snowcli-object-list).\n    \n*   [Display the description of an object](#label-snowcli-object-describe).\n    \n*   [Delete an object](#label-snowcli-object-drop).\n    \n\nTo see a list of supported types use the `--help` option for any of the `snow object` commands, such as the following:\n\n```\nsnow object list --help\n\n```\n\nCopy\n\n```\nUsage: snow object list [OPTIONS] OBJECT_TYPE\n\nLists all available Snowflake objects of given type.\nSupported types: compute-pool, database, function, image-repository, integration, network-rule,\nprocedure, role, schema, secret, service, stage, stream, streamlit, table, task,\nuser, view, warehouse\n\n...\n\n```\n\nThe object subcommands let you perform common operations, while leaving service-specific commands groups dedicated to service-specific operations.\n\n## Create an object of a specific type[¶](#create-an-object-of-a-specific-type \"Link to this heading\")\n\nThe `snow object create` command creates a specified object based on the definition provided, using the following syntax:\n\n```\nsnow object create TYPE ([OBJECT_ATTRIBUTES]|[--json {OBJECT_DEFINITION}])\n\n```\n\nCopy\n\nwhere:\n\n*   `TYPE` is a Snowflake object type:\n    \n    *   `account`\n        \n    *   `catalog-integration`\n        \n    *   `compute-pool`\n        \n    *   `database`\n        \n    *   `database-role`\n        \n    *   `dynamic-table`\n        \n    *   `event-table`\n        \n    *   `external-volume`\n        \n    *   `function`\n        \n    *   `image-repository`\n        \n    *   `managed-account`\n        \n    *   `network-policy`\n        \n    *   `notebook`\n        \n    *   `notification-integration`\n        \n    *   `pipe`\n        \n    *   `procedure`\n        \n    *   `role`\n        \n    *   `schema`\n        \n    *   `service`\n        \n    *   `stage`\n        \n    *   `stream`\n        \n    *   `table`\n        \n    *   `task`\n        \n    *   `user-defined-function`\n        \n    *   `view`\n        \n    *   `warehouse`\n        \n\n*   `OBJECT_ATTRIBUTES` contains the object definition in the form of a list of `<key>=<value>` pairs, such as:\n    \n    ```\n    snow object create database name=my_db comment=\"Created with Snowflake CLI\"\n    \n    ```\n    \n    Copy\n    \n*   `--json {OBJECT_DEFINITION}` contains the object definition in JSON, such as:\n    \n    ```\n    snow object create database --json '{\"name\":\"my_db\", \"comment\":\"Created with Snowflake CLI\"}'\n    \n    ```\n    \n    Copy\n    \n\nNote\n\nThe following object types require a database to be identified in the connection configuration, such as `config.toml`, or passed to the command using the `--database` option.\n\n*   image-repository\n    \n*   schema\n    \n*   service\n    \n*   table\n    \n*   task\n    \n\nTo create a database object using the `option-attributes` parameter:\n\n```\nsnow object create database name=my_db comment='Created with Snowflake CLI'\n\n```\n\nCopy\n\nTo create a table object using the `option-attributes` parameter:\n\n```\nsnow object create table name=my_table columns='[{\"name\":\"col1\",\"datatype\":\"number\", \"nullable\":false}]' constraints='[{\"name\":\"prim_key\", \"column_names\":[\"col1\"], \"constraint_type\":\"PRIMARY KEY\"}]' --database my_db --schema public\n\n```\n\nCopy\n\nTo create a database using the `--json object-definition` option:\n\n```\nsnow object create database --json '{\"name\":\"my_db\", \"comment\":\"Created with Snowflake CLI\"}'\n\n```\n\nCopy\n\nTo create a table using the `--json object-definition` option:\n\n```\nsnow object create table --json \"$(cat table.json)\" --database my_db\n\n```\n\nCopy\n\nwhere `table.json` contains the following:\n\n```\n{\n  \"name\": \"my_table\",\n  \"columns\": [\n    {\n      \"name\": \"col1\",\n      \"datatype\": \"number\",\n      \"nullable\": false\n    }\n  ],\n  \"constraints\": [\n    {\n      \"name\": \"prim_key\",\n      \"column_names\": [\"col1\"],\n      \"constraint_type\": \"PRIMARY KEY\"\n    }\n  ]\n}\n\n```\n\nCopy\n\n## List all objects of a specific type[¶](#list-all-objects-of-a-specific-type \"Link to this heading\")\n\nThe `snow object list` command lists all objects of given type available with your permissions.\n\n```\nsnow object list TYPE\n\n```\n\nCopy\n\nwhere `TYPE` is the type of the object. Use `snow object list --help` for the full list of supported types.\n\nTo list all role objects, enter the following command:\n\n```\nsnow object list role\n\n```\n\nCopy\n\n```\n+--------------------------------------------------------------------------------------------------------------------------------+\n|            |            |            |            | is_inherit | assigned_t | granted_to | granted_ro |            |           |\n| created_on | name       | is_default | is_current | ed         | o_users    | _roles     | les        | owner      | comment   |\n|------------+------------+------------+------------+------------+------------+------------+------------+------------+-----------|\n| 2023-07-24 | ACCOUNTADM | N          | N          | N          | 2          | 0          | 2          |            | Account   |\n| 06:05:49-0 | IN         |            |            |            |            |            |            |            | administr |\n| 7:00       |            |            |            |            |            |            |            |            | ator can  |\n|            |            |            |            |            |            |            |            |            | manage    |\n|            |            |            |            |            |            |            |            |            | all       |\n|            |            |            |            |            |            |            |            |            | aspects   |\n|            |            |            |            |            |            |            |            |            | of the    |\n|            |            |            |            |            |            |            |            |            | account.  |\n| 2023-07-24 | PUBLIC     | N          | N          | Y          | 0          | 0          | 0          |            | Public    |\n| 06:05:48.9 |            |            |            |            |            |            |            |            | role is   |\n| 56000-07:0 |            |            |            |            |            |            |            |            | automatic |\n| 0          |            |            |            |            |            |            |            |            | ally      |\n|            |            |            |            |            |            |            |            |            | available |\n|            |            |            |            |            |            |            |            |            | to every  |\n|            |            |            |            |            |            |            |            |            | user in   |\n|            |            |            |            |            |            |            |            |            | the       |\n|            |            |            |            |            |            |            |            |            | account.  |\n| 2023-07-24 | SYSADMIN   | N          | N          | N          | 0          | 1          | 0          |            | System    |\n| 06:05:49.0 |            |            |            |            |            |            |            |            | administr |\n| 33000-07:0 |            |            |            |            |            |            |            |            | ator can  |\n| 0          |            |            |            |            |            |            |            |            | create    |\n|            |            |            |            |            |            |            |            |            | and       |\n|            |            |            |            |            |            |            |            |            | manage    |\n|            |            |            |            |            |            |            |            |            | databases |\n|            |            |            |            |            |            |            |            |            | and       |\n|            |            |            |            |            |            |            |            |            | warehouse |\n|            |            |            |            |            |            |            |            |            | s.        |\n| 2023-07-24 | USERADMIN  | N          | N          | N          | 0          | 1          | 0          |            | User      |\n| 06:05:49.0 |            |            |            |            |            |            |            |            | administr |\n| 45000-07:0 |            |            |            |            |            |            |            |            | ator can  |\n| 0          |            |            |            |            |            |            |            |            | create    |\n|            |            |            |            |            |            |            |            |            | and       |\n|            |            |            |            |            |            |            |            |            | manage    |\n|            |            |            |            |            |            |            |            |            | users and |\n|            |            |            |            |            |            |            |            |            | roles     |\n+--------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\nYou can also use the `--like [-l] <pattern>` to filter objects by name using a SQL LIKE pattern. For example, `list function --like \"my%\"` lists all functions that begin with **my**. For more information about SQL patterns syntax, see [SQL LIKE Keyword](https://www.w3schools.com/sql/sql_ref_like.asp).\n\nTo list only role objects that begin with the string, **public**, enter the following command:\n\n```\nsnow object list role --like public%\n\n```\n\nCopy\n\n```\nshow roles like 'public%'\n+-------------------------------------------------------------------------------\n| created_on                       | name        | is_default | is_current | ...\n|----------------------------------+-------------+------------+------------+----\n| 2023-02-01 15:25:04.105000-08:00 | PUBLIC      | N          | N          | ...\n| 2024-01-15 12:55:05.840000-08:00 | PUBLIC_TEST | N          | N          | ...\n+-------------------------------------------------------------------------------\n\n```\n\n## Display the description for an object of a specified type[¶](#display-the-description-for-an-object-of-a-specified-type \"Link to this heading\")\n\nThe `snow object describe` command provides a description of an object of given type.\n\n```\nsnow object describe TYPE IDENTIFIER\n\n```\n\nCopy\n\nwhere:\n\n*   `TYPE` is the type of the object. Use `snow object describe --help` for the full list of supported types.\n    \n*   `IDENTIFIER` is the name of the object. For procedures and functions, the identifier must specify arguments types, such as `\"hello(int,string)\"`.\n    \n\nTo describe a function object, enter a command similar to the following:\n\n```\nsnow object describe function \"hello_function(string)\"\n\n```\n\nCopy\n\n```\ndescribe function hello_function(string)\n+---------------------------------------------------------------------\n| property           | value\n|--------------------+------------------------------------------------\n| signature          | (NAME VARCHAR)\n| returns            | VARCHAR(16777216)\n| language           | PYTHON\n| null handling      | CALLED ON NULL INPUT\n| volatility         | VOLATILE\n| body               | None\n| imports            |\n| handler            | functions.hello_function\n| runtime_version    | 3.9\n| packages           | ['snowflake-snowpark-python']\n| installed_packages | ['_libgcc_mutex==0.1','_openmp_mutex==5.1',...\n+---------------------------------------------------------------------\n\n```\n\n## Delete an object of a specified type[¶](#delete-an-object-of-a-specified-type \"Link to this heading\")\n\nThe `snow object drop` command deletes a Snowflake object of given name and type.\n\n```\nsnow object drop TYPE IDENTIFIER\n\n```\n\nCopy\n\nwhere:\n\n*   `TYPE` is the type of the object. Use `snow object drop --help` for the full list of supported types.\n    \n*   `IDENTIFIER` is the name of the object. For procedures and functions, the identifier must specify arguments types, such as `\"hello(int,string)\"`.\n    \n\nTo drop a procedure, enter a commands similar to the following:\n\n```\nsnow object drop procedure \"test_procedure()\"\n\n```\n\nCopy\n\n```\ndrop procedure test_procedure()\n+--------------------------------------+\n| status                               |\n|--------------------------------------|\n| TEST_PROCEDURE successfully dropped. |\n+--------------------------------------+\n\n```\n\nOn this page\n\n1.  [Create an object of a specific type](#create-an-object-of-a-specific-type)\n2.  [List all objects of a specific type](#list-all-objects-of-a-specific-type)\n3.  [Display the description for an object of a specified type](#display-the-description-for-an-object-of-a-specified-type)\n4.  [Delete an object of a specified type](#delete-an-object-of-a-specified-type)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/objects/../index)\n2.  [snow object commands](/developer-guide/snowflake-cli/objects/../command-reference/object-commands/overview)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/objects/manage-objects",
    "content_hash": "8c4fc19274932f93d3a795c51eadab7d19c70d1916b9d015e8618a99c08b333c"
  },
  {
    "raw_content": "# Managing Snowflake stages[¶](#managing-snowflake-stages \"Link to this heading\")\n\nThe `snow stage` commands let you perform additional stage-specific tasks:\n\n*   [Create a named stage if it does not already exist](#label-snowcli-stage-create).\n    \n*   [Copy all files from source to target directory](#label-snowcli-stage-copy).\n    \n*   [List the contents of a stage](#label-snowcli-stage-list).\n    \n*   [Execute SQL files from a stage](#label-snowcli-stage-execute).\n    \n*   [Remove a file from a stage](#label-snowcli-stage-remove).\n    \n\n## Create a named stage[¶](#create-a-named-stage \"Link to this heading\")\n\nThe `snow stage create` command creates a named stage if it does not already exist.\n\n```\nsnow stage create <stage_name>\n\n```\n\nCopy\n\nFor example, to create a stage called `new_stage`, enter the following command:\n\n```\nsnow stage create new_stage\n\n```\n\nCopy\n\n```\n+-----------------------------------------------------+\n| key    | value                                      |\n|--------+--------------------------------------------|\n| status | Stage area NEW_STAGE successfully created. |\n+-----------------------------------------------------+\n\n```\n\nThe following example shows what happens if you try to create a stage, `packages`, that already exists.\n\n```\n# stage that already exists\nsnow stage create packages\n\n```\n\nCopy\n\n```\n+--------------------------------------------------------+\n| key    | value                                         |\n|--------+-----------------------------------------------|\n| status | PACKAGES already exists, statement succeeded. |\n+--------------------------------------------------------+\n\n```\n\nIf you want to specify the type of encryption to use for all files stored on the stage, add the `--encryption` option to specify whether you want to full encryption (`SNOWFLAKE_FULL`) or only server-side encryption (`SNOWFLAKE_SSE`).\n\n```\nsnow stage create new_stage --encryption SNOWFLAKE_FULL\n\n```\n\nCopy\n\n```\n+-----------------------------------------------------+\n| key    | value                                      |\n|--------+--------------------------------------------|\n| status | Stage area NEW_STAGE successfully created. |\n+-----------------------------------------------------+\n\n```\n\n## Copy files to and from a stage[¶](#copy-files-to-and-from-a-stage \"Link to this heading\")\n\nThe `snow stage copy` command copies a file from the local machine to a stage, from a stage to a local machine, or between named stages.\n\n```\nsnow stage copy <source_path> <destination_path>\n\n```\n\nCopy\n\nNote the following guidelines:\n\n*   The stage path must start with `@`, as shown in the following examples.\n    \n*   When you copy a single file, `<destination_path>` must identify a directory, not a file. If the specified directory does not exist, the command creates it.\n    \n*   By default, when you copy a local directory to a stage, the local directory must contain only files. You can use the `--recursive` option to upload sub-directories in the local directory. You can use glob patterns with the `--recursive` option.\n    \n*   When you copy a directory from a stage to a local filesystem, the command currently flattens its internal tree structure. To illustrate, assume your local directory contains the following:\n    \n    ```\n    test_case.py\n    tests/abc.py\n    tests/test1/x1.txt\n    tests/test1/x2.txt\n    \n    ```\n    \n    After copying the directory from the stage, the local filesystem directory contains the following:\n    \n    ```\n    test_case.py\n    abc.py\n    x1.txt\n    x2.txt\n    \n    ```\n    \n    Note\n    \n    If you want to maintain the file structure from the source directory, you can include the `--recursive` option.\n    \n\n### Copy files to a stage[¶](#copy-files-to-a-stage \"Link to this heading\")\n\n*   To copy files from the local machine to a stage, enter a command similar to the following:\n    \n    ```\n    snow stage copy local_example_app @example_app_stage/app\n    \n    ```\n    \n    Copy\n    \n    ```\n    put file:///.../local_example_app/* @example_app_stage/app4 auto_compress=false parallel=4 overwrite=False\n    +--------------------------------------------------------------------------------------\n    | source           | target           | source_size | target_size | source_compression...\n    |------------------+------------------+-------------+-------------+--------------------\n    | environment.yml  | environment.yml  | 62          | 0           | NONE             ...\n    | snowflake.yml    | snowflake.yml    | 252         | 0           | NONE             ...\n    | streamlit_app.py | streamlit_app.py | 109         | 0           | NONE             ...\n    +--------------------------------------------------------------------------------------\n    \n    ```\n    \n\nYou can use the `snow stage list-files` command to verify the command copied the files successfully:\n\n```\nsnow stage list-files example_app_stage\n\n```\n\nCopy\n\n```\nls @example_app_stage\n​+------------------------------------------------------------------------------------\n| name                                   | size | md5                              | ...\n|----------------------------------------+------+----------------------------------+-\n| example_app_stage/app/environment.yml  | 64   | 45409c8da098125440bfb7ffbcd900f5 | ...\n| example_app_stage/app/snowflake.yml    | 256  | a510b1d59fa04f451b679d43c703b6d4 | ...\n| example_app_stage/app/streamlit_app.py | 112  | e6c2a89c5a164e34a0faf60b086bbdfc | ...\n+------------------------------------------------------------------------------------\n\n```\n\n### Copy files from a stage[¶](#copy-files-from-a-stage \"Link to this heading\")\n\n*   To copy files from a stage to a directory on the local machine, enter a command similar to the following:\n    \n    ```\n    mkdir local_app_backup\n    snow stage copy @example_app_stage/app local_app_backup\n    \n    ```\n    \n    Copy\n    \n    ```\n    get @example_app_stage/app file:///.../local_app_backup/ parallel=4\n    +------------------------------------------------+\n    | file             | size | status     | message |\n    |------------------+------+------------+---------|\n    | environment.yml  | 62   | DOWNLOADED |         |\n    | snowflake.yml    | 252  | DOWNLOADED |         |\n    | streamlit_app.py | 109  | DOWNLOADED |         |\n    +------------------------------------------------+\n    \n    ```\n    \n\nYou can list the directory contents to verify the command copied the files correctly:\n\n```\nls local_app_backup\n\n```\n\nCopy\n\n```\nenvironment.yml  snowflake.yml    streamlit_app.py\n\n```\n\nNote that the local directory must exist.\n\nYou can copy from a user stage (`@~`):\n\n> ```\n> snow stage copy \"@~\" . --recursive\n> \n> ```\n> \n> Copy\n> \n> ```\n> +------------------------------------------------+\n> | file             | size | status     | message |\n> |------------------+------+------------+---------|\n> | environment.yml  | 62   | DOWNLOADED |         |\n> | snowflake.yml    | 252  | DOWNLOADED |         |\n> | streamlit_app.py | 109  | DOWNLOADED |         |\n> +------------------------------------------------+\n> \n> ```\n\n### Copy files between stages[¶](#copy-files-between-stages \"Link to this heading\")\n\nYou can copy files directly between two named stages without downloading them to your local machine first. This can be useful for organizing files across different stages or creating backups.\n\n*   To copy files from one stage to another, use the following syntax:\n    \n    ```\n    snow stage copy @source_stage @destination_stage\n    \n    ```\n    \n    Copy\n    \n\nThe following example copies all files from the `production_stage` to the `backup_stage`:\n\n```\nsnow stage copy @production_stage @backup_stage\n\n```\n\nCopy\n\n```\n+------------------------------------------------------------+\n| file                                                       |\n|------------------------------------------------------------|\n| __init__.py                                                |\n| main.py                                                    |\n| procedure.py                                               |\n+------------------------------------------------------------+\n\n```\n\nNote\n\nWhen you copy between stages, the destination cannot be a user stage (`@~`). You must specify named stages for both source and destination.\n\n### Use glob patterns to specify files[¶](#use-glob-patterns-to-specify-files \"Link to this heading\")\n\nYou can specify multiple files matching a regular expression by using a glob pattern for the `source_path` argument. You must enclose the glob pattern in single or double quotes.\n\nThe following example copies all `.txt` files in a directory to a stage.\n\n```\nsnow stage copy \"testdir/*.txt\" @TEST_STAGE_3\n\n```\n\nCopy\n\n```\nput file:///.../testdir/*.txt @TEST_STAGE_3 auto_compress=false parallel=4 overwrite=False\n+------------------------------------------------------------------------------------------------------------+\n| source | target | source_size | target_size | source_compression | target_compression | status   | message |\n|--------+--------+-------------+-------------+--------------------+--------------------+----------+---------|\n| b1.txt | b1.txt | 3           | 16          | NONE               | NONE               | UPLOADED |         |\n| b2.txt | b2.txt | 3           | 16          | NONE               | NONE               | UPLOADED |         |\n+------------------------------------------------------------------------------------------------------------+\n\n```\n\n## List the contents of a stage[¶](#list-the-contents-of-a-stage \"Link to this heading\")\n\nThe `snow stage list-files` command lists the stage contents.\n\n```\nsnow stage list-files <stage_path>\n\n```\n\nCopy\n\nFor example, to list the packages in a stage, enter the following command:\n\n```\nsnow stage list-files packages\n\n```\n\nCopy\n\n```\nls @packages\n+-------------------------------------------------------------------------------------\n| name                 | size     | md5                              | last_modified\n|----------------------+----------+----------------------------------+----------------\n| packages/plp.Ada.zip | 824736   | 90639175a0ac7735e67525118b81047c | Tue, 16 Jan ...\n| packages/samrand.zip | 13721024 | 648f0bae2f65fd4c9f178b17c23de7e5 | Tue, 16 Jan ...\n+-------------------------------------------------------------------------------------\n\n```\n\n## Execute files from a stage[¶](#execute-files-from-a-stage \"Link to this heading\")\n\nNote\n\nSnowflake CLI does not support executing Python files for Python versions 3.12 and above.\n\nThe `snow stage execute` command executes SQL or Python files from a stage.\n\n```\nsnow stage execute <stage_path>\n\n```\n\nCopy\n\n*   For `.sql` files, the it performs an [EXECUTE IMMEDIATE FROM](../../../sql-reference/sql/execute-immediate-from) command on `.sql` files from a stage.\n    \n*   For `.py` files, it executes a session-scoped [Snowpark Python procedure](../../snowpark/python/creating-sprocs).\n    \n    Snowflake CLI executes the procedure in Snowflake to guarantee a consistent execution environment. If your Python scripts require additional requirements, you should specify them in a `requirements.txt` file that resides in the same directory as the files on the stage. The `snow stage execute` command only supports packages from the Snowflake Anaconda channel.\n    \n    By default, the command looks for the `requirements.txt` file in the following precedence:\n    \n    *   Stage path specified in the command’s `stage_path` parameter.\n        \n    *   Parent directories of the specified stage path hierarchy, until it reaches the stage.\n        \n    *   If you don’t specify a `requirements.txt` file, the command assumes no additional packages are necessary.\n        \n    \n    For example, if you run `snow stage execute @my_stage/ml/app1/scripts`, the command looks for the file as follows:\n    \n    *   `my_stage/ml/app1/scripts/requirements.txt`\n        \n    *   `my_stage/ml/app1/requirements.txt`\n        \n    *   `my_stage/ml/requirements.txt`\n        \n    *   `my_stage/ml/requirements.txt`\n        \n\nThe following examples illustrate ways to execute different sets of `.sql` files from a stage:\n\n*   Specify only a stage name to execute all `.sql` files in the stage:\n    \n    ```\n    snow stage execute \"@scripts\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    SUCCESS - scripts/script1.sql\n    SUCCESS - scripts/script2.sql\n    SUCCESS - scripts/dir/script.sql\n    +------------------------------------------+\n    | File                   | Status  | Error |\n    |------------------------+---------+-------|\n    | scripts/script1.sql    | SUCCESS | None  |\n    | scripts/script2.sql    | SUCCESS | None  |\n    | scripts/dir/script.sql | SUCCESS | None  |\n    +------------------------------------------+\n    \n    ```\n    \n*   Specify a user stage (`@~`) to execute the `script.sql` files in the user stage:\n    \n    ```\n    snow stage execute \"@~/script1.sql\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    SUCCESS - scripts/script1.sql\n    +------------------------------------------+\n    | File                   | Status  | Error |\n    |------------------------+---------+-------|\n    | @~/script.sql          | SUCCESS | None  |\n    +------------------------------------------+\n    \n    ```\n    \n\n### Use glob patterns to select subsets of files[¶](#use-glob-patterns-to-select-subsets-of-files \"Link to this heading\")\n\n*   Specify a glob-like pattern to execute all `.sql` files in the `dir` directory:\n    \n    ```\n    snow stage execute \"@scripts/dir/*\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    SUCCESS - scripts/dir/script.sql\n    +------------------------------------------+\n    | File                   | Status  | Error |\n    |------------------------+---------+-------|\n    | scripts/dir/script.sql | SUCCESS | None  |\n    +------------------------------------------+\n    \n    ```\n    \n*   Specify a glob-like pattern to execute only `.sql` files in the `dir` directory that begin with “script”, followed by one character:\n    \n    ```\n    snow stage execute \"@scripts/script?.sql\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    SUCCESS - scripts/script1.sql\n    SUCCESS - scripts/script2.sql\n    +---------------------------------------+\n    | File                | Status  | Error |\n    |---------------------+---------+-------|\n    | scripts/script1.sql | SUCCESS | None  |\n    | scripts/script2.sql | SUCCESS | None  |\n    +---------------------------------------+\n    \n    ```\n    \n*   Specify a direct file path with the `--silent` option:\n    \n    ```\n    snow stage execute \"@scripts/script1.sql\" --silent\n    \n    ```\n    \n    Copy\n    \n    ```\n    +---------------------------------------+\n    | File                | Status  | Error |\n    |---------------------+---------+-------|\n    | scripts/script1.sql | SUCCESS | None  |\n    +---------------------------------------+\n    \n    ```\n    \n\n## Remove a file from a stage[¶](#remove-a-file-from-a-stage \"Link to this heading\")\n\nThe `snow stage remove` command removes a file from a stage.\n\n```\nsnow stage remove <stage_name> <file_name>\n\n```\n\nCopy\n\nFor example, to remove a file from a stage, enter a command similar to the following:\n\n```\nsnow stage remove example_app_stage app/pages/my_page.py\n\n```\n\nCopy\n\n```\n+-------------------------------------------------+\n| key    | value                                  |\n|--------+----------------------------------------|\n| name   | example_app_stage/app/pages/my_page.py |\n| result | removed                                |\n+-------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Create a named stage](#create-a-named-stage)\n2.  [Copy files to and from a stage](#copy-files-to-and-from-a-stage)\n3.  [List the contents of a stage](#list-the-contents-of-a-stage)\n4.  [Execute files from a stage](#execute-files-from-a-stage)\n5.  [Remove a file from a stage](#remove-a-file-from-a-stage)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/stages/../index)\n2.  [snow stage commands](/developer-guide/snowflake-cli/stages/../command-reference/stage-commands/overview)",
    "metadata": "NULL",
    "title": "Managing Snowflake stages¶",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/stages/manage-stages",
    "content_hash": "a83392c9b940376f07d67a723f54920173ee33d9cd2f5a7acda20416aeb95c6a",
    "category": "NULL",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "command_group": "NULL",
    "parent_command": "NULL"
  },
  {
    "id": "NULL",
    "title": "Managing Git repositories¶",
    "content_hash": "64010c9454d1180d0fc9ee55c1c15535e63a5caa030dc7c492a0111847375c56",
    "category": "NULL",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/overview",
    "command_group": "NULL",
    "full_command": "NULL",
    "metadata": "NULL",
    "parent_command": "NULL",
    "raw_content": "# Managing Git repositories[¶](#managing-git-repositories \"Link to this heading\")\n\nYou can integrate your remote Git repository with Snowflake so that files from the repository are synchronized to a special kind of stage called a _repository stage_. The repository stage acts as a local Git repository with a full clone of the remote repository, including branches, tags, and commits.\n\nFor more information, see [Using a Git repository in Snowflake](../../git/git-overview).\n\nSnowflake CLI supports the following git operations:\n\n*   [Setting up a Git repository](setup-git)\n    \n*   [Refreshing a repository](refresh-repo)\n    \n*   [Listing the contents of a repository](list-contents)\n    \n*   [Copying files in Git](copy-files)\n    \n*   [Executing files from a repository](execute-sql)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)\n2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)"
  },
  {
    "last_scraped": "NULL",
    "id": "NULL",
    "title": "Managing Snowpark Container Services in Snowflake CLI¶",
    "full_command": "NULL",
    "category": "NULL",
    "raw_content": "# Managing Snowpark Container Services in Snowflake CLI[¶](#managing-snowpark-container-services-in-sf-cli \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nSnowpark Container Services is a fully managed container offering that helps you easily deploy, manage, and scale containerized applications without having to move data out of Snowflake. As a fully managed service, it comes with Snowflake security, configuration, and operational best practices built in.\n\nSnowpark Container Services is fully integrated with Snowflake. For example, your application can easily:\n\n*   Connect to Snowflake and run SQL in a Snowflake virtual warehouse.\n    \n*   Access data files in a Snowflake stage.\n    \n\nSnowpark Container Services is also integrated with third-party tools. It allows you to use third-party clients (such as Docker) to easily upload your application images to Snowflake. Seamless integration makes it easier for teams to focus on building the data applications, not the environment.\n\nThis section describes the following topics:\n\n*   [Working with image registries and repositories](manage-images)\n    \n*   [Managing compute pools](manage-compute-pools)\n    \n*   [Managing services](manage-services)\n    \n\nRelated content\n\n1.  [spcs command reference](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/overview)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/services/overview",
    "content_hash": "440401bed49bdc293ea4f502d2717c19d68c157a7e0e774a34195063cc5a5a46",
    "metadata": "NULL",
    "command_group": "NULL",
    "parent_command": "NULL"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/overview",
    "command_group": "NULL",
    "raw_content": "# Using Snowpark in Snowflake CLI[¶](#using-snowpark-in-sf-cli \"Link to this heading\")\n\nThe [Snowpark API](../../snowpark/index) provides an intuitive library for querying and processing data at scale in Snowflake, without using SQL. Using a library for any of three languages, you can build applications that process data in Snowflake—without moving data to the system where your application code runs—and process at scale as part of the elastic and serverless Snowflake engine.\n\nSnowflake CLI gives developers convenient tooling for developing and managing their Snowpark functions and procedures. To create and maintain Snowpark functions and procedures, use the following process:\n\n*   [Initialize](initialize) — create a boilerplate\n    \n    The `snow init <project-name> --template example_snowpark` command creates a boilerplate project that you can customize.\n    \n*   [Create](create) — create a project definition\n    \n    You edit the `snowflake.yml` file with the project details.\n    \n*   [Build](build) — create artifacts\n    \n    The `snow snowpark build` command builds the Snowpark project as a `.zip` archive that can be used by the `snow snowpark deploy` command. The archive is built using only the `src` directory specified in the `snowflake.yml` file.\n    \n*   [Deploy](deploy) — create Snowflake objects\n    \n    The `snow snowpark deploy` command uploads local files to the specified stage and creates procedure and function objects defined in the project.\n    \n*   [Execute](execute) — use deployed procedures and functions\n    \n    The `snow snowpark execute` command executes deployed procedures and functions.\n    \n*   [Upload](upload) — upload already implemented Snowpark functions, procedures, and custom packages, such as from PyPi, in your projects.\n    \n    The `snow snowpark package` commands let you reuse existing packages.\n    \n*   [Manage](manage) — manage your Snowpark functions and procedures\n    \n    The `snow snowpark` and `snow object` commands let you create, list, execute, and delete Snowpark functions and procedures.\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)\n3.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",
    "category": "NULL",
    "last_scraped": "NULL",
    "content_hash": "eb0b39afc756f936f82e4362b2cfeaff154908eaedd9a3f2d5870d0319d44fbb",
    "id": "NULL",
    "full_command": "NULL",
    "title": "Using Snowpark in Snowflake CLI¶",
    "metadata": "NULL",
    "parent_command": "NULL"
  },
  {
    "raw_content": "# Using Snowflake Notebooks[¶](#using-snowflake-notebooks \"Link to this heading\")\n\nSnowflake CLI includes the following `snow notebook` commands that let you create and execute [Snowflake notebooks](../../../user-guide/ui-snowsight/notebooks) from the command line:\n\n*   [snow notebook create](../command-reference/notebook-commands/create)\n    \n*   [snow notebook deploy](../command-reference/notebook-commands/deploy)\n    \n*   [snow notebook execute](../command-reference/notebook-commands/execute)\n    \n*   [snow notebook get-url](../command-reference/notebook-commands/get-url)\n    \n*   [snow notebook open](../command-reference/notebook-commands/open)\n    \n*   [Snowflake notebooks](../../../user-guide/ui-snowsight/notebooks)\n    \n\n## Create a notebook[¶](#create-a-notebook \"Link to this heading\")\n\nNote\n\nBeginning with version 3.4.0, Snowflake CLI added the `snow notebook deploy` command to replace the `snow notebook create` command. To support backward compatibility, you can still create a notebook using the `snow notebook create` command, but Snowflake recommends that you begin using the new [Deploy and create a notebook](#label-cli-deploy-notebook) procedure.\n\nThe `snow notebook create` command creates a notebook from an existing notebook on stage. The command returns a link to the new notebook. The following example creates the MY\\_NOTEBOOK notebook from the specified staged notebook:\n\n```\nsnow notebook create MY_NOTEBOOK -f @MY_STAGE/path/to/notebook.ipynb\n\n```\n\nCopy\n\nThe command creates the notebook in the default warehouse defined for the connection. You can use the `--warehouse` option to specify an alternative warehouse or to specify one if the connection doesn’t define a default warehouse.\n\n## Deploy and create a notebook[¶](#deploy-and-create-a-notebook \"Link to this heading\")\n\nThe `snow notebook deploy` command uploads local files to a stage and creates a new Notebook object inside your chosen database and schema. Your project definition file should specify the main notebook file and query warehouse. The `--replace` option replaces the specified Notebook object if it already exists.\n\nEach notebook in Snowflake must include a `snowflake.yml` project definition file.\n\nThe following example shows a sample `snowflake.yml` notebook project definition file:\n\n```\ndefinition_version: 2\nentities:\n  my_notebook:\n    type: notebook\n    query_warehouse: xsmall\n    notebook_file: notebook.ipynb\n    runtime_environment_version: \"2025.07\"\n    artifacts:\n    - notebook.ipynb\n    - data.csv\n\n```\n\nCopy\n\nThe following table describes the properties of a notebook [project definition](../project-definitions/about):\n\n| Property | Definition |\n| --- | --- |\n| typerequired, string | Must be notebook. |\n| query_warehouserequired, string | Snowflake warehouse to host the notebook. |\n| notebook_filerequired, string | Path to the notebook file. |\n| artifactsrequired, string sequence | List of files uploaded to the stage. Notebook file should be included in this list. |\n| stage_pathoptional, string | Path to the stage where the artifacts will be stored. Default: notebooks/<notebook_id>. |\n| compute_pooloptional, string | Compute pool for a containerized notebook to use.NoteContainerized notebooks are currently in PuPr. |\n| runtime_nameoptional, string | Name of the Container Runtime for a containerized notebook to use. The following values are valid:SYSTEM$BASIC_RUNTIME for CPU runtimeSYSTEM$GPU_RUNTIME for GPU runtimeNoteContainerized notebooks are currently in PuPr. |\n| runtime_environment_versionoptional, string | Runtime environment version for a notebook entity in your project definition file.Notebook entity deployments will be rejected if both compute_pool and runtime_environment_version are specified in the configuration, leading to a validation failure.NoteThis field currently applies only to notebooks running on standard Snowflake warehouses, not those using compute pools (containerized notebooks). |\n| identifieroptional, string | Optional Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-notebook-id\nCopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (e.g., ’”My Notebook”’).Objectidentifier:\n  name: my-notebook-id\n  schema: my-schema # optional\n  database: my-db # optional\nCopyNoteAn error occurs if you specify a schema or database and use a fully qualified name in the name property (such as mydb.schema1.my-notebook). |\n\nThe following example uploads the files specified in your project definition file and creates a new notebook named `my_notebook`:\n\n```\nsnow notebook deploy my_notebook\n\n```\n\nCopy\n\n```\nUploading artifacts to @notebooks/my_notebook\n  Creating stage notebooks if not exists\n  Uploading artifacts\nCreating notebook my_notebook\nNotebook successfully deployed and available under https://snowflake.com/provider-deduced-from-connection/#/notebooks/DB.SCHEMA.MY_NOTEBOOK\n\n```\n\n## Execute a notebook[¶](#execute-a-notebook \"Link to this heading\")\n\nThe snow notebook execute command executes a notebook in headless mode. Currently, the command only returns a message indicating whether the notebook executed successfully.\n\n```\nsnow notebook execute MY_NOTEBOOK\n\n```\n\nCopy\n\n```\nNotebook MY_NOTEBOOK executed.\n\n```\n\nOn this page\n\n1.  [Create a notebook](#create-a-notebook)\n2.  [Deploy and create a notebook](#deploy-and-create-a-notebook)\n3.  [Execute a notebook](#execute-a-notebook)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/notebooks/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/notebooks/../command-reference/overview)\n3.  [snow notebook commands](/developer-guide/snowflake-cli/notebooks/../command-reference/notebook-commands/overview)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/notebooks/use-notebooks",
    "last_scraped": "NULL",
    "content_hash": "f894108eae812b1e9843f4a8906f29563a3496535a184a8ac4963d88ac6ac07e",
    "metadata": "NULL",
    "full_command": "NULL",
    "category": "NULL",
    "title": "Using Snowflake Notebooks¶",
    "parent_command": "NULL",
    "command_group": "NULL",
    "id": "NULL"
  },
  {
    "metadata": "NULL",
    "category": "NULL",
    "raw_content": "# Managing Streamlit apps with Snowflake CLI[¶](#managing-streamlit-apps-with-sf-cli \"Link to this heading\")\n\nFor Streamlit developers who currently use a local IDE development flow and a Git-backed continuous integration and deployment (CI/CD) collaboration workflow, switching to in-browser editing for [Streamlit in Snowflake](../../streamlit/about-streamlit) can be difficult. Snowflake CLI gives developers critical and familiar tooling to integrate SiS into their current development flow.\n\nUsing Snowflake CLI, developers can now easily deploy apps from a CLI and perform operations efficiently without requiring any SQL knowledge. Without Snowflake CLI, Streamlit app developers had to deploy locally developed apps to the Snowflake infrastructure by executing SQL commands and copying local files to a stage. Now, these app developers can use whichever method they prefer.\n\nYou can perform the following operations when managing Streamlit apps:\n\n*   [Creating a Streamlit app](manage-apps/initialize-app)\n    \n*   [Deploying a Streamlit app](manage-apps/deploy-app)\n    \n*   [Retrieving the URL for a Streamlit app](manage-apps/get-url)\n    \n*   [Share a Streamlit app](manage-apps/share-app)\n    \n*   [Managing Streamlit apps](manage-apps/manage-app)\n    \n\nFor more information about Streamlit apps in Native Apps, see [Add a Streamlit app](../../native-apps/adding-streamlit).\n\nRelated content\n\n1.  [About Streamlit in Snowflake](/developer-guide/snowflake-cli/streamlit-apps/../../streamlit/about-streamlit)",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/overview",
    "title": "Managing Streamlit apps with Snowflake CLI¶",
    "command_group": "NULL",
    "id": "NULL",
    "parent_command": "NULL",
    "full_command": "NULL",
    "content_hash": "2c322c760742b33ca2f897c69aee3892682e4c9c032db5ec1669ec42fa0cdf7a"
  },
  {
    "full_command": "NULL",
    "id": "NULL",
    "title": "Using Snowflake Native App in Snowflake CLI¶",
    "raw_content": "# Using Snowflake Native App in Snowflake CLI[¶](#using-native-app-in-sf-cli \"Link to this heading\")\n\nSnowflake Native App developers can now initiate their own Snowflake Native App code repository from an existing git template, create and deploy their application package and application instance within minutes, and drop these objects once they are done verifying this behavior — all through the Snowflake CLI without requiring any SQL knowledge.\n\nDevelopers no longer need to keep track of different platforms for performing uploads to stage or creating Snowflake objects, and will have an easier time with their local development of a Snowflake Native App.\n\nBefore you can get started with the CLI commands, here are a few new concepts you will find useful:\n\n*   [About Snowflake Native App projects](about-projects)\n    \n*   [Project definition files](project-definitions)\n    \n*   [Creating and managing Snowflake Native App objects](create-manage-apps)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [About Snowflake Native App projects](/developer-guide/snowflake-cli/native-apps/about-projects)\n3.  [Project definition files](/developer-guide/snowflake-cli/native-apps/project-definitions)\n4.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)\n5.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)\n6.  [Opening an app in a browser](/developer-guide/snowflake-cli/native-apps/open-app)\n7.  [Publishing a Snowflake Native App to customers](/developer-guide/snowflake-cli/native-apps/publish-app)\n8.  [Dropping Snowflake Native App objects](/developer-guide/snowflake-cli/native-apps/drop-objects)\n9.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",
    "last_scraped": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/overview",
    "metadata": "NULL",
    "content_hash": "11025c315ea4100f867f6f0635562d8bbec7458f92c09e656793f9423793964c",
    "parent_command": "NULL",
    "category": "NULL"
  },
  {
    "raw_content": "# Executing SQL statements[¶](#executing-sql-statements \"Link to this heading\")\n\nThe [snow sql](../command-reference/sql-commands/sql) command lets you execute ad-hoc SQL queries or files containing SQL queries using the following options:\n\n*   To execute an ad-hoc query, use the `-q` command-line option. For example, to execute a simple SQL SELECT query, as shown in the following example:\n    \n    ```\n    snow sql -q \"SELECT * FROM FOO;\"\n    \n    ```\n    \n    Copy\n    \n*   To execute a file containing a SQL query, use the `-f` command-line option to specify the path to the file. For example, to execute a file containing a SQL query, as shown in the following example:\n    \n    ```\n    snow sql -f my_query.sql\n    \n    ```\n    \n    Copy\n    \n\nThe `snow sql` command also can execute multiple statements; in that case, multiple result sets are returned. For example running:\n\n```\nsnow sql  -q \"select 'a', 'b'; select 'c', 'd';\"\n\n```\n\nCopy\n\nresults in the following output:\n\n```\nselect 'a', 'b';\n+-----------+\n| 'A' | 'B' |\n|-----+-----|\n| a   | b   |\n+-----------+\n\nselect 'c', 'd';\n+-----------+\n| 'C' | 'D' |\n|-----+-----|\n| c   | d   |\n+-----------+\n\n```\n\nYou can also execute [scripting blocks](../../snowflake-scripting/running-examples) in Snowflake CLI with a caveat relating to the `$$` delimiter.\n\nFor example:\n\n```\nEXECUTE IMMEDIATE $$\n-- Snowflake Scripting code\nDECLARE\n  radius_of_circle FLOAT;\n  area_of_circle FLOAT;\nBEGIN\n  radius_of_circle := 3;\n  area_of_circle := pi() * radius_of_circle * radius_of_circle;\n  RETURN area_of_circle;\nEND;\n$$\n;\n\n```\n\nCopy\n\nSome operating systems interpret `$$`, such as a process ID (PID), instead of recognizing it as a scripting block delimiter. To address this limitation, you can use the following alternatives:\n\n> *   If you still want to specify the scripting block on the command line, you can escape the `$$` delimiters, as in `\\$\\$`.\n>     \n> *   You can also put the scripting block with the default `$$` delimiters into a separate file and call it with the `snow sql -f <filename>` command.\n>     \n\nFor more information, see the [snow sql](../command-reference/sql-commands/sql) command.\n\n## Using variables for SQL templates[¶](#using-variables-for-sql-templates \"Link to this heading\")\n\nIn certain situations, you might want to change your SQL queries based on the context. The `snow sql` command supports client-side variable substitution that lets you use variables in the command that are resolved locally before submitting the query. Variables in the SQL string take the form `<% variable_name %>`, and the `-D` (or `--variable`) option specifies the value of the variable.\n\n> Note\n> \n> You can currently use the SnowSQL `&variable_name` and `<% variable_name %>` syntax for templates. However, Snowflake recommends using the `<% variable_name %>` syntax.\n\nFor example, to specify a database using a client-side variable, you can enter a command similar to the following:\n\n```\nsnow sql -q \"select * from <% database %>.logs\" -D \"database=dev\"\n\n```\n\nCopy\n\nWhen executed, the command substitutes the value `dev` in the `<% database %>` variable to create the `dev.logs` filename and then sends the `select * from dev.logs` SQL query to Snowflake for processing.\n\nYou can also specify multiple variable inputs, as shown:\n\n```\nsnow sql \\\n-q \"grant usage on database <% database %> to <% role %>\" \\\n-D \"database=dev\" \\\n-D \"role=eng_rl\"\n\n```\n\nCopy\n\nThis example generates the following SQL query:\n\n```\ngrant usage on database dev to eng_rl\n\n```\n\nCopy\n\nThe `--enable-templating` option lets you specify which templating syntaxes are resolved in a SQL query. Snowflake CLI supports the following syntaxes:\n\n*   `STANDARD`: Support the standard Snowflake CLI variable syntax (`<% variable_name %>`). Enabled by default.\n    \n*   `LEGACY`: Support the SnowSQL variable syntax (`&{ variable_name }` or `&variable_name`). Enabled by default.\n    \n*   `JINJA`: Support the jinja variable syntax (`{{ variable_name }}`). Disabled by default.\n    \n*   `ALL`: Allow all supported syntaxes. Disabled by default.\n    \n*   `NONE`: Do not support templating. Disabled by default.\n    \n\nThe following examples illustrate different ways to support templating:\n\n*   Disable templating, so that neither of the query variables is resolved:\n    \n    ```\n    snow sql --enable-templating NONE -q \"select '<% not_resolved %> &not_resolved'\"\n    \n    ```\n    \n    Copy\n    \n*   Allow JINJA and STANDARD templating, while disallowing LEGACY templating:\n    \n    ```\n    snow sql --enable-templating JINJA --enable-templating STANDARD -q \"select '<% resolved %> {{ resolved }} &not_resolved'\"\n    \n    ```\n    \n    Copy\n    \n*   Enable all syntaxes, so the SQL query resolves all three syntaxes:\n    \n    ```\n    snow sql --enable-templating ALL -q \"select '<% resolved %> {{ resolved }}'\"\n    snow sql --enable-templating ALL -q \"select '&resolved {{ resolved }}'\"\n    \n    ```\n    \n    Copy\n    \n\nNote\n\nJINJA variables, if enabled, are resolved after STANDARD and LEGACY variables.\n\n## Storing variables in the `snowflake.yml` project definition file[¶](#storing-variables-in-the-snowflake-yml-project-definition-file \"Link to this heading\")\n\nSpecifying variables as `snow sql` command-line options might not always be practical, or perhaps you might not want to specify sensitive values on the command line. In such cases, you can define variables and values in the `snowflake.yml` project definition file. Then you can just specify the variable names in the form `<% ctx.env.<variable_name> %>` instead of using the `-D \"<variable> = <value>\"` option.\n\nUsing the example from the previous section, you could store the database and role variables in `snowflake.yml` file and change the query to:\n\n```\nsnow sql -q \"grant usage on database <% ctx.env.database %> to <% ctx.env.role %>\"\n\n```\n\nCopy\n\nIn this example, the `snow sql` command looks for the variable definitions in the project definition file and extracts the values without making them visible on the command line. The `snowflake.yml` file should be located either in the current working directory or in the location specified with the `-p` option.\n\nFor more information about storing these values in the project definition file, see [Use variables in SQL](../project-definitions/use-sql-variables).\n\n## Executing SQL queries asynchronously[¶](#executing-sql-queries-asynchronously \"Link to this heading\")\n\nSnowflake CLI lets you execute one or more SQL queries asynchronously. Instead of waiting for a result, the `snow sql` command schedules the queries at Snowflake and returns a query ID. After a query finishes, you can get the result using the [!result](#label-snowcli-sql-query-result-cmd) query command or the SQL [RESULT\\_SCAN](../../../sql-reference/functions/result_scan) command.\n\nTo execute a SQL query asynchronously, end the query with `;>` instead of `;`, as shown:\n\n```\nsnow sql -q 'select \"My async query\" ;>'\n\n```\n\nCopy\n\nThe following example executes a single query asynchronously:\n\n```\nsnow sql -q \"select 'This is async query';>\"\n\n```\n\nCopy\n\n```\nselect 'This is async query'\n+--------------------------------------+\n| scheduled query ID                   |\n|--------------------------------------|\n| 01bc3011-080f-f2d7-0001-c1be14bae7c2 |\n+--------------------------------------+\n\n```\n\nYou can then use the returned query ID in the [!result](#label-snowcli-sql-query-result-cmd) query command to display the query result:\n\n```\nsnow sql -q '!result 01bc3011-080f-f2d7-0001-c1be14bae7c2'\n\n```\n\nCopy\n\n```\npath-to-private-key-file\n+-----------------------+\n| 'THIS IS ASYNC QUERY' |\n|-----------------------|\n| This is async query   |\n+-----------------------+\n\n```\n\nYou can also execute multiple queries in the query string, both asynchronously and synchronously, as shown:\n\n```\nsnow sql -q \"select 'This is async query';> select 'Not an async query'; select 'Another async query';>\"\n\n```\n\nCopy\n\n```\nselect 'This is async query'\n+--------------------------------------+\n| scheduled query ID                   |\n|--------------------------------------|\n| 01bc3b8c-0109-2e81-0000-0f2d0e5a4a32 |\n+--------------------------------------+\n\nselect 'Not an async query';\n+----------------------+\n| 'NOT AN ASYNC QUERY' |\n|----------------------|\n| Not an async query   |\n+----------------------+\n\nselect 'Another async query'\n+--------------------------------------+\n| scheduled query ID                   |\n|--------------------------------------|\n| 01bc3b8c-0109-2e81-0000-0f2d0e5a4a36 |\n+--------------------------------------+\n\n```\n\n## Working with SQL query commands[¶](#working-with-sql-query-commands \"Link to this heading\")\n\nSnowflake CLI provides the following commands that you can use inside your SQL queries:\n\n*   [!source](#label-snowcli-sql-query-source-cmd), which executes SQL in local files or URLs.\n    \n*   [!queries](#label-snowcli-sql-query-queries-cmd), which lists all SQL queries.\n    \n*   [!result](#label-snowcli-sql-query-result-cmd), which displays the result of a SQL query.\n    \n*   [!abort](#label-snowcli-sql-query-abort-cmd), which aborts an active SQL query.\n    \n*   [!edit](#label-snowcli-sql-query-edit-cmd), which opens an external editor to modify and execute SQL commands.\n    \n\nTip\n\nIf you enclose your SQL query in double quotes (`\"\"`) instead of single quotes (`''`), you might need to escape the exclamation point (`!`) based on which shell you use.\n\n### Execute SQL in local files or URLs[¶](#execute-sql-in-local-files-or-urls \"Link to this heading\")\n\nYou can use the `!source` query command in your SQL query to execute SQL in local files or a URL-based file. For example, the following command executes all SQL commands in a local file named `my_sql_code.sql`:\n\n```\nsnow sql -q '!source my_sql_code.sql'\n\n```\n\nCopy\n\nYou can also nest `!source` commands in the SQL files, such as:\n\n```\nselect emp_id FROM employees;\n!source code_file_2.sql\n\n```\n\nCopy\n\nIn this example, the command executes the SELECT query and then executes the SQL commands in the `code_file_2.sql` file. Before executing `!source` queries, Snowflake CLI does the following:\n\n*   Evaluates variable substitutions and templates.\n    \n*   Reads the contents of all nested files to ensure that no recursion occurs.\n    \n\nWhen the variables and templates are resolved and no recursion is detected, the command sends the code to Snowflake for execution.\n\nNote\n\nIf you use double quotes (`\"\"`) instead of single quotes (`''`) around a `!source` query, you might need to escape the `!` (`\\!`) depending on which shell you use.\n\nThe following examples illustrate different ways you can execute source files.\n\n*   Execute code in a local file.\n    \n    This example assumes you have a simple query in a local SQL file.\n    \n    ```\n    cat code_to_execute.sql\n    \n    ```\n    \n    Copy\n    \n    ```\n    select 73;\n    \n    ```\n    \n    To execute the code in the file, enter the following command:\n    \n    ```\n    snow sql -q '!source code_to_execute.sql'\n    \n    ```\n    \n    Copy\n    \n    ```\n    select 73;\n    +----+\n    | 73 |\n    |----|\n    | 73 |\n    +----+\n    \n    ```\n    \n*   Execute code in a URL-based file.\n    \n    This example assumes you have the same simple query in a SQL file at a URL.\n    \n    To execute the code in the file, enter the following command:\n    \n    ```\n    snow sql -q '!source https://trusted-host/trusted-content.sql'\n    \n    ```\n    \n    Copy\n    \n    ```\n    select 73;\n    +----+\n    | 73 |\n    |----|\n    | 73 |\n    +----+\n    \n    ```\n    \n*   Execute code that uses variable substitution and templating.\n    \n    This example assumes you have a query in a local SQL file that uses a template variable.\n    \n    ```\n    cat code_with_variable.sql\n    \n    ```\n    \n    Copy\n    \n    ```\n    select '<% ctx.env.Message %>';\n    \n    ```\n    \n    To execute the code in the file, enter the following command that defines the variable value:\n    \n    ```\n    snow sql -q '!source code_&value.sql;' -D value=with_variable --env Message='Welcome !'\n    \n    ```\n    \n    Copy\n    \n    ```\n    select 'Welcome !';\n    +-------------+\n    | 'WELCOME !' |\n    |-------------|\n    | Welcome !   |\n    +-------------+\n    \n    ```\n    \n\nNote\n\nThe `!source` command supports the legacy `!load` alias.\n\n### List all SQL queries[¶](#list-all-sql-queries \"Link to this heading\")\n\nThe `!queries` query command lists all queries for an account. By default, the command lists the 25 most recent queries executed in the current session.\n\nFor example, the following `!queries` query command returns the three most recent queries for a specific user:\n\n> ```\n> snow sql -q '!queries user=user1 amount=3'\n> \n> ```\n> \n> Copy\n> \n> ```\n> +-------------------------------------------------------------------------------------------------------------------------------------+\n> | QUERY ID                             | SQL TEXT                                                           | STATUS    | DURATION_MS |\n> |--------------------------------------+--------------------------------------------------------------------+-----------+-------------|\n> | 01bc3040-080f-f4f9-0001-c1be14bb603a | select current_version();                                          | SUCCEEDED | 3858        |\n> | 01bc303d-080f-f4e9-0001-c1be14bb1812 | SELECT SYSTEM$CANCEL_QUERY('01bc3011-080f-f2d7-0001-c1be14bae7c2') | SUCCEEDED | 564         |\n> | 01bc3011-080f-f2d7-0001-c1be14bae7c2 | select 'This is async query'                                       | SUCCEEDED | 931         |\n> +-------------------------------------------------------------------------------------------------------------------------------------+\n> \n> ```\n\nYou can use the following filters to narrow the list of returned queries:\n\n| Filter | Default | Description |\n| --- | --- | --- |\n| amount (integer) | 25 | Number of recent queries to return (default: 25). |\n| session (boolean) | N/A | If provided, return only queries executed in the current session. |\n| warehouse (string) | None | Return queries executed only on the specified warehouse. |\n| user (string) | None | Return queries executed only by the specified user. |\n| duration (milliseconds) | 0 | Return only queries that took at least the specified number of milliseconds. |\n| start_date (string) | None | Return only queries executed after the specified date. Date is expected to be provided in ISO format (for example 2025-01-01T09:00:00) |\n| end_date (string) | None | Return only queries executed before the specified date. Date is expected to be provided in ISO format (for example 2025-01-01T09:00:00) |\n| start (integer) | None | Return only queries executed after the specified Unix timestamp (in milliseconds). |\n| end (integer) | None | Return only queries executed before the specified Unix timestamp (in milliseconds). |\n| status (enum) | None | Return only queries in one of the following statuses:RUNNINGSUCCEEDEDFAILEDBLOCKEDQUEUEDABORTED |\n| type | None | Return only queries of one of the following types:SELECTINSERTUPDATEDELETEMERGEMULTI_TABLE_INSERTCOPYCOMMITROLLBACKBEGIN_TRANSACTIONSHOWGRANTCREATEALTER |\n\nThe following examples return queries using different filters:\n\n*   Return the 25 most recent queries executed in the current session:\n    \n    ```\n    snow sql -q 'select 42; select 15; !queries session'\n    \n    ```\n    \n    Copy\n    \n*   Return the 20 most recent queries executed in the account:\n    \n    ```\n    snow sql -q '!queries amount=20'\n    \n    ```\n    \n    Copy\n    \n*   Return the 20 most recent queries executed in the account that took longer than 200 milliseconds to run:\n    \n    ```\n    snow sql -q '!queries amount=20 duration=200'\n    \n    ```\n    \n    Copy\n    \n*   Return the 25 most recent queries executed in the specified warehouse:\n    \n    ```\n    snow sql -q '!queries warehouse=mywh'\n    \n    ```\n    \n    Copy\n    \n\n### Return a completed SQL query result[¶](#return-a-completed-sql-query-result \"Link to this heading\")\n\nThe `!result` query command returns the result of a completed query, given its query ID. You can obtain the query ID in the following ways:\n\n*   Check the [Query History page](../../../user-guide/ui-snowsight-activity) in Snowsight.\n    \n*   Run the `!queries` SQL query command.\n    \n*   Use the ID returned by an [asynchronous query](#label-snowcli-sql-async).\n    \n\n```\nsnow sql -q '!result 01bc3011-080f-f2d7-0001-c1be14bae7c2'\n\n```\n\nCopy\n\n```\n+-----------------------+\n| 'THIS IS ASYNC QUERY' |\n|-----------------------|\n| This is async query   |\n+-----------------------+\n\n```\n\n### Abort an active SQL query[¶](#abort-an-active-sql-query \"Link to this heading\")\n\nThe `!abort` query command aborts an active query, given its query ID. You can obtain the query ID in the following ways:\n\n*   Check the [Query History page](../../../user-guide/ui-snowsight-activity) in Snowsight.\n    \n*   Run the `!queries` SQL query command.\n    \n*   Use the ID returned by an [asynchronous query](#label-snowcli-sql-async).\n    \n\n```\nsnow sql -q '!abort 01bc3011-080f-f2d7-0001-c1be14bae7c2'\n\n```\n\nCopy\n\n```\n+-------------------------------------------------------------+\n| SYSTEM$CANCEL_QUERY('01BC3011-080F-F2D7-0001-C1BE14BAE7C2') |\n|-------------------------------------------------------------|\n| Identified SQL statement is not currently executing.        |\n+-------------------------------------------------------------+\n\n```\n\n### Open an external editor to modify and execute SQL commands[¶](#open-an-external-editor-to-modify-and-execute-sql-commands \"Link to this heading\")\n\nThe `!edit` query command opens an external editor where you can modify SQL commands to execute when you exit the editor. The editor is specified in the `EDITOR` environment variable or, if the environment variable is not set, the default system editor is used.\n\nTo enter commands in an external editor, follow these steps:\n\n1.  If not already defined in your shell, set the `EDITOR` environment variable to your preferred text editor.\n    \n2.  Enter the `snow sql` command:\n    \n    ```\n    snow sql\n    \n    ```\n    \n    Copy\n    \n3.  At the `>` prompt, enter the `!edit` command:\n    \n    ```\n    > !edit\n    \n    ```\n    \n    Copy\n    \n    The command opens the specified text editor.\n    \n4.  Enter your SQL commands in the editor, as shown:\n    \n    ```\n    SELECT current_user() ;\n    \n    ```\n    \n    Copy\n    \n5.  Save the file and exit the editor.\n    \n    The commands you entered are displayed, as shown:\n    \n    ```\n    ✓ Edited SQL loaded into prompt. Modify as needed or press Enter to execute.\n    > select current_user();\n    \n    ```\n    \n6.  To execute the commands, select `ENTER`.\n    \n    The command output is displayed, as shown:\n    \n    ```\n    +----------------+\n    | CURRENT_USER() |\n    |----------------|\n    | USER1          |\n    +----------------+\n    \n    ```\n    \n\n## Entering multiple commands in a single transaction[¶](#entering-multiple-commands-in-a-single-transaction \"Link to this heading\")\n\nThe `--single-transaction` option lets you enter multiple SQL commands to execute as an all-or-nothing set of commands. By executing commands in a single transaction, you can ensure that all of the commands are completed successfully before committing any of the changes. If any of the commands fail, none of the changes from the successful commands persist.\n\nThe following examples show successful and unsuccessful transactions:\n\n*   Successful command execution\n    \n    ```\n    snow sql -q \"insert into my_tbl values (123); insert into my_tbl values (124);\" --single-transaction\n    \n    ```\n    \n    Copy\n    \n    ```\n    BEGIN;\n    +----------------------------------+\n    | status                           |\n    |----------------------------------|\n    | Statement executed successfully. |\n    +----------------------------------+\n    \n    insert into my_tbl values (123);\n    +-------------------------+\n    | number of rows inserted |\n    |-------------------------|\n    | 1                       |\n    +-------------------------+\n    \n    insert into my_tbl values (124);\n    +-------------------------+\n    | number of rows inserted |\n    |-------------------------|\n    | 1                       |\n    +-------------------------+\n    \n    COMMIT\n    +----------------------------------+\n    | status                           |\n    |----------------------------------|\n    | Statement executed successfully. |\n    +----------------------------------+\n    \n    ```\n    \n    You can then verify that the commands were committed to the database:\n    \n    ```\n    snow sql -q \"select count(*) from my_tbl\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    select count(*) from my_tbl\n    +----------+\n    | COUNT(*) |\n    |----------|\n    | 2        |\n    +----------+\n    \n    ```\n    \n*   Unsuccessful single transaction\n    \n    ```\n    snow sql -c patcli -q \"insert into my_tbl values (123); insert into my_tbl values (124); select BAD;\" --single-transaction\n    \n    ```\n    \n    Copy\n    \n    ```\n    BEGIN;\n    +----------------------------------+\n    | status                           |\n    |----------------------------------|\n    | Statement executed successfully. |\n    +----------------------------------+\n    \n    insert into my_tbl values (123);\n    +-------------------------+\n    | number of rows inserted |\n    |-------------------------|\n    | 1                       |\n    +-------------------------+\n    \n    insert into my_tbl values (124);\n    +-------------------------+\n    | number of rows inserted |\n    |-------------------------|\n    | 1                       |\n    +-------------------------+\n    \n    select BAD;\n    ╭─ Error ───────────────────────────────────────────────────────────────────────────────╮\n    │ 000904 (42000): 01bc3b84-0810-0247-0001-c1be14ee11ce: SQL compilation error: error    │\n    │ line 1 at position 7                                                                  │\n    │ invalid identifier 'BAD'                                                              │\n    ╰───────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n\n> You can then verify that the commands were not committed to the database:\n> \n> > ```\n> > snow sql -q \"select count(*) from my_tbl\"\n> > \n> > ```\n> > \n> > Copy\n> > \n> > ```\n> > select count(*) from my_tbl\n> > +----------+\n> > | COUNT(*) |\n> > |----------|\n> > | 0        |\n> > +----------+\n> > \n> > ```\n\n## Entering SQL commands in interactive mode[¶](#entering-sql-commands-in-interactive-mode \"Link to this heading\")\n\nThe `snow sql` command supports an interactive mode that lets you enter SQL commands one at a time. Interactive mode provides the following features:\n\n*   Syntax highlighting\n    \n    ![Interactive mode syntax highlighting](../../../_images/interactive-sql-syntax-highlight.png)\n    \n*   Code completion while typing\n    \n    ![Interactive mode code completion](../../../_images/interactive-sql-code-completion.png)\n    \n*   Searchable history\n    \n    Pressing CTRL\\-R: lets you search your command history:\n    \n    ![Interactive mode searchable history](../../../_images/interactive-sql-history.png)\n    \n*   Multi-line input\n    \n    Pressing ENTER on a line that does not end with a semicolon (`;`) moves the cursor to the next line for more commands until a statement ends with a semicolon.\n    \n    ![Interactive mode multi-line input](../../../_images/interactive-sql-multiline.png)\n    \n\nTo use interactive mode, enter the `snow sql` command followed by ENTER, as shown:\n\n```\nsnow sql\n\n```\n\nCopy\n\nThe command opens a sub-shell with a `>` prompt where you can enter SQL commands interactively:\n\n```\n$ snow sql\n  ╭───────────────────────────────────────────────────────────────────────────────────╮\n  │ Welcome to Snowflake-CLI REPL                                                     │\n  │ Type 'exit' or 'quit' to leave                                                    │\n  ╰───────────────────────────────────────────────────────────────────────────────────╯\n  >\n\n```\n\nYou can then enter SQL commands, as shown:\n\n```\n> create table my_table (c1 int);\n\n```\n\nCopy\n\n```\n+-------------------------------------+\n| status                              |\n|-------------------------------------|\n| Table MY_TABLE successfully created.|\n+-------------------------------------+\n\n```\n\nNote\n\nYou must end each SQL statement with a semicolon (`;`).\n\nTo exit interactive mode, enter `exit`, `quit`, or CTRL\\-D.\n\nOn this page\n\n1.  [Using variables for SQL templates](#using-variables-for-sql-templates)\n2.  [Storing variables in the snowflake.yml project definition file](#storing-variables-in-the-snowflake-yml-project-definition-file)\n3.  [Executing SQL queries asynchronously](#executing-sql-queries-asynchronously)\n4.  [Working with SQL query commands](#working-with-sql-query-commands)\n5.  [Execute SQL in local files or URLs](#execute-sql-in-local-files-or-urls)\n6.  [List all SQL queries](#list-all-sql-queries)\n7.  [Return a completed SQL query result](#return-a-completed-sql-query-result)\n8.  [Abort an active SQL query](#abort-an-active-sql-query)\n9.  [Open an external editor to modify and execute SQL commands](#open-an-external-editor-to-modify-and-execute-sql-commands)\n10.  [Entering multiple commands in a single transaction](#entering-multiple-commands-in-a-single-transaction)\n11.  [Entering SQL commands in interactive mode](#entering-sql-commands-in-interactive-mode)\n\nRelated content\n\n1.  [snow sql](/developer-guide/snowflake-cli/sql/../command-reference/sql-commands/sql)\n2.  [SQL reference](/developer-guide/snowflake-cli/sql/../../../reference)",
    "metadata": "NULL",
    "title": "Executing SQL statements¶",
    "category": "NULL",
    "command_group": "NULL",
    "parent_command": "NULL",
    "content_hash": "6e6ff835bdadff3500bca7475bcb18feb24970a4c89c70f259120de9b015ea7f",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/sql/execute-sql",
    "last_scraped": "NULL",
    "full_command": "NULL"
  },
  {
    "parent_command": "NULL",
    "title": "Managing data pipelines in Snowflake CLI¶",
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/data-pipelines/data-pipelines",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "command_group": "NULL",
    "raw_content": "# Managing data pipelines in Snowflake CLI[¶](#managing-data-pipelines-in-sf-cli \"Link to this heading\")\n\n*   [Managing dbt Projects on Snowflake using Snowflake CLI](dbt-projects)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/data-pipelines/../index)",
    "id": "NULL",
    "content_hash": "c295cb24f1888363de169da239fc2cb6711e0a2c4623953f57bbf72e7a7a0ec8",
    "full_command": "NULL"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/cicd/integrate-ci-cd",
    "last_scraped": "NULL",
    "content_hash": "fc928df2bf4d42adfc491ee6547df3ceabc58e16f64207466a2fb0331719f307",
    "id": "NULL",
    "title": "Integrating CI/CD with Snowflake CLI¶",
    "raw_content": "# Integrating CI/CD with Snowflake CLI[¶](#integrating-ci-cd-with-sf-cli \"Link to this heading\")\n\nSnowflake CLI integrates popular CI/CD (continuous integration and continuous delivery) systems and frameworks, such as [GitHub Actions](https://github.com/features/actions), to efficiently automate your Snowflake workflows for SQL, Snowpark, Native Apps, or Notebooks.\n\nThe following illustration shows a typical CI/CD workflow in Snowflake CLI.\n\n![Snowflake CI/CD workflow](../../../_images/cli-cicd-devops-flow.png)\n\n## CI/CD workflow steps[¶](#ci-cd-workflow-steps \"Link to this heading\")\n\n1.  **Store:** Configure a remote Git repository to manage your Snowflake files securely.\n    \n2.  **Code:** Develop your Snowflake code using an IDE or Snowsight, tailored to your preferences.\n    \n3.  **Install:** [Install](../installation/installation) Snowflake CLI, and provision your preferred CI/CD provider, such as GitHub Actions.\n    \n4.  **Deploy:** Automate deployment by combining the Snowflake CLI with your selected CI/CD tool.\n    \n5.  **Monitor:** Track code and workflow performance in Snowflake using [Snowflake Trail](https://www.snowflake.com/en/product/features/snowflake-trail/) for real-time insights.\n    \n6.  **Iterate:** Apply small, frequent updates to your project for continuous improvement; smaller changes simplify management and rollback, if necessary.\n    \n\n## CI/CD with GitHub Actions[¶](#ci-cd-with-github-actions \"Link to this heading\")\n\nA Snowflake CLI action is a GitHub action designed to integrate Snowflake CLI into CI/CD pipelines. You can use it to automate execution of Snowflake CLI commands within your GitHub workflows. For more information, see the [snowflake-cli-action](https://github.com/snowflakedb/snowflake-cli-action) repository.\n\n## Using Snowflake CLI actions[¶](#using-sf-cli-actions \"Link to this heading\")\n\nGithub Actions streamlines the process of installing and using Snowflake CLI in your CI/CD workflows. The CLI is installed in an isolated way, ensuring that it won’t conflict with the dependencies of your project. It automatically sets up the input configuration file within the `~/.snowflake/` directory.\n\nThe action enables automation of your Snowflake CLI tasks, such as deploying Snowflake Native Apps or running Snowpark scripts within your Snowflake environment.\n\n### Input parameters[¶](#input-parameters \"Link to this heading\")\n\nA Snowflake CLI action uses the following inputs from your Github workflow YAML file, such as `<repo-name>/.github/workflows/my-workflow.yaml`:\n\n*   `cli-version`: The specified Snowflake CLI version, such as `3.11.0`. If not provided, the latest version of the Snowflake CLI is used.\n    \n*   `custom-github-ref`: The branch, tag, or commit in the Github repository that you want to install Snowflake CLI directly from.\n    \n    Note\n    \n    You cannot use both `cli-version` and `custom-github-ref` together; specify only one of these parameters.\n    \n*   `default-config-file-path`: Path to the configuration file (`config.toml`) in your repository. The path must be relative to the root of the repository. The configuration file is not required when a temporary connection (`-x` option) is used. For more information, see [Managing Snowflake connections](../connecting/configure-connections).\n    \n*   `use-oidc`: Boolean flag to enable OIDC authentication. When set to `true`, the action configures the CLI to use GitHub’s OIDC token for authentication with Snowflake, eliminating the need for storing private keys as secrets. Default is `false`.\n    \n\n### Install Snowflake CLI from a GitHub branch or tag[¶](#install-sf-cli-from-a-github-branch-or-tag \"Link to this heading\")\n\n*   To install Snowflake CLI from a specific branch, tag, or commit in the GitHub repository (for example, to test unreleased features or a fork), use the following configuration:\n    \n\n```\n- uses: snowflakedb/snowflake-cli-action@v2.0\n  with:\n    custom-github-ref: \"feature/my-branch\" # or a tag/commit hash\n\n```\n\nCopy\n\nYou can also include other [input parameters](#label-cli-cicd-inputs).\n\nThis feature is available in snowflake-cli-action version 1.6 or later.\n\n### Safely configure the action in your CI/CD workflow[¶](#safely-configure-the-action-in-your-ci-cd-workflow \"Link to this heading\")\n\nYou can safely configure the action in your CI/CD workflow by using either of the following methods:\n\n*   [Use workload identity federation (WIF) OpenID Connect (OIDC) authentication](#label-cli-github-actions-oidc-auth)\n    \n*   [Use private key authentication](#label-cli-github-actions-private-key-auth)\n    \n\n#### Use workload identity federation (WIF) OpenID Connect (OIDC) authentication[¶](#use-workload-identity-federation-wif-openid-connect-oidc-authentication \"Link to this heading\")\n\nNote\n\nWIF OIDC authentication requires Snowflake CLI version 3.11.0 or later.\n\nWIF OIDC authentication provides a secure and modern way to authenticate with Snowflake without storing private keys as secrets. This approach uses GitHub’s OIDC (OpenID Connect) token to authenticate with Snowflake.\n\nTo set up WIF OIDC authentication, follow these steps:\n\n1.  Configure WIF OIDC by setting up a service user with the OIDC workload identity type:\n    \n    ```\n    CREATE USER <username>\n    TYPE = SERVICE\n    WORKLOAD_IDENTITY = (\n      TYPE = OIDC\n      ISSUER = 'https://token.actions.githubusercontent.com'\n      SUBJECT = '<your_subject>'\n    )\n    \n    ```\n    \n    Copy\n    \n\nNote\n\n> By default, your subject should look like `repo:<repository-owner/repository-name>:environment:<environment>`.\n\n*   To simplify generation of the subject, use `gh` command, where `<environment_name>` is the environment defined in your repository settings, as shown in the following example:\n    \n\n> ```\n> gh repo view <repository-owner/repository-name> --json nameWithOwner | jq -r '\"repo:\\(.nameWithOwner):environment:<environment_name>\"'\n> \n> ```\n> \n> Copy\n> \n> For more information about customizing your subject, see the [OpenID Connect](https://docs.github.com/en/actions/reference/security/oidc) reference on GitHub.\n\n1.  Store your Snowflake account identifier in GitHub secrets. For more information, see [GitHub Actions documentation](https://docs.github.com/en/actions/security-guides/using-secrets-in-github-actions#creating-secrets-for-a-repository).\n    \n2.  Configure the Snowflake CLI action in your GitHub workflow YAML file, as shown:\n    \n    ```\n    name: Snowflake OIDC\n    on: [push]\n    \n    permissions:\n      id-token: write  # Required for OIDC token generation\n      contents: read\n    \n    jobs:\n      oidc-job:\n        runs-on: ubuntu-latest\n        environment: test-env # this should match the environment used in the subject\n        steps:\n          - uses: actions/checkout@v4\n            with:\n              persist-credentials: false\n          - name: Set up Snowflake CLI\n            uses: snowflakedb/snowflake-cli-action@v2.0\n            with:\n              use-oidc: true\n              cli-version: \"3.11\"\n          - name: test connection\n            env:\n              SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n            run: snow connection test -x\n    \n    ```\n    \n    Copy\n    \n    For more information about setting up WIF OIDC authentication for your Snowflake account and configuring the GitHub OIDC provider, see [Workload identity federation](../../../user-guide/workload-identity-federation).\n    \n\n#### Use private key authentication[¶](#use-private-key-authentication \"Link to this heading\")\n\nTo use private key authentication, you need to store your Snowflake private key in GitHub secrets and configure the Snowflake CLI action to use it.\n\n1.  Store your Snowflake private key in GitHub secrets.\n    \n\nFor more information, see [GitHub Actions documentation](https://docs.github.com/en/actions/security-guides/using-secrets-in-github-actions#creating-secrets-for-a-repository).\n\n2.  Configure the Snowflake CLI action in your GitHub workflow YAML file, as shown:\n    \n    ```\n    name: Snowflake Private Key\n    on: [push]\n    \n    jobs:\n      private-key-job:\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v4\n            with:\n              persist-credentials: false\n          - name: Set up Snowflake CLI\n            uses: snowflakedb/snowflake-cli-action@v2.0\n    \n    ```\n    \n    Copy\n    \n\n## Defining connections[¶](#defining-connections \"Link to this heading\")\n\nYou can define a GitHub action to connect to Snowflake with a temporary connection or with a connection defined in your configuration file. For more information about managing connections, see [Managing Snowflake connections](../connecting/configure-connections).\n\n### Use a temporary connection[¶](#use-a-temporary-connection \"Link to this heading\")\n\nFor more information about temporary connections, see [Use a temporary connection](../connecting/configure-connections.html#label-snowcli-temporary-connection).\n\nTo set up your Snowflake credentials for a temporary connection, follow these steps:\n\n1.  Map secrets to environment variables in your GitHub workflow, in the form `SNOWFLAKE_<key>=<value>`, as shown:\n    \n    ```\n    env:\n      SNOWFLAKE_PRIVATE_KEY_RAW: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}\n      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n    \n    ```\n    \n    Copy\n    \n2.  Configure the Snowflake CLI action.\n    \n    If you use the latest version of Snowflake CLI, you do not need to include the `cli-version` parameter. The following example instructs the action to use Snowflake CLI version 3.11.0 specifically:\n    \n    ```\n    - uses: snowflakedb/snowflake-cli-action@v2.0\n      with:\n        cli-version: \"3.11.0\"\n    \n    ```\n    \n    Copy\n    \n3.  Optional: If your private key is encrypted, to set up a passphrase, set the PRIVATE\\_KEY\\_PASSPHRASE environment variable to the private key passphrase. Snowflake uses this passphrase to decrypt the private key. For example:\n    \n    ```\n    - name: Execute Snowflake CLI command\n      env:\n        PRIVATE_KEY_PASSPHRASE: ${{ secrets.PASSPHARSE }}\n    \n    ```\n    \n    Copy\n    \n    To use a password instead of a private key, unset the `SNOWFLAKE_AUTHENTICATOR` environment variable, and add the `SNOWFLAKE_PASSWORD` variable, as follows:\n    \n    ```\n    - name: Execute Snowflake CLI command\n      env:\n        SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}\n        SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n        SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}\n    \n    ```\n    \n    Copy\n    \n    Note\n    \n    To enhance your experience when using a password and MFA, Snowflake recommends that you [configure MFA caching](../connecting/configure-connections.html#label-snowcli-mfa-caching).\n    \n    For more information about setting Snowflake credentials in environment variables, see [Use environment variables for Snowflake credentials](../connecting/configure-connections.html#label-snowcli-environment-creds), and for information about defining environment variables within your GitHub CI/CD workflow, see [Defining environment variables for a single workflow](https://docs.github.com/en/actions/learn-github-actions/variables#defining-environment-variables-for-a-single-workflow).\n    \n4.  Add the `snow` commands you want to execute with the temporary connection, as shown:\n    \n    ```\n    run: |\n      snow --version\n      snow connection test --temporary-connection\n    \n    ```\n    \n    Copy\n    \n\nThe following example shows a completed sample `<repo-name>/.github/workflows/my-workflow.yaml` file:\n\n```\nname: deploy\non: [push]\n\njobs:\n  version:\n    name: \"Check Snowflake CLI version\"\n    runs-on: ubuntu-latest\n    steps:\n      # Snowflake CLI installation\n      - uses: snowflakedb/snowflake-cli-action@v2.0\n\n        # Use the CLI\n      - name: Execute Snowflake CLI command\n        env:\n          SNOWFLAKE_AUTHENTICATOR: SNOWFLAKE_JWT\n          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}\n          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n          SNOWFLAKE_PRIVATE_KEY_RAW: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}\n          PRIVATE_KEY_PASSPHRASE: ${{ secrets.PASSPHARSE }} # Passphrase is only necessary if private key is encrypted.\n        run: |\n          snow --help\n          snow connection test -x\n\n```\n\nCopy\n\nAfter verifying that your action can connect to Snowflake successfully, you can add more Snowflake CLI commands like `snow notebook create` or `snow git execute`. For information about supported commands, see [Snowflake CLI command reference](../command-reference/overview).\n\n### Use a configuration file[¶](#use-a-configuration-file \"Link to this heading\")\n\nFor more information about defining connections, see [Define connections](../connecting/configure-connections.html#label-snowcli-define-connections).\n\nTo set up your Snowflake credentials for a specific connection, follow these steps:\n\n1.  Create a `config.toml` file at the root of your Git repository with an empty configuration connection, as shown:\n    \n    ```\n    default_connection_name = \"myconnection\"\n    \n    [connections.myconnection]\n    \n    ```\n    \n    Copy\n    \n    This file serves as a template and should not contain actual credentials.\n    \n2.  Map secrets to environment variables in your GitHub workflow, in the form `SNOWFLAKE_<key>=<value>`, as shown:\n    \n    ```\n    env:\n      SNOWFLAKE_CONNECTIONS_MYCONNECTION_PRIVATE_KEY_RAW: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}\n      SNOWFLAKE_CONNECTIONS_MYCONNECTION_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n    \n    ```\n    \n    Copy\n    \n3.  Configure the Snowflake CLI action.\n    \n    If you use the latest version of Snowflake CLI, you do not need to include the `cli-version` parameter. The following example specifies a desired version and the name of your default configuration file:\n    \n    ```\n    - uses: snowflakedb/snowflake-cli-action@v2.0\n      with:\n        cli-version: \"3.11.0\"\n        default-config-file-path: \"config.toml\"\n    \n    ```\n    \n    Copy\n    \n4.  Optional: If your private key is encrypted, to set up a passphrase, set the PRIVATE\\_KEY\\_PASSPHRASE environment variable to the private key passphrase. Snowflake uses this passphrase to decrypt the private key. For example:\n    \n    ```\n    - name: Execute Snowflake CLI command\n      env:\n        PRIVATE_KEY_PASSPHRASE: ${{ secrets.PASSPHARSE }}\n    \n    ```\n    \n    Copy\n    \n    To use a password instead of a private key, unset the `SNOWFLAKE_AUTHENTICATOR` environment variable, and add the `SNOWFLAKE_PASSWORD` variable, as follows:\n    \n    ```\n    - name: Execute Snowflake CLI command\n      env:\n        SNOWFLAKE_CONNECTIONS_MYCONNECTION_USER: ${{ secrets.SNOWFLAKE_USER }}\n        SNOWFLAKE_CONNECTIONS_MYCONNECTION_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n        SNOWFLAKE_CONNECTIONS_MYCONNECTION_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}\n    \n    ```\n    \n    Copy\n    \n    Note\n    \n    To enhance your experience when using a password and MFA, Snowflake recommends that you [configure MFA caching](../connecting/configure-connections.html#label-snowcli-mfa-caching).\n    \n5.  Add the `snow` commands you want to execute with a named connection, as shown:\n    \n    ```\n    run: |\n      snow --version\n      snow connection test\n    \n    ```\n    \n    Copy\n    \n\nThe following example shows a sample `config.toml` file in your Git repository and a completed sample `<repo-name>/.github/workflows/my-workflow.yaml` file:\n\n*   Sample `config.toml` file:\n    \n    ```\n    default_connection_name = \"myconnection\"\n    \n    [connections.myconnection]\n    \n    ```\n    \n    Copy\n    \n*   Sample Git workflow file:\n    \n    ```\n    name: deploy\n    on: [push]\n    jobs:\n      version:\n        name: \"Check Snowflake CLI version\"\n        runs-on: ubuntu-latest\n        steps:\n          # Checkout step is necessary if you want to use a config file from your repo\n          - name: Checkout repo\n            uses: actions/checkout@v4\n            with:\n              persist-credentials: false\n    \n            # Snowflake CLI installation\n          - uses: snowflakedb/snowflake-cli-action@v2.0\n            with:\n              default-config-file-path: \"config.toml\"\n    \n            # Use the CLI\n          - name: Execute Snowflake CLI command\n            env:\n              SNOWFLAKE_CONNECTIONS_MYCONNECTION_AUTHENTICATOR: SNOWFLAKE_JWT\n              SNOWFLAKE_CONNECTIONS_MYCONNECTION_USER: ${{ secrets.SNOWFLAKE_USER }}\n              SNOWFLAKE_CONNECTIONS_MYCONNECTION_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n              SNOWFLAKE_CONNECTIONS_MYCONNECTION_PRIVATE_KEY_RAW: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}\n              PRIVATE_KEY_PASSPHRASE: ${{ secrets.PASSPHARSE }} #Passphrase is only necessary if private key is encrypted.\n            run: |\n              snow --help\n              snow connection test\n    \n    ```\n    \n    Copy\n    \n\nAfter verifying that your action can connect to Snowflake successfully, you can add more Snowflake CLI commands like `snow notebook create` or `snow git execute`. For information about supported commands, see [Snowflake CLI command reference](../command-reference/overview).\n\nOn this page\n\n1.  [CI/CD workflow steps](#ci-cd-workflow-steps)\n2.  [CI/CD with GitHub Actions](#ci-cd-with-github-actions)\n3.  [Using Snowflake CLI actions](#using-sf-cli-actions)\n4.  [Defining connections](#defining-connections)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/cicd/../index)",
    "full_command": "NULL",
    "command_group": "NULL",
    "parent_command": "NULL",
    "metadata": "NULL",
    "category": "NULL"
  },
  {
    "title": "Snowflake CLI command reference¶",
    "full_command": "NULL",
    "content_hash": "60239ba000514eb9f03101a8dcba70326cafadd4462402457221e9cb5175af5a",
    "metadata": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/overview",
    "id": "NULL",
    "last_scraped": "NULL",
    "category": "NULL",
    "command_group": "NULL",
    "parent_command": "NULL",
    "raw_content": "# Snowflake CLI command reference[¶](#sf-cli-command-reference \"Link to this heading\")\n\nSnowflake CLI supports commands for the following objects and activities:\n\n*   [snow](snow) command\n    \n*   Bootstrap commands\n    \n    *   [snow bootstrap commands](bootstrap-commands/overview)\n        \n*   Connection commands\n    \n    *   [snow connection commands](connection-commands/overview)\n        \n*   Cortex commands\n    \n    *   [snow cortex commands](cortex-commands/overview)\n        \n*   Git commands\n    \n    *   [snow git commands](git-commands/overview)\n        \n*   Helpers commands\n    \n    *   [snow helpers commands](helpers-commands/overview)\n        \n*   Logs commands\n    \n    *   [snow logs commands](logs-commands/overview)\n        \n*   Notebook commands\n    \n    *   [snow notebook commands](notebook-commands/overview)\n        \n*   Snowflake Native App Framework commands\n    \n    *   [snow app commands](native-apps-commands/overview)\n        \n*   Snowflake objects commands\n    \n    *   [snow object commands](object-commands/overview)\n        \n*   Snowpark commands\n    \n    *   [snow snowpark commands](snowpark-commands/overview)\n        \n    *   [snow snowpark package commands](snowpark-commands/package-commands/overview)\n        \n*   Snowpark Container Services (spcs) commands\n    \n    *   [snow spcs image-registry commands](spcs-commands/image-registry-commands/overview)\n        \n    *   [snow spcs image-repository commands](spcs-commands/image-repository-commands/overview)\n        \n    *   [snow spcs compute-pool commands](spcs-commands/compute-pool-commands/overview)\n        \n    *   [snow spcs service commands](spcs-commands/service-commands/overview)\n        \n*   SQL commands\n    \n    *   [snow sql commands](sql-commands/overview)\n        \n*   Stage commands\n    \n    *   [snow stage commands](stage-commands/overview)\n        \n*   Streamlit commands\n    \n    *   [snow streamlit commands](streamlit-commands/overview)\n        \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/../index)"
  },
  {
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/connecting/configure-connections",
    "content_hash": "9c7a6a49f3090bde1dc76854207ff15db4c889d3d9567644e329c54d06bc2df6",
    "metadata": "NULL",
    "command_group": "NULL",
    "full_command": "NULL",
    "raw_content": "# Managing Snowflake connections[¶](#managing-snowflake-connections \"Link to this heading\")\n\nBefore you can use Snowflake CLI, you must define connections, which specify how Snowflake CLI connects to Snowflake. Snowflake CLI uses the following precedence hierarchy to determine which value to use when a connection parameter is defined in multiple locations:\n\n*   Command-line parameters\n    \n*   Environment variables overriding specific `config.toml` parameters, such as `SNOWFLAKE_CONNECTIONS_MYCONNECTION_PASSWORD`\n    \n*   Connections defined in `config.toml` file manually or using `snow connection add` command\n    \n*   Generic environment variables, such as `SNOWFLAKE_USER`.\n    \n\nYou can also use the `--temporary-connection` option, which does not require defining it in `config.toml`.\n\nCaution\n\nFor improved security, Snowflake strongly recommends using either `SNOWFLAKE_CONNECTIONS_<NAME>_PASSWORD` or `SNOWFLAKE_PASSWORD` environment variable.\n\n## Define connections[¶](#define-connections \"Link to this heading\")\n\nConnection definitions are stored in the `[connections]` section of the `config.toml` file, similar to the following block of code:\n\n```\n[connections.myconnection]\naccount = \"myaccount\"\nuser = \"jondoe\"\npassword = \"password\"\nwarehouse = \"my-wh\"\ndatabase = \"my_db\"\nschema = \"my_schema\"\n\n```\n\nCopy\n\nConnection definitions support the same configuration options as the [Snowflake Connector for Python](../../python-connector/python-connector-api.html#label-snowflake-connector-methods-connect). Additionally, you can specify a default connection in the `default_connection_name` variable at the top of the file. You cannot include it within a connection definition. For example:\n\n```\ndefault_connection_name = \"myconnection\"\n\n[connections.myconnection]\naccount = \"myaccount\"\n...\n\n```\n\nCopy\n\nNote\n\nFor MacOS and Linux systems, Snowflake CLI requires the `config.toml` file to limit its file permissions to read and write for the file owner only. To set the file required file permissions execute the following commands:\n\n```\nchown $USER config.toml\nchmod 0600 config.toml\n\n```\n\nCopy\n\n### Alternative configuration file[¶](#alternative-configuration-file \"Link to this heading\")\n\nNote\n\nFor Snowflake CLI, Snowflake recommends that you use the `config.toml` file for configuration definitions. However, you can use the `connections.toml` file, if desired.\n\nSnowflake CLI also supports the `connections.toml` configuration file. The file should be placed in the same directory as the `config.toml` file, and it should contain only connections. Configurations in `connections.toml` require a different section name, without `connections`. For example, `[connections.myconnection]` would be just `[myconnection]`.\n\nNote\n\nIf both the `config.toml` and `connections.toml` configurations contain connections, Snowflake CLI uses only configurations from `connections.toml`.\n\n## Manage or add your connections to Snowflake with the `snow connection` commands[¶](#manage-or-add-your-connections-to-snowflake-with-the-snow-connection-commands \"Link to this heading\")\n\nThe `snow connection` commands let you create, manage, and test Snowflake connections.\n\n### Add a connection[¶](#add-a-connection \"Link to this heading\")\n\nNote\n\nIf you need to add a connection for Snowflake Open Catalog, see [Create a Snowflake CLI connection for Open Catalog](https://other-docs.snowflake.com/opencatalog/sso-configure-open-catalog#create-a-snowflake-cli-connection-for-open-catalog) in the Open Catalog documentation. You might need to add this connection for tasks like configuring Open Catalog to use SSO.\n\nTo create a new connection and add it to the [configuration file](configure-cli.html#label-cli-config-locations), do the following:\n\n1.  Execute the `snow connection add` command:\n    \n    > ```\n    > snow connection add\n    > \n    > ```\n    > \n    > Copy\n    \n2.  When prompted, supply the required connection, account, and username parameters, as well as any other desired optional parameters.\n    \n    > ```\n    > Enter connection name: <connection_name>\n    > Enter account: <account>\n    > Enter user: <user-name>\n    > Enter password: <password>\n    > Enter role: <role-name>\n    > Enter warehouse: <warehouse-name>\n    > Enter database: <database-name>\n    > Enter schema: <schema-name>\n    > Enter host: <host-name>\n    > Enter port: <port-number>\n    > Enter region: <region-name>\n    > Enter authenticator: <authentication-method>\n    > Enter private key file: <path-to-private-key-file>\n    > Enter token file path: <path-to-mfa-token>\n    > Do you want to configure key pair authentication? [y/N]: y\n    > Key length [2048]: <key-length>\n    > Output path [~/.ssh]: <path-to-output-file>\n    > Private key passphrase: <key-description>\n    > Wrote new connection <connection-name> to config.toml\n    > \n    > ```\n    \n\nYou can also add values for specific parameters on the command line, as shown:\n\n```\nsnow --config-file config.toml connection add -n myconnection2 --account myaccount2 --user jdoe2\n\n```\n\nCopy\n\nNote\n\nIf the command finishes with an error, such as if the `--private_key_file` option references a non-existing file, the connection is not saved in the `config.toml` configuration file.\n\nBy default, the `snow connection add` command prompts for optional parameters if they are not specified on the command line. If you want to add connections without specifying some optional parameter, like `account`, and skip the interactive prompts, you can use the `--no-interactive` option, as shown:\n\n```\nsnow connection add -n myconnection2 --user jdoe2 --no-interactive\n\n```\n\nCopy\n\nAfter adding a connection, you can [test the connection](#label-cli-test-connection) to make sure it works correctly.\n\n### List defined connections[¶](#list-defined-connections \"Link to this heading\")\n\nTo list the available connections, enter the `snow connection list` command, as shown:\n\n```\nsnow connection list\n\n```\n\nCopy\n\n```\n+-------------------------------------------------------------------------------------------------+\n| connection_name | parameters                                                       | is_default |\n|-----------------+------------------------------------------------------------------+------------|\n| myconnection    | {'account': 'myaccount', 'user': 'jondoe', 'password': '****',   | False      |\n|                 | 'database': 'my_db', 'schema': 'my_schema', 'warehouse':         |            |\n|                 | 'my-wh'}                                                         |            |\n| myconnection2   | {'account': 'myaccount2', 'user': 'jdoe2'}                       | False      |\n+-------------------------------------------------------------------------------------------------+\n\n```\n\n### Test and diagnose a connection[¶](#test-and-diagnose-a-connection \"Link to this heading\")\n\nTo test whether a connection can successfully connect to Snowflake, enter the `snow connection test` command, similar to the following:\n\n```\nsnow connection test -c myconnection2\n\n```\n\nCopy\n\n```\n+--------------------------------------------------+\n| key             | value                          |\n|-----------------+--------------------------------|\n| Connection name | myconnection2                  |\n| Status          | OK                             |\n| Host            | example.snowflakecomputing.com |\n| Account         | myaccount2                     |\n| User            | jdoe2                          |\n| Role            | ACCOUNTADMIN                   |\n| Database        | not set                        |\n| Warehouse       | not set                        |\n+--------------------------------------------------+\n\n```\n\nIf you encounter connectivity issues, you can run diagnostics directly within Snowflake CLI. Snowflake Support might also request this information to help you with connectivity issues.\n\nThe diagnostics collection uses the following `snow connection test` command options:\n\n*   `--enable-diag` to generate a diagnostic report.\n    \n*   `--diag-log-path` to specify the absolute path for the generated report.\n    \n*   `--diag-allowlist-path` to specify the absolute path to a JSON file containing the output of the SYSTEM$ALLOWLIST() or SYSTEM$ALLOWLIST\\_PRIVATELINK() SQL commands. This option is required only if the user defined in the connection does not have permission to run the system allowlist functions or if connecting to the account URL fails.\n    \n\nThe following example generates a diagnostic report for the `myconnection2` connection and stores in the `~/report/SnowflakeConnectionTestReport.txt` file:\n\n```\nsnow connection test -c myconnection2 --enable-diag --diag-log-path $(HOME)/report\n\n```\n\nCopy\n\n```\n+----------------------------------------------------------------------------+\n| key                  | value                                               |\n|----------------------+-----------------------------------------------------|\n| Connection name      | myconnection2                                       |\n| Status               | OK                                                  |\n| Host                 | example.snowflakecomputing.com                      |\n| Account              | myaccount2                                          |\n| User                 | jdoe2                                               |\n| Role                 | ACCOUNTADMIN                                        |\n| Database             | not set                                             |\n| Warehouse            | not set                                             |\n| Diag Report Location | /Users/<username>/SnowflakeConnectionTestReport.txt |\n+----------------------------------------------------------------------------+\n\n```\n\nYou can review the report for any connectivity issues and discuss them with your network team. You can also provide the report to Snowflake Support for additional assistance.\n\n### Remove a connection[¶](#remove-a-connection \"Link to this heading\")\n\nYou can use the `snow connection remove` command to delete a specific connection, similar to the following:\n\n```\nsnow connection remove bad_connection\n\n```\n\nCopy\n\n```\nRemoved connection bad_connection from /Users/jdoe/.snowflake/config.toml.\n\n```\n\n### Set the default connection[¶](#set-the-default-connection \"Link to this heading\")\n\nYou can use the `snow connection set-default` command to specify which configuration Snowflake CLI should use as the default, overriding the `default_connection_name` configuration file and `SNOWFLAKE_DEFAULT_CONNECTION_NAME` variables, if set.\n\nThe following example sets the default connection to `myconnection2`:\n\n```\nsnow connection set-default myconnection2\n\n```\n\nCopy\n\n```\nDefault connection set to: myconnection2\n\n```\n\nNote\n\nIf both `connections.toml` and `config.toml` files are present, Snowflake CLI uses only connections defined in `connections.toml`.\n\n### Use environment variables for Snowflake credentials[¶](#use-environment-variables-for-snowflake-credentials \"Link to this heading\")\n\nYou can specify Snowflake credentials in system environment variables instead of in configuration files. You can use the following generic environment variables only to specify connection parameters:\n\n*   `SNOWFLAKE_ACCOUNT`\n    \n*   `SNOWFLAKE_USER`\n    \n*   `SNOWFLAKE_PASSWORD`\n    \n*   `SNOWFLAKE_DATABASE`\n    \n*   `SNOWFLAKE_SCHEMA`\n    \n*   `SNOWFLAKE_ROLE`\n    \n*   `SNOWFLAKE_WAREHOUSE`\n    \n*   `SNOWFLAKE_AUTHENTICATOR`\n    \n*   `SNOWFLAKE_PRIVATE_KEY_PATH`\n    \n*   `SNOWFLAKE_PRIVATE_KEY_RAW`\n    \n*   `SNOWFLAKE_SESSION_TOKEN`\n    \n*   `SNOWFLAKE_MASTER_TOKEN`\n    \n*   `SNOWFLAKE_TOKEN`\n    \n*   `SNOWFLAKE_TOKEN_FILE_PATH`\n    \n*   `SNOWFLAKE_OAUTH_CLIENT_ID`\n    \n*   `SNOWFLAKE_OAUTH_CLIENT_SECRET`\n    \n*   `SNOWFLAKE_OAUTH_AUTHORIZATION_URL`\n    \n*   `SNOWFLAKE_OAUTH_TOKEN_REQUEST_URL`\n    \n*   `SNOWFLAKE_OAUTH_REDIRECT_URI`\n    \n*   `SNOWFLAKE_OAUTH_SCOPE`\n    \n*   `SNOWFLAKE_OAUTH_DISABLE_PKCE`\n    \n*   `SNOWFLAKE_OAUTH_ENABLE_REFRESH_TOKENS`\n    \n*   `SNOWFLAKE_OAUTH_ENABLE_SINGLE_USE_REFRESH_TOKENS`\n    \n*   `SNOWFLAKE_CLIENT_STORE_TEMPORARY_CREDENTIAL`\n    \n*   `SNOWFLAKE_WORKLOAD_IDENTITY_PROVIDER`\n    \n\n### Pass connection parameters to the `snow` command[¶](#pass-connection-parameters-to-the-snow-command \"Link to this heading\")\n\nYou can pass connection parameters directly in every `snow` command that requires a connection. For a full list of connection configuration parameters, execute the `snow sql --help` command, as shown. Note that the output shows only the section with the connection configuration options.\n\n```\nsnow sql --help\n\n```\n\nCopy\n\n```\n╭─ Connection configuration ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n│ --connection,--environment             -c      TEXT     Name of the connection, as defined in your config.toml. Default: default.\n│ --host                                         TEXT     Host address for the connection. Overrides the value specified for the connection.\n│ --port                                         INTEGER  Port for the connection. Overrides the value specified for the connection.\n│ --account,--accountname                        TEXT     Name assigned to your Snowflake account. Overrides the value specified for the connection.\n│ --user,--username                              TEXT     Username to connect to Snowflake. Overrides the value specified for the connection.\n│ --password                                     TEXT     Snowflake password. Overrides the value specified for the connection.\n│ --authenticator                                TEXT     Snowflake authenticator. Overrides the value specified for the connection.\n│ --private-key-file,--private-key-path          TEXT     Snowflake private key file path. Overrides the value specified for the connection.\n│ --token                                        TEXT     OAuth token to use when connecting to Snowflake.\n│ --token-file-path                              TEXT     Path to file with an OAuth token that should be used when connecting to Snowflake.\n│ --database,--dbname                            TEXT     Database to use. Overrides the value specified for the connection.\n│ --schema,--schemaname                          TEXT     Database schema to use. Overrides the value specified for the connection.\n│ --role,--rolename                              TEXT     Role to use. Overrides the value specified for the connection.\n│ --warehouse                                    TEXT     Warehouse to use. Overrides the value specified for the connection.\n│ --temporary-connection                 -x               Uses connection defined with command-line parameters, instead of one defined in config.\n│ --mfa-passcode                                 TEXT     Token to use for multi-factor authentication (MFA).\n│ --oauth-client-id                              TEXT     Value of the client ID provided by the identity provider for Snowflake integration.\n│ --oauth-client-secret                          TEXT     Value of the client secret provided by the identity provider for Snowflake integration.\n│ --oauth-authorization-url                      TEXT     Identity provider endpoint supplying the authorization code to the driver.\n│ --oauth-token-request-url                      TEXT     Identity provider endpoint supplying the access tokens to the driver.\n│ --oauth-redirect-uri                           TEXT     URI to use for the authorization code.\n│ --oauth-scope                                  TEXT     Scope requested in the identity provider authorization request.\n│ --oauth-disable-pkce                                    Disables Proof Key for Code Exchange (PKCE). Default: False.\n│ --oauth-enable-refresh-tokens                           Enables a silent re-authentication when the actual access token becomes outdated. Default: False.\n│ --oauth-enable-single-use-refresh-tokens                Whether to opt in to single-use refresh token semantics. Default: False.\n│ --client-store-temporary-credential                     Store the temporary credential.\n│ --enable-diag                                           Run the python connector diagnostic test.\n│ --diag-log-path                                TEXT     Diagnostic report path.\n│ --diag-allowlist-path                          TEXT     Diagnostic report path to optional allowlist.\n╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n\n```\n\nCaution\n\nFor improved security, Snowflake strongly recommends using either `SNOWFLAKE_CONNECTIONS_<NAME>_PASSWORD` or `SNOWFLAKE_PASSWORD` environment variable.\n\n## Import connections from SnowSQL[¶](#import-connections-from-snowsql \"Link to this heading\")\n\nSnowflake CLI is an open-source command-line tool explicitly designed for developer-centric workloads in addition to SQL operations. Snowflake CLI is a more modern, robust, and efficient CLI client than legacy SnowSQL. In addition to executing SQL commands with Snowflake CLI, you can also execute commands for other Snowflake products like Streamlit in Snowflake, Snowpark Container Services, and Snowflake Native App Framework. Because new features and enhancements will be added only to Snowflake CLI, Snowflake recommends that you begin transitioning from SnowSQL to Snowflake CLI.\n\nTo import any existing connections defined in [SnowSQL](../../../user-guide/snowsql) into your Snowflake CLI `config.toml` configuration file, use the `snow helpers import-snowsql-connections` command.\n\nTo import SnowSQL connections, enter the `snow helpers import-snowsql-connections` command similar to the following code block that imports SnowSQL connections from the standard configuration file locations:\n\n```\nsnow helpers import-snowsql-connections\n\n```\n\nCopy\n\nAs the command processes the SnowSQL configuration files, it shows the progress and prompts for confirmation when a connection with the same name is already defined in the Snowflake CLI `config.toml` file:\n\n```\nSnowSQL config file [/etc/snowsql.cnf] does not exist. Skipping.\nSnowSQL config file [/etc/snowflake/snowsql.cnf] does not exist. Skipping.\nSnowSQL config file [/usr/local/etc/snowsql.cnf] does not exist. Skipping.\nTrying to read connections from [/Users/<user>/.snowsql.cnf].\nReading SnowSQL's connection configuration [connections.connection1] from [/Users/<user>/.snowsql.cnf]\nTrying to read connections from [/Users/<user>/.snowsql/config].\nReading SnowSQL's default connection configuration from [/Users/<user>/.snowsql/config]\nReading SnowSQL's connection configuration [connections.connection1] from [/Users/<user>/.snowsql/config]\nReading SnowSQL's connection configuration [connections.connection2] from [/Users/<user>/.snowsql/config]\nConnection 'connection1' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: Y\nConnection 'connection2' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: n\nConnection 'default' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: n\nSaving [connection1] connection in Snowflake CLI's config.\nConnections successfully imported from SnowSQL to Snowflake CLI.\n\n```\n\nFor more information about this command, see the [snow helpers import-snowsql-connections](../command-reference/helpers-commands/import-snowsql-connections) command reference.\n\nFor help with migrating from SnowSQL to Snowflake CLI, see [Migrating from SnowSQL to Snowflake CLI](../../../user-guide/snowsql-migrate).\n\n## Use a temporary connection[¶](#use-a-temporary-connection \"Link to this heading\")\n\nYou can also specify connection parameters from the command line using the `--temporary-connection [-x]` option. It ignores all definitions from the `config.toml`, using ones specified by command-line options instead. This approach can be helpful for CI/CD use cases when you don’t want to use a configuration file. When you use a temporary connection, Snowflake CLI ignores any connection variables defined in the `config.toml` file, but does still use any of the following [environment variables](#label-snowcli-environment-creds) you set:\n\n*   `SNOWFLAKE_ACCOUNT`\n    \n*   `SNOWFLAKE_USER`\n    \n*   `SNOWFLAKE_PASSWORD`\n    \n*   `SNOWFLAKE_DATABASE`\n    \n*   `SNOWFLAKE_SCHEMA`\n    \n*   `SNOWFLAKE_ROLE`\n    \n*   `SNOWFLAKE_WAREHOUSE`\n    \n*   `SNOWFLAKE_AUTHENTICATOR`\n    \n*   `SNOWFLAKE_PRIVATE_KEY_FILE`\n    \n*   `SNOWFLAKE_PRIVATE_KEY_RAW`\n    \n*   `SNOWFLAKE_PRIVATE_KEY_PATH`\n    \n*   `SNOWFLAKE_SESSION_TOKEN`\n    \n*   `SNOWFLAKE_MASTER_TOKEN`\n    \n*   `SNOWFLAKE_TOKEN_FILE_PATH`\n    \n*   `WORKLOAD_IDENTITY_PROVIDER`\n    \n\nThe following example shows how to create a temporary connection using a username and password. This example assumes you stored the password in the `SNOWFLAKE_PASSWORD` environment variable.\n\n```\nsnow sql -q \"select 42;\" --temporary-connection \\\n                           --account myaccount \\\n                           --user jdoe\n\n```\n\nCopy\n\n```\nselect 42;\n+----+\n| 42 |\n|----|\n| 42 |\n+----+\n\n```\n\nCaution\n\nFor improved security, Snowflake strongly recommends using either `SNOWFLAKE_CONNECTIONS_<NAME>_PASSWORD` or `SNOWFLAKE_PASSWORD` environment variable.\n\nFor additional security, you can use a [private key file](#label-snowcli-private-key) and store the path to your private key file in the `SNOWFLAKE_PRIVATE_KEY_FILE` environment variable, as shown:\n\n```\nSNOWFLAKE_ACCOUNT = \"account\"\nSNOWFLAKE_USER = \"user\"\nSNOWFLAKE_PRIVATE_KEY_FILE = \"/path/to/key.p8\"\n\n```\n\nCopy\n\nYou can then create a temporary connection without specifying the options, as shown:\n\n```\nsnow sql -q \"select 42\" --temporary-connection\n\n```\n\nCopy\n\n```\nselect 42;\n+----+\n| 42 |\n|----|\n| 42 |\n+----+\n\n```\n\nWhen using CI/CD pipelines with key pair authentication, you might not be able to access local private key files (`SNOWFLAKE_PRIVATE_KEY_FILE`). In this situation, you can store the private key in the `SNOWFLAKE_PRIVATE_KEY_RAW` environment variable, as shown:\n\n```\nSNOWFLAKE_ACCOUNT = \"account\"\nSNOWFLAKE_USER = \"user\"\nSNOWFLAKE_PRIVATE_KEY_RAW = \"-----BEGIN PRIVATE KEY-----...\"\n\n```\n\nCopy\n\nYou can then create a temporary connection without specifying the options, as shown:\n\n```\nsnow sql -q \"select 42\" --temporary-connection\n\n```\n\nCopy\n\n```\nselect 42;\n+----+\n| 42 |\n|----|\n| 42 |\n+----+\n\n```\n\nNote\n\nIf you use the `SNOWFLAKE_PRIVATE_KEY_RAW` environment variable, you should not also define `SNOWFLAKE_PRIVATE_KEY_FILE`.\n\n## Additional ways to authenticate your connection[¶](#additional-ways-to-authenticate-your-connection \"Link to this heading\")\n\nYou can also use the following methods to authenticate your connection to Snowflake:\n\n*   [Use a private key file for authentication](#label-snowcli-private-key)\n    \n*   [Use OAuth authentication](#label-snowcli-oauth)\n    \n*   [Use the OAuth 2.0 Authorization Code flow](#label-snowcli-oauth-code-flow)\n    \n*   [Use the OAuth 2.0 Client Credentials flow](#label-snowcli-oauth-client-flow)\n    \n*   [Use multi-factor authentication (MFA)](#label-snowcli-mfa)\n    \n*   [Use MFA caching](#label-snowcli-mfa-caching)\n    \n*   [Use SSO (single sign-on)](#label-snowcli-sso)\n    \n*   [Use an external browser](#label-snowcli-externalbrowser)\n    \n*   [Use PAT (Programmatic Access Token)](#label-snowcli-pat)\n    \n*   [Use workload identity federation (WIF)](#label-snowcli-wif)\n    \n\n### Use a private key file for authentication[¶](#use-a-private-key-file-for-authentication \"Link to this heading\")\n\nTo use private key file for authentication, your connection configuration requires you to set the `authenticator` parameter to `SNOWFLAKE_JWT` and provide path to file with your private key similar to the following:\n\n*   Specify the `--private_key-file` option in the `snow connection add` command, as shown:\n    \n    > ```\n    > snow connection add \\\n    >    --connection-name jwt \\\n    >    --authenticator SNOWFLAKE_JWT \\\n    >    --private-key-file ~/.ssh/sf_private_key.p8\n    > \n    > ```\n    > \n    > Copy\n    \n*   Use the configuration file:\n    \n    > ```\n    > [connections.jwt]\n    > account = \"my_account\"\n    > user = \"jdoe\"\n    > authenticator = \"SNOWFLAKE_JWT\"\n    > private_key_file = \"~/sf_private_key.p8\"\n    > \n    > ```\n    > \n    > Copy\n    \n\nFor more details on configuring key pair authentication, see [Key-pair authentication and key-pair rotation](../../../user-guide/key-pair-auth).\n\nSnowflake CLI looks for the private key in the connection parameters in the following order:\n\n1.  If `private_key_file` is specified, Snowflake CLI reads the key from the specified file path.\n    \n2.  If `private_key_path` is specified, Snowflake CLI reads the key from the specified file path.\n    \n3.  If `private_key_file` or `private_key_path` are not specified, Snowflake CLI reads the key directly from the `private_key_raw` parameter.\n    \n\nCaution\n\nIf you specify your private key in the `private_key_raw` parameter, Snowflake recommends using either the `SNOWFLAKE_CONNECTIONS_<NAME>_PRIVATE_KEY_RAW` or the `SNOWFLAKE_PRIVATE_KEY_RAW` environment variables for improved security.\n\nNote\n\nIf your private key is passphrase-protected, set the `PRIVATE_KEY_PASSPHRASE` environment variable to that passphrase.\n\n### Use OAuth authentication[¶](#use-oauth-authentication \"Link to this heading\")\n\nTo use connect using OAuth, you can do either of the following:\n\n*   Specify the `--token-file-path` option in the `snow connection add` command, as shown:\n    \n    ```\n    snow connection add --token-file-path \"my-token.txt\"\n    \n    ```\n    \n    Copy\n    \n*   In the `config.toml` file, set `authenticator = \"oauth\"`, and add the `token_file_path` parameter to the connection definition, as shown:\n    \n    ```\n    [connections.oauth]\n    account = \"my_account\"\n    user = \"jdoe\"\n    authenticator = \"oauth\"\n    token_file_path = \"my-token.txt\"\n    \n    ```\n    \n    Copy\n    \n\n### Use the OAuth 2.0 Authorization Code flow[¶](#use-the-oauth-2-0-authorization-code-flow \"Link to this heading\")\n\nThe OAuth 2.0 Authorization Code flow is a secure method for a client application to obtain an access token from an authorization server on behalf of a user, without revealing the user’s credentials. For more information about this flow and its parameters, see [Enable the OAuth 2.0 Authorization Code flow](../../python-connector/python-connector-connect.html#label-python-oauth-code-flow) in the Snowflake Connector for Python documentation.\n\nTo use the OAuth 2.0 Authorization Code flow, add a connection definition to your `config.toml` file similar to the following:\n\n```\n[connections.oauth]\nauthenticator = \"OAUTH_AUTHORIZATION_CODE\"\nuser = \"user\"\naccount = \"account\"\noauth_client_id = \"client_id\"\noauth_client_secret = \"client_secret\"\noauth_redirect_uri = \"http://localhost:8001/snowflake/oauth-redirect\"\noauth_scope = \"session:role:PUBLIC\"\n\n```\n\nCopy\n\n### Use the OAuth 2.0 Client Credentials flow[¶](#use-the-oauth-2-0-client-credentials-flow \"Link to this heading\")\n\nThe OAuth 2.0 Client Credentials flow provides a secure way for machine-to-machine (M2M) authentication, such as the Snowflake Connector for Python connecting to a backend service. Unlike the OAuth 2.0 Authorization Code flow, this method does not rely on any user-specific data. For more information about this flow and its parameters, see [Enable the OAuth 2.0 Client Credentials flow](../../python-connector/python-connector-connect.html#label-python-oauth-client-flow) in the Snowflake Connector for Python documentation.\n\nTo use the OAuth 2.0 Client Credentials flow, add a connection definition to your `config.toml` file similar to the following:\n\n```\n[connections.oauth]\nauthenticator = \"OAUTH_CLIENT_CREDENTIALS\"\nuser = \"user\"\naccount = \"account\"\noauth_client_id = \"client_id\"\noauth_client_secret = \"client_secret\"\noauth_token_request_url = \"http://identity.provider.com/token\"\noauth_scope = \"session:role:PUBLIC\"\n\n```\n\nCopy\n\n### Use multi-factor authentication (MFA)[¶](#use-multi-factor-authentication-mfa \"Link to this heading\")\n\nTo use MFA:\n\n1.  Set up [multi-factor authentication](../../../user-guide/security-mfa) in Snowflake and set the `authenticator` parameter to `snowflake` (which is a default value).\n    \n2.  If you want to use a Duo-generated passcode instead of the push mechanism, use either the `--mfa-passcode <passcode>` option or set `passcode_in_password = true` in the `config.toml` file and include the passcode in your password as described in [Using MFA with Python](../../../user-guide/security-mfa.html#label-security-mfa-python).\n    \n    Note\n    \n    If you want use the passcode in the password for authentication, after executing the first `snow` command, you can no longer provide the passcode as long as the token in valid. You must do the following:\n    \n    *   Remove the passcode from the password.\n        \n    *   Remove or comment the `passcode_in_password = true` in the `config.toml` file.\n        \n    \n\n### Use MFA caching[¶](#use-mfa-caching \"Link to this heading\")\n\nMFA caching is a security feature that reduces the frequency of Multi-Factor Authentication (MFA) prompts during logins. Frequent MFA prompts can disrupt workflow and decrease productivity. MFA caching addresses this issue by securely storing MFA session information for a specified period. Using MFA caching lets you authenticate without repeatedly entering MFA codes, as long as they are within the cached session’s timeframe.\n\nTo enable MFA caching:\n\n1.  For your account, set `ALLOW_CLIENT_MFA_CACHING = true`.\n    \n2.  In your `config.toml` file, add `authenticator = \"username_password_mfa\"` to your connection.\n    \n\nFor more information, see [Using MFA token caching to minimize the number of prompts during authentication — optional](../../../user-guide/security-mfa.html#label-mfa-token-caching).\n\n### Use SSO (single sign-on)[¶](#use-sso-single-sign-on \"Link to this heading\")\n\nIf you have [configured Snowflake to use single sign-on (SSO)](../../../user-guide/admin-security-fed-auth-overview), you can configure your client application to use SSO for authentication. See [Using SSO with client applications that connect to Snowflake](../../../user-guide/admin-security-fed-auth-use.html#label-sso-with-command-line-clients) for details and configure your connection using the instructions for Python.\n\n### Use an external browser[¶](#use-an-external-browser \"Link to this heading\")\n\nYou can use your browser to authenticate your Snowflake CLI connection with any SAML 2.0 compliant identity provider (IdP), such as Okta or Active Directory Federation Services.\n\nNote\n\nThe `externalbrowser` authenticator is only supported in terminal windows that have web browser access. For example, a terminal window on a remote machine accessed through a SSH (Secure Shell) session might require additional setup to open a web browser.\n\nIf you don’t have access to a web browser, but your IdP is Okta, you can use native Okta by setting the authenticator to `https://<okta_account_name>.okta.com`.\n\nTo use external browser authentication, use one of the following methods:\n\n*   Use the `snow connection add --authenticator` command option:\n    \n    ```\n    snow connection add --authenticator externalbrowser\n    \n    ```\n    \n    Copy\n    \n*   Set `authenticator` to `externalbrowser` in your `config.toml` file:\n    \n    ```\n    [connections.externalbrowser]\n    account = \"my_account\"\n    user = \"jdoe\"\n    authenticator = \"externalbrowser\"\n    \n    ```\n    \n    Copy\n    \n\n### Use PAT (Programmatic Access Token)[¶](#use-pat-programmatic-access-token \"Link to this heading\")\n\nProgrammatic Access Token (PAT) is a Snowflake-specific authentication method. The feature must be enabled for the account before usage (see the [Prerequisites](../../../user-guide/programmatic-access-tokens.html#label-pat-prerequisites) for more information). Authentication with PAT doesn’t involve any human interaction.\n\nTo use PAT with the connection, set `authenticator` to `PROGRAMMATIC_ACCESS_TOKEN` and `token_file_path` to point the file with token, as shown:\n\n```\n[connections.externalbrowser]\naccount = \"my_account\"\nuser = \"jdoe\"\nauthenticator = \"PROGRAMMATIC_ACCESS_TOKEN\"\ntoken_file_path = \"path-to-pat-token\"\n\n```\n\nCopy\n\nFor more information about PATs, see [Using programmatic access tokens for authentication](../../../user-guide/programmatic-access-tokens).\n\n### Use workload identity federation (WIF)[¶](#use-workload-identity-federation-wif \"Link to this heading\")\n\nWorkload identity federation (WIF) is a feature that allows you to use your CI/CD environment’s identity to authenticate to Snowflake without the need for static credentials. This is particularly useful in automated workloads, where you want to minimize the risk of credential exposure.\n\nFor more information, see [Workload identity federation](../../../user-guide/workload-identity-federation).\n\n#### Set up WIF connections[¶](#set-up-wif-connections \"Link to this heading\")\n\nTo set up a WIF connection, you need to create a service account in Snowflake using the following steps:\n\n1.  Create a service user in Snowflake with the proper WORKLOAD\\_IDENTITY:\n    \n\n> ```\n> CREATE USER <username>\n> WORKLOAD_IDENTITY = (\n>   TYPE = <WIF type>\n>   // ...\n> )\n> TYPE = SERVICE\n> DEFAULT_ROLE = PUBLIC;\n> \n> ```\n> \n> Copy\n\n1.  Configure a connection in Snowflake CLI using either of the following methods\n    \n    *   Add the connection to the `config.toml` file\n        \n        > ```\n        > [connections.my_wif_conn]\n        > account = \"my_account\"\n        > authenticator = \"WORKLOAD_IDENTITY\"\n        > workload_identity_provider = \"<provider type>\"\n        > \n        > ```\n        > \n        > Copy\n        \n    *   Use the `snow connection add` command:\n        \n        ```\n        snow connection add \\\n         --connection-name my_wif_conn \\\n         --account <account>\n         --authenticatior WORKLOAD_IDENTITY \\\n         --workload-identity-provider <provider type>\n        \n        ```\n        \n        Copy\n        \n\nwhere:\n\n> `<provider type>` is one of the following:\n> \n> *   AWS\n>     \n> *   AZURE\n>     \n> *   GCP\n>     \n> *   OIDC\n>     \n\nNote\n\nWhen using OIDC as a provider, you need to retrieve the token from your environment and provide it to cli. You can provide retrieved token via\n\n*   `--token` parameter\n    \n*   `SNOWFLAKE_TOKEN` environment variable\n    \n*   `SNOWFLAKE_CONNECTIONS_<connection_name>_TOKEN` environment variable\n    \n*   `token_file_path` in your `config.toml` file\n    \n\nFor more information, see [Using Snowflake CLI actions](../cicd/integrate-ci-cd.html#label-cli-use-sf-actions).\n\n#### Connect to Snowflake using a temporary WIF connection[¶](#connect-to-snowflake-using-a-temporary-wif-connection \"Link to this heading\")\n\nTo connect to Snowflake using a [temporary connection](#label-snowcli-temporary-connection), you can use the following command:\n\n```\nsnow sql -x \\\n--authenticator WORKLOAD_IDENTITY \\\n--workload-identity-provider AWS \\\n--account <my_account> \\\n-q 'select current_user()'\n\nselect current_user();\n+----------------+\n| CURRENT_USER() |\n|----------------|\n| <user name>    |\n+----------------+\n\n```\n\nCopy\n\nOn this page\n\n1.  [Define connections](#define-connections)\n2.  [Alternative configuration file](#alternative-configuration-file)\n3.  [Manage or add your connections to Snowflake with the snow connection commands](#manage-or-add-your-connections-to-snowflake-with-the-snow-connection-commands)\n4.  [Add a connection](#add-a-connection)\n5.  [List defined connections](#list-defined-connections)\n6.  [Test and diagnose a connection](#test-and-diagnose-a-connection)\n7.  [Remove a connection](#remove-a-connection)\n8.  [Set the default connection](#set-the-default-connection)\n9.  [Use environment variables for Snowflake credentials](#use-environment-variables-for-snowflake-credentials)\n10.  [Pass connection parameters to the snow command](#pass-connection-parameters-to-the-snow-command)\n11.  [Import connections from SnowSQL](#import-connections-from-snowsql)\n12.  [Use a temporary connection](#use-a-temporary-connection)\n13.  [Additional ways to authenticate your connection](#additional-ways-to-authenticate-your-connection)\n14.  [Use a private key file for authentication](#use-a-private-key-file-for-authentication)\n15.  [Use OAuth authentication](#use-oauth-authentication)\n16.  [Use the OAuth 2.0 Authorization Code flow](#use-the-oauth-2-0-authorization-code-flow)\n17.  [Use the OAuth 2.0 Client Credentials flow](#use-the-oauth-2-0-client-credentials-flow)\n18.  [Use multi-factor authentication (MFA)](#use-multi-factor-authentication-mfa)\n19.  [Use MFA caching](#use-mfa-caching)\n20.  [Use SSO (single sign-on)](#use-sso-single-sign-on)\n21.  [Use an external browser](#use-an-external-browser)\n22.  [Use PAT (Programmatic Access Token)](#use-pat-programmatic-access-token)\n23.  [Use workload identity federation (WIF)](#use-workload-identity-federation-wif)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/connecting/../index)\n2.  [Configuring Snowflake CLI and connecting to Snowflake](/developer-guide/snowflake-cli/connecting/connect)\n3.  [Configuring Snowflake CLI](/developer-guide/snowflake-cli/connecting/configure-cli)\n4.  [snow connection commands](/developer-guide/snowflake-cli/connecting/../command-reference/connection-commands/overview)",
    "id": "NULL",
    "category": "NULL",
    "parent_command": "NULL",
    "title": "Managing Snowflake connections¶"
  },
  {
    "title": "snow init¶",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/bootstrap-commands/init",
    "full_command": "snow bootstrap init",
    "content_hash": "42da6217c6bd426d98c8ba8aa9cd22a4c8cd70c8d062da5d5f6dcb8d684347a3",
    "command_group": "NULL",
    "parent_command": "snow bootstrap",
    "metadata": "NULL",
    "category": "NULL",
    "id": "NULL",
    "raw_content": "# snow init[¶](#snow-init \"Link to this heading\")\n\nCreates project directory from template.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow init\n  <path>\n  --template <template>\n  --template-source <template_source>\n  --variable <variables>\n  --no-interactive\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_path_`\n\nDirectory to be initialized with the project. This directory must not already exist.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--template _TEXT_`\n\nwhich template (subdirectory of –template-source) should be used. If not provided, whole source will be used as the template.\n\n`--template-source _TEXT_`\n\nlocal path to template directory or URL to git repository with templates. Default: [https://github.com/snowflakedb/snowflake-cli-templates](https://github.com/snowflakedb/snowflake-cli-templates).\n\n`--variable, -D _TEXT_`\n\nString in `key=value` format. Provided variables will not be prompted for.\n\n`--no-interactive`\n\nDisable prompting. Default: False.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow init` command initializes a directory specified in the `<path>` parameter with a chosen template. It renders all files mentioned in the `files_to_render` list in the `template.yml`, resolving all variables enclosed in `<! … !>`. If a `template.yml` file is not present in the template’s root directory, the command finishes with an error. For information about creating project templates, see [Bootstrapping a project from a template](../../bootstrap-project/bootstrap).\n\nBy default, the command interactively prompts you for each parameter defined in the `template.yml` file. You can bypass the interactive prompts in the following ways:\n\n*   Use the `-D` option to specify the values for each parameter contained in the project template.\n    \n*   Use the `--no-interactive` option to use default values, if defined, for each template parameter in the `template.yml` file.\n    \n*   Use a combination of the `-D` and `--no-interactive` options to define values for some parameters and use the specified default values for the template.\n    \n    Note\n    \n    If you do not provide a value using the `-D` option that does not have a corresponding default value defined, the snow init command terminates with an error.\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   Bootstrap a Snowpark project that prompts for the parameters specified in the `example_snowpark` template contained in the [snowflake-cli-templates Git repository](https://github.com/snowflakedb/snowflake-cli-templates/).\n    \n    ```\n    snow init new_snowpark_project --template example_snowpark\n    \n      Project identifier (used to determine artifacts stage path) [my_snowpark_project]:\n      What stage should the procedures and functions be deployed to? [dev_deployment]: snowpark\n    \n    ```\n    \n    Copy\n    \n    ```\n    Initialized the new project in new_snowpark_project\n    \n    ```\n    \n*   Bootstrap a Streamlit project by using the `-D` option to provide the values for some of the parameters specified in the local `../local_templates/example_streamlit` template and prompt for others.\n    \n    ```\n    snow init new_streamlit_project --template-source ../local_templates/example_streamlit -D query_warehouse=dev_wareshouse -D stage=testing\n    \n      Name of the streamlit app [streamlit_app]: My streamlit\n    \n    ```\n    \n    Copy\n    \n    ```\n    Initialized the new project in new_streamlit_project\n    \n    ```\n    \n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/bootstrap-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/bootstrap-commands/overview)"
  },
  {
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/specify-entities",
    "parent_command": "NULL",
    "content_hash": "88a2a4636ba10665055c05b93dbae23b1b6f3a190335aa4a0db2c15013740f58",
    "full_command": "NULL",
    "metadata": "NULL",
    "command_group": "NULL",
    "title": "Specify entities¶",
    "last_scraped": "NULL",
    "raw_content": "# Specify entities[¶](#specify-entities \"Link to this heading\")\n\nIn the `snowflake.yml` definition file, you can specify multiple entities. Each entity is identified by a unique key. The example below specifies two entities with the `entity_a` and `entity_b` keys:\n\n```\nentities:\n  entity_a:\n    ...\n  entity_b:\n    ...\n\n```\n\nCopy\n\nEach entity has to specify a type. Currently supported types include:\n\n*   [function](about.html#label-snowcli-func-proc-properties)\n    \n*   [procedure](about.html#label-snowcli-func-proc-properties)\n    \n*   [streamlit](../streamlit-apps/manage-apps/initialize-app.html#label-snowcli-streamlit-project-definition)\n    \n*   [application package](../native-apps/project-definitions)\n    \n*   [application](../native-apps/project-definitions)\n    \n\n## Entity identifiers[¶](#entity-identifiers \"Link to this heading\")\n\nYou can specify multiple entities of the same type in the `snowflake.yml` file. You can name entities in the following ways:\n\n*   Use a unique key in the entities list.\n    \n    The following example shows using `entity_a` and `entity_b` as the unique keys:\n    \n    ```\n    entities:\n      entity_a:\n        ...\n      entity_b:\n        ...\n    \n    ```\n    \n    Copy\n    \n*   Specify an `identifier` name to each entity.\n    \n    The following example adds identifier names to the `entity_a` and `entity_b` entities:\n    \n    ```\n    entities:\n      entity_a:\n        identifier: entity_a_name\n        ...\n      entity_b:\n        identifier:\n          name: entity_a_name\n    \n    ```\n    \n    Copy\n    \n*   Add an `identifier` object to each entity.\n    \n    Using identifier objects allow to specify a name, database, and schema for each entity, as shown in the following example:\n    \n    ```\n    entities:\n      entity_b:\n        identifier:\n          name: entity_a_name\n          schema: public\n          database: DEV\n    \n    ```\n    \n    Copy\n    \n\nIf you don’t specify an identifier, the entity key is used as the name of the object, without any database or schema qualification.\n\n## Project mixins[¶](#project-mixins \"Link to this heading\")\n\nIn many cases you might find it useful to define project-wide default values. Mixins provide a way to extract common attributes out of individual entities. You can specify multiple mixins. You need to declare which mixins should be used by each entity using `meta.use_mixins` property.\n\nWhen using mixins with an entity, you must ensure that all properties of a mixin can be applied to that entity. Applying a property that is not available on an entity causes an error. Consequently, in some cases you might need to use multiple mixins.\n\nNote\n\nMixin values are overridden by explicitly-declared entity attributes.\n\nThe following example includes two mixins: `stage_mixin` and `snowpark_shared`. The `my_dashboard` entity uses only `stage_mixin`, while the `my_function` entity uses both of the mixins.\n\n```\ndefinition_version: 2\nmixins:\n  stage_mixin:\n    stage: \"my_stage\"\n  snowpark_shared:\n    artifacts: [\"app/\"]\n    imports: [\"@package_stage/package.zip\"]\n\nentities:\n  my_function:\n    type: \"function\"\n    ...\n    meta:\n      use_mixins:\n        - \"stage_mixin\"\n        - \"snowpark_shared\"\n  my_dashboard:\n    type: \"dashboard\"\n    ...\n    meta:\n      use_mixins:\n        - \"stage_mixin\"\n\n```\n\nCopy\n\nIf an entity uses multiple mixins that specify the same property, the entity uses the value of later mixin. In the following example, the value of key on the `foo` entity will be `mixin_2_value`.\n\n```\nmixins:\n  mixin_1:\n    key: mixin_1_value\n  mixin_2:\n    key: mixin_2_value\n\nentities:\n  foo:\n    meta:\n      use_mixin:\n      - mixin_1\n      - mixin_2\n\n```\n\nCopy\n\nThe behavior of applying mixins values depends on value type. For scalar values (strings, numbers, Booleans) values are overridden.\n\n| Mixin notation | Explicit result |\n| --- | --- |\n| definition_version: 2\nmixins:\n  mix1:\n    stage: A\n\n  mix2:\n    stage: B\n\nentities:\n  test_procedure:\n    stage: C\n    meta:\n      use_mixins:\n        - mix1\n        - mix2\nCopy | definition_version: 2\nentities:\n  test_procedure:\n    stage: C\nCopy |\n\nIn case of sequences, values are merged to create a new sequence. This implementation avoids creating duplicate entries in the sequence.\n\n| Mixin notation | Explicit result |\n| --- | --- |\n| definition_version: 2\nmixins:\n  mix1:\n    artifacts:\n    - a.py\n\n  mix2:\n    artifacts:\n    - b.py\n\nentities:\n  test_procedure:\n    artifacts:\n      - app/\n    meta:\n      use_mixins:\n        - mix1\n        - mix2\nCopy | definition_version: 2\nentities:\n  test_procedure:\n    artifacts:\n      - a.py\n      - b.py\n      - app/\nCopy |\n\nFor mapping values new keys are being added and existing values are updated. The update is recursive.\n\n| Mixin notation | Explicit result |\n| --- | --- |\n| definition_version: 2\nmixins:\n  mix1:\n    secrets:\n      secret1: v1\n\n  mix2:\n    secrets:\n      secret2: v2\n\nentities:\n  test_procedure:\n    secrets:\n      secret3: v3\n    meta:\n      use_mixins:\n        - mix1\n        - mix2\nCopy | definition_version: 2\nentities:\n  test_procedure:\n    secrets:\n      secret1: v1\n      secret2: v2\n      secret3: v3\nCopy |\n| definition_version: 2\nmixins:\n  mix1:\n    secrets:\n      secret_name: v1\n\n  mix2:\n    secrets:\n      secret_name: v2\n\nentities:\n  test_procedure:\n    secrets:\n      secret_name: v3\n    meta:\n      use_mixins:\n        - mix1\n        - mix2\nCopy | definition_version: 2\nentities:\n  test_procedure:\n    secrets:\n      secret_name: v3\nCopy |\n| definition_version: 2\nmixins:\n  shared:\n    identifier:\n      schema: foo\n\nentities:\n  sproc1:\n    identifier:\n      name: sproc\n    meta:\n      use_mixins: [\"shared\"]\n  sproc2:\n    identifier:\n      name: sproc\n      schema: from_entity\n    meta:\n      use_mixins: [\"shared\"]\nCopy | definition_version: 2\nentities:\n  sproc1:\n    identifier:\n      name: sproc\n      schema: foo\n  sproc2:\n    identifier:\n      name: sproc\n      schema: from_entity\nCopy |\n\nOn this page\n\n1.  [Entity identifiers](#entity-identifiers)\n2.  [Project mixins](#project-mixins)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",
    "category": "NULL"
  },
  {
    "category": "NULL",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "parent_command": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/use-sql-variables",
    "raw_content": "# Use variables in SQL[¶](#use-variables-in-sql \"Link to this heading\")\n\nNote\n\nSupport for variables requires project definition version 1.1.\n\nYou can also use project files to define variables that other commands, such as `snow sql`, can use. The `env` section in the project definition file(typically, `snowflake.yml`) lets you define variables as shown:\n\n```\ndefinition_version: 2\nenv:\n  database: \"dev\"\n  role: \"eng_rl\"\n\n```\n\nCopy\n\nAfter adding the `env` section to the project definition file, you can pass the variables to the `snow sql` command instead of specifying the variable and value on the command line.\n\nInstead specifying the database and role on the command line with the `--variable` option, as shown:\n\n```\nsnow sql \\\n-q \"grant usage on database <% database %> to <% role %>\" \\\n-D \"database=dev\" \\\n-D \"role=eng_rl\"\n\n```\n\nCopy\n\nyou can specify the variables defined in the `env` section as shown:\n\n```\nsnow sql -q \"grant usage on database <% ctx.env.database %> to <% ctx.env.role %>\"\n\n```\n\nCopy\n\nYou can include the `env` section in addition to any other sections you include in the project definition file.\n\n```\ndefinition_version: 2\nentities:\n  test_function:\n    type: \"function\"\n    stage: \"dev_deployment\"\n    artifacts: [\"app/\"]\n    handler: \"functions.hello_function\"\n    signature: \"\"\n    returns: string\n\n  hello_procedure:\n    type: \"procedure\"\n    stage: \"dev_deployment\"\n    artifacts: [\"app/\"]\n    handler: \"procedures.hello_procedure\"\n    signature:\n      - name: \"name\"\n        type: \"string\"\n    returns: string\n\nenv:\n  database: \"dev\"\n  role: \"eng_rl\"\n\n```\n\nCopy\n\nNote\n\nIf your current project definition file uses `definition_version: 1`, you must update it to `definition_version: 1.1` if you want to take advantage of the variables feature. If you do not change the value, Snowflake CLI ignores the `env` section, but the other types of projects (`snowpark`, in this example) still work as expected.\n\nYou can override any variable defined the in `snowflake.yml` project definition file by setting a shell environment variable by the same name (case-sensitive). For example, to override the `database` value defined in the example, you can execute the following shell command:\n\n```\nexport database=\"other\"\n\n```\n\nCopy\n\nFor more information about using `env` variables, see [Storing variables in the snowflake.yml project definition file](../sql/execute-sql.html#label-cli-sql-env-vars).\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)\n2.  [snow sql](/developer-guide/snowflake-cli/project-definitions/../command-reference/sql-commands/sql)",
    "title": "Use variables in SQL¶",
    "id": "NULL",
    "metadata": "NULL",
    "content_hash": "4f0efda5bdc585befdc9e01bd06cddc22bdb02243f5ad5c36d254a9eb9997010",
    "command_group": "NULL"
  },
  {
    "parent_command": "NULL",
    "raw_content": "# Create project definition file templates[¶](#create-project-definition-file-templates \"Link to this heading\")\n\nIn some situations, you might want to reference information already present in a project definition file in another place of the file. Snowflake CLI supports templating the project definition file.\n\nProject definition file templates use the `<% … %>` syntax for specifying the templates. The following example uses the `env` section to define a name for a Streamlit application:\n\n```\ndefinition_version: 2\nenv:\n  name: \"my-app\"\nentities:\n  my_streamlit:\n    type: \"streamlit\"\n    identifier: <% ctx.env.name %>\n\n```\n\nCopy\n\nThe `<% ctx.env.name %>` syntax references a global context object that provides access to the project definition. The `ctx` object has the same structure as the project definition. You can access attributes of defined objects using dot notation. Example uses include:\n\n*   `<% ctx.entities.pkg.identifier %>` to access the name of a Native App package with ID `pkg`.\n    \n*   `<% ctx.entities.function.stage_name %>` to access the stage name for a snowpark UDFs and procedures.\n    \n*   `<% ctx.entities.my_streamlit.identifier %>` to access the Streamlit dashboard name.\n    \n\nYou can override any variable defined in the `snowflake.yml` project definition file `env` section by setting a shell environment variable by the same case-sensitive name. For example, to override the name value defined in the example, you can execute the following shell command:\n\n```\nexport name=\"other\"\n\n```\n\nCopy\n\n## Access template defaults[¶](#access-template-defaults \"Link to this heading\")\n\nTemplate defaults let you access default and automatically-generated fields from a project definition file, even if the fields are not explicitly defined. To illustrate, consider the following Snowflake Native App project definition file:\n\n```\ndefinition_version: 2\nentities:\n  pkg:\n    type: application package\n    artifacts:\n      - src: app/*\n        dest: ./\n  app:\n    type: application\n    from:\n      target: pkg\n\n```\n\nCopy\n\nThis definition provides enough information to create a Snowflake Native App, so the default values for the application package and application instance are automatically generated when you create the application. You can then access these values using the following syntax:\n\n> ```\n> <% ctx.entities.app.identifier %>\n> <% ctx.entities.pkg.identifier %>\n> \n> ```\n> \n> Copy\n\nOn this page\n\n1.  [Access template defaults](#access-template-defaults)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",
    "last_scraped": "NULL",
    "content_hash": "e0c42261db6857d07d9ce115bbce759b530169353d6614ea86ef1eb46f8b6cc7",
    "metadata": "NULL",
    "title": "Create project definition file templates¶",
    "category": "NULL",
    "command_group": "NULL",
    "full_command": "NULL",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/create-templates"
  },
  {
    "metadata": "NULL",
    "title": "Alter command behavior using templates¶",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/alter-with-templates",
    "parent_command": "NULL",
    "last_scraped": "NULL",
    "category": "NULL",
    "content_hash": "2e4cd9286f9d613482411a7652143324fae50649210186fa7cb76ac64a2d7227",
    "id": "NULL",
    "full_command": "NULL",
    "raw_content": "# Alter command behavior using templates[¶](#alter-command-behavior-using-templates \"Link to this heading\")\n\nYou can use templates to alter the definition using environment variables. For example, the following project definition templates the schema for a Streamlit dashboard:\n\n```\ndefinition_version: \"1.1\"\nenv:\n  schema: \"test\"\nstreamlit:\n  name: \"MY_APP\"\n  schema: <% ctx.env.schema %>\n\n```\n\nCopy\n\nThis feature lets you to alter the behavior of the `snow streamlit deploy` command by setting a `schema` environment variable. Using this approach, you can deploy the same dashboard to multiple different schemas by entering the following commands to deploy different schemas:\n\n```\nschema=\"staging\"; snow streamlit deploy\nschema=\"prod\"; snow streamlit deploy\n\n```\n\nCopy\n\nNote\n\nThe variables and environment variables are case-sensitive.\n\nYou can also use the template feature without defining variables in the `env` section. If a variable is not present in `env` section, Snowflake CLI looks for corresponding environment variables. For example, if you define a Streamlit application similar to the following, you can still alter the behavior of `snow streamlit deploy` by specifying a `schema` environment variable.\n\n```\ndefinition_version: \"1.1\"\nstreamlit:\n  name: \"MY_APP\"\n  schema: <% ctx.env.schema %>\n\n```\n\nCopy\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)"
  },
  {
    "category": "NULL",
    "parent_command": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/use-template-functions",
    "last_scraped": "NULL",
    "raw_content": "# Use template functions[¶](#use-template-functions \"Link to this heading\")\n\nTo enable the concatenation of SQL identifiers such as database names and schema names, and to provide flexibility in using quoted or unquoted identifiers in different contexts, Snowflake CLI provides the following set of utility functions you can use in project template definition templates:\n\n*   [fn.concat\\_ids()](#label-cli-fn-concat-ids)\n    \n*   [fn.str\\_to\\_id()](#label-cli-fn-str-to-id)\n    \n*   [fn.id\\_to\\_str()](#label-cli-fn-id-to-str)\n    \n*   [fn.get\\_username()](#label-cli-fn-get-username)\n    \n*   [fn.sanitize\\_id()](#label-cli-fn-sanitize-id)\n    \n\n## `fn.concat_ids()`[¶](#fn-concat-ids \"Link to this heading\")\n\n*   Input: one or more string arguments (SQL ID or plain String)\n    \n*   Output: a valid SQL ID (quoted or unquoted)\n    \n\nThe `fn.concat_ids()` function concatenates multiple string arguments into a single string representing a SQL ID (quoted or unquoted). If any of the input strings is a valid quoted identifier, it will be unescaped before the concatenation. The resulting string is then escaped and quoted if it contains non-SQL safe characters or if any of the input strings was a valid quoted identifier.\n\nExamples:\n\n*   Calling `fn.concat_ids('id1_', '\"quoted_id2\"')` outputs `\"id1_quoted_id2\"` because one of the input values is a quoted identifier.\n    \n*   Calling `fn.concat_ids('id1_', 'id2')` outputs `id1_id2` because none of the input values is a quoted identifier and none of the input values contains non SQL safe characters.\n    \n\n## `fn.str_to_id()`[¶](#fn-str-to-id \"Link to this heading\")\n\n*   Input: one or more string arguments (SQL ID or plain String)\n    \n*   Output: a valid SQL ID (quoted or unquoted)\n    \n\nThe `fn.str_to_id()` function returns a string as a an ID. If the input string contains a valid quoted or unquoted identifier, the function returns it as is. However, if the input string contains unsafe SQL characters that are not properly quoted, the function returns a quoted ID that escapes the unsafe characters.\n\nExamples:\n\n*   Calling `fn.str_to_id('id1')` returns `id1` because it is a valid unquoted identifier.\n    \n*   Calling `fn.str_to_id('unsafe\"id')` returns `\"unsafe\"\"id\"` because it contains unsafe SQL characters.\n    \n\n## `fn.id_to_str()`[¶](#fn-id-to-str \"Link to this heading\")\n\n*   Input: one string argument (SQL ID or plain String)\n    \n*   Output: a plain string\n    \n\nIf the input is a valid SQL ID, the function returns an unescaped plain String. Otherwise, the function returns the input string as is.\n\nExamples:\n\n*   Calling `fn.id_to_str('id1')`, returns `id1` because it is already unquoted.\n    \n*   Calling `fn.id_to_str('\"quoted\"\"id.example\"')` returns `quoted\"id.example`.\n    \n\n## `fn.get_username()`[¶](#fn-get-username \"Link to this heading\")\n\n*   Input: one optional string containing the fallback value\n    \n*   Output: current username detected from the Operating System\n    \n\nReturns the current username from the operating system environment variables. If the current username is not found or is empty, it will either return an empty value or use the fallback value if one is provided.\n\nExamples:\n\n*   `fn.get_username('default_user')` returns the current username if found, otherwise, it returns `default_user`.\n    \n\n## `fn.sanitize_id()`[¶](#fn-sanitize-id \"Link to this heading\")\n\n*   Input: one string argument\n    \n*   Output: a valid non-quoted SQL ID\n    \n\nThe function `fn.sanitize_id()` removes any unsafe SQL characters from the input and returns it as a valid unquoted SQL ID. If the result does not start with a letter or an underscore, it appends an underscore to it. For very long strings, the function truncates the string to 255 characters.\n\nExamples:\n\n*   When using `fn.sanitize_id('Some.id\"With_Special_Chars')` the output is `SomeidWith_Special_Chars`.\n    \n*   When using `fn.sanitize_id('1abc')` the output is `_1abc`.\n    \n\n## Sample use case[¶](#sample-use-case \"Link to this heading\")\n\nThe following example shows how to use these functions in `snowflake.yml` project definition files:\n\n```\ndefinition_version: 2\nentities:\n  pkg:\n    type: application package\n    identifier: <% fn.concat_ids(ctx.env.app_name, ctx.env.pkg_suffix) %>\n    artifacts:\n      - src: app/*\n        dest: ./\n  app:\n    type: application\n    identifier: <% fn.concat_ids(ctx.env.app_name, ctx.env.app_suffix) %>\n\nenv:\n  app_name: myapp_base_name_<% fn.sanitize_id(fn.get_username()) %>\n  app_suffix: _app_instance\n  pkg_suffix: _pkg\n\n```\n\nCopy\n\nThe following example illustrates how to use the functions in a SQL file:\n\n```\nDESC APPLICATION <% fn.str_to_id(ctx.entities.app.identifier) %>;\nDESC APPLICATION PACKAGE <% fn.str_to_id(ctx.entities.pkg.identifier) %>;\n\n```\n\nCopy\n\nOn this page\n\n1.  [fn.concat\\_ids()](#fn-concat-ids)\n2.  [fn.str\\_to\\_id()](#fn-str-to-id)\n3.  [fn.id\\_to\\_str()](#fn-id-to-str)\n4.  [fn.get\\_username()](#fn-get-username)\n5.  [fn.sanitize\\_id()](#fn-sanitize-id)\n6.  [Sample use case](#sample-use-case)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",
    "content_hash": "9970df5cc7b8365406e2913fc32d8d0f004a243c728862d9131f21347c0413e7",
    "title": "Use template functions¶",
    "metadata": "NULL",
    "full_command": "NULL",
    "command_group": "NULL",
    "id": "NULL"
  },
  {
    "title": "Migrating project definition files from version 1.x to 2.0¶",
    "id": "NULL",
    "command_group": "NULL",
    "last_scraped": "NULL",
    "category": "NULL",
    "parent_command": "NULL",
    "full_command": "NULL",
    "content_hash": "7ae93e8fbddc4b96cff8c64c44323cebd9785bb85b9403b30e7cbff7dae05955",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/project-definitions/migrate-projects",
    "raw_content": "# Migrating project definition files from version 1.x to 2.0[¶](#migrating-project-definition-files-from-version-1-x-to-2-0 \"Link to this heading\")\n\nTo convert a version 1.x project definition file to the version 2 format, do the following:\n\n1.  Go to your project directory that contains the version 1.x `snowflake.yml` file.\n    \n2.  Enter the `snow helpers v1-to-v2` command.\n    \n    *   If the version 1.x file conversion succeeds, the command displays a message similar to the following:\n        \n        > ```\n        > cd <project-directory>\n        > snow helpers v1-to-v2\n        > \n        > ```\n        > \n        > Copy\n        > \n        > ```\n        > Project definition migrated to version 2.\n        > \n        > ```\n        \n    *   If your project definition file is already updated to version 2, the command displays the following message:\n        \n        > ```\n        > cd <project-directory>\n        > snow helpers v1-to-v2\n        > \n        > ```\n        > \n        > Copy\n        > \n        > ```\n        > Project definition is already at version 2.\n        > \n        > ```\n        \n\n> *   If you try to convert a project file that contains a `snowflake.local.yml` file, without using the `--[no]-migrate-local-overrides` option, the command generates an error similar to the following:\n>     \n> \n> > *   If you try to convert a project file that contains templates, without using the `--accept-templates` option, the command generates an error similar to the following:\n> >     \n> >     > ```\n> >     > cd <project-directory>\n> >     > snow helpers v1-to-v2\n> >     > \n> >     > ```\n> >     > \n> >     > Copy\n> >     > \n> >     > ```\n> >     > +- Error-------------------------------------------------------------------+\n> >     > | snowflake.local.yml file detected, please specify                        |\n> >     > | --migrate-local-overrides to include or --no-migrate-local-overrides to  |\n> >     > | exclude its values.                                                      |\n> >     > +--------------------------------------------------------------------------+\n> >     > \n> >     > ```\n> >     \n> > *   If you convert a project definition file that contains templates, and use the `--accept-templates` option, the command converts the file and displays a warning message similar to the following:\n> >     \n> >     > ```\n> >     > cd <project-directory>\n> >     > snow helpers v1-to-v2\n> >     > \n> >     > ```\n> >     > \n> >     > Copy\n> >     > \n> >     > ```\n> >     > WARNING  snowflake.cli._plugins.workspace.commands:commands.py:60 Your V1 definition contains templates. We cannot guarantee the correctness of the migration.\n> >     > Project definition migrated to version 2\n> >     > \n> >     > ```\n> >     \n\n## Convert Native App projects[¶](#convert-native-app-projects \"Link to this heading\")\n\nThis section shows an example from a V1 to V2 conversion of a Snowflake Native App project, lists the changes in property names, and offers some tips to help with migration.\n\n### Snowflake Native App conversion example[¶](#native-app-conversion-example \"Link to this heading\")\n\n| V1 project file | V2 project file |\n| --- | --- |\n| definition_version: 1\nnative_app:\n  name: myapp\n  source_stage: app_src.stage\n  artifacts:\n    - src: app/*\n      dest: ./\n      processors:\n        - native app setup\n        - name: templates\n          properties:\n            foo: bar\n  package:\n    role: pkg_role\n    distribution: external\n  application:\n    name: myapp_app\n    warehouse: app_wh\nCopy | definition_version: 2\nentities:\n  pkg:\n    type: application package\n    meta:\n      role: pkg_role\n    identifier: <% fn.concat_ids('myapp', '_pkg_', fn.sanitize_id(fn.get_username('unknown_user')) \\| lower) %>\n    manifest: app/manifest.yml\n    artifacts:\n    - src: app/*\n      dest: ./\n      processors:\n      - name: native app setup\n      - name: templates\n        properties:\n          foo: bar\n    stage: app_src.stage\n  app:\n    meta:\n      warehouse: app_wh\n    identifier: myapp_app\n    type: application\n    from:\n      target: pkg\nCopy |\n\n### Native App project definition V1 to V2 property changes[¶](#native-app-project-definition-v1-to-v2-property-changes \"Link to this heading\")\n\n| V1 property | V2 property |\n| --- | --- |\n| native_app.name | No equivalent. Use a template variable to port, if required. |\n| native_app.deploy_root | <package entity>.deploy_root |\n| native_app.generated_root | <package entity>.generated_root |\n| native_app.bundle_root | <package entity>.bundle_root |\n| native_app.source_stage | <package entity>.source_stage |\n| native_app.scratch_stage | <package entity>.scratch_stage |\n| native_app.artifacts | <package entity>.artifacts |\n| native_app.application.debug | <application entity>.debug |\n| native_app.application.name | <application entity>.identifier |\n| native_app.application.post_deploy | <application entity>.meta.post_deploy (see above notes) |\n| native_app.application.role | <application entity>.meta.role |\n| native_app.application.warehouse | <application entity>.meta.warehouse |\n| native_app.package.distribution | <package entity>.distribution |\n| native_app.package.name | <package entity>.identifier |\n| native_app.package.post_deploy | <package entity>.meta.post_deploy (see above notes) |\n| native_app.package.role | <package entity>.meta.role |\n| native_app.package.scripts | <package entity>.meta.post_deploy (see above notes) |\n| native_app.package.warehouse | <package entity>.meta.warehouse |\n\n### Migration tips[¶](#migration-tips \"Link to this heading\")\n\n*   When migrating Snowflake Native App package scripts, the `v1-to-v2` command converts them to `package post-deploy` hooks and replaces `{{package_name}}` in the package script file with the equivalent template expression.\n    \n*   When migrating existing template expressions, `ctx.native_app`, `ctx.streamlit`, and `ctx.snowpark` variables are no longer accepted. The `v1-to-v2` command with equivalent template expressions that reference the specific entity name instead. For example, `ctx.native_app.package.name` could be replaced with `ctx.entities.pkg.identifier` if the package was migrated to an entity named `pkg` in the `snowflake.yml` file.\n    \n\n## Convert Streamlit projects[¶](#convert-streamlit-projects \"Link to this heading\")\n\nThis section shows an example from a V1 to V2 conversion of a Streamlit project, lists the changes in property names, and offers some tips to help with migration.\n\n### Streamlit conversion example[¶](#streamlit-conversion-example \"Link to this heading\")\n\n| V1 project file | V2 project file |\n| --- | --- |\n| definition_version: 1\nstreamlit:\n  name: test_streamlit\n  stage: streamlit\n  query_warehouse: test_warehouse\n  main_file: \"streamlit_app.py\"\n  title: \"My Fancy Streamlit\"\nCopy | definition_version: 2\nentities:\n  test_streamlit:\n    identifier:\n      name: test_streamlit\n    type: streamlit\n    title: My Fancy Streamlit\n    query_warehouse: test_warehouse\n    main_file: streamlit_app.py\n    pages_dir: None\n    stage: streamlit\n    artifacts:\n    - streamlit_app.py\nCopy |\n\n### Streamlit project definition V1 to V2 property changes[¶](#streamlit-project-definition-v1-to-v2-property-changes \"Link to this heading\")\n\n| V1 property | V2 property |\n| --- | --- |\n| streamlit.name | <streamlit entity>.identifier.name |\n| streamlit.schema | <streamlit entity>.identifier.schema |\n| streamlit.database | <streamlit entity>.identifier.database |\n| streamlit.comment | <streamlit entity>.comment |\n| streamlit.title | <streamlit entity>.title |\n| streamlit.query_warehouse | <streamlit entity>.query_warehouse |\n| streamlit.main_file | <streamlit entity>.main_file and <streamlit entity>.artifacts |\n| streamlit.stage | <streamlit entity>.stage |\n| streamlit.env_file | <streamlit entity>.artifacts |\n| streamlit.pages_dir | <streamlit entity>.pages_dir and <streamlit entity>.artifacts |\n| streamlit.additional_source_files | <streamlit entity>.artifacts |\n\n### Streamlit migration tips[¶](#streamlit-migration-tips \"Link to this heading\")\n\nNone.\n\n## Convert Snowpark projects[¶](#convert-snowpark-projects \"Link to this heading\")\n\nThis section shows an example from a V1 to V2 conversion of a Snowpark project, lists the changes in property names, and offers some tips to help with migration.\n\n### Snowpark conversion example[¶](#snowpark-conversion-example \"Link to this heading\")\n\n| V1 project file | V2 project file |\n| --- | --- |\n| definition_version: 1\nsnowpark:\n  project_name: \"my_snowpark_project\"\n  stage_name: \"dev_deployment\"\n  src: \"app/\"\n  functions:\n    - name: func1\n      handler: \"app.func1_handler\"\n      signature:\n        - name: \"a\"\n          type: \"string\"\n          default: \"default value\"\n        - name: \"b\"\n          type: \"variant\"\n      returns: string\n      runtime: 3.10\n  procedures:\n    - name: procedureName\n      handler: \"hello\"\n      signature:\n        - name: \"name\"\n          type: \"string\"\n      returns: string\nCopy | definition_version: 2\nentities:\n  procedureName:\n    imports: []\n    external_access_integrations: []\n    secrets: {}\n    meta:\n      use_mixins:\n      - snowpark_shared\n    identifier:\n      name: procedureName\n    handler: hello\n    returns: string\n    signature:\n    - name: name\n      type: string\n    stage: dev_deployment\n    artifacts:\n    - src: app\n      dest: my_snowpark_project\n    type: procedure\n    execute_as_caller: false\n  func1:\n    imports: []\n    external_access_integrations: []\n    secrets: {}\n    meta:\n      use_mixins:\n      - snowpark_shared\n    identifier:\n      name: func1\n    handler: app.func1_handler\n    returns: string\n    signature:\n    - name: a\n      type: string\n      default: default value\n    - name: b\n      type: variant\n    runtime: '3.10'\n    stage: dev_deployment\n    artifacts:\n    - src: app\n      dest: my_snowpark_project\n    type: function\nmixins:\n  snowpark_shared:\n    stage: dev_deployment\n    artifacts:\n    - src: app/\n      dest: my_snowpark_project\nCopy |\n\n### Snowpark project definition V1 to V2 property changes[¶](#snowpark-project-definition-v1-to-v2-property-changes \"Link to this heading\")\n\n| V1 property | V2 property |\n| --- | --- |\n| snowpark.project_name | <function or procedure entity>.artifacts.dest for each function and/or procedure migrated from the project. See above notes regarding Snowpark migration. Each function or procedure should declare an artifact with dest defined as the snowpark.project_name value, and src defined as the snowpark.src value. Use of a mixin is recommended. |\n| snowpark.stage_name | <function or procedure entity>.stage for each function and/or procedure migrated from the project. |\n| snowpark.src | <function or procedure entity>.artifacts.src for each function and/or procedure migrated from the project. (see snowpark.project_name above) |\n| snowpark.functions (list) | <function entities> (top-level) |\n| snowpark.procedures (list) | <procedure entities> (top-level) |\n\n| V1 property | V2 property |\n| --- | --- |\n| name | identifier.name |\n| schema | identifier.schema |\n| database | identifier.database |\n| handler | handler |\n| returns | returns |\n| signature | signature |\n| runtime | runtime |\n| external_access_integrations | external_access_integrations |\n| secrets | secrets |\n| imports | imports |\n| execute_as_caller | execute_as_caller (only for procedures) |\n\n### Snowpark migration tips[¶](#snowpark-migration-tips \"Link to this heading\")\n\n*   When migrating Snowpark projects, each function (from the `snowpark.functions` array) or procedure (from the `snowpark.procedures` array) maps to a top-level entity.\n    \n*   All top-level Snowpark project properties (e.g. `src`) are now defined for each function and procedure. To reduce duplication, Snowflake recommends that you declare a `mixin` and include it in each of the migrated function and procedure entities.\n    \n\nOn this page\n\n1.  [Convert Native App projects](#convert-native-app-projects)\n2.  [Convert Streamlit projects](#convert-streamlit-projects)\n3.  [Convert Snowpark projects](#convert-snowpark-projects)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/project-definitions/../index)",
    "metadata": "NULL"
  },
  {
    "metadata": "NULL",
    "id": "NULL",
    "raw_content": "# Project definition files[¶](#project-definition-files \"Link to this heading\")\n\nA project definition file called `snowflake.yml` declares a directory as a Snowflake Native App project. It is a version-controlled file that resides at the root of a Snowflake Native App project directory and can either be created manually or by Snowflake CLI as part of project initialization. As long as you can provide this structured file in the directory but choose to use your own independent project structure, Snowflake CLI can discover the relevant files and carry out its functionality as usual.\n\nFor Native Apps, your `snowflake.yml` would look similar to the following:\n\n```\ndefinition_version: 2\nentities:\n  pkg:\n    type: application package\n    identifier: <name_of_app_pkg>\n    stage: app_src.stage\n    manifest: app/manifest.yml\n    artifacts:\n      - src: app/*\n        dest: ./\n      - src: src/module-add/target/add-1.0-SNAPSHOT.jar\n        dest: module-add/add-1.0-SNAPSHOT.jar\n      - src: src/module-ui/src/*\n        dest: streamlit/\n    meta:\n      role: <your_app_pkg_owner_role>\n      warehouse: <your_app_pkg_warehouse>\n      post_deploy:\n        - sql_script: scripts/any-provider-setup.sql\n        - sql_script: scripts/shared-content.sql\n  app:\n    type: application\n    identifier: <name_of_app>\n    from:\n      target: pkg\n    debug: <true|false>\n    meta:\n      role: <your_app_owner_role>\n      warehouse: <your_app_warehouse>\n\n```\n\nCopy\n\n## Common entity properties[¶](#common-entity-properties \"Link to this heading\")\n\nThe following table describes common properties available for project definition entities for Native Apps. See [Specify entities](../project-definitions/specify-entities) for more information on project definition entities.\n\n| Property | Definition |\n| --- | --- |\n| typerequired, string | The type of entity to manage. For Snowflake Native App, valid values include:application package. For more information about application package properties, see Application package entity properties.application. For more information about application properties, see Application entity properties. |\n| identifieroptional, string | Optional Snowflake identifier for the entity, both unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (e.g. ’”My Native Application Package”’).If not specified, the entity ID in the project definition is used as the identifier. |\n| meta.warehouseoptional, string | Warehouse used to run the scripts provided as part of meta.post_deploy, if any SQL commands within these scripts require use of warehouse.Default: Warehouse specified for the connection in the Snowflake CLI config.toml file.NoteIf you do not specify a warehouse, the application passes validation, but fails to install.Typically, you specify this value in the snowflake.local.yml as described in Project definition overrides. |\n| meta.roleoptional, string | Role to use when creating the entity and provider-side objects.NoteIf you do not specify a role, Snowflake CLI attempts to use the default role assigned to your user in your Snowflake account.Typically, you specify this value in the snowflake.local.yml as described in Project definition overrides.Default: Role specified in the Snowflake CLI connection |\n| meta.post_deployoptional, sequence | List of SQL scripts to execute after the entity has been created. The following example shows how to define these scripts in the project definition file:definition_version: 2\nentities:\n  myapp_pkg:\n    type: application package\n    ...\n    meta:\n      post_deploy:\n        - sql_script: scripts/post_deploy1.sql\n        - sql_script: scripts/post_deploy2.sql\nCopyThese scripts are invoked by commands that create or update an entity. For example, running the snow app deploy command executes these scripts after creating or updating a package. They are also executed by snow app run if the application instance is not being directly installed from a version or release directive.You can also use templates in the post-deploy SQL scripts as well, as shown in the following sample script content:GRANT reference_usage on database provider_data to share in entity <% fn.str_to_id(ctx.entities.myapp_pkg.identifier) %>\nCopy |\n| meta.use_mixinsoptional, sequence | Names of mixins to apply to this entity. See Project mixins for more information |\n\n## Application package entity properties[¶](#application-package-entity-properties \"Link to this heading\")\n\nThe following table describes common properties available for application package entities for Native Apps. See [Specify entities](../project-definitions/specify-entities) for more information on project definition entities.\n\n| Property | Definition |\n| --- | --- |\n| typerequired, string | Must be application package. |\n| manifestoptional, string | The location of the Snowflake Native App manifest.yml file in your project.NoteWith version 3.2, this property switched from required to optional. |\n| deploy_rootoptional, string | Subdirectory at the root of your project where the build step copies the artifacts. Once copied to this location, you can deploy them to a Snowflake stage.Default: output/deploy |\n| generated_rootoptional, string | Subdirectory of the deploy root where Snowflake CLI writes generated files.Default: __generated |\n| stageoptional, string | Identifier of the stage that stores the application artifacts. The value uses the form <schema_name>.<stage_name>. The stage lives within the Application Package object. You can change the name to avoid name collisions.Default: app_src.stage |\n| artifactsrequired, sequence | List of file source and destination pairs to add to the deploy root, as well as an optional Snowpark annotation processor. You can use the following artifact properties:src: Path to the code source file or filesdest: Path to the directory to deploy the artifacts.Destination paths that reference directories must end with a /. A glob pattern’s destination that does not end with a / results in an error. If omitted, dest defaults to the same string as src.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest.processors: Name of the processor to use to process the src code files. See More information about artifacts processors for more details.If src refers to just one file (not a glob), dest can refer to a target <path> or a <path/name>.You can also pass in a string for each item instead of a dict, which case, the value is treated as both src and dest.Example without a processor:pkg:\n  artifacts:\n    - src: app/*\n      dest: ./\n    - src: streamlit/*\n      dest: streamlit/\n    - src: src/resources/images/snowflake.png\n      dest: streamlit/\nCopyExample with a processor:pkg:\n  artifacts:\n    - src: qpp/*\n      dest: ./\n      processors:\n          - name: snowpark\n            properties:\n              env:\n                type: conda\n                name: <conda_name>\nCopy |\n| distributionoptional, string | Distribution of the application package created by the Snowflake CLI. When running snow app commands, Snowflake CLI warns you if the application package you are working with has a different value for distribution than is set in your resolved project definition.Default: Internal |\n| scratch_stageoptional, string | Identifier of the stage that stores temporary scratch data used by Snowflake CLI. The value uses the form <schema_name>.<stage_name>. The stage lives within the Application Package object. You can change the name to avoid name collisions.Default: app_src.stage_snowflake_cli_scratch |\n| stage_subdirectoryoptional, string | Name of the folder for Snowflake CLI to add as a subdirectory under the stage to hold the artifacts specified in this Application Package Entity. If none are specified, the artifacts are uploaded to the root of the stage.Default: \"\" (empty string) |\n| enable_release_channelsoptional, bool | Whether to enable publishing this application package in release channels.Default: Unset |\n\n## Application entity properties[¶](#application-entity-properties \"Link to this heading\")\n\nThe following table describes common properties available for application entities for Native Apps. See [Specify entities](../project-definitions/specify-entities) for more information on project definition entities.\n\n| Property | Definition |\n| --- | --- |\n| typerequired, string | Must be application. |\n| from.targetrequired, string | Application package from which to create this application entity. In the following example, target defines the name of an entity in the snowflake.yml file.from:\n  target: my_pkg\nCopy |\n| telemetry.share_mandatory_eventsoptional, boolean | Whether to enable event sharing at the application level. When this is set to true, all mandatory events are automatically shared with the application package provider.telemetry:\n  share_mandatory_events: true\nCopy |\n| telemetry.optional_shared_eventsoptional, sequence | List of optional events to share with the provider in addition to the mandatory events. All events listed here must be declared in the configuration.telemetry_event_definitions section of the manifest.yml file. This field is supported only when share_mandatory_events is set to true.telemetry:\n  share_mandatory_events: true\n  optional_shared_events:\n    - DEBUG_LOGS\nCopy |\n| debugoptional, boolean | Whether to enable debug mode when using a named stage to create an application.Default: True |\n\n### Sharing events with providers[¶](#sharing-events-with-providers \"Link to this heading\")\n\nNote\n\nSnowflake CLI supports event sharing only in `snowflake.yml` files based on definition version 2 or later. If you currently use an earlier version, see [Migrating project definition files from version 1.x to 2.0](../project-definitions/migrate-projects).\n\n[Event sharing](../../native-apps/event-definition) allows applications to send telemetry events back to application package owners. When testing an application with an application package requiring event sharing, you must explicitly enable event sharing for the application installation to succeed.\n\nTo enable sharing of specific events, you must also have the events configured in the `configuration.telemetry_event_definitions` section in the `manifest.yml` file for the application package. You must also have the MANAGE EVENT SHARING global privilege to authorize event sharing for the application.\n\nAfter event sharing is enabled in your application’s manifest, you must add a `telemetry` section to your `snowflake.yml` file that specifies the events you want to share from your application. The following code shows a sample `telemetry` section:\n\n```\ndefinition_version: 2\nentities:\n  app:\n    type: application\n    from:\n      target: pkg\n    telemetry:\n      share_mandatory_events: true\n      optional_shared_events:\n        - DEBUG_LOGS\n\n...\n\n```\n\nCopy\n\nThe following examples illustrate different ways to share events in the `snowflake.yml` file. All of the examples are based on the following section in the application package’s `manifest.yml` file:\n\n```\nconfiguration:\n    telemetry_event_definitions:\n        - type: ERRORS_AND_WARNINGS\n          sharing: MANDATORY\n        - type: DEBUG_LOGS\n          sharing: OPTIONAL\n\n```\n\nCopy\n\n*   Authorize telemetry and share all mandatory events with the provider. In this case, only `ERRORS_AND_WARNINGS` events are shared.\n    \n    ```\n    definition_version: 2\n    entities:\n      app:\n        type: application\n        from:\n          target: pkg\n        telemetry:\n          share_mandatory_events: true\n    \n    ```\n    \n    Copy\n    \n*   Share both `DEBUG_LOGS` and `ERRORS_AND_WARNINGS` events with the application package provider. Setting `share_mandatory_events` to `true` enables sharing of mandatory `ERRORS_AND_WARNINGS` events, while the `optional_shared_events` section enables optional events like `DEBUG_LOGS`.\n    \n    ```\n    definition_version: 2\n    entities:\n      app:\n        type: application\n        from:\n          target: pkg\n        telemetry:\n          share_mandatory_events: true\n          optional_shared_events:\n            - DEBUG_LOGS\n    \n    ```\n    \n    Copy\n    \n\n## More information about artifacts processors[¶](#more-information-about-artifacts-processors \"Link to this heading\")\n\nIf you include the `artifacts.processors` field in the project definition file, the `snow app bundle` command invokes custom processing for Python code files in the `src` directory or file.\n\nThis section covers a list of supported processors.\n\n### Snowpark processor[¶](#snowpark-processor \"Link to this heading\")\n\nNote\n\nThe Snowpark processor has been deprecated and will be removed in a future release.\n\nOne of the processors supported by Snowflake CLI is `snowpark`, which applies Snowpark annotation processing to Python files. The following code examples show the basic structure and syntax for different processing environments:\n\n*   To execute code in a conda environment, use the following:\n    \n    ```\n    pkg:\n      artifacts:\n        - src: <some_src>\n          dest: <some_dest>\n          processors:\n              - name: snowpark\n                properties:\n                  env:\n                    type: conda\n                    name: <conda_name>\n    \n    ```\n    \n    Copy\n    \n    where `<conda_name>` is the name of the conda environment containing the Python interpreter and the Snowpark library you want to use for Snowpark annotation processing.\n    \n*   To execute code in a Python virtual environment, use the following:\n    \n    ```\n    pkg:\n      artifacts:\n        - src: <some_src>\n          dest: <some_dest>\n          processors:\n              - name: snowpark\n                properties:\n                  env:\n                    type: venv\n                    path: <venv_path>\n    \n    ```\n    \n    Copy\n    \n    where `<venv_path>` is the path of the Python virtual environment containing the Python interpreter and the Snowpark library you want to use for Snowpark annotation processing. The path can be absolute or relative to the project directory.\n    \n*   To execute code in the currently active environment, use any of the following equivalent definitions:\n    \n    ```\n    pkg:\n      artifacts:\n        - src: <some_src>\n          dest: <some_dest>\n          processors:\n              - name: snowpark\n                properties:\n                  env:\n                    type: current\n    \n    ```\n    \n    Copy\n    \n    or\n    \n    ```\n    pkg:\n      artifacts:\n        - src: <some_src>\n          dest: <some_dest>\n          processors:\n              - name: snowpark\n    \n    ```\n    \n    Copy\n    \n    or\n    \n    ```\n    pkg:\n      artifacts:\n        - src: <some_src>\n          dest: <some_dest>\n          processors:\n              - snowpark\n    \n    ```\n    \n    Copy\n    \n\nFor more information about custom processing, see [Automatic SQL code generation](bundle-app.html#label-cli-nativeapp-bundle-codegen) and the [snow app bundle](../command-reference/native-apps-commands/bundle-app) command.\n\n### Templates processor[¶](#templates-processor \"Link to this heading\")\n\nSnowflake Native App projects support templates in arbitrary files, which lets you expand templates in all files in an artifact’s `src` directory. You can enable this feature by including a `templates` processor in the desired `artifacts` definition, as shown in the following example:\n\n```\ndefinition_version: 2\nentities:\n  pkg:\n    type: application package\n    identifier: myapp_pkg\n    artifacts:\n      - src: app/*\n        dest: ./\n        processors:\n          - templates\n    manifest: app/manifest.yml\n  app:\n    type: application\n    identifier: myapp_<% fn.get_username() %>\n    from:\n      target: pkg\n\n```\n\nCopy\n\nWhen Snowflake CLI uploads the files to a stage, it automatically expands the templates before uploading them. For example, suppose your application contained an `app/README.md` file with the following content that includes the `<% ctx.entities.pkg.identifier %>` template:\n\n```\nThis is a README file for application package <% ctx.entities.pkg.identifier %>.\n\n```\n\nCopy\n\nThe template is then expanded to the following before uploading the file to a stage:\n\n```\nThis is a README file for application package myapp_pkg.\n\n```\n\nCopy\n\n## Project definition overrides[¶](#project-definition-overrides \"Link to this heading\")\n\nThough your project directory must have a `snowflake.yml` file, you can choose to customize the behavior of the Snowflake CLI by providing local overrides to `snowflake.yml`, such as a new role to test out your own application package. These overrides must be put in the `snowflake.local.yml` file that lives beside the base project definition. Snowflake suggests that you add it to your `.gitignore` file so it won’t be version-controlled by git. All templates provided by Snowflake already include it in the `.gitignore` file.\n\nThis overrides file must live in the same location as your `snowflake.yml` file.\n\nThe `snowflake.local.yml` file shares the exact schema as `snowflake.yml`, except that every value that was required is now optional, in additional to the already optional ones. The following shows a sample `snowflake.local.yml` file:\n\n```\nentities:\n  pkg:\n    meta:\n      role: <your_app_pkg_owner_role>\n      name: <name_of_app_pkg>\n      warehouse: <your_app_pkg_warehouse>\n  app:\n    debug: <true|false>\n    meta:\n      role: <your_app_owner_role>\n      name: <name_of_app>\n      warehouse: <your_app_warehouse>\n\n```\n\nCopy\n\nEvery `snow app` command prioritizes the parameters in this file over those set in base `snowflake.yml` configuration file. Sensible defaults already provide isolation between developers using the same Snowflake account to develop the same application project, so if you are just getting started we suggest not including an overrides file.\n\nThe final definition schema obtained after overriding `snowflake.yml` with `snowflake.local.yml` is called the resolved project definition.\n\n### Limitations[¶](#limitations \"Link to this heading\")\n\nCurrently, Snowflake CLI does not support\n\n*   Multiple override files.\n    \n*   A blank override file. Only create this file if you want to override a value from `snowflake.yml`.\n    \n\nOn this page\n\n1.  [Common entity properties](#common-entity-properties)\n2.  [Application package entity properties](#application-package-entity-properties)\n3.  [Application entity properties](#application-entity-properties)\n4.  [Sharing events with providers](#sharing-events-with-providers)\n5.  [More information about artifacts processors](#more-information-about-artifacts-processors)\n6.  [Snowpark processor](#snowpark-processor)\n7.  [Templates processor](#templates-processor)\n8.  [Project definition overrides](#project-definition-overrides)\n9.  [Limitations](#limitations)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)\n3.  [About Snowflake Native App projects](/developer-guide/snowflake-cli/native-apps/about-projects)\n4.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/project-definitions",
    "category": "NULL",
    "command_group": "NULL",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "parent_command": "NULL",
    "content_hash": "d27fbcc7a454df0f0a3ad3e75270bbebe2d0e02144d1c37e512210b88f7edf6c",
    "title": "Project definition files¶"
  },
  {
    "title": "Working with image registries and repositories¶",
    "command_group": "NULL",
    "category": "NULL",
    "metadata": "NULL",
    "last_scraped": "NULL",
    "raw_content": "# Working with image registries and repositories[¶](#working-with-image-registries-and-repositories \"Link to this heading\")\n\nSnowpark Container Services provides an [OCIv2](https://github.com/opencontainers/distribution-spec/blob/main/spec.md)\\-compliant image registry service and a storage unit call repository to store images. You can use the following Snowflake CLI commands to manage Snowpark Container Services image registries and repositories:\n\n*   [Manage image registries](#label-sfcli-manage-img-registries)\n    \n*   [Manage image repositories](#label-sfcli-manage-img-repos)\n    \n\nFor more information about Snowpark Container Services image registries and repositories, see [Snowpark Container Services: Working with an image registry and repository](../../snowpark-container-services/working-with-registry-repository).\n\n## Manage image registries[¶](#manage-image-registries \"Link to this heading\")\n\nSnowflake CLI lets you perform the following tasks with Snowpark Container Services image repositories:\n\n*   [Get environment tokens for registry authentication](#label-sfcli-registry-tokens)\n    \n*   [Log in to an image registry](#label-sfcli-registry-login)\n    \n*   [Retrieve the URL for an image registry](#label-sfcli-registry-url)\n    \n\nFor common operations, such as listing or dropping, Snowflake CLI uses `snow object` commands as described in [Managing Snowflake objects](../objects/manage-objects).\n\n### Get environment tokens for registry authentication[¶](#get-environment-tokens-for-registry-authentication \"Link to this heading\")\n\nYou can use the [snow spcs image-registry token](../command-reference/spcs-commands/image-registry-commands/token) command to return the token associated with the specified connection that you can use to authenticate with the registry.\n\n```\nsnow spcs image-registry token --connection mytest\n\n```\n\nCopy\n\n```\n+----------------------------------------------------------------------------------------------------------------------+\n| key        | value                                                                                                   |\n|------------+---------------------------------------------------------------------------------------------------------|\n| token      | ****************************************************************************************************    |\n|            | ****************************************************************************************************    |\n| expires_in | 3600                                                                                                    |\n+----------------------------------------------------------------------------------------------------------------------+\n\n```\n\nYou can then use that token to log in to a Docker container by piping it to the `docker login` command, similar to the following:\n\n```\nsnow spcs image-registry token --format=JSON | docker login <org>-<account>.registry.snowflakecomputing.com -u 0sessiontoken --password-stdin\n\n```\n\nCopy\n\n### Log in to an image registry[¶](#log-in-to-an-image-registry \"Link to this heading\")\n\nThe [snow spcs image-registry login](../command-reference/spcs-commands/image-registry-commands/login) logs you into an image repository with the credentials specified for your connection. Before logging in, you must meet the following prerequisites:\n\n*   [Docker Desktop](https://www.docker.com/products/docker-desktop/) must be installed because the command uses docker to log in to Snowflake.\n    \n*   The current role must have READ privileges for the image repository in the account to get the registry URL.\n    \n\nTo log in to an image registry with your account credentials, use the following:\n\n```\nsnow spcs image-registry login\n\n```\n\nCopy\n\n```\nLogin Succeeded\n\n```\n\n### Retrieve the URL for an image registry[¶](#retrieve-the-url-for-an-image-registry \"Link to this heading\")\n\nThe [snow spcs image-registry url](../command-reference/spcs-commands/image-registry-commands/url) command returns a URL for an image repository. The current role must have READ privileges for the image repository in the account to get the registry URL.\n\nTo get the URL for a repository, do the following:\n\n```\nsnow spcs image-registry url\n\n```\n\nCopy\n\n```\n<orgname-acctname>.registry.snowflakecomputing.com\n\n```\n\n## Manage image repositories[¶](#manage-image-repositories \"Link to this heading\")\n\nSnowflake CLI lets you perform the following tasks with Snowpark Container Services image repositories:\n\n*   [Create an image repository](#label-sfcli-repo-create)\n    \n*   [Create and deploy an image repository from a project definition](#label-sfcli-repo-pdf)\n    \n*   [Retrieve the URL for an image repository](#label-sfcli-repo-url)\n    \n*   [List tags and images in an image repository](#label-sfcli-repo-list)\n    \n\nFor common operations, such as listing or dropping, Snowflake CLI uses `snow object` commands as described in [Managing Snowflake objects](../objects/manage-objects).\n\n### Create an image repository[¶](#create-an-image-repository \"Link to this heading\")\n\nThe [snow spcs image-repository create](../command-reference/spcs-commands/image-repository-commands/create) command creates a new image repository in the current schema.\n\nTo create an image repository, enter a command similar to the following:\n\n```\nsnow spcs image-repository create tutorial_repository\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\n### Create and deploy an image repository from a project definition[¶](#create-and-deploy-an-image-repository-from-a-project-definition \"Link to this heading\")\n\nYou can deploy an image repository to a stage by creating a `snowflake.yml` project definition file and executing the `snow spcs image-repository deploy` command.\n\nThe following shows a sample `snowflake.yml` project definition file:\n\n```\ndefinition_version: 2\nentities:\n  my_image_repository:\n    type: image-repository\n    identifier: my_image_repository\n\n```\n\nCopy\n\nThe following table describes the properties of a compute pool project definition.\n\n| Property | Definition |\n| --- | --- |\n| typerequired, string | Must be image-repository. |\n| identifieroptional, string | Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-image-repository\nCopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (for example, \"My Image Repository\").Objectidentifier:\n  name: my-image-repository\n  schema: my-schema # optional\n  database: my-db # optional\nCopyNoteAn error occurs if you specify a schema or database and use a fully qualified name in the name property (such as mydb.schema1.my-app). |\n\nTo create and deploy the image repository, do the following:\n\n1.  Change your current directory to the directory containing the project definition file.\n    \n2.  Run a `snow spcs image-repository deploy` command similar to the following:\n    \n    ```\n    snow spcs image-repository deploy\n    \n    ```\n    \n    Copy\n    \n    ```\n    +---------------------------------------------------------------------+\n    | key    | value                                                      |\n    |--------+------------------------------------------------------------|\n    | status | Image Repository MY_IMAGE_REPOSITORY successfully created. |\n    +---------------------------------------------------------------------+\n    \n    ```\n    \n\n### Retrieve the URL for an image repository[¶](#retrieve-the-url-for-an-image-repository \"Link to this heading\")\n\nThe [snow spcs image-repository url](../command-reference/spcs-commands/image-repository-commands/url) command gets the URL for an image repository.\n\nTo get the URL, enter a command similar to the following:\n\n```\nsnow spcs image-repository url tutorial_repository\n\n```\n\nCopy\n\n```\n<orgname-acctname>.registry.snowflakecomputing.com/tutorial_db/data_schema/tutorial_repository\n\n```\n\n### List tags and images in an image repository[¶](#list-tags-and-images-in-an-image-repository \"Link to this heading\")\n\nThe [snow spcs image-repository list-images](../command-reference/spcs-commands/image-repository-commands/list-images) command lets you get the images and tags for an image repository.\n\nTo list the images and tags in a repository, enter a command similar to the following, which lists the images in a repository named `images` in the `my_db` database:\n\n```\nsnow spcs image-repository list-images images --database my_db\n\n```\n\nCopy\n\n```\n+----------------------------+---------------+---------+-------------------------------------------------+-----------------------------------------+\n| created_on                 | image_name    | tags    | digest                                          | image_path                              |\n|----------------------------+---------------+---------+-------------------------------------------------+-----------------------------------------|\n| 2024-10-11 14:23:49-07:00  | echo_service  | latest  | sha256:a8a001fef406fdb3125ce8e8bf9970c35af7084  | my_db/test_schema/images/echo_service:  |\n|                            |               |         | fc33b0886d7a8915d3082c781                       | latest                                  |\n| 2024-10-14 22:21:14-07:00  | test_counter  | latest  | sha256:8cae96dac29a4a05f54bb5520003f964baf67fc  | my_db/test_schema/images/test_counter:  |\n|                            |               |         | 38dcad3d2c85d6c5aa7381174                       | latest                                  |\n+----------------------------+---------------+---------+-------------------------------------------------+-----------------------------------------+\n\n```\n\nOn this page\n\n1.  [Manage image registries](#manage-image-registries)\n2.  [Get environment tokens for registry authentication](#get-environment-tokens-for-registry-authentication)\n3.  [Log in to an image registry](#log-in-to-an-image-registry)\n4.  [Retrieve the URL for an image registry](#retrieve-the-url-for-an-image-registry)\n5.  [Manage image repositories](#manage-image-repositories)\n6.  [Create an image repository](#create-an-image-repository)\n7.  [Create and deploy an image repository from a project definition](#create-and-deploy-an-image-repository-from-a-project-definition)\n8.  [Retrieve the URL for an image repository](#retrieve-the-url-for-an-image-repository)\n9.  [List tags and images in an image repository](#list-tags-and-images-in-an-image-repository)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/services/../index)\n2.  [Managing Snowpark Container Services in Snowflake CLI](/developer-guide/snowflake-cli/services/overview)\n3.  [snow spcs image-registry commands](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/image-registry-commands/overview)\n4.  [snow spcs image-repository commands](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/image-repository-commands/overview)\n5.  [snow spcs image-repository deploy](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/image-repository-commands/deploy)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/services/manage-images",
    "full_command": "NULL",
    "id": "NULL",
    "parent_command": "NULL",
    "content_hash": "3cfc67fdd2a36c0939e4b998054a2c9c210c53ce5bba88bbdf08edef3a6f08e5"
  },
  {
    "metadata": "NULL",
    "raw_content": "# Managing compute pools[¶](#managing-compute-pools \"Link to this heading\")\n\nA compute pool is a collection of one or more virtual machine (VM) nodes on which Snowflake runs your Snowpark Container Services jobs and services.\n\nFor more information about compute pools, see [Snowpark Container Services: Working with compute pools](../../snowpark-container-services/working-with-compute-pool).\n\nThis topic shows how to do the following tasks with services:\n\n*   [Create a compute pool](#label-sfcli-pool-create)\n    \n*   [Create a compute pool from a project definition](#label-sfcli-pool-pdf)\n    \n*   [Suspend and resume a compute pool](#label-sfcli-pool-suspend-resume)\n    \n*   [Set and unset a compute pool’s properties or parameters](#label-sfcli-pool-set-unset)\n    \n*   [Stop all services in a compute pool](#label-sfcli-pool-stop-all)\n    \n\nFor common operations, such as listing or dropping, Snowflake CLI uses `snow object` commands as described in [Managing Snowflake objects](../objects/manage-objects).\n\n## Create a compute pool[¶](#create-a-compute-pool \"Link to this heading\")\n\nTo create a compute pool named “pool\\_1” composed of two CPUs with 4 GB of memory, enter a [spcs pool create](../command-reference/spcs-commands/compute-pool-commands/create) command similar to the following:\n\n```\nsnow spcs compute-pool create \"pool_1\" --min-nodes 2 --max-nodes 2 --family \"CPU_X64_XS\"\n\n```\n\nCopy\n\nFor more information about instance families, see the SQL `CREATE COMPUTE POOL` command.\n\n## Create a compute pool from a project definition[¶](#create-a-compute-pool-from-a-project-definition \"Link to this heading\")\n\nYou can create a compute pool from a `snowflake.yml` project definition file and then executing the `snow spcs compute-pool deploy` command.\n\nThe following shows a sample `snowflake.yml` project definition file:\n\n```\ndefinition_version: 2\nentities:\n  my_compute_pool:\n    type: compute-pool\n    identifier:\n      name: my_compute_pool\n    min_nodes: 1\n    max_nodes: 2\n    instance_family: CPU_X64_XS\n    auto_resume: true\n    initially_suspended: true\n    auto_suspend_seconds: 60\n    comment: \"My compute pool\"\n    tags:\n      - name: my_tag\n        value: tag_value\n\n```\n\nCopy\n\nThe following table describes the properties of a compute pool project definition.\n\n| Property | Definition |\n| --- | --- |\n| typerequired, string | Must be compute-pool. |\n| identifieroptional, string | Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-compute-pool\nCopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (for example, \"My Compute Pool\").Objectidentifier:\n  name: my-compute-pool\n  schema: my-schema # optional\n  database: my-db # optional\nCopyNoteAn error occurs if you specify a schema or database and use a fully qualified name in the name property (such as mydb.schema1.my-app). |\n| instance_familyrequired, string | Name of the instance family. For a list of available instance families, see the CREATE COMPUTE POOL INSTANCE_FAMILY parameter. |\n| min_nodesoptional, string | Minimum number of nodes for the compute pool. This value must be greater than 0.Default: 1 |\n| max_nodesoptional, int | Maximum number of nodes for the compute pool. |\n| auto_resumeoptional, boolean | Whether to automatically resume a compute pool when a service or job is submitted to it.Default: True |\n| initially_suspendedoptional, boolean | Whether the compute pool is created initially in the suspended state. If true, Snowflake doesn’t provision any nodes requested for the compute pool at the compute pool creation time.Default: False |\n| auto_suspend_secondsoptional, int | Number of seconds of inactivity after which you want Snowflake to automatically suspend the compute pool.Default: 3600 |\n| commentoptional, string | Comments to associate with the compute pool. |\n| tagsoptional, Tag sequence | Tag names and values for the compute pool. For more information, see Tag quotas |\n\nTo create and deploy the compute pool to a stage, do the following:\n\n1.  Change your current directory to the directory containing the project definition file.\n    \n2.  Run a `snow spcs compute-pool deploy` command similar to the following:\n    \n    ```\n    snow spcs compute-pool deploy\n    \n    ```\n    \n    Copy\n    \n    ```\n    +---------------------------------------------------------------------+\n    | key    | value                                                      |\n    |--------+------------------------------------------------------------|\n    | status | Compute pool MY_COMPUTE_POOL successfully created.         |\n    +---------------------------------------------------------------------+\n    \n    ```\n    \n\n## Suspend and resume a compute pool[¶](#suspend-and-resume-a-compute-pool \"Link to this heading\")\n\nNote\n\nThe current role must have OPERATE privilege on the compute pool to suspend or resume it.\n\nTo suspend a compute pool, enter a command similar to the following:\n\n```\nsnow spcs compute-pool suspend tutorial_compute_pool\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nTo resume a suspended compute pool, enter a command similar to the following:\n\n```\nsnow spcs compute-pool resume tutorial_compute_pool\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\n## Set and unset a compute pool’s properties or parameters[¶](#set-and-unset-a-compute-pool-s-properties-or-parameters \"Link to this heading\")\n\nNote\n\nThe current role must have MODIFY privilege on the compute pool to set properties.\n\nTo set a property or parameter, enter a command similar to the following:\n\n```\nsnow spcs compute-pool set tutorial_compute_pool --min-nodes 2 --max-nodes 4\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nTo reset a property or parameter to its default value, enter a command similar to the following:\n\n```\nsnow spcs compute-pool unset tutorial_compute_pool --auto-resume\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\n## Stop all services in a compute pool[¶](#stop-all-services-in-a-compute-pool \"Link to this heading\")\n\nStopping a compute pool deletes all of the services running on the compute pool; however, it does not stop the compute pool itself.\n\nTo stop a compute pool, enter a [spcs compute-pool stop-all](../command-reference/spcs-commands/compute-pool-commands/stop-all) command similar to the following:\n\n```\nsnow spcs compute-pool stop-all \"pool_1\"\n\n```\n\nCopy\n\nOn this page\n\n1.  [Create a compute pool](#create-a-compute-pool)\n2.  [Create a compute pool from a project definition](#create-a-compute-pool-from-a-project-definition)\n3.  [Suspend and resume a compute pool](#suspend-and-resume-a-compute-pool)\n4.  [Set and unset a compute pool’s properties or parameters](#set-and-unset-a-compute-pool-s-properties-or-parameters)\n5.  [Stop all services in a compute pool](#stop-all-services-in-a-compute-pool)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/services/../index)\n2.  [Managing Snowpark Container Services in Snowflake CLI](/developer-guide/snowflake-cli/services/overview)\n3.  [snow spcs compute-pool commands](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/compute-pool-commands/overview)\n4.  [snow spcs compute-pool deploy](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/compute-pool-commands/deploy)\n5.  [Snowpark Container Services: Working with compute pools](/developer-guide/snowflake-cli/services/../../snowpark-container-services/working-with-compute-pool)\n6.  [CREATE COMPUTE POOL](/developer-guide/snowflake-cli/services/../../../sql-reference/sql/create-compute-pool)",
    "full_command": "NULL",
    "parent_command": "NULL",
    "command_group": "NULL",
    "title": "Managing compute pools¶",
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/services/manage-compute-pools",
    "content_hash": "e6839a435c09321fa4c53fe507e3d174748e60da1c4555a0e03c367c31ea2774",
    "id": "NULL",
    "last_scraped": "NULL"
  },
  {
    "metadata": "NULL",
    "last_scraped": "NULL",
    "title": "Managing services¶",
    "content_hash": "330bf0cfc7fe5488b6bb28a48ae6e3045347e55a24c01478da6bedfa39e27eb0",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/services/manage-services",
    "category": "NULL",
    "command_group": "NULL",
    "id": "NULL",
    "parent_command": "NULL",
    "full_command": "NULL",
    "raw_content": "# Managing services[¶](#managing-services \"Link to this heading\")\n\nSnowpark Container Services enables you to easily deploy, manage, and scale containerized applications. After you upload your application image to a repository in your account, you run your application containers as a service or a job. This topic explains working with services.\n\nA service is long-running, like a web service, and does not end on its own. Snowflake manages running services. For example, if a service container exits, for whatever reason, Snowflake restarts that container so the service runs uninterrupted. If your service needs more resources, such as more compute power, Snowflake provisions additional nodes in the compute pool.\n\nFor more information about working with container services, see [Snowpark Container Services: Working with services](../../snowpark-container-services/working-with-services).\n\nThis topic shows how to do the following tasks with services:\n\n*   [Create a Snowpark Container Services service](#label-sfcli-service-create)\n    \n*   [Create and deploy a service from a project definition](#label-sfcli-service-pdf)\n    \n*   [Suspend and resume a service](#label-sfcli-service-suspend-resume)\n    \n*   [Get status information about a service](#label-sfcli-service-status)\n    \n*   [List the endpoints in a service](#label-sfcli-service-endpoints)\n    \n*   [Set and unset a service’s properties or parameters](#label-sfcli-service-set-unset)\n    \n*   [Display logs for a named service](#label-sfcli-service-logs)\n    \n*   [Upgrade a named service](#label-sfcli-service-upgrade)\n    \n\nFor common operations, such as listing or dropping, Snowflake CLI uses `snow object` commands as described in [Managing Snowflake objects](../objects/manage-objects).\n\n## Create a Snowpark Container Services service[¶](#create-a-snowpark-container-services-service \"Link to this heading\")\n\nA Snowpark container service requires the following:\n\n*   **A compute pool**: Snowflake runs your service in the specified compute pool.\n    \n*   **A service specification file**: This specification gives Snowflake the information needed to configure and run your service.\n    \n\nTo create a service, enter a [snow spcs service create](../command-reference/spcs-commands/service-commands/create) command similar to the following:\n\n```\nsnow spcs service create \"job_1\" --compute-pool \"pool_1\" --spec-path \"/some-dir/spec_file.yaml\"\n\n```\n\nCopy\n\nFor more information, see [Managing Snowflake objects](../objects/manage-objects).\n\n### Create and deploy a service from a project definition[¶](#create-and-deploy-a-service-from-a-project-definition \"Link to this heading\")\n\nYou can create a service from a `snowflake.yml` project definition file and then executing the `snow spcs service deploy` command.\n\nThe following shows a sample `snowflake.yml` project definition file:\n\n```\ndefinition_version: 2\nentities:\n  my_service:\n    type: service\n    identifier: my_service\n    stage: my_stage\n    compute_pool: my_compute_pool\n    spec_file: spec.yml\n    min_instances: 1\n    max_instances: 2\n    query_warehouse: my_warehouse\n    auto_resume: true\n    external_access_integrations:\n      - my_external_access\n    secrets:\n        cred: my_cred_name\n    artifacts:\n      - spec.yml\n    comment: \"My service\"\n    tags:\n      - name: test_tag\n        value: test_value\n\n```\n\nCopy\n\nThe following table describes the properties of a compute pool project definition.\n\n| Property | Definition |\n| --- | --- |\n| typerequired, string | Must be service. |\n| stagerequired, string | Stage where the service specification file is located. |\n| compute_poolrequired, string | Compute pool where the service runs. |\n| spec_filerequired, string | Path to service specification file on the stage. |\n| identifieroptional, string | Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-service\nCopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (for example, ’”My Image Repository\").Objectidentifier:\n  name: my-service\n  schema: my-schema # optional\n  database: my-db # optional\nCopyNoteAn error occurs if you specify a schema or database and use a fully qualified name in the name property (such as mydb.schema1.my-app). |\n| min_instancesoptional, string | Minimum number of service instances to run.Default: 1 |\n| max_instancesoptional, string | Maximum number of service instances to run. |\n| query_warehouseoptional, string | Warehouse to use if a service container connects to Snowflake to execute a query without explicitly specifying a warehouse to use. |\n| auto_resumeoptional, string | Whether to automatically resume when a service function or ingress is called.Default: True |\n| external_access_integrationsoptional, string sequence | Names of external access integrations needed for this entity to access external networks. |\n| secretsoptional, dictionary | Names and values of secrets variables so that you can use the variables to reference the secrets. |\n| artifactsoptional, string sequence | List of file source and destination pairs to add to the deploy root. You can use the following artifact properties:src: Path to the code source file or filesdest: Path to the directory to deploy the artifacts.Destination paths that reference directories must end with a /. A glob pattern’s destination that does not end with a / results in an error. If omitted, dest defaults to the same string as src.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest.If src refers to just one file (not a glob), dest can refer to a target <path> or a <path/name>.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest. |\n| commentoptional, string | Comments to associate with the compute pool. |\n| tagsoptional, Tag sequence | Tag names and values for the compute pool. For more information, see Tag quotas |\n\nTo create and deploy a service, do the following:\n\n1.  Change your current directory to the directory containing the project definition file.\n    \n2.  Run a `snow spcs service deploy` command similar to the following:\n    \n    ```\n    snow spcs service deploy\n    \n    ```\n    \n    Copy\n    \n    ```\n    +---------------------------------------------------------------------+\n    | key    | value                                                      |\n    |--------+------------------------------------------------------------|\n    | status | Service MY_SERVICE successfully created.                   |\n    +---------------------------------------------------------------------+\n    \n    ```\n    \n\n## Suspend and resume a service[¶](#suspend-and-resume-a-service \"Link to this heading\")\n\nTo suspend a named service, enter a [snow spcs service suspend](../command-reference/spcs-commands/service-commands/suspend) command similar to the following:\n\n```\nsnow spcs service suspend echo_service\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nTo resume a suspended service, enter a [snow spcs service resume](../command-reference/spcs-commands/service-commands/resume) command similar to the following:\n\n```\nsnow spcs service resume echo_service\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\n## Get status information about a service[¶](#get-status-information-about-a-service \"Link to this heading\")\n\nNote\n\nThe current role must have MONITOR privilege on the service to get its status.\n\n### List all services[¶](#list-all-services \"Link to this heading\")\n\nThe [snow spcs service list](../command-reference/spcs-commands/service-commands/list) command returns an overview of all services, including the runtime state of the services, such as PENDING or RUNNING, and the upgrading status. To get the status of all services, enter a command similar to the following:\n\n```\nsnow spcs service list\n\n```\n\nCopy\n\n```\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|        |        |        |        |        |        |        |        |        |        |        |         | extern |         |        |         |        |         |        |        |         |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         | al_acc |         |        |         |        |         |        |        |         |        | managin | managi |\n|        |        | databa |        |        |        |        | curren | target | min_in | max_in |         | ess_in |         |        |         |        | owner_r | query_ |        |         |        | g_objec | ng_obj |\n|        |        | se_nam | schema |        | comput | dns_na | t_inst | _insta | stance | stance | auto_re | tegrat | created | update | resumed | commen | ole_typ | wareho |        | spec_di | is_upg | t_domai | ect_na |\n| name   | status | e      | _name  | owner  | e_pool | me     | ances  | nces   | s      | s      | sume    | ions   | _on     | d_on   | _on     | t      | e       | use    | is_job | gest    | rading | n       | me     |\n|--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+--------+---------+--------+---------+--------+---------+--------+--------+---------+--------+---------+--------|\n| ECHO_S | RUNNIN | TEST00 | TEST_S | SYSADM | TUTORI | echo-s | 1      | 1      | 1      | 1      | true    | None   | 2024-10 | 2024-1 | None    | This   | ROLE    | COMPUT | false  | 52e62d1 | false  | None    | None   |\n| ERVICE | G      | _DB    | CHEMA  | IN     | AL_COM | ervice |        |        |        |        |         |        | -16     | 0-16   |         | is a   |         | E_WH   |        | f19c720 |        |         |        |\n|        |        |        |        |        | PUTE_P | .imhd. |        |        |        |        |         |        | 15:09:3 | 15:09: |         | test   |         |        |        | 6b5f4ef |        |         |        |\n|        |        |        |        |        | OOL    | svc.sp |        |        |        |        |         |        | 0.49300 | 31.905 |         | servic |         |        |        | c069557 |        |         |        |\n|        |        |        |        |        |        | cs.int |        |        |        |        |         |        | 0-07:00 | 000-07 |         | e      |         |        |        | 8b6c2b3 |        |         |        |\n|        |        |        |        |        |        | ernal  |        |        |        |        |         |        |         | :00    |         |        |         |        |        | 806ad76 |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 67d78cc |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | ce8b6ed |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 6501a8a |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 3       |        |         |        |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\n### Get the status of a named service[¶](#get-the-status-of-a-named-service \"Link to this heading\")\n\nTo get the status of an individual service, enter a [snow spcs service describe](../command-reference/spcs-commands/service-commands/describe) command similar to the following:\n\n```\nsnow spcs service describe echo_service\n\n```\n\nCopy\n\n```\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|        |        |        |        |        |        |        |        |        |        |        |         | extern |         |        |         |        |         |        |        |         |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         | al_acc |         |        |         |        |         |        |        |         |        | managin | managi |\n|        |        | databa |        |        |        |        | curren | target | min_in | max_in |         | ess_in |         |        |         |        | owner_r | query_ |        |         |        | g_objec | ng_obj |\n|        |        | se_nam | schema |        | comput | dns_na | t_inst | _insta | stance | stance | auto_re | tegrat | created | update | resumed | commen | ole_typ | wareho |        | spec_di | is_upg | t_domai | ect_na |\n| name   | status | e      | _name  | owner  | e_pool | me     | ances  | nces   | s      | s      | sume    | ions   | _on     | d_on   | _on     | t      | e       | use    | is_job | gest    | rading | n       | me     |\n|--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+--------+---------+--------+---------+--------+---------+--------+--------+---------+--------+---------+--------|\n| ECHO_S | RUNNIN | TEST00 | TEST_S | SYSADM | TUTORI | echo-s | 1      | 1      | 1      | 1      | true    | None   | 2024-10 | 2024-1 | None    | This   | ROLE    | COMPUT | false  | 52e62d1 | false  | None    | None   |\n| ERVICE | G      | _DB    | CHEMA  | IN     | AL_COM | ervice |        |        |        |        |         |        | -16     | 0-16   |         | is a   |         | E_WH   |        | f19c720 |        |         |        |\n|        |        |        |        |        | PUTE_P | .imhd. |        |        |        |        |         |        | 15:09:3 | 15:09: |         | test   |         |        |        | 6b5f4ef |        |         |        |\n|        |        |        |        |        | OOL    | svc.sp |        |        |        |        |         |        | 0.49300 | 31.905 |         | servic |         |        |        | c069557 |        |         |        |\n|        |        |        |        |        |        | cs.int |        |        |        |        |         |        | 0-07:00 | 000-07 |         | e      |         |        |        | 8b6c2b3 |        |         |        |\n|        |        |        |        |        |        | ernal  |        |        |        |        |         |        |         | :00    |         |        |         |        |        | 806ad76 |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 67d78cc |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | ce8b6ed |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 6501a8a |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 3       |        |         |        |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\n### List instances and containers[¶](#list-instances-and-containers \"Link to this heading\")\n\nYou can list service’s instances and containers with the `snow spcs service list-instances` and `snow spcs service list-containers` commands, respectively.\n\nTo get the list of instances in the `echo_service` service, enter the following [snow spcs service list-instances](../command-reference/spcs-commands/service-commands/list-instances) command:\n\n```\nsnow spcs service list-instances echo_service\n\n```\n\nCopy\n\n```\n+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| database_name | schema_name | service_name | instance_id | status | spec_digest                                                      | creation_time        | start_time           |\n|---------------+-------------+--------------+-------------+--------+------------------------------------------------------------------+----------------------+----------------------|\n| TEST00_DB     | TEST_SCHEMA | ECHO_SERVICE | 0           | READY  | 336c065739dd2b96e770f01804affdc7810e6df68a23b23052d851627abfbdf9 | 2024-10-10T06:06:30Z | 2024-10-10T06:06:30Z |\n+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\nTo get the list of containers in the `echo_service` service, enter the following [snow spcs service list-containers](../command-reference/spcs-commands/service-commands/list-containers) command:\n\n```\nsnow spcs service list-containers echo_service\n\n```\n\nCopy\n\n```\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| database_name | schema_name | service_name | instance_id | container_name | status | message | image_name                                | image_digest                              | restart_count | start_time           |\n|---------------+-------------+--------------+-------------+----------------+--------+---------+-------------------------------------------+-------------------------------------------+---------------+----------------------|\n| TEST00_DB     | TEST_SCHEMA | ECHO_SERVICE | 0           | main           | READY  | Running | org-test-account-00.registry.registry.sno | sha256:06c3d54edc24925abe398eda70d37eb6b8 | 0             | 2024-10-16T22:09:35Z |\n|               |             |              |             |                |        |         | wflakecomputing.com/test00_db/test_schema | 7b1c4dd6211317592764e1e7d94498            |               |                      |\n|               |             |              |             |                |        |         | /test00_repo/echo_service:latest          |                                           |               |                      |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\n### List the endpoints in a service[¶](#list-the-endpoints-in-a-service \"Link to this heading\")\n\nTo list the endpoints a named service, enter a [snow spcs service list-endpoints](../command-reference/spcs-commands/service-commands/list-endpoints) command similar to the following:\n\n```\nsnow spcs service list-endpoints echo_service\n\n```\n\nCopy\n\n```\n+--------------+------+----------+-----------------+-----------------------------------------+\n| name         | port | protocol | ingress_enabled | ingress_url                             |\n|--------------+------+----------+-----------------+-----------------------------------------|\n| echoendpoint | 8000 | TCP      | true            | org-id-acct-id.snowflakecomputing.app   |\n+--------------+------+----------+-----------------+-----------------------------------------+\n\n```\n\n### List the service roles associated with a service[¶](#list-the-service-roles-associated-with-a-service \"Link to this heading\")\n\nYou can manage access to individual endpoints exposed by a service by defining service roles and permissions in the service specification. For more information about how to use service roles, see [GRANT SERVICE ROLE](../../../sql-reference/sql/grant-service-role).\n\nTo get a list of service roles created for a service, use the [snow spcs service list-roles](../command-reference/spcs-commands/service-commands/list-roles) command, as shown:\n\n```\nsnow spcs service list-roles my_service\n\n```\n\nCopy\n\n```\n+------------------------------------------------------------------+\n| created_on                       | name                | comment |\n|----------------------------------+---------------------+---------|\n| 2024-10-09 16:48:52.980000-07:00 | ALL_ENDPOINTS_USAGE | None    |\n+------------------------------------------------------------------+\n\n```\n\n## Set and unset a service’s properties or parameters[¶](#set-and-unset-a-service-s-properties-or-parameters \"Link to this heading\")\n\nNote\n\nThe current role must have OPERATE privilege on the service to set properties.\n\nTo set a service’s property or parameter, enter a [snow spcs service set](../command-reference/spcs-commands/service-commands/set) command similar to the following:\n\n```\nsnow spcs service set echo_service --min-instances 2 --max-instances 4\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nTo reset a service’s property or parameter to its default value, enter a command similar to the following:\n\n```\nsnow spcs compute-pool unset tutorial_compute_pool --auto-resume\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\n## Display logs for a named service[¶](#display-logs-for-a-named-service \"Link to this heading\")\n\nNote\n\nThe current role must have MONITOR privilege on the service to display logs.\n\nTo display local logs for a named service, enter a [snow spcs service logs](../command-reference/spcs-commands/service-commands/logs) command similar to the following:\n\n```\nsnow spcs service logs \"service_1\" --container-name \"container_1\" --instance-id \"0\"\n\n```\n\nCopy\n\n## Upgrade a named service[¶](#upgrade-a-named-service \"Link to this heading\")\n\nNote\n\nThe current role must have OPERATE privilege on the service to upgrade it.\n\nTo upgrade a named service, enter a [snow spcs service upgrade](../command-reference/spcs-commands/service-commands/upgrade) command similar to the following:\n\n```\nsnow spcs service upgrade echo_service --spec-path spec.yml\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Create a Snowpark Container Services service](#create-a-snowpark-container-services-service)\n2.  [Suspend and resume a service](#suspend-and-resume-a-service)\n3.  [Get status information about a service](#get-status-information-about-a-service)\n4.  [Set and unset a service’s properties or parameters](#set-and-unset-a-service-s-properties-or-parameters)\n5.  [Display logs for a named service](#display-logs-for-a-named-service)\n6.  [Upgrade a named service](#upgrade-a-named-service)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/services/../index)\n2.  [Managing Snowpark Container Services in Snowflake CLI](/developer-guide/snowflake-cli/services/overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/overview)\n4.  [snow spcs service commands](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/service-commands/overview)\n5.  [snow spcs service deploy](/developer-guide/snowflake-cli/services/../command-reference/spcs-commands/service-commands/deploy)\n6.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/services/../../snowpark-container-services/working-with-services)"
  },
  {
    "parent_command": "NULL",
    "title": "Creating a Streamlit app¶",
    "last_scraped": "NULL",
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/initialize-app",
    "raw_content": "# Creating a Streamlit app[¶](#creating-a-streamlit-app \"Link to this heading\")\n\n## Prerequisites[¶](#prerequisites \"Link to this heading\")\n\nBefore creating a Streamlit app with Snowflake CLI, you should meet the following prerequisites:\n\n*   Ensure that your account has the correct privileges as described in [Privileges required to create and use a Streamlit app](../../../streamlit/object-management/privileges).\n    \n*   Ensure that you can create or have access to a named stage where you can upload your Streamlit app files.\n    \n\n## Bootstrap a Streamlit app[¶](#bootstrap-a-streamlit-app \"Link to this heading\")\n\nThe `snow init` command creates a local directory with a sample set of files that help you get started creating a Streamlit app. When you execute this command, Snowflake CLI creates the following directory structure:\n\n```\nexample_streamlit/            - project name (default: example_streamlit)\n  snowflake.yml               - configuration for snow streamlit commands\n  environment.yml             - additional config for Streamlit, for example installing packages\n  streamlit_app.py            - entrypoint file of the app\n  pages/                      - directory name for Streamlit pages (default pages)\n  common/                     - example “shared library”\n\n```\n\nTo initialize a Streamlit app, enter the following command:\n\n```\nsnow init new_streamlit_project --template example_streamlit -D query_warehouse=dev_warehouse -D stage=testing\n\n```\n\nCopy\n\nCaution\n\nFiles inside a project directory are processed by Snowflake CLI and could be uploaded to Snowflake when executing other `snow streamlit` commands. You should use caution when putting any sensitive information inside files in a project directory.\n\nFor more information about the file structure, see [Optional: Create the Streamlit files on your local file system](../../../streamlit/getting-started/create-streamlit-sql.html#label-streamlit-create-app-files).\n\n## Create the project definition for a Streamlit app[¶](#create-the-project-definition-for-a-streamlit-app \"Link to this heading\")\n\nEach Streamlit app in Snowflake must include a `snowflake.yml` project definition file. Streamlit is limited to one application per project definition file.\n\nThe following shows a sample `snowflake.yml` project definition file:\n\n```\ndefinition_version: 2\nentities:\n  my_streamlit:\n    type: streamlit\n    identifier: streamlit_app\n    stage: my_streamlit_stage\n    query_warehouse: my_streamlit_warehouse\n    main_file: streamlit_app.py\n    pages_dir: pages/\n    external_access_integrations:\n      - test_egress\n    secrets:\n      dummy_secret: \"db.schema.dummy_secret\"\n    imports:\n      - \"@my_stage/foo.py\"\n    artifacts:\n      - common/hello.py\n      - environment.yml\n    grants:\n      - privilege: USAGE\n        role: streamlit_role\n\n```\n\nCopy\n\nThe following table describes the properties of a Streamlit project definition.\n\n| Property | Definition |\n| --- | --- |\n| identifieroptional, string | Optional Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-streamlit-id\nCopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (e.g. ’”My Streamlit Application”’).Objectidentifier:\n  name: my-streamlit-id\n  schema: my-schema # optional\n  database: my-db # optional\nCopyNoteAn error occurs if you specify a schema or database and use a fully-qualified name in the name property (such as mydb.schema1.my-app). |\n| typeoptional, string | Must be streamlit. |\n| commentoptional, string | Comment for the Streamlit dashboard. |\n| titleoptional, string | Human-readable title for the Streamlit dashboard. |\n| stageoptional, string | Stage in which the app’s artifacts will be stored. Default: None. |\n| query_warehouserequired, string | Snowflake warehouse to host the app. |\n| main_fileoptional, string | Entrypoint file of the streamlit app. Default: “streamlit_app.py”. |\n| pages_diroptional, string | Streamlit pages. Default: “pages”. |\n| external_access_integrationsoptional, string sequence | Names of external access integrations needed for this Streamlit application code to access external networks. See the optional parameters for CREATE STREAMLIT for more details. |\n| secretsoptional, dictionary | Assigns the names of secrets to variables so that you can use the variables to reference the secrets when retrieving information from secrets in application code. |\n| importsoptional, string sequence | Stage and path to previously uploaded files you want to import. See the optional parameters for CREATE STREAMLIT for more details. |\n| artifactsrequired, string sequence | List of file source and destination pairs to add to the deploy root. You can use the following artifact properties:src: Path to the code source file or files.dest: Path to the directory to deploy the artifacts.Destination paths that reference directories must end with a /. A glob pattern’s destination that does not end with a / results in an error. If omitted, dest defaults to the same string as src.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest.If src refers to just one file (not a glob), dest can refer to a target <path> or a <path/name>.You can also pass in a string for each item instead of a dict; in that case, the value is treated as both src and dest. |\n| grantsoptional, grant sequence | Grants that should be given for the Streamlit app. Each grant must specify the privilege and target role. For more details, see the optional parameters for CREATE STREAMLIT. |\n\nOn this page\n\n1.  [Prerequisites](#prerequisites)\n2.  [Bootstrap a Streamlit app](#bootstrap-a-streamlit-app)\n3.  [Create the project definition for a Streamlit app](#create-the-project-definition-for-a-streamlit-app)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../index)\n2.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)\n3.  [snow init](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/bootstrap-commands/init)",
    "id": "NULL",
    "metadata": "NULL",
    "full_command": "NULL",
    "command_group": "NULL",
    "content_hash": "775ddc827880d39484e67b9f709d612d7af33b1a74f899fc26a5f10a521485d6"
  },
  {
    "last_scraped": "NULL",
    "category": "NULL",
    "title": "Initialize a Snowpark project¶",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/initialize",
    "command_group": "NULL",
    "metadata": "NULL",
    "raw_content": "# Initialize a Snowpark project[¶](#initialize-a-snowpark-project \"Link to this heading\")\n\nThe first step when creating Snowpark projects is to create a project boilerplate. The `snow init` command creates a fully-functional boilerplate with the following structure:\n\n```\nsnowflake.yml      - project definition\nrequirements.txt   - project dependencies\napp/               - code of functions and procedures\n  __init__.py\n  functions.py     - example functions\n  procedures.py    - example procedures\n  common.py        - example \"shared library\"\n\n```\n\n*   The `snowflake.yml` file contains a [project definition](../project-definitions/about) that describes the project structure that the `snow snowpark` commands use.\n    \n*   The `app` directory stores the project code. You can think about it as a Python module. All functions and procedures must reside in this directory.\n    \n*   The `requirements.txt` file contains project dependencies. Snowflake CLI supports all requirement specifiers supported by `pip`, such as a package name, a URL for a package, or a local path.\n    \n    You can add more dependencies (such as previously deployed custom packages) as `imports` parameters in the function and procedure declarations in the [project definition](../project-definitions/about).\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)\n3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)\n4.  [snow init](/developer-guide/snowflake-cli/snowpark/../command-reference/bootstrap-commands/init)\n5.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",
    "full_command": "NULL",
    "parent_command": "NULL",
    "content_hash": "69df207355f0123dc670ff1a15856b71cae8438c5696238996e2c424e5be383a"
  },
  {
    "raw_content": "# Create a Snowpark project definition[¶](#create-a-snowpark-project-definition \"Link to this heading\")\n\nThe `snowflake.yml` file contains the functions and procedures declarations for a Snowpark project.\n\nNote\n\nCurrently, the Snowpark project definition file must be named `snowflake.yml`.\n\nThe following snippet shows a sample Snowpark project definition file: with two functions and two procedures. The `hello_function` function uses external capabilities of Snowpark.\n\n```\ndefinition_version: '2'\n\nmixins:\n  snowpark_shared:\n    artifacts:\n      - dest: my_snowpark_project\n        src: app/\n    stage: dev_deployment\n\nentities:\n\n  hello_function:\n    type: function\n    identifier:\n      name: hello_function\n    handler: functions.hello_function\n    signature:\n      - name: name\n        type: string\n    returns: string\n    external_access_integrations:\n      - my_external_access\n    secrets:\n        cred: my_cred_name\n    meta:\n      use_mixins:\n        - snowpark_shared\n\n  hello_procedure:\n    type: procedure\n    identifier:\n      name: hello_procedure\n    handler: procedures.hello_procedure\n    signature:\n      - name: name\n        type: string\n    returns: string\n    meta:\n      use_mixins:\n        - snowpark_shared\n\n  test_procedure:\n    type: procedure\n    identifier:\n      name: test_procedure\n    handler: procedures.test_procedure\n    signature: ''\n    returns: string\n    meta:\n      use_mixins:\n        - snowpark_shared\n\n```\n\nCopy\n\nCaution\n\nFiles inside a project directory are processed by Snowflake CLI and could be uploaded to Snowflake when executing other `snow snowpark` commands. You should use caution when putting any sensitive information inside files in a project directory.\n\n## Function and procedure object properties[¶](#function-and-procedure-object-properties \"Link to this heading\")\n\nThe following table describes the properties used by functions and procedures.\n\n| Property | Definition |\n| --- | --- |\n| identifieroptional, string | Optional Snowflake identifier for the entity. The value can have the following forms:String identifier textidentifier: my-snowpark-id\nCopyBoth unquoted and quoted identifiers are supported. To use quoted identifiers, include the surrounding quotes in the YAML value (e.g. ’”My Snowpark Function”’).Objectidentifier:\n  name: my-snowpark-id\n  schema: my-schema # optional\n  database: my-db # optional\nCopyNoteAn error occurs if you specify a schema or database and use a fully-qualified name in the name property (such as mydb.schema1.my-app). |\n| typeoptional, string | Must be one of: function or procedure. |\n| artifact_repositoryoptional, string | Name of the artifact repository. Snowflake has a default artifact repository called snowflake.snowpark.pypi_shared_repository that you use to connect and install PyPI packages within Snowpark UDFs and procedures. For more information, see Artifact Repository overview.The artifact_repository and packages parameters let you use non-anaconda packages, similar to the following:In the project’s app.py file, you can define a function like the following:from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef udf():\n  X, y = load_iris(return_X_y=True)\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n  model = RandomForestClassifier()\n  model.fit(X_train, y_train)\n  return model.score(X_test, y_test)\nCopyIn the snowflake.yml file, you would then define it like the following:test_function:\n  type: \"function\"\n  handler: \"app.udf\"\n  identifier:\n    - name: \"udf\"\n  stage: \"dev_deployment\"\n  signature: \"\"\n  returns: float\n  artifact_repository: snowflake.snowpark.pypi_shared_repository\n  packages:\n    - \"scikit-learn\"\n  artifacts: \"app.py\"\nCopyFor packages that depend on specific architectures, you can define them in the resource_constraint parameter as follows:test_function:\n   type: \"function\"\n   handler: \"app.udf\"\n   identifier:\n     - name: \"udf\"\n   stage: \"dev_deployment\"\n   signature: \"\"\n   returns: float\n   artifact_repository: snowflake.snowpark.pypi_shared_repository\n   packages:\n     - \"scikit-learn\"\n   artifacts: \"app.py\"\nCopyFor more information, see Packages built only for x86. |\n| artifact_repository_packagesoptional, string | NoteThis property has been deprecated in favor of the packages property. |\n| packagesoptional, string | List of packages to install from the artifact_repository. For example:artifact_repository: snowflake.snowpark.pypi_shared_repository\npackages:\n\n  - Faker\n  - rich\n  - pytest\nCopy |\n| artifactsrequired, string sequence | List of file source and destination pairs to add to the deploy root. You can use the following artifact properties:src: Path to the code source file or filesdest: Path to the directory to deploy the artifacts.Destination paths that reference directories must end with a /. A glob pattern’s destination that does not end with a / results in an error. If omitted, dest defaults to the same string as src.NoteUsing glob patterns in Snowpark snowflake.yml files requires enabling the ENABLE_SNOWPARK_GLOB_SUPPORT feature flag.You can also pass in a string for each item instead of a dict, in which case the value is treated as both src and dest.If src refers to just one file (not a glob), dest can refer to a target <path> or a <path/name>.You can also pass in a string for each item instead of a dict, which case, the value is treated as both src and dest. |\n| handlerrequired, string | Function’s or procedure’s implementation of the object inside module defined in snowpark.src. For example functions.hello_function refers to function hello_function from file <src>/functions.py. |\n| returnsrequired, string | SQL type of the result. Check the list of available types. |\n| signaturerequired, sequence | The signature parameter describes consecutive arguments passed to the object. Each should specify its name and type, for example:signature:\n  - name: \"first_argument\"\n    type: int\n  - name: \"second_argument\"\n    default: \"default value\"\n    type: string\nCopyIf a function or procedure takes no arguments, set this value to an empty string (signature: \"\").Check the SQL Type column of available types. To learn more about the syntax of named and optional arguments, see Calling a UDF that has optional arguments. |\n| runtimeoptional, string | Python version to use when executing the procedure or function. Default: “3.12”. |\n| external_access_integrationsoptional, string sequence | Names of external access integrations needed for this procedure’s handler code to access external networks. See the EXTERNAL_ACCESS_INTEGRATIONS parameter in CREATE PROCEDURE for more details. |\n| secretsoptional, dictionary | Assigns the names of secrets to variables so that you can use the variables to reference the secrets when retrieving information from secrets in handler code. See the SECRETS parameter in CREATE PROCEDURE for more details. |\n| importsoptional, string sequence | Stage and path to previously uploaded files you want to import. See the IMPORT parameter in CREATE PROCEDURE for more details. |\n| execute_as_calleroptional, bool | Available only for procedures. Determine whether the procedure is executed with the privileges of the owner (you) or with the privileges of the caller. Default: False (owner’s privileges). |\n\nOn this page\n\n1.  [Function and procedure object properties](#function-and-procedure-object-properties)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)\n3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)\n4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",
    "command_group": "NULL",
    "parent_command": "NULL",
    "content_hash": "5b83183145bfea6a043003fdf056cc3406588df0135c04def6d03d6f88a0bb92",
    "last_scraped": "NULL",
    "title": "Create a Snowpark project definition¶",
    "category": "NULL",
    "full_command": "NULL",
    "metadata": "NULL",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/create"
  },
  {
    "id": "NULL",
    "raw_content": "# Build a Snowpark project[¶](#build-a-snowpark-project \"Link to this heading\")\n\nThe `snow snowpark build` command builds the Snowpark project as one or more `.zip` archive files that can be used by the `deploy` command. The cp,,amd builds the archives using only the `src` directory specified in the project file.\n\n```\nsnow snowpark build\n\n```\n\nCopy\n\n```\nResolving dependencies from requirements.txt\n  No external dependencies.\nPreparing artifacts for source code\n  Creating: app.zip\nBuild done.\n\n```\n\nAdditional options:\n\n*   `--allow-shared-libraries`: Allows shared (`.so`/`.dll`) libraries, when using packages installed through `pip`.\n    \n*   `--ignore-anaconda`: Does not lookup packages on Snowflake Anaconda channel.\n    \n*   `--index-url`: Specifies the base URL of the Python Package Index to use for package lookup. This URL should point to a repository compliant with PEP 503 (the simple repository API) or a local directory laid out in the same format.\n    \n*   `--skip-version-check`: Skips comparing versions of dependencies between requirements and Anaconda.\n    \n*   `--project [-p]`: Specifies the path where the Snowpark project resides. Defaults to the current working directory.\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)\n3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)\n4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",
    "command_group": "NULL",
    "parent_command": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/build",
    "category": "NULL",
    "last_scraped": "NULL",
    "content_hash": "4a7a12afa7e48bcc83a1cd53fb6ee3063bd58bcd3203195790efdd6189d51265",
    "metadata": "NULL",
    "title": "Build a Snowpark project¶",
    "full_command": "NULL"
  },
  {
    "category": "NULL",
    "id": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/deploy",
    "raw_content": "# Deploy a Snowpark project[¶](#deploy-a-snowpark-project \"Link to this heading\")\n\nThe `snow snowpark deploy` command uploads local files to the specified stage and creates procedure and function objects defined in the project. Deploying the project alters all objects defined in it. By default, if any of the objects exist already the commands fails unless you provide the `--replace` option. All deployed objects use the same artifact, which is uploaded only once.\n\n```\nsnow snowpark deploy\n\n```\n\nCopy\n\n```\n+-------------------------------------------------------------+\n| object                       | type      | status           |\n|------------------------------+-----------+------------------|\n| hello_procedure(name string) | procedure | created          |\n| test_procedure()             | procedure | packages updated |\n| hello_function(name string)  | function  | created          |\n+-------------------------------------------------------------+\n\n```\n\nWhen you run `snow snowpark deploy`, the command does the following:\n\n1.  Snowflake CLI checks whether any of the defined objects (functions or procedures) already exists.\n    \n2.  If any exist and the `--replace` flag is not provided, the command exits. The reasoning behind this approach is to be “production-safe” by avoiding unintentional changes to existing objects.\n    \n3.  If all objects don’t exist or `--replace` is provided, the command:\n    \n    *   If the `--prune` flag is provided, all previous contents of the stages used by defined procedure and function objects are removed.\n        \n    *   Uploads the new zip artifacts.\n        \n    *   Updates definitions of every procedure.\n        \n    *   Updates definitions of every function.\n        \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)\n3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)\n4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "content_hash": "c4089d6e64cf38fbe17810e68cafbee5af64296c06c361f40257ffcc5e6e192f",
    "title": "Deploy a Snowpark project¶",
    "parent_command": "NULL",
    "metadata": "NULL"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/execute",
    "id": "NULL",
    "command_group": "NULL",
    "last_scraped": "NULL",
    "title": "Execute a Snowpark procedure or function¶",
    "raw_content": "# Execute a Snowpark procedure or function[¶](#execute-a-snowpark-procedure-or-function \"Link to this heading\")\n\nTo execute a Snowpark procedure or function, use the `snow snowpark execute OBJECT_TYPE EXECUTION_IDENTIFIER` command, where:\n\n*   `OBJECT_TYPE` is one of `function` or `procedure`.\n    \n*   `EXECUTION_IDENTIFIER` is function or procedure signature, with all arguments provided.\n    \n\nThe following example calls a Snowpark function called `hello_function`:\n\n```\nsnow snowpark execute function \"hello_function('Olaf')\"\n\n```\n\nCopy\n\n```\n+--------------------------------------+\n| key                    | value       |\n|------------------------+-------------|\n| HELLO_FUNCTION('Olaf') | Hello Olaf! |\n+--------------------------------------+\n\n```\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)\n3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)\n4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",
    "metadata": "NULL",
    "full_command": "NULL",
    "content_hash": "fb829181a2037c31a8bd380995e5bf00f21517ac56287088cbf3d7fbd5323945",
    "category": "NULL",
    "parent_command": "NULL"
  },
  {
    "command_group": "NULL",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/upload",
    "content_hash": "22556be5ca464203f5e2b02ca83253a6f4298a8abec49325f1b6abe798a6a932",
    "raw_content": "# Upload an existing Python package[¶](#upload-an-existing-python-package \"Link to this heading\")\n\nSnowflake CLI allows you to add existing Python packages to Snowpark imports using the `snow snowpark package` commands. You can use already implemented packages, such as those from PyPi, in your functions and procedures.\n\nTo add a Python package to Snowpark imports, do the following:\n\n1.  [Check whether a package is already available](#label-snowcli-check-for-package).\n    \n2.  [Download a package and create a Snowflake artifact](#label-snowcli-download-package).\n    \n3.  [Upload the package to a Snowflake stage](#label-snowcli-upload-package).\n    \n4.  [Use the package in Snowpark procedures and functions](#label-snowcli-use-package).\n    \n\n## Check whether a package is already available[¶](#check-whether-a-package-is-already-available \"Link to this heading\")\n\nTo check whether a package is not already available use the `snow snowpark package lookup` command.\n\nThe following example illustrates looking up a package that is already available on the Snowflake Anaconda channel:\n\n```\nsnow snowpark package lookup numpy\n\n```\n\nCopy\n\n```\nPackage `numpy` is available in Anaconda. Latest available version: 1.26.4.\n\n```\n\nIf a package is not available on the Snowflake Anaconda channel, you can get a message similar to the following:\n\n```\nsnow snowpark package lookup july\n\n```\n\nCopy\n\n```\nPackage `july` is not available in Anaconda. To prepare Snowpark compatible package run:\n\n  snow snowpark package create july\n\n```\n\nFor more information, see the [snowpark package lookup](../command-reference/snowpark-commands/package-commands/lookup) command.\n\n## Download a package and create a Snowflake artifact[¶](#download-a-package-and-create-a-snowflake-artifact \"Link to this heading\")\n\nTo download a package and create a Snowflake artifact to upload use the `snow snowpark package create` command.\n\n```\nsnow snowpark package create <name>\n\n```\n\nCopy\n\nwhere:\n\n*   `<name>` can be any requirement specifier supported by `pip`, such as a package name, an URL for a package, or a local file path.\n    \n\nAdditional options:\n\n*   `--allow-shared-libraries`: Allows shared (`.so`/`.dll`) libraries, when using packages installed through `pip`.\n    \n*   `--ignore-anaconda`: Does not lookup packages on Snowflake Anaconda channel.\n    \n*   `--index-url`: Specifies the base URL of the Python Package Index to use for package lookup. This URL should point to a repository compliant with PEP 503 (the simple repository API) or a local directory laid out in the same format.\n    \n*   `--skip-version-check`: Skips comparing versions of dependencies between requirements and Anaconda.\n    \n\nThe following examples illustrate some different situations for creating Snowflake artifacts:\n\n*   [Example: create a package with Anaconda dependencies](#label-snowcli-snowpark-anaconda)\n    \n*   [Example: create a package using the --ignore-anaconda option](#label-snowcli-snowpark-ignore-anaconda)\n    \n*   [Example: create a package already available in the Snowflake Anaconda channel](#label-snowcli-snowpark-existing-anaconda)\n    \n\n### Example: create a package with Anaconda dependencies[¶](#example-create-a-package-with-anaconda-dependencies \"Link to this heading\")\n\nThis example creates a Python package as a zip file that can be uploaded to a stage and later imported by a Snowpark Python app. Dependencies for “july” package are found on the Anaconda channel, so they were excluded from the `.zip` file. The command displays the packages you would need to include in `requirements.txt` of your Snowpark project.\n\n```\nsnow snowpark package create july==0.1\n\n```\n\nCopy\n\n```\nPackage july.zip created. You can now upload it to a stage using\nsnow snowpark package upload -f july.zip -s <stage-name>`\nand reference it in your procedure or function.\nRemember to add it to imports in the procedure or function definition.\n\nThe package july==0.1 is successfully created, but depends on the following\nAnaconda libraries. They need to be included in project requirements,\nas their are not included in .zip.\nmatplotlib\nnumpy\n\n```\n\n### Example: create a package using the `--ignore-anaconda` option[¶](#example-create-a-package-using-the-ignore-anaconda-option \"Link to this heading\")\n\nThis example creates the `july.zip` package that you can use in your Snowpark project without needing to add any dependencies to the `requirements.txt` file. The error messages indicate that some packages contain shared libraries, which might not work, such as when creating a package using Windows.\n\n```\nsnow snowpark package create july==0.1 --ignore-anaconda --allow-shared-libraries\n\n```\n\nCopy\n\n```\n2024-05-09 15:34:02 ERROR Following dependencies utilise shared libraries, not supported by Conda:\n2024-05-09 15:34:02 ERROR contourpy\nnumpy\npillow\nkiwisolver\nmatplotlib\nfonttools\n2024-05-09 15:34:02 ERROR You may still try to create your package with --allow-shared-libraries, but the might not work.\n2024-05-09 15:34:02 ERROR You may also request adding the package to Snowflake Conda channel\n2024-05-09 15:34:02 ERROR at https://support.anaconda.com/\n\nPackage july.zip created. You can now upload it to a stage using\nsnow snowpark package upload -f july.zip -s <stage-name>`\nand reference it in your procedure or function.\nRemember to add it to imports in the procedure or function definition.\n\n```\n\n### Example: create a package already available in the Snowflake Anaconda channel[¶](#example-create-a-package-already-available-in-the-snowflake-anaconda-channel \"Link to this heading\")\n\nThis example fails to create the package because it already exists. You can still forcibly create the package by using the `--ignore-anaconda` option.\n\n```\nsnow snowpark package create matplotlib\n\n```\n\nCopy\n\n```\nPackage matplotlib is already available in Snowflake Anaconda Channel.\n\n```\n\nFor more information about creating a package, see the [snowpark package create](../command-reference/snowpark-commands/package-commands/create) command.\n\n## Upload the package to a Snowflake stage[¶](#upload-the-package-to-a-snowflake-stage \"Link to this heading\")\n\nTo upload your package, use the `snow snowpark package upload` command.\n\nThis command uploads a Python package zip file to a Snowflake stage so it can be referenced in the imports of a procedure or function.\n\n```\nsnow snowpark package upload --file=\"july.zip\" --stage=\"packages\"\n\n```\n\nCopy\n\n```\nPackage july.zip UPLOADED to Snowflake @packages/july.zip.\n\n```\n\n## Use the package in Snowpark procedures and functions[¶](#use-the-package-in-snowpark-procedures-and-functions \"Link to this heading\")\n\nTo use the package in procedures or functions, add it to the `imports` parameter of [Snowpark definition](create.html#label-snowcli-func-proc-properties) section in `snowflake.yml`.\n\n> ```\n> get_custom_package_version:\n>   handler: \"functions.get_custom_package_version\"\n>   signature: \"\"\n>   returns: string\n>   type: function\n>   imports:\n>     - \"@packages/july.zip\"\n>   meta:\n>     use_mixins:\n>       - snowpark_shared\n> \n> ```\n> \n> Copy\n> \n> Then import your package in the function handler.\n> \n> ```\n> # functions.py\n> import july\n> \n> def get_custom_package_version():\n>   return july.__VERSION__\n> \n> ```\n> \n> Copy\n\nOn this page\n\n1.  [Check whether a package is already available](#check-whether-a-package-is-already-available)\n2.  [Download a package and create a Snowflake artifact](#download-a-package-and-create-a-snowflake-artifact)\n3.  [Upload the package to a Snowflake stage](#upload-the-package-to-a-snowflake-stage)\n4.  [Use the package in Snowpark procedures and functions](#use-the-package-in-snowpark-procedures-and-functions)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)\n3.  [snow snowpark package commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/package-commands/overview)\n4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",
    "metadata": "NULL",
    "category": "NULL",
    "title": "Upload an existing Python package¶",
    "parent_command": "NULL"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/snowpark/manage",
    "content_hash": "f97bba37be2255f608c2f3c092239db88fc3694ee8ffbd8c1bd4e0a1ef442567",
    "title": "Manage your Snowpark functions and procedures¶",
    "command_group": "NULL",
    "raw_content": "# Manage your Snowpark functions and procedures[¶](#manage-your-snowpark-functions-and-procedures \"Link to this heading\")\n\n> *   Add and modify functions and procedures using the [Build a Snowpark project](build) and [Deploy a Snowpark project](deploy) processes.\n>     \n> *   List functions and procedures to which you have access using the `snow snowpark list functions` and `snow snowpark list procedures` commands. For more information, see [List all objects of a specific type](../objects/manage-objects.html#label-snowcli-object-list).\n>     \n> *   View details of a function or procedure using the `snow snowpark describe function [IDENTIFIER]` and `snow snowpark describe procedure [IDENTIFIER]` commands. For more information, see [Display the description for an object of a specified type](../objects/manage-objects.html#label-snowcli-object-describe).\n>     \n> *   Delete function/procedure using the `snow snowpark drop function [IDENTIFIER]` and `snow snowpark drop procedure [IDENTIFIER]` commands. For more information, see [Delete an object of a specified type](../objects/manage-objects.html#label-snowcli-object-drop).\n>     \n> *   Execute functions and procedures using the `snow snowpark execute` command. For more information, see [Execute a Snowpark procedure or function](execute).\n>     \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/snowpark/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/snowpark/../command-reference/overview)\n3.  [snow snowpark commands](/developer-guide/snowflake-cli/snowpark/../command-reference/snowpark-commands/overview)\n4.  [Snowpark API](/developer-guide/snowflake-cli/snowpark/../../snowpark/index)",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "id": "NULL",
    "parent_command": "NULL",
    "metadata": "NULL",
    "category": "NULL"
  },
  {
    "category": "NULL",
    "content_hash": "084a77f1811eb100d58f1dda3a550e59f5e05eb0aac64e80f9e47a5ebed44d82",
    "id": "NULL",
    "parent_command": "snow notebook",
    "raw_content": "# snow notebook create[¶](#snow-notebook-create \"Link to this heading\")\n\nNote\n\nBeginning with version 3.4.0, Snowflake CLI added the [snow notebook deploy](deploy) command to replace the `snow notebook create` command. To support backward compatibility, you can still create a notebook using this command, but Snowflake recommends that you begin using the new [Deploy and create a notebook](../../notebooks/use-notebooks.html#label-cli-deploy-notebook) procedure.\n\nCreates notebook from stage.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/create-notebook)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow notebook create\n  <identifier>\n  --notebook-file <notebook_file>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_identifier_`\n\nIdentifier of the notebook; for example: MY\\_NOTEBOOK.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--notebook-file, -f _TEXT_`\n\nStage path with notebook file. For example `@stage/path/to/notebook.ipynb`.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nBy default, the command creates notebooks using the default warehouse provided in the connection. You can use the `--warehouse` parameter to specify a different warehouse or to specify one if the connection does not include a warehouse.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example creates `MY_NOTEBOOK` from the staged `@MY_STAGE/path/to/notebook.ipynb` notebook:\n\n```\nsnow notebook create MY_NOTEBOOK -f @MY_STAGE/path/to/notebook.ipynb\n\n```\n\nCopy\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)\n2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "title": "snow notebook create¶",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/create",
    "command_group": "NULL",
    "full_command": "snow notebook create"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/deploy",
    "parent_command": "snow notebook",
    "content_hash": "e3e0aaf41bf29ce68b6b18ca8e3b4467a2b84ca359c4e7e6a6ee8b50bb16045b",
    "raw_content": "# snow notebook deploy[¶](#snow-notebook-deploy \"Link to this heading\")\n\nUploads a notebook and required files to a stage and creates a Snowflake notebook.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow notebook deploy\n  <entity_id>\n  --replace\n  --prune / --no-prune\n  --project <project_definition>\n  --env <env_overrides>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_entity_id_`\n\nID of notebook entity.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--replace`\n\nReplace notebook object if it already exists. It only uploads new and overwrites existing files, but does not remove any files already on the stage. Default: False.\n\n`--prune / --no-prune`\n\nDelete files that exist in the stage, but not in the local filesystem. Default: False.\n\n`-p, --project _TEXT_`\n\nPath where the Snowflake project is stored. Defaults to the current working directory.\n\n`--env _TEXT_`\n\nString in the format key=value. Overrides variables from the env section used for templates. Default: \\[\\].\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow notebook deploy` command uploads local files to a stage and creates a new Notebook object inside your chosen database and schema. Your [project definition file](../../notebooks/use-notebooks.html#label-cli-deploy-notebook) should specify the main notebook file and query warehouse. The `--replace` option replaces the specified Notebook object if it already exists.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example uploads the files specified in your project definition file and creates a new notebook named `my_notebook`:\n\n```\nsnow notebook deploy my_notebook\n\n```\n\nCopy\n\n```\nUploading artifacts to @notebooks/my_notebook\n  Creating stage notebooks if not exists\n  Uploading artifacts\nCreating notebook my_notebook\nNotebook successfully deployed and available under https://snowflake.com/provider-deduced-from-connection/#/notebooks/DB.SCHEMA.MY_NOTEBOOK\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)\n2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",
    "title": "snow notebook deploy¶",
    "category": "NULL",
    "full_command": "snow notebook deploy",
    "last_scraped": "NULL",
    "command_group": "NULL",
    "metadata": "NULL",
    "id": "NULL"
  },
  {
    "category": "NULL",
    "command_group": "NULL",
    "title": "snow notebook execute¶",
    "id": "NULL",
    "last_scraped": "NULL",
    "full_command": "snow notebook execute",
    "raw_content": "# snow notebook execute[¶](#snow-notebook-execute \"Link to this heading\")\n\nExecutes a notebook in a headless mode.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/execute-notebook)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow notebook execute\n  <identifier>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_identifier_`\n\nIdentifier of the notebook; for example: MY\\_NOTEBOOK.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow notebook execute` command executes a notebook in headless mode. Currently, the command only returns a message indicating whether the notebook executed successfully. It doesn’t return any result data from the notebook.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example executes the `MY_NOTEBOOK` notebook:\n\n```\nsnow notebook execute MY_NOTEBOOK\n\n```\n\nCopy\n\n```\nNotebook MY_NOTEBOOK executed.\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)\n2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",
    "content_hash": "ad74fdd29ff445e4c5903c2be4ff7852d103091952978a3463fa95c786f55309",
    "parent_command": "snow notebook",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/execute",
    "metadata": "NULL"
  },
  {
    "metadata": "NULL",
    "raw_content": "# snow notebook get-url[¶](#snow-notebook-get-url \"Link to this heading\")\n\nReturn a url to a notebook.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow notebook get-url\n  <identifier>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_identifier_`\n\nIdentifier of the notebook; for example: MY\\_NOTEBOOK.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe notebook get-url command returns a url link to an existing notebooks. Note the following requirements:\n\n*   The notebook must already be deployed.\n    \n*   If your notebook is running under a different database and schema than specified in the connection, you must provide them in name as a fully-qualified name, such as `database.schema.name`.\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\nThis example gets a URL for an notebook using a fully-qualified database and schema name:\n\n```\nsnow notebook get-url database.schema.my_notebook\n\n```\n\nCopy\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)\n2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",
    "command_group": "NULL",
    "full_command": "snow notebook get url",
    "parent_command": "snow notebook",
    "id": "NULL",
    "category": "NULL",
    "content_hash": "d246715049d8b29f4615aba75689645ca635224ee29d4ea7e7e34a2d9d6074ac",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/get-url",
    "title": "snow notebook get-url¶",
    "last_scraped": "NULL"
  },
  {
    "title": "snow notebook open¶",
    "command_group": "NULL",
    "category": "NULL",
    "parent_command": "snow notebook",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/open",
    "last_scraped": "NULL",
    "full_command": "snow notebook open",
    "raw_content": "# snow notebook open[¶](#snow-notebook-open \"Link to this heading\")\n\nOpens a notebook in default browser\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow notebook open\n  <identifier>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_identifier_`\n\nIdentifier of the notebook; for example: MY\\_NOTEBOOK.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe notebook open command opens existing notebooks in your default browser. Note the following requirements:\n\n*   The notebook must already be deployed.\n    \n*   If your notebook is running under a different database and schema than specified in the connection, you must provide them in name as a fully-qualified name, such as `database.schema.name`.\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\nThis example opens a notebook using a fully-qualified database and schema name:\n\n```\nsnow notebook open database.schema.my_notebook\n\n```\n\nCopy\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)\n2.  [snow notebook commands](/developer-guide/snowflake-cli/command-reference/notebook-commands/overview)",
    "content_hash": "cdc476ccaf9919ec58e83acd1784ff4c55e14c413d77bc9b7f22b97a02612c87",
    "metadata": "NULL"
  },
  {
    "parent_command": "NULL",
    "category": "NULL",
    "id": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/deploy-app",
    "raw_content": "# Deploying a Streamlit app[¶](#deploying-a-streamlit-app \"Link to this heading\")\n\nThe [snow streamlit deploy](../../command-reference/streamlit-commands/deploy) command creates a new Streamlit object inside your chosen database and schema. By default, this command looks for a main file called `streamlit_app.py` in your current working directory.\n\n## Prerequisites[¶](#prerequisites \"Link to this heading\")\n\nBefore deploying a Streamlit app with Snowflake CLI, you should meet the following prerequisites:\n\n*   Ensure that you have a local Streamlit app with the correct directory structure and `snowflake.yml` project definition file must exist.\n    \n*   Ensure that your account has the correct privileges as described in [Privileges required to create and use a Streamlit app](../../../streamlit/object-management/privileges).\n    \n*   Ensure that you can create or have access to a named stage where you can upload your Streamlit app files.\n    \n\n## How to deploy a Streamlit app[¶](#how-to-deploy-a-streamlit-app \"Link to this heading\")\n\nNote\n\nWith the release of Snowflake CLI 3.14.0, the `snow streamlit deploy` command now uses the updated CREATE STREAMLIT syntax (FROM _source\\_location_) instead of the deprecated syntax (ROOT\\_LOCATION = ‘<stage\\_path\\_and\\_root\\_directory>’). To continue using the deprecated syntax, you can use the `--legacy` option.\n\nThe `snow streamlit deploy` command uploads local files to a stage and creates a new Streamlit object inside your chosen database and schema. Your [project definition file](initialize-app.html#label-snowcli-streamlit-project-definition) should specify the main Python file and query warehouse. You can also specify the following options:\n\n*   `--replace`: Replaces the specified Streamlit app, if it already exists.\n    \n*   `--open`: Opens the Streamlit app in your default browser after deploying the app.\n    \n*   `--prune`: Removes files that exist in the stage, but not files in the local filesystem (by default no files are removed).\n    \n*   `--legacy`: Uses the deprecated SQLsyntax (ROOT\\_LOCATION = ‘<stage\\_path\\_and\\_root\\_directory>’).\n    \n\nBy default the command automatically deploys the `environment.yml` file and the content of the `pages/` directory, if any of those exists. You can use different files by using [command-line options](../../command-reference/streamlit-commands/deploy).\n\nFor more information about creating Streamlit apps, see the CLI [snow streamlit deploy](../../command-reference/streamlit-commands/deploy) and SQL [CREATE STREAMLIT](../../../../sql-reference/sql/create-streamlit) commands.\n\nOn this page\n\n1.  [Prerequisites](#prerequisites)\n2.  [How to deploy a Streamlit app](#how-to-deploy-a-streamlit-app)\n\nRelated content\n\n1.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)\n2.  [Creating a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/initialize-app)\n3.  [Retrieving the URL for a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/get-url)\n4.  [Share a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/share-app)\n5.  [snow streamlit deploy](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/streamlit-commands/deploy)\n6.  [SQL: CREATE STREAMLIT](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../../../sql-reference/sql/create-streamlit)",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "title": "Deploying a Streamlit app¶",
    "content_hash": "8846d547d3af5a31f9c14ec865baa455acf93ee393a2c99836b1a425a037a7f6"
  },
  {
    "raw_content": "# Retrieving the URL for a Streamlit app[¶](#retrieving-the-url-for-a-streamlit-app \"Link to this heading\")\n\n## Prerequisites[¶](#prerequisites \"Link to this heading\")\n\n*   The Streamlit app must already be uploaded to a stage in the connection you are currently using.\n    \n*   Your current ROLE must have access to the app.\n    \n\n## How to get the URL for a deployed Streamlit app[¶](#how-to-get-the-url-for-a-deployed-streamlit-app \"Link to this heading\")\n\nThe `snow streamlit get-url` command returns a URL for a deployed Streamlit app that you can then use to open the app in a browser.\n\nTo get an app URL, do the following:\n\n1.  Ensure your connection specifies the database and schema where your app is deployed.\n    \n2.  Enter a command similar to the following:\n    \n    ```\n    snow streamlit get-url my_streamlit_app\n    \n    ```\n    \n    Copy\n    \n    ```\n    https://snowflake.com/provider-deduced-from-connection/#/streamlit-apps/DB.SCHEMA.MY_STREAMLIT_APP\n    \n    ```\n    \n\nYou can use the command to return the URL and open the app automatically in your default browser by using the `--open` option, similar to the following:\n\n```\nsnow streamlit get-url my_streamlit_app --open\n\n```\n\nCopy\n\n## How to resolve common errors[¶](#how-to-resolve-common-errors \"Link to this heading\")\n\n*   If the command fails because your ROLE does not have access to the Streamlit app, try the following:\n    \n    *   Verify you are using the same ROLE in your browser that was used to deploy the app.\n        \n    *   Switch to a ROLE that has access to the app. If you don’t have access to the ROLE used to create the app, the app developer can grant access to another ROLE with the `snow streamlit share` command.\n        \n*   If the command fails because it could not find the Streamlit app, try the following:\n    \n    *   Check the app name.\n        \n    *   Verify you generated the URL using the same connection (host, account, database, and schema) that was used to deploy the app.\n        \n    *   Ensure the database and schema are correct. If you specified the database and schema as a fully-qualified name, it overrides the values for them in the connection.\n        \n\nOn this page\n\n1.  [Prerequisites](#prerequisites)\n2.  [How to get the URL for a deployed Streamlit app](#how-to-get-the-url-for-a-deployed-streamlit-app)\n3.  [How to resolve common errors](#how-to-resolve-common-errors)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../index)\n2.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)\n3.  [Deploying a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/deploy-app)\n4.  [Creating a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/initialize-app)\n5.  [Share a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/share-app)\n6.  [snow streamlit get-url](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/streamlit-commands/get-url)\n7.  [snow streamlit share](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/streamlit-commands/share)",
    "title": "Retrieving the URL for a Streamlit app¶",
    "last_scraped": "NULL",
    "content_hash": "87c2c6745995eba3cee32325ef768b2670a28afb7efd4431215d1bd9cab6a892",
    "metadata": "NULL",
    "id": "NULL",
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/get-url",
    "command_group": "NULL",
    "full_command": "NULL",
    "parent_command": "NULL"
  },
  {
    "content_hash": "cc5a6cac7cb1dcca24fd7f6f2f889321acb26c258bbf9742b227ace7de137df5",
    "command_group": "NULL",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "category": "NULL",
    "title": "Share a Streamlit app¶",
    "id": "NULL",
    "raw_content": "# Share a Streamlit app[¶](#share-a-streamlit-app \"Link to this heading\")\n\n## Prerequisites[¶](#prerequisites \"Link to this heading\")\n\nBefore sharing a Streamlit app with Snowflake CLI, you should meet the following prerequisites:\n\n*   Ensure that your account has the correct privileges as described in [Privileges required to create and use a Streamlit app](../../../streamlit/object-management/privileges).\n    \n*   Ensure that the app is already deployed in your connection.\n    \n*   Ensure that your connection has the right ROLE and that the connection uses the correct database and schema.\n    \n\n## How to share a Streamlit app[¶](#how-to-share-a-streamlit-app \"Link to this heading\")\n\nTo share a Streamlit app from the stage, enter the following command:\n\n```\nsnow streamlit share my-app some-role\n\n```\n\nCopy\n\nFor more information about sharing Streamlit apps, see the CLI [snow streamlit share](../../command-reference/streamlit-commands/share) command.\n\nOn this page\n\n1.  [Prerequisites](#prerequisites)\n2.  [How to share a Streamlit app](#how-to-share-a-streamlit-app)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../index)\n2.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)\n3.  [Deploying a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/deploy-app)\n4.  [Retrieving the URL for a Streamlit app](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/get-url)\n5.  [CLI: streamlit share](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../command-reference/streamlit-commands/share)\n6.  [SQL: DROP STREAMLIT](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../../../sql-reference/sql/drop-streamlit)",
    "parent_command": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/share-app"
  },
  {
    "last_scraped": "NULL",
    "category": "NULL",
    "title": "Managing Streamlit apps¶",
    "parent_command": "NULL",
    "raw_content": "# Managing Streamlit apps[¶](#managing-streamlit-apps \"Link to this heading\")\n\nAfter you have created a Streamlit app, you can use the following commands to manage the app:\n\n*   To retrieve the URL of your Streamlit app, use the `snow streamlit get-url NAME` command. See [snow streamlit get-url](../../command-reference/streamlit-commands/get-url) for more information.\n    \n*   To share your app to other roles, use the snow `streamlit share NAME TO_ROLE` command. See [snow streamlit share](../../command-reference/streamlit-commands/share) for more information.\n    \n*   To list the Streamlit apps for which you have access, use the `snow streamlit list` command. See [snow streamlit list](../../command-reference/streamlit-commands/list) for more information.\n    \n*   To display details about a Streamlit app, use the `snow streamlit describe NAME` command. See [snow streamlit describe](../../command-reference/streamlit-commands/describe) for more information.\n    \n*   To delete a Streamlit app, use the `snow streamlit drop NAME` command. See [snow streamlit drop](../../command-reference/streamlit-commands/drop) for more information.\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../../index)\n2.  [Managing Streamlit apps with Snowflake CLI](/developer-guide/snowflake-cli/streamlit-apps/manage-apps/../overview)",
    "content_hash": "587a62503ae2e6ecde8fc3f45d745260900ad14ca77a9bbd2940df585e2e2658",
    "full_command": "NULL",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/streamlit-apps/manage-apps/manage-app",
    "command_group": "NULL",
    "metadata": "NULL"
  },
  {
    "parent_command": "NULL",
    "title": "Listing the contents of a repository¶",
    "category": "NULL",
    "raw_content": "# Listing the contents of a repository[¶](#listing-the-contents-of-a-repository \"Link to this heading\")\n\nSnowflake CLI supports the following ways to list the contents of a Git repository:\n\n*   [List branches in a repository](#label-snowcli-git-list-branches)\n    \n*   [List tags in a repository](#label-snowcli-git-list-tags)\n    \n*   [List files in a repository](#label-snowcli-git-list-files)\n    \n\n## List branches in a repository[¶](#list-branches-in-a-repository \"Link to this heading\")\n\nThe `snow git list-branches` command lists all of the branches in a repository.\n\n```\nsnow git list-branches <REPO_NAME>\n\n```\n\nCopy\n\nwhere:\n\n*   `<REPO_NAME>` is the ID of the repository stage.\n    \n\nFor example, to list all of the branches in a repository named `my_snow_git`, enter the following command:\n\n```\nsnow git list-branches my_snow_git\n\n```\n\nCopy\n\n```\nshow git branches in my_snow_git\n+--------------------------------------------------------------------------------------------------------------------------------------------+\n| name                                     | path                                     | checkouts | commit_hash                              |\n|------------------------------------------+------------------------------------------+-----------+------------------------------------------|\n| SNOW-1011750-service-create-options      | /branches/SNOW-1011750-service-create-op |           | 729855df0104c8d0ef1c7a3e8f79fe50c6c8d2fa |\n|                                          | tions                                    |           |                                          |\n| SNOW-1011775-containers-to-spcs-int-test | /branches/SNOW-1011775-containers-to-spc |           | e81b00de6b0eb73a99a7baaa39b0afa5ea1202d0 |\n| s                                        | s-int-tests                              |           |                                          |\n| SNOW-1105629-git-integration-tests       | /branches/SNOW-1105629-git-integration-t |           | 712b07b5e692624c34caabe07d64801615ce5f0f |\n+--------------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\n## List tags in a repository[¶](#list-tags-in-a-repository \"Link to this heading\")\n\nThe `snow git list-tabs` command lists all of the tags in a repository.\n\n```\nsnow git list-tags <REPO_NAME>\n\n```\n\nCopy\n\nwhere:\n\n*   `<REPO_NAME>` is the ID of the repository stage you want to create. Note that if the repository stage already exists, the command fails.\n    \n\nFor example, to list all of the tags in a repository named `my_snow_git`, enter the following command:\n\n```\nsnow git list-tags my_snow_git\n\n```\n\nCopy\n\n```\nshow git tags in my_snow_git\n+--------------------------------------------------------------------------------------------------------------+\n| name           | path                 | commit_hash                 | author                       | message |\n|----------------+----------------------+-----------------------------+------------------------------+---------|\n| v2.0.0rc3      | /tags/v2.0.0rc3      | 2b019d2841da823d8001f23c6f3 | None                         | None    |\n|                |                      | 064e5899142a0               |                              |         |\n| v2.1.0-rc0     | /tags/v2.1.0-rc0     | 829887b758b43b86959611dd612 | None                         | None    |\n|                |                      | 7638da75cf871               |                              |         |\n| v2.1.0-rc1     | /tags/v2.1.0-rc1     | b7efe1fe9c0925b95ba214e233b | None                         | None    |\n|                |                      | 18924fa0404b3               |                              |         |\n+--------------------------------------------------------------------------------------------------------------+\n\n```\n\n## List files in a repository[¶](#list-files-in-a-repository \"Link to this heading\")\n\nThe `snow git list-files` command lists all of the files on a specified repository state (a specific branch, tag or commit).\n\n```\nsnow git list-files <REPO_PATH>\n\n```\n\nCopy\n\nwhere:\n\n*   `<REPO_PATH>` is a stage path with a specific scope where the value is the repository name is followed by a suffix specifying which branch, tag or commit. The following lists some different types of values:\n    \n    *   `@snowcli_git/branches/main/` refers to last commit of the `main` branch.\n        \n    *   `@snowcli_git/tags/v2.1.0/` refers to a commit tagged `v2.1.0`.\n        \n    *   `@snowcli_git/commits/1e939d69ca6fd0f89074e7e97c9fd1/` refers to a specific commit. Commit hashes should be between 6 and 40 characters long.\n        \n    \n    A repository path can also be a subdirectory or file in the repository, but still must be preceded with a scope prefix.\n    \n\nThe following example lists all of the files in the `my_snow_git` repository marked with the `v2.0.0` tag:\n\n```\nsnow git list-files @my_snow_git/tags/v2.0.0/\n\n```\n\nCopy\n\n```\nls @snowcli_git/tags/v2.0.0/\n+---------------------------------------------------------------------------------------------------------------------------------+\n| name                                    | size | md5  | sha1                                     | last_modified                |\n|-----------------------------------------+------+------+------------------------------------------+------------------------------|\n| snowcli_git/tags/v2.0.0/CONTRIBUTING.md | 5472 | None | 1cc437b88d20afe4d5751bd576114e3b20be27ea | Mon, 5 Feb 2024 13:16:25 GMT |\n| snowcli_git/tags/v2.0.0/LEGAL.md        | 251  | None | 4453da50b7a2222006289ff977bfb23583657214 | Mon, 5 Feb 2024 13:16:25 GMT |\n| snowcli_git/tags/v2.0.0/README.md       | 1258 | None | bdc918baae93467c258c6634c872ca6bd4ee1e9c | Mon, 5 Feb 2024 13:16:25 GMT |\n| snowcli_git/tags/v2.0.0/SECURITY.md     | 308  | None | 27e7e1b2fd28a86943b3f4c0a35a931577422389 | Mon, 5 Feb 2024 13:16:25 GMT |\n| ...\n+---------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\nThe following example lists all of the files in the `tests/` directory of the `my_snow_git` repository marked with the `v2.0.0` tag:\n\n```\nsnow git list-files @my_snow_git/tags/v2.0.0/tests --pattern \".*\\.toml\"\n\n```\n\nCopy\n\n```\nls @snowcli_git/tags/v2.0.0/tests pattern = '.*\\.toml'\n+-----------------------------------------------------------------------------------------------------------------------------------------+\n| name                                            | size | md5  | sha1                                     | last_modified                |\n|-------------------------------------------------+------+------+------------------------------------------+------------------------------|\n| snowcli_git/tags/v2.0.0/tests/empty_config.toml | 0    | None | e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 | Mon, 5 Feb 2024 13:16:25 GMT |\n| snowcli_git/tags/v2.0.0/tests/test.toml         | 381  | None | 45f1c00f16eba1b7bc7b4ab2982afe95d0161e7f | Mon, 5 Feb 2024 13:16:25 GMT |\n+-----------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [List branches in a repository](#list-branches-in-a-repository)\n2.  [List tags in a repository](#list-tags-in-a-repository)\n3.  [List files in a repository](#list-files-in-a-repository)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)\n2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)\n3.  [snow git list-branches](/developer-guide/snowflake-cli/git/../command-reference/git-commands/list-branches)\n4.  [snow git list-files](/developer-guide/snowflake-cli/git/../command-reference/git-commands/list-files)\n5.  [snow git list-tags](/developer-guide/snowflake-cli/git/../command-reference/git-commands/list-tags)",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "content_hash": "d62154f08fd972ebd51ff2653d13b9150324d17018942bdd167eda9f5db98e6d",
    "id": "NULL",
    "metadata": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/list-contents"
  },
  {
    "category": "NULL",
    "command_group": "NULL",
    "metadata": "NULL",
    "title": "About Snowflake Native App projects¶",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/about-projects",
    "id": "NULL",
    "last_scraped": "NULL",
    "raw_content": "# About Snowflake Native App projects[¶](#about-native-app-projects \"Link to this heading\")\n\nFrom the point of view of Snowflake Native App, a project encompasses a codebase that can be added to an application package in a Snowflake account. It includes references to all the extension code that app functionality needs, references to external databases for shared content, as well as required files such as [manifest.yml](../../native-apps/manifest-overview), an [environment.yml](../../streamlit/getting-started/create-streamlit-sql.html#label-streamlit-install-packages-manual) (for a Streamlit app), and any code artifacts such as JAR files and images. It also includes a configuration to describe how the application package can be built from the files in the project folder.\n\nA Snowflake Native App project is simply a set of files in a directory; like other code repositories, these files can be version-controlled using technologies like git and shared on platforms like Github.\n\nTo give you an idea of what a Snowflake Native App project should look like, Snowflake has created a few templates that are available for you to clone through Snowflake CLI commands. You can access these publicly available templates from the [Snowflake Git repository](https://github.com/snowflakedb/snowflake-cli-templates) and even create projects directly from them using Snowflake CLI. You can also create and share your own templates. For more information, see [Bootstrapping a project from a template](../bootstrap-project/bootstrap).\n\nCaution\n\nSnowflake CLI processes the files inside a project directory. These files can be uploaded to Snowflake by other `snow app` commands, so you should use caution when putting any sensitive information inside files in a project directory.\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)\n3.  [Project definition files](/developer-guide/snowflake-cli/native-apps/project-definitions)\n4.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)\n5.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)\n6.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",
    "full_command": "NULL",
    "parent_command": "NULL",
    "content_hash": "bbebd7be2f973e0a7db971d52d5e65501bd85052c7f271f9422f8815c7b18f78"
  },
  {
    "content_hash": "9e5e97ab3a36b0ce27d807d2898bfe77c7b3cb80bc05b3a44799de9743727ec1",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/create-manage-apps",
    "category": "NULL",
    "last_scraped": "NULL",
    "full_command": "NULL",
    "command_group": "NULL",
    "metadata": "NULL",
    "title": "Creating and managing Snowflake Native App objects¶",
    "id": "NULL",
    "parent_command": "NULL",
    "raw_content": "# Creating and managing Snowflake Native App objects[¶](#creating-and-managing-native-app-objects \"Link to this heading\")\n\nYou can perform the following operations when creating and managing Snowflake Native App objects:\n\n*   [Creating a Snowflake Native App project](initiate-app)\n    \n*   [Preparing a local folder with configured Snowflake Native App artifacts](bundle-app)\n    \n*   [Validating an application package](validate-app)\n    \n*   [Creating and installing your application](create-package)\n    \n*   [Creating an application package with a version (or patch)](create-app-package-version)\n    \n*   [Listing all versions defined in an application package](list-app-package-version)\n    \n*   [Opening an app in a browser](open-app)\n    \n*   [Publishing a Snowflake Native App to customers](publish-app)\n    \n*   [Dropping an existing version of an app in an application package](drop-app-package-version)\n    \n*   [Dropping Snowflake Native App objects](drop-objects)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)\n3.  [About Snowflake Native App projects](/developer-guide/snowflake-cli/native-apps/about-projects)\n4.  [Project definition files](/developer-guide/snowflake-cli/native-apps/project-definitions)\n5.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)\n6.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)\n7.  [Opening an app in a browser](/developer-guide/snowflake-cli/native-apps/open-app)\n8.  [Publishing a Snowflake Native App to customers](/developer-guide/snowflake-cli/native-apps/publish-app)\n9.  [Dropping Snowflake Native App objects](/developer-guide/snowflake-cli/native-apps/drop-objects)\n10.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)"
  },
  {
    "category": "NULL",
    "raw_content": "# Creating a Snowflake Native App project[¶](#creating-a-native-app-project \"Link to this heading\")\n\nYou can use the `snow init` command to bootstrap a Snowflake Native App project, and get the project up and running quickly.\n\nTo create a Snowflake Native App project from a Snowflake provided Snowflake Native App template:\n\n*   Enter a `snow init` command, similar to the following:\n    \n    ```\n    snow init --template app_basic my_app\n    \n    ```\n    \n    Copy\n    \n    When successful, the command returns a confirmation message similar to the following:\n    \n    ```\n    Initialized the new project in my_app\n    \n    ```\n    \n\nCaution\n\nFiles inside a project directory are processed by Snowflake CLI and could be uploaded to Snowflake when executing other `snow app` commands. You should use caution when putting any sensitive information inside files in a project directory.\n\nFor more information about creating a Snowflake Native App project, see the snow init command as well as the [Snowflake CLI templates](https://github.com/snowflakedb/snowflake-cli-templates) repository.\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)\n3.  [About Snowflake Native App projects](/developer-guide/snowflake-cli/native-apps/about-projects)\n4.  [Project definition files](/developer-guide/snowflake-cli/native-apps/project-definitions)\n5.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)\n6.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",
    "id": "NULL",
    "content_hash": "421b4ca0524f24f4df6b8f6538f542c048e2b84b0330aa71a9089f92e15eccad",
    "metadata": "NULL",
    "parent_command": "NULL",
    "url": "https://docs.snowflake.com/developer-guide/snowflake-cli/native-apps/initiate-app",
    "command_group": "NULL",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "title": "Creating a Snowflake Native App project¶"
  },
  {
    "raw_content": "# Creating and installing your application[¶](#creating-and-installing-your-application \"Link to this heading\")\n\n## Prerequisites[¶](#prerequisites \"Link to this heading\")\n\n*   You must have an existing connection in your `config.toml` file.\n    \n*   You must have a `snowflake.yml` file in your native app project.\n    \n\n## How to create an application package and an application object together[¶](#how-to-create-an-application-package-and-an-application-object-together \"Link to this heading\")\n\nThe [snow app run](../command-reference/native-apps-commands/run-app) command brings all the different code files together, creates an application package, uploads code to a Snowflake stage in this application package, [validates the setup script SQL](../command-reference/native-apps-commands/validate-app), and also installs or upgrades an application in the same account from this application package. This command is driven by the values specified in your resolved project definition for determining which stage to upload files to, which files to upload, and the names of the objects to be created.\n\nTo create an application object, do the following:\n\n1.  [Create a connection](../connecting/connect), if necessary.\n    \n2.  Make relevant changes to your code files, including `snowflake.yml`, `manifest.yml`, any setup scripts and extension code files.\n    \n3.  Execute the `snow app run` command from within your project, similar to the following:\n    \n    ```\n    snow app run --connection=\"dev\"\n    \n    ```\n    \n    Copy\n    \n\n> When successful, the command displays a message similar to the following:\n> \n> ```\n> Your application (\"my_app_admin\") is now live:\n> https://app.snowflake.com/data_org/data_acct/#/apps/application/my_app_admin\n> \n> ```\n\nUsing the `snow app run --connection=\"dev\"` command creates an application using the files on a named stage that is automatically managed by Snowflake CLI. You can also use the command to create or update your application even if your application package already exists. In this case, the command issues an UPGRADE on your application object, which will execute your setup script. For information about how to avoid re-running the setup script, see the next section.\n\nTo create an application using a version (and patch) of an existing application package, execute the following:\n\n```\nsnow app run --version v1 --patch 12 --connection=\"dev\"\n\n```\n\nCopy\n\nHere, version `V1` and patch `12` are used as an example only. For more information about creating Snowflake Native App objects, see the [snow app run](../command-reference/native-apps-commands/run-app) command.\n\n## How to create an application package[¶](#how-to-create-an-application-package \"Link to this heading\")\n\nThe `snow app deploy` command performs a subset of the steps `snow app run` takes to deploy your code to Snowflake. While it still brings all the different code files together, creates an application package, and uploads code to a named stage in this application package, and [validates the setup script SQL](../command-reference/native-apps-commands/validate-app), the `snow app deploy` command does not attempt to create or upgrade an application object.\n\nThe `snow app deploy` command is particularly useful in the following situations:\n\n*   Deploying only the application package and stage files, for situations where an application object is not required (such as part of a Continuous Delivery pipeline).\n    \n*   Updating the stage files linked to the application object. For example, if you only changed python code files, you do not need to re-create the PROCEDURE, FUNCTION, and STREAMLIT objects that point to it when using stage development mode. This approach saves time and reduces cost, as you do not need to use a warehouse to re-execute the setup script to use the updated python code.\n    \n\nTo create an application package without a corresponding application object, do the following:\n\n1.  [Create a connection](../connecting/connect), if necessary.\n    \n2.  Make relevant changes to your code files, including `snowflake.yml`, `manifest.yml`, any setup scripts, and extension code files.\n    \n3.  Execute the `snow app deploy` command from within your project, similar to the following:\n    \n    ```\n    snow app deploy --connection=\"dev\"\n    \n    ```\n    \n    Copy\n    \n\n> When successful, the command displays a message similar to the following:\n> \n> ```\n> Checking if stage exists, or creating a new one if none exists.\n> Performing a diff between the Snowflake stage and your local deploy_root\n> ...\n> Deployed successfully. Application package and stage are up-to-date.\n> \n> ```\n\nYou can also use the `snow app deploy` command to restrict which files it synchronizes to a stage by listing paths as positional arguments after the `snow app deploy` command. For more information about this and other advanced functionality, see the [snow app deploy](../command-reference/native-apps-commands/deploy-app) command.\n\nOn this page\n\n1.  [Prerequisites](#prerequisites)\n2.  [How to create an application package and an application object together](#how-to-create-an-application-package-and-an-application-object-together)\n3.  [How to create an application package](#how-to-create-an-application-package)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)\n3.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)\n4.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)\n5.  [snow app deploy](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/deploy-app)\n6.  [snow app run](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/run-app)\n7.  [snow app validate](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/validate-app)",
    "command_group": "NULL",
    "title": "Creating and installing your application¶",
    "id": "NULL",
    "parent_command": "NULL",
    "last_scraped": "NULL",
    "content_hash": "d44af1e54f8562a095b6e237cfa4cdd55e6896189f143bcbd3fffe3f4679b77f",
    "metadata": "NULL",
    "category": "NULL",
    "url": "https://docs.snowflake.com/developer-guide/snowflake-cli/native-apps/create-package",
    "full_command": "NULL"
  },
  {
    "parent_command": "NULL",
    "command_group": "NULL",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/developer-guide/snowflake-cli/native-apps/open-app",
    "title": "Opening an app in a browser¶",
    "full_command": "NULL",
    "id": "NULL",
    "raw_content": "# Opening an app in a browser[¶](#opening-an-app-in-a-browser \"Link to this heading\")\n\n## Prerequisites[¶](#prerequisites \"Link to this heading\")\n\n*   You must have an existing connection in your `config.toml` file.\n    \n*   You must have a `snowflake.yml` file in your Snowflake Native App project.\n    \n\n## How to open a Snowflake Native App application in your default browser[¶](#how-to-open-a-native-app-application-in-your-default-browser \"Link to this heading\")\n\nThe `snow app open` command opens the app specified in the resolved project definition of your Snowflake Native App project.\n\n1.  [Create a connection](../connecting/connect), if necessary.\n    \n2.  Execute the `snow app open` command from within your project, similar to the following:\n    \n    > ```\n    > snow app open --connection=\"dev\"\n    > \n    > ```\n    > \n    > Copy\n    \n    When successful, the command returns the following message:\n    \n    > ```\n    > Application opened in browser.\n    > \n    > ```\n    \n    If you have not yet installed an application as part of the `snow app run`, the following error message is displayed:\n    \n    > ```\n    > Application not yet deployed! Please run \"snow app run\" first.\n    > \n    > ```\n    \n\nFor more information about opening a Snowflake Native App in a browser, see the CLI [snow app open](../command-reference/native-apps-commands/open-app) command.\n\nOn this page\n\n1.  [Prerequisites](#prerequisites)\n2.  [How to open a Snowflake Native App application in your default browser](#how-to-open-a-native-app-application-in-your-default-browser)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)\n3.  [Creating a Snowflake Native App project](/developer-guide/snowflake-cli/native-apps/initiate-app)\n4.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)\n5.  [Opening an app in a browser](/developer-guide/snowflake-cli/native-apps/#)\n6.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",
    "category": "NULL",
    "content_hash": "3d01d3e868fe20ae37d60693f36d1e1dc0c69b43d2e529f7b52ed524c2864c6e",
    "metadata": "NULL"
  },
  {
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/developer-guide/snowflake-cli/native-apps/drop-objects",
    "raw_content": "# Dropping Snowflake Native App objects[¶](#dropping-native-app-objects \"Link to this heading\")\n\n## Prerequisites[¶](#prerequisites \"Link to this heading\")\n\n*   You must have an existing connection in your `config.toml` file.\n    \n*   You must have a `snowflake.yml` file in your Snowflake Native App project.\n    \n\n## How to drop Snowflake Native App application packages and application objects[¶](#how-to-drop-native-app-application-packages-and-application-objects \"Link to this heading\")\n\nThe `snow app teardown` drops both the application object and the application package defined in the resolved project definition. This command succeeds even if one or both of these objects do not exist.\n\n1.  [Create a connection](../connecting/connect), if necessary.\n    \n2.  Execute the `snow app teardown` command from within your project, similar to the following:\n    \n    > ```\n    > snow app teardown --connection=\"dev\"\n    > \n    > ```\n    > \n    > Copy\n    > \n    > When successful, the command returns the following message:\n    > \n    > ```\n    > Teardown is now complete.\n    > \n    > ```\n    \n\nNote\n\nWhen dropping applications that own objects outside of the application object, such as compute pools, Snowflake CLI shows a list of these dependent objects and asks whether you would like to drop them in addition to the application object and package.\n\n> You can choose this option non-interactively by passing in the `--cascade` option.\n\nIf Snowflake CLI is unable to drop the application, it does note drop the application package either. For more information about dropping Snowflake Native App objects, see the [snow app teardown](../command-reference/native-apps-commands/teardown-app) command.\n\nOn this page\n\n1.  [Prerequisites](#prerequisites)\n2.  [How to drop Snowflake Native App application packages and application objects](#how-to-drop-native-app-application-packages-and-application-objects)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)\n3.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)",
    "content_hash": "290a01607fee0a322aef1dbec66a8f045b7dbad3d2e045cea923a46e20ed288e",
    "command_group": "NULL",
    "title": "Dropping Snowflake Native App objects¶",
    "metadata": "NULL",
    "full_command": "NULL",
    "parent_command": "NULL",
    "id": "NULL",
    "category": "NULL"
  },
  {
    "category": "NULL",
    "full_command": "snow",
    "raw_content": "# snow[¶](#snow \"Link to this heading\")\n\nSnowflake CLI tool for developers.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow [<resource-commands>]\n  --version\n  --info\n  --config-file <configuration_file>\n  --install-completion\n  --show-completion\n  --help\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`[_resource-commands_]`\n\nOptional commands for managing Snowflake CLI resources.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--version`\n\nShows the version of the Snowflake CLI.\n\n`--info`\n\nShows information about the Snowflake CLI.\n\n`--config-file _configuration_file_`\n\nSpecifies Snowflake CLI configuration file that should be used.\n\n`--install-completion`\n\nInstall completion for the current shell.\n\n`--show-completion`\n\nShow completion for the current shell, to copy it or customize the installation.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe **snow** command supports the following commands to manage Snowflake resources:\n\n*   [snow app commands](native-apps-commands/overview)\n    \n*   [snow connection commands](connection-commands/overview)\n    \n*   [snow git commands](git-commands/overview)\n    \n*   [snow helpers commands](helpers-commands/overview)\n    \n*   [snow notebook commands](notebook-commands/overview)\n    \n*   [snow object commands](object-commands/overview)\n    \n*   [snow snowpark commands](snowpark-commands/overview)\n    \n*   [snow spcs service commands](spcs-commands/service-commands/overview)\n    \n*   [snow sql commands](sql-commands/overview)\n    \n*   [snow stage commands](stage-commands/overview)\n    \n*   [snow streamlit commands](streamlit-commands/overview)\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   To display the Snowflake CLI version, run the following command:\n    \n    ```\n    snow --version\n    \n    ```\n    \n    Copy\n    \n    ```\n    Snowflake CLI version: 3.0.0\n    \n    ```\n    \n*   To display information about Snowflake CLI, run the following command:\n    \n    ```\n    snow --info\n    \n    ```\n    \n    Copy\n    \n    ```\n    [\n      {\n          \"key\": \"version\",\n          \"value\": \"3.2.0\"\n      },\n      {\n          \"key\": \"default_config_file_path\",\n          \"value\": \"<user-home>/.snowflake/config.toml\"\n      },\n      {\n          \"key\": \"python_version\",\n          \"value\": \"3.11.6 (v3.11.6:8b6ee5ba3b, Oct  2 2023, 11:18:21) [Clang 13.0.0 (clang-1300.0.29.30)]\"\n      },\n      {\n          \"key\": \"system_info\",\n          \"value\": \"macOS-14.4.1-x86_64-i386-64bit\"\n      },\n      {\n          \"key\": \"feature_flags\",\n          \"value\": {}\n      },\n      {\n          \"key\": \"SNOWFLAKE_HOME\",\n          \"value\": null\n      }\n    ]\n    \n    ```\n    \n*   To display command-line help for the `snow` command, run the following command:\n    \n    ```\n    snow --help\n    \n    ```\n    \n    Copy\n    \n    ```\n    Usage: snow [OPTIONS] COMMAND [ARGS]...\n    \n    Snowflake CLI tool for developers.\n    \n    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ --version                           Shows version of the Snowflake CLI                                                                   │\n    │ --info                              Shows information about the Snowflake CLI                                                            │\n    │ --config-file                 FILE  Specifies Snowflake CLI configuration file that should be used [default: None]                       │\n    │ --install-completion                Install completion for the current shell.                                                            │\n    │ --show-completion                   Show completion for the current shell, to copy it or customize the installation.                     │\n    │ --help                -h            Show this message and exit.                                                                          │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ app          Manages a Snowflake Native App                                                                                              │\n    │ connection   Manages connections to Snowflake.                                                                                           │\n    │ cortex       Provides access to Snowflake Cortex.                                                                                        │\n    │ git          Manages git repositories in Snowflake.                                                                                      │\n    │ notebook     Manages notebooks in Snowflake.                                                                                             │\n    │ object       Manages Snowflake objects like warehouses and stages                                                                        │\n    │ snowpark     Manages procedures and functions.                                                                                           │\n    │ spcs         Manages Snowpark Container Services compute pools, services, image registries, and image repositories.                      │\n    │ sql          Executes Snowflake query.                                                                                                   │\n    │ stage        Manages stages.                                                                                                             │\n    │ streamlit    Manages a Streamlit app in Snowflake.                                                                                       │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n*   To display command-line help resource commands, run a command similar to the following that displays help for the `snow spcs` commands:\n    \n    ```\n    snow spcs --help\n    \n    ```\n    \n    Copy\n    \n    ```\n    Usage: snow spcs [OPTIONS] COMMAND [ARGS]...\n    \n    Manages Snowpark Container Services compute pools, services, image registries, and image repositories.\n    \n    ╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ --help  -h        Show this message and exit.                                                                        │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    ╭─ Commands ───────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n    │ compute-pool       Manages compute pools.                                                                            │\n    │ image-registry     Manages image registries.                                                                         │\n    │ image-repository   Manages image repositories.                                                                       │\n    │ service            Manages services.                                                                                 │\n    ╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/overview)\n3.  [SQL command reference](/developer-guide/snowflake-cli/command-reference/overview)",
    "title": "snow¶",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snow",
    "id": "NULL",
    "content_hash": "cc5b4c62b457089613189790cb85f834fc6901b413e3d7a743a05840256a9891",
    "parent_command": "NULL"
  },
  {
    "category": "NULL",
    "full_command": "snow logs overview",
    "raw_content": "# snow logs commands[¶](#snow-logs-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands for accessing logs for various entities:\n\n*   [snow logs](logs)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/logs-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/logs-commands/../overview)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/logs-commands/overview",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "parent_command": "snow logs",
    "title": "snow logs commands¶",
    "content_hash": "80e7bb2e0b48ca3dd79922a2ff82315bb543371c02b4923f9a4a758a2c373356",
    "id": "NULL",
    "command_group": "NULL"
  },
  {
    "metadata": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/sql-commands/sql",
    "id": "NULL",
    "command_group": "NULL",
    "last_scraped": "NULL",
    "parent_command": "snow sql",
    "category": "NULL",
    "raw_content": "# snow sql[¶](#snow-sql \"Link to this heading\")\n\nExecutes Snowflake query. Use either query, filename or input option. Query to execute can be specified using query option, filename option (all queries from file will be executed) or via stdin by piping output from other command. For example `cat my.sql | snow sql -i`. The command supports variable substitution that happens on client-side.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow sql\n  --query <query>\n  --filename <files>\n  --stdin\n  --variable <data_override>\n  --retain-comments\n  --single-transaction / --no-single-transaction\n  --enable-templating <enabled_templating>\n  --project <project_definition>\n  --env <env_overrides>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\nNone\n\n## Options[¶](#options \"Link to this heading\")\n\n`--query, -q _TEXT_`\n\nQuery to execute.\n\n`--filename, -f _FILE_`\n\nFile to execute. Default: \\[\\].\n\n`--stdin, -i`\n\nRead the query from standard input. Use it when piping input to this command. Default: False.\n\n`--variable, -D _TEXT_`\n\nString in format of key=value. If provided the SQL content will be treated as template and rendered using provided data.\n\n`--retain-comments`\n\nRetains comments in queries passed to Snowflake. Default: False.\n\n`--single-transaction / --no-single-transaction`\n\nConnects with autocommit disabled. Wraps BEGIN/COMMIT around statements to execute them as a single transaction, ensuring all commands complete successfully or no change is applied. Default: False.\n\n`--enable-templating [LEGACY|STANDARD|JINJA|ALL|NONE]`\n\nSyntax used to resolve variables before passing queries to Snowflake. Default: \\[<\\_EnabledTemplating.LEGACY: ‘LEGACY’>, <\\_EnabledTemplating.STANDARD: ‘STANDARD’>\\].\n\n`-p, --project _TEXT_`\n\nPath where the Snowflake project is stored. Defaults to the current working directory.\n\n`--env _TEXT_`\n\nString in the format key=value. Overrides variables from the env section used for templates. Default: \\[\\].\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nYou can specify the SQL query to execute using one of the following options:\n\n*   Specify the query string using the `--query` option.\n    \n*   Use the `--filename` option to execute one or more files containing a SQL query or queries. For example:\n    \n    *   `snow sql -f myfile.sql`\n        \n    *   `snow sql -f file1.sql -f file2.sql`\n        \n*   Specify the query as `stdin` and pipe it to the `snow sql` command, such as `cat my.sql | snow sql`.\n    \n*   If your query contains special characters, such as the dollar sign in [SYSTEM functions](../../../../sql-reference/functions-system), that you do not want the shell to interpret, you can do either of the following:\n    \n    *   Enclose the query in single quotes instead of double quotes, as in:\n        \n        `snow sql -q 'SELECT SYSTEM$CLIENT_VERSION_INFO()'`\n        \n    *   Escape the special character, as in:\n        \n        `snow sql -q \"SELECT SYSTEM\\$CLIENT_VERSION_INFO()\"`\n        \n*   Use variables for templating SQL queries with a combination of a `<% variable_name %>` placeholder in your SQL queries and a `-D` command-line option, in the form:\n    \n    ```\n    snow sql -q \"select * from my-database order by <% column_name %>\" -D \"column_name=Country\"\n    \n    ```\n    \n    Copy\n    \n    Note\n    \n    You can currently use the SnowSQL `&variable_name` and `<% variable_name %>` syntax for templates. However, Snowflake recommends using the `<% variable_name %>` syntax.\n    \n*   Specify a scripting block in queries. For example:\n    \n    ```\n    EXECUTE IMMEDIATE $$\n    -- Snowflake Scripting code\n    DECLARE\n      radius_of_circle FLOAT;\n      area_of_circle FLOAT;\n    BEGIN\n      radius_of_circle := 3;\n      area_of_circle := pi() * radius_of_circle * radius_of_circle;\n      RETURN area_of_circle;\n    END;\n    $$\n    ;\n    \n    ```\n    \n    Copy\n    \n    Note\n    \n    When specifying the scripting block directly on the Snowflake CLI command line, the `$$` delimiters might not work for some shells because they interpret that delimiter as something else. For example, the bash and zsh shells interpret it as the process ID (PID). To address this limitation, you can use the following alternatives:\n    \n    *   If you still want to specify the scripting block on the command line, you can escape the `$$` delimiters, as in `\\$\\$`.\n        \n    *   You can also put the scripting block with the default `$$` delimiters into a separate file and call it with the `snow sql -f <filename>` command.\n        \n    \n\n### Formatting JSON output[¶](#formatting-json-output \"Link to this heading\")\n\nThe `--format` option provides two ways to display JSON:\n\n*   `JSON`: Returns JSON as quoted strings, similar to the following:\n    \n    ```\n    snow sql --format json -q \"SELECT PARSE_JSON('{\"name\": \"Alice\", \"age\": 30}') as json_col\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    [\n      {\n          \"JSON_COL\": \"{\\\"name\\\": \\\"Alice\\\", \\\"age\\\": 30}\"\n      }\n    ]\n    \n    ```\n    \n*   `JSON_EXT`: Returns JSON as JSON objects, similar to the following:\n    \n    ```\n    snow sql --format JSON_EXT -q \"SELECT PARSE_JSON('{\"name\": \"Alice\", \"age\": 30}') as json_col\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    [\n      {\n        \"JSON_COL\": {\n        \"name\": \"Alice\",\n        \"age\": 30\n      }\n    ]\n    \n    ```\n    \n\n### Enhanced error codes[¶](#enhanced-error-codes \"Link to this heading\")\n\nThe `--enhanced-exit-codes` option provides information that helps identify whether problems result from query execution or from invalid command options. With this option, the `snow sql` command provides the following return codes:\n\n*   `0`: Successful execution\n    \n*   `2`: Command parameter issues\n    \n*   `5`: Query execution issues\n    \n*   `1`: Other types of issues\n    \n\nAfter the command executes, you can use the `echo $?` shell command to see the return code.\n\nIn this example, the command contains both a query parameter (`-q 'select 1'`) and a query file parameter (`-f my.query`), which is an invalid parameter combination:\n\n```\nsnow sql --enhanced-exit-codes -q 'select 1' -f my.query\n\necho $?\n\n```\n\nCopy\n\n```\n2\n\n```\n\nThe following examples show the effect of the `--enhanced-exit-codes` option when the command contains an invalid query (slect is misspelled):\n\n*   With the `--enhanced-exit-codes` option, the command returns a `5` exit code to indicate a query error:\n    \n    ```\n    snow sql --enhanced-exit-codes -q 'slect 1'\n    \n    echo $?\n    \n    ```\n    \n    Copy\n    \n    ```\n    5\n    \n    ```\n    \n*   Without the `--enhanced-exit-codes` option, the command returns a `1` exit code to indicate a generic (other) error:\n    \n    ```\n    snow sql --enhanced-exit-codes -q 'slect 1'\n    \n    echo $?\n    \n    ```\n    \n    Copy\n    \n    ```\n    1\n    \n    ```\n    \n\nAlternatively, you can set the `SNOWFLAKE_ENHANCED_EXIT_CODES` environment variable to `1` to send the enhanced return codes for all `snow sql` commands.\n\n### Interactive mode[¶](#interactive-mode \"Link to this heading\")\n\nThe `snow sql` command supports an interactive mode that lets you enter SQL commands one at a time. Interactive mode provides the following features:\n\n*   Syntax highlighting\n    \n    ![Interactive mode syntax highlighting](../../../../_images/interactive-sql-syntax-highlight.png)\n    \n*   Code completion while typing\n    \n    ![Interactive mode code completion](../../../../_images/interactive-sql-code-completion.png)\n    \n*   Searchable history\n    \n    To search your command history, press CTRL\\-R:\n    \n    ![Interactive mode searchable history](../../../../_images/interactive-sql-history.png)\n    \n*   Multi-line input\n    \n    Pressing ENTER on a line that does not end with a semicolon (`;`) moves the cursor to the next line for more commands until a statement ends with a semi-colon.\n    \n    ![Interactive mode multi-line input](../../../../_images/interactive-sql-multiline.png)\n    \n\nTo use interactive mode, enter the `snow sql` command followed by ENTER, as shown:\n\n```\nsnow sql\n\n```\n\nCopy\n\nThe command opens a sub-shell with a `>` prompt where you can enter SQL commands interactively:\n\n```\n$ snow sql\n  ╭───────────────────────────────────────────────────────────────────────────────────╮\n  │ Welcome to Snowflake-CLI REPL                                                   │\n  │ Type 'exit' or 'quit' to leave                                                  │\n  ╰───────────────────────────────────────────────────────────────────────────────────╯\n  >\n\n```\n\nYou can then enter SQL commands, as shown:\n\n```\n> create table my_table (c1 int);\n\n```\n\nCopy\n\n```\n+-------------------------------------+\n| status                              |\n|-------------------------------------|\n| Table MY_TABLE successfully created.|\n+-------------------------------------+\n\n```\n\nNote\n\nYou must end each SQL statement with a semicolon (`;`).\n\nTo exit interactive mode, enter `exit`, `quit`, or CTRL\\-D.\n\n### Multiple commands in a single transaction[¶](#multiple-commands-in-a-single-transaction \"Link to this heading\")\n\nThe `--single-transaction` option lets you enter multiple SQL commands to execute as an all-or-nothing set of commands. By executing commands in a single transaction, you can ensure that all of the commands complete successfully before committing any of the changes. If any of the commands fail, none of the changes from the successful commands persist.\n\nThe following examples show successful and unsuccessful transactions:\n\n*   Successful command execution\n    \n    ```\n    snow sql -q \"insert into my_tbl values (123); insert into my_tbl values (124);\" --single-transaction\n    \n    ```\n    \n    Copy\n    \n    ```\n    BEGIN;\n    +----------------------------------+\n    | status                           |\n    |----------------------------------|\n    | Statement executed successfully. |\n    +----------------------------------+\n    \n    insert into my_tbl values (123);\n    +-------------------------+\n    | number of rows inserted |\n    |-------------------------|\n    | 1                       |\n    +-------------------------+\n    \n    insert into my_tbl values (124);\n    +-------------------------+\n    | number of rows inserted |\n    |-------------------------|\n    | 1                       |\n    +-------------------------+\n    \n    COMMIT\n    +----------------------------------+\n    | status                           |\n    |----------------------------------|\n    | Statement executed successfully. |\n    +----------------------------------+\n    \n    ```\n    \n    You can then verify that the commands were committed to the database:\n    \n    ```\n    snow sql -q \"select count(*) from my_tbl\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    select count(*) from my_tbl\n    +----------+\n    | COUNT(*) |\n    |----------|\n    | 2        |\n    +----------+\n    \n    ```\n    \n*   Unsuccessful single transaction\n    \n    ```\n    snow sql -q \"insert into my_tbl values (123); insert into my_tbl values (124); select BAD;\" --single-transaction\n    \n    ```\n    \n    Copy\n    \n    ```\n    BEGIN;\n    +----------------------------------+\n    | status                           |\n    |----------------------------------|\n    | Statement executed successfully. |\n    +----------------------------------+\n    \n    insert into my_tbl values (123);\n    +-------------------------+\n    | number of rows inserted |\n    |-------------------------|\n    | 1                       |\n    +-------------------------+\n    \n    insert into my_tbl values (124);\n    +-------------------------+\n    | number of rows inserted |\n    |-------------------------|\n    | 1                       |\n    +-------------------------+\n    \n    select BAD;\n    ╭─ Error ───────────────────────────────────────────────────────────────────────────────╮\n    │ 000904 (42000): 01bc3b84-0810-0247-0001-c1be14ee11ce: SQL compilation error: error    │\n    │ line 1 at position 7                                                                  │\n    │ invalid identifier 'BAD'                                                              │\n    ╰───────────────────────────────────────────────────────────────────────────────────────╯\n    \n    ```\n    \n\n> You can then verify that the commands were not committed to the database:\n> \n> > ```\n> > snow sql -q \"select count(*) from my_tbl\"\n> > \n> > ```\n> > \n> > Copy\n> > \n> > ```\n> > select count(*) from my_tbl\n> > +----------+\n> > | COUNT(*) |\n> > |----------|\n> > | 0        |\n> > +----------+\n> > \n> > ```\n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   The following example uses the SQL [SYSTEM$CLIENT\\_VERSION\\_INFO](../../../../sql-reference/functions/system_client_version_info) system function to return version information about the clients and drivers.\n    \n    ```\n    snow sql --query 'SELECT SYSTEM$CLIENT_VERSION_INFO();'\n    \n    ```\n    \n    Copy\n    \n    ```\n    select current_version();\n    +-------------------+\n    | CURRENT_VERSION() |\n    |-------------------|\n    | 8.25.1            |\n    +-------------------+\n    \n    ```\n    \n*   The following example shows how you can specify a database using a client-side variable:\n    \n    ```\n    snow sql -q \"select * from <% database %>.logs\" -D \"database=dev\"\n    \n    ```\n    \n    Copy\n    \n    When executed, the command substitutes the value `dev` in the `<% database %>` variable to create the `dev.logs` identifier and then sends the `select * from dev.logs` SQL query to Snowflake for processing.\n    \n    Note\n    \n    You can currently use the SnowSQL `&variable_name` and &\\`\\`{ variable\\_name }\\`\\` syntax for templates. However, Snowflake recommends using the `<% variable_name %>` syntax.\n    \n*   This example shows how to pass in environment variables using the `--env` option:\n    \n    ```\n    snow sql -q \"select '<% ctx.env.test %>'\" --env test=value_from_cli\n    \n    ```\n    \n    Copy\n    \n*   By default, Snowflake CLI removes comments in SQL query from the output. The following example uses the `--retain-comments` option to include the comments in the query results.\n    \n    Assume the `example.sql` file contains the following statements and comment:\n    \n    ```\n    select 'column1';\n    -- My comment\n    select 'column2';\n    \n    ```\n    \n    Copy\n    \n    When you execute the following command, `-- My comment` appears in the query results.\n    \n    ```\n    snow sql -f example.sql --retain-comments\n    \n    ```\n    \n    Copy\n    \n    ```\n    select 'column1';\n    +-----------+\n    | 'COLUMN1' |\n    |-----------|\n    | ABC       |\n    +-----------+\n    \n    -- My comment\n    select 'bar';\n    +-----------+\n    | 'COLUMN2' |\n    |-----------|\n    | 123       |\n    +-----------+\n    \n    ```\n    \n    Copy\n    \n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/sql-commands/../../index)\n2.  [Executing SQL statements](/developer-guide/snowflake-cli/command-reference/sql-commands/../../sql/execute-sql)\n3.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/sql-commands/../overview)\n4.  [SQL command reference](/developer-guide/snowflake-cli/command-reference/sql-commands/overview)",
    "title": "snow sql¶",
    "content_hash": "2fdec66703b71d9791b27e75c8db94e05b00ff6ad2f5da92af13823fee6e9ebf",
    "full_command": "snow sql sql"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/setup-git",
    "category": "NULL",
    "last_scraped": "NULL",
    "command_group": "NULL",
    "raw_content": "# Setting up a Git repository[¶](#setting-up-a-git-repository \"Link to this heading\")\n\nYou can integrate your remote Git repository with Snowflake so that files from the repository are synchronized to a special kind of stage called a _repository stage_. The repository stage acts as a local Git repository with a full clone of the remote repository, including branches, tags, and commits.\n\nFor more information, see [Using a Git repository in Snowflake](../../git/git-overview).\n\n## Before you start[¶](#before-you-start \"Link to this heading\")\n\nBefore setting a Git repository, you need the following information:\n\n*   URL of the for the remote repository (also called the `origin` in Git).\n    \n*   Optional credentials for connecting to Git, including a secret, username, and password.\n    \n*   Optional API integration ID.\n    \n*   Role or user with privileges to create API integrations, if you do not already have an API integration.\n    \n\nFor more information, see [Setting up Snowflake to use Git](../../git/git-setting-up).\n\n## Set up a Git repository[¶](#set-up-a-git-repository \"Link to this heading\")\n\nTo clone a Git repository into Git repository stage, use the `snow git setup` command, as shown:\n\n```\nsnow git setup <REPO_NAME>\n\n```\n\nCopy\n\nwhere:\n\n*   `<REPO_NAME>` is the ID of the repository stage you want to create. Note that if the repository stage already exists, the command fails.\n    \n\nThe `snow git setup` command provide a series of prompts to collect the necessary information, as shown in the following examples:\n\n*   Create a repository that requires a secret and credentials:\n    \n    ```\n    $ snow git setup snowcli_git\n    Origin url: https://github.com/snowflakedb/snowflake-cli.git\n    Use secret for authentication? [y/N]: y\n    Secret identifier (will be created if not exists) [snowcli_git_secret]: new_secret\n    Secret 'new_secret' will be created\n    username: john_doe\n    password/token: ****\n    API integration identifier (will be created if not exists) [snowcli_git_api_integration]:\n    \n    ```\n    \n    Copy\n    \n    ```\n    Secret 'new_secret' successfully created.\n    API integration snowcli_git_api_integration successfully created.\n    +------------------------------------------------------+\n    | status                                               |\n    |------------------------------------------------------|\n    | Git Repository SNOWCLI_GIT was successfully created. |\n    +------------------------------------------------------+\n    \n    ```\n    \n*   Create a repository without a secret and an existing API integration ID:\n    \n    ```\n    $ snow git setup snowcli_git\n    Origin url: https://github.com/snowflakedb/snowflake-cli.git\n    Use secret for authentication [y/N]: n\n    API integration identifier (will be created if not exists) [snowcli_git_api_integration]: EXISTING_INTEGRATION\n    \n    ```\n    \n    Copy\n    \n    ```\n    Using existing API integration 'EXISTING_INTEGRATION'.\n    +------------------------------------------------------+\n    | status                                               |\n    |------------------------------------------------------|\n    | Git Repository SNOWCLI_GIT was successfully created. |\n    +------------------------------------------------------+\n    \n    ```\n    \n\nIf the role or user specified in your [connection](../connecting/configure-connections) has not been granted, executing this command generates an error similar to the following:\n\n```\n003001 (42501): 01b2f095-0508-c66d-0001-c1be009a66ee: SQL access control error: Insufficient privileges to operate on account XXX\n\n```\n\nCopy\n\nIn this situation, you should check your connection configuration or ask your account administrator to give you the necessary privileges or to create the integration for you. For more information, see [Setting up Snowflake to use Git](../../git/git-setting-up)\n\nOn this page\n\n1.  [Before you start](#before-you-start)\n2.  [Set up a Git repository](#set-up-a-git-repository)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)\n2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)\n3.  [snow git setup](/developer-guide/snowflake-cli/git/../command-reference/git-commands/setup)",
    "id": "NULL",
    "title": "Setting up a Git repository¶",
    "metadata": "NULL",
    "parent_command": "NULL",
    "full_command": "NULL",
    "content_hash": "653f19de0dd9ff142a9c1812e389cc5d996fb8bc76a7f985a95de44baae541fd"
  },
  {
    "content_hash": "7275cfef7606019b53e183b83fe31ee714d1b0956ff10183dd3ccd2cbd04cfef",
    "metadata": "NULL",
    "full_command": "NULL",
    "command_group": "NULL",
    "id": "NULL",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/refresh-repo",
    "title": "Refreshing a repository¶",
    "parent_command": "NULL",
    "category": "NULL",
    "raw_content": "# Refreshing a repository[¶](#refreshing-a-repository \"Link to this heading\")\n\nThe `snow git fetch` command updates a repository stage with all branches, tags, and new commits from a remote repository.\n\nTo fetch changes in a repository, use the following command:\n\n```\nsnow git fetch <REPO_NAME>\n\n```\n\nCopy\n\nwhere:\n\n*   `<REPO_NAME>` is the ID of the repository stage.\n    \n\nThe following example refreshes a repository named `my_snow_git`:\n\n```\nsnow git fetch my_snow_git\n\n```\n\nCopy\n\n```\nalter Git repository my_snow_git fetch\n+-------------------------------------------------------------------+\n| status                                                            |\n|-------------------------------------------------------------------|\n| Git Repository MY_SNOW_GIT is up to date. No change was fetched.. |\n+-------------------------------------------------------------------+\n\n```\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)\n2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)\n3.  [snow git fetch](/developer-guide/snowflake-cli/git/../command-reference/git-commands/fetch)"
  },
  {
    "full_command": "NULL",
    "id": "NULL",
    "category": "NULL",
    "command_group": "NULL",
    "raw_content": "# Copying files in Git[¶](#copying-files-in-git \"Link to this heading\")\n\nThe `snow git copy` command copies files from given state of the repository (specific branch, tag, or commit) into another stage or local file system.\n\n```\nsnow git copy <REPO_PATH> <DEST_PATH> [--parallel INT]\n\n```\n\nCopy\n\nwhere:\n\n*   `<REPO_PATH>` is a stage path with a specific scope where the value is the repository name followed by a suffix specifying which branch, tag, or commit to copy. The following lists some different types of values:\n    \n    *   `@snowcli_git/branches/main/` refers to last commit of the “main” branch\n        \n    *   `@snowcli_git/tags/v2.1.0/` refers to a commit tagged `v2.1.0`.\n        \n    *   `@snowcli_git/commits/1e939d69ca6fd0f89074e7e97c9fd1/` refers to a specific commit. Commit hashes should be between 6 and 40 characters long.\n        \n    \n    A repository path can also be a subdirectory or file in the repository, but still must be preceded with a scope prefix.\n    \n*   `<DEST_PATH>` is a path to a local directory or to a remote directory on the Snowflake stage.\n    \n*   `--parallel` specifies the number of threads to use when downloading files.\n    \n\nWhen `<DEST_PATH>` specifies a stage, the command operates differently based on its suffix format, as follows:\n\n*   If the source ends with a `/`, such as `@my_snow_git/branches/main/tests/plugin/`, the command copies the contents of the `plugin` directory into the destination.\n    \n*   If the source does not end with a `/`, such as `@my_snow_git/branches/main/tests/plugin`, the command copies the entire `plugin` directory.\n    \n\n## Example: Copy files from a commit to a directory in a stage[¶](#example-copy-files-from-a-commit-to-a-directory-in-a-stage \"Link to this heading\")\n\nThis example creates a `snowcli2.0/` directory on stage `@public` and copies all files from the commit marked with tag `v2.0.0` into that directory:\n\n```\nsnow git copy @my_snow_git/tags/v2.0.0/ @public/snowcli2.0/\n\n```\n\nCopy\n\n## Example: Copy files from inside a directory to a directory in a stage[¶](#example-copy-files-from-inside-a-directory-to-a-directory-in-a-stage \"Link to this heading\")\n\nThe following example creates a `plugin_tests` directory on the `test_stage` stage and copies the contents of the `tests/plugin/` directory into it.\n\n```\nsnow git copy @my_snow_git/branches/main/tests/plugin/ @test_stage/plugin_tests/\n\n```\n\nCopy\n\n## Example: Copy an entire directory to a directory in a stage[¶](#example-copy-an-entire-directory-to-a-directory-in-a-stage \"Link to this heading\")\n\nThis example creates a `plugin_tests` directory on the `test_stage` stage and copies the entire `tests/plugin` directory into it. Because `tests/plugin` does note end with a /, the command copies all of the files to `@test_stage/plugin_tests/plugin`.\n\n```\nsnow git copy @snowcli_git/branches/main/tests/plugin @test_stage/plugin_tests\n\n```\n\nCopy\n\n## Example: Copy files from a directory in a stage to the local file system[¶](#example-copy-files-from-a-directory-in-a-stage-to-the-local-file-system \"Link to this heading\")\n\nThe following example creates a `plugin_tests` directory in the local file system and downloads the contents of the `tests/plugin` directory into it.\n\n```\nsnow git copy @snowcli_git/branches/main/tests/plugin plugin_tests/\n\n```\n\nCopy\n\nOn this page\n\n1.  [Example: Copy files from a commit to a directory in a stage](#example-copy-files-from-a-commit-to-a-directory-in-a-stage)\n2.  [Example: Copy files from inside a directory to a directory in a stage](#example-copy-files-from-inside-a-directory-to-a-directory-in-a-stage)\n3.  [Example: Copy an entire directory to a directory in a stage](#example-copy-an-entire-directory-to-a-directory-in-a-stage)\n4.  [Example: Copy files from a directory in a stage to the local file system](#example-copy-files-from-a-directory-in-a-stage-to-the-local-file-system)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)\n2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)\n3.  [snow git copy](/developer-guide/snowflake-cli/git/../command-reference/git-commands/copy)",
    "title": "Copying files in Git¶",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/copy-files",
    "parent_command": "NULL",
    "metadata": "NULL",
    "content_hash": "df890eb1849394680e965d80a4dd3b51db138f74ae35d692588016b0a5f5f297"
  },
  {
    "parent_command": "NULL",
    "category": "NULL",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/git/execute-sql",
    "raw_content": "# Executing files from a repository[¶](#executing-files-from-a-repository \"Link to this heading\")\n\nNote\n\nSnowflake CLI does not support executing Python files for Python versions 3.12 and above.\n\nYou can use the `snow git execute` command for all `.sql` and `.py` files in a repository path. The command searches for all SQL and Python files and then executes the [EXECUTE IMMEDIATE](../../../sql-reference/sql/execute-immediate) command on each of them.\n\n```\nsnow git execute <REPO_PATH> [--silent]\n\n```\n\nCopy\n\nwhere:\n\n*   `<REPO_PATH>` can be any of the following:\n    \n    *   A repository stage, such as `@snowcli_git/branches/main/`, to execute commands from all `.sql` files in the stage.\n        \n    *   A glob-like pattern, such as `@snowcli_git/branches/main/scripts/*`, to execute commands from all `.sql` files in the `scripts` directory.\n        \n    *   A specific `.sql` file, such as `@snowcli_git/branches/main/scripts/script.sql`, to execute commands contained only the `script.sql` file.\n        \n*   `--silent` hides intermediate messages with file execution results.\n    \n\nNote\n\nThe `snow git execute` command does not display the output of any of the SQL commands it processes.\n\nThe following example shows how to execute SQL commands in all files within the `project` directory that match a regular expression.\n\n```\nsnow git execute \"@git_test/branches/main/projects/script?.sql\"\n\n```\n\nCopy\n\n```\nSUCCESS - git_test/branches/main/projects/script1.sql\nSUCCESS - git_test/branches/main/projects/script2.sql\nSUCCESS - git_test/branches/main/projects/script3.sql\n+---------------------------------------------------------------+\n| File                                        | Status  | Error |\n|---------------------------------------------+---------+-------|\n| git_test/branches/main/projects/script1.sql | SUCCESS | None  |\n| git_test/branches/main/projects/script2.sql | SUCCESS | None  |\n| git_test/branches/main/projects/script3.sql | SUCCESS | None  |\n+---------------------------------------------------------------+\n\n```\n\nAdding the `--silent` option to the same command hides the intermediate messages showing the progression of the files processed.\n\n```\nsnow git execute \"@git_test/branches/main/projects/script?.sql\" --silent\n\n```\n\nCopy\n\n```\n+---------------------------------------------------------------+\n| File                                        | Status  | Error |\n|---------------------------------------------+---------+-------|\n| git_test/branches/main/projects/script1.sql | SUCCESS | None  |\n| git_test/branches/main/projects/script2.sql | SUCCESS | None  |\n| git_test/branches/main/projects/script3.sql | SUCCESS | None  |\n+---------------------------------------------------------------+\n\n```\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/git/../index)\n2.  [Using a Git repository in Snowflake](/developer-guide/snowflake-cli/git/../../git/git-overview)\n3.  [snow git execute](/developer-guide/snowflake-cli/git/../command-reference/git-commands/execute)",
    "command_group": "NULL",
    "id": "NULL",
    "full_command": "NULL",
    "metadata": "NULL",
    "title": "Executing files from a repository¶",
    "content_hash": "7b5209505422da408b9c73de078c7ac901b74bafaa6e3bb15d946a576ecb0dd5"
  },
  {
    "content_hash": "826a9e155857b724114f6435440202aed0e16576c1ec080a7678b291bb6c5a46",
    "parent_command": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/data-pipelines/dbt-projects",
    "id": "NULL",
    "metadata": "NULL",
    "raw_content": "# Managing dbt Projects on Snowflake using Snowflake CLI[¶](#managing-sf-dbt-using-sf-cli \"Link to this heading\")\n\nNote\n\nThe dbt Projects on Snowflake features in Snowflake CLI are available only in version 3.13.0 or later.\n\nYou can use Snowflake CLI to manage dbt projects with the following operations:\n\n*   [Deploying a dbt project object](#label-snowcli-snow-dbt-deploy)\n    \n*   [Listing all available dbt project objects](#label-snowcli-snow-dbt-list)\n    \n*   [Executing a dbt project object command](#label-snowcli-snow-dbt-execute)\n    \n*   [Describing a dbt project object](#label-snowcli-snow-dbt-describe)\n    \n*   [Dropping a dbt project object](#label-snowcli-snow-dbt-drop)\n    \n\n## Deploying a dbt project object[¶](#deploying-a-dbt-project-object \"Link to this heading\")\n\nThe [snow dbt deploy](../command-reference/dbt-commands/deploy) command uploads local files to a temporary stage and creates a new dbt project object, updates it by making a new version, or completely recreates it. A valid dbt project must contain two files:\n\n*   `dbt_project.yml`: A standard dbt configuration file that specifies the profile to use.\n    \n*   `profiles.yml`: A dbt connection profile definition referenced in `dbt_project.yml`. `profiles.yaml` must define the database, role, schema, and type.\n    \n    *   By default, dbt Projects on Snowflake uses your target schema (`target.schema`) specified from your dbt environment or profile. Unlike dbt Core behavior, the target schema specified in the `profiles.yml` file must exist before you create your dbt Project in order for it to compile or execute successfully.\n        \n    \n    ```\n    <profile_name>:\n    target: dev\n    outputs:\n      dev:\n        database: <database_name>\n        role: <role_name>\n        schema: <schema_name>\n        type: snowflake\n    \n    ```\n    \n    Copy\n    \n\nThe following examples illustrate how to use the `snow dbt deploy` command:\n\n*   Deploy a dbt project object named `jaffle_shop`:\n    \n    ```\n    snow dbt deploy jaffle_shop\n    \n    ```\n    \n    Copy\n    \n*   Deploy a project named `jaffle_shop` from a specified directory and create or add a new version depending on whether the dbt project object already exists:\n    \n    ```\n    snow dbt deploy jaffle_shop --source /path/to/dbt/directory --profiles-dir ~/.dbt/ --force\n    \n    ```\n    \n    Copy\n    \n*   Deploy a project named `jaffle_shop` from a specified directory using a custom profiles directory and enabling [external access integrations](../../external-network-access/creating-using-external-network-access):\n    \n    ```\n    snow dbt deploy jaffle_shop --source /path/to/dbt/directory\n    --profiles-dir ~/.dbt/ --default-target dev\n    --external-access-integration dbthub-integration\n    --external-access-integration github-integration\n    --force\n    \n    ```\n    \n    Copy\n    \n\n## Listing all available dbt project objects[¶](#listing-all-available-dbt-project-objects \"Link to this heading\")\n\nThe [snow dbt list](../command-reference/dbt-commands/list) command lists all available dbt project objects on Snowflake.\n\nThe following examples illustrate how to use the `snow dbt list` command:\n\n*   List all available dbt project objects:\n    \n    ```\n    snow dbt list\n    \n    ```\n    \n    Copy\n    \n*   List dbt project objects in the `product` database whose names begin with `JAFFLE`:\n    \n    ```\n    snow dbt list --like JAFFLE% --in database product\n    \n    ```\n    \n    Copy\n    \n\n## Executing a dbt project object command[¶](#executing-a-dbt-project-object-command \"Link to this heading\")\n\nThe [snow dbt execute](../command-reference/dbt-commands/execute/overview) command executes one of the following [dbt commands](https://docs.getdbt.com/reference/dbt-commands) on a Snowflake dbt project object:\n\n*   [build](https://docs.getdbt.com/reference/commands/build)\n    \n*   [compile](https://docs.getdbt.com/reference/commands/compile)\n    \n*   [deps](https://docs.getdbt.com/reference/commands/deps)\n    \n*   [list](https://docs.getdbt.com/reference/commands/list)\n    \n*   [parse](https://docs.getdbt.com/reference/commands/parse)\n    \n*   [retry](https://docs.getdbt.com/reference/commands/retry)\n    \n*   [run](https://docs.getdbt.com/reference/commands/run)\n    \n*   [run-operation](https://docs.getdbt.com/reference/commands/run-operation)\n    \n*   [seed](https://docs.getdbt.com/reference/commands/seed)\n    \n*   [show](https://docs.getdbt.com/reference/commands/show)\n    \n*   [snapshot](https://docs.getdbt.com/reference/commands/snapshot)\n    \n*   [test](https://docs.getdbt.com/reference/commands/test)\n    \n\nFor more information about using dbt commands, see the [dbt Command reference](https://docs.getdbt.com/reference/dbt-commands).\n\nThe following examples illustrate how to use the `snow dbt execute` command:\n\n*   Execute the dbt `test` command:\n    \n    ```\n    snow dbt execute jaffle_shop test\n    \n    ```\n    \n    Copy\n    \n*   Execute the `run` dbt command asynchronously:\n    \n    ```\n    snow dbt execute --run-async jaffle_shop run --select @source:snowplow,tag:nightly models/export\n    \n    ```\n    \n    Copy\n    \n\n## Describing a dbt project object[¶](#describing-a-dbt-project-object \"Link to this heading\")\n\nThe [snow dbt describe](../command-reference/dbt-commands/describe) command describes a dbt project object on Snowflake.\n\nThe following example describes the dbt project object named `my_dbt_project` on Snowflake:\n\n```\nsnow dbt describe my_dbt_project\n\n```\n\nCopy\n\n## Dropping a dbt project object[¶](#dropping-a-dbt-project-object \"Link to this heading\")\n\nThe [snow dbt drop](../command-reference/dbt-commands/drop) command deletes a dbt project object on Snowflake.\n\nThe following example deletes the dbt project object named `my_dbt_project` on Snowflake:\n\n```\nsnow dbt drop my_dbt_project\n\n```\n\nCopy\n\n## Use `snow dbt` commands in a CI/CD workflow[¶](#use-snow-dbt-commands-in-a-ci-cd-workflow \"Link to this heading\")\n\nNote\n\nWhen building CI/CD workflows, you only need your git server, such as Github, and Snowflake CLI. A Git repository object is not required.\n\nYou can run dbt commands with Snowflake CLI to build CI/CD pipelines. These pipelines are commonly used to test new code, such as new pull requests, or to update production applications whenever something is merged to the main branch.\n\nTo build a CI/CD workflow with `snow dbt` commands, follow these steps:\n\n1.  Prepare your dbt project:\n    \n    1.  Download your dbt project or start a new one.\n        \n        *   Ensure that the main project directory contains the `dbt_project.yml` and `profiles.yml` files.\n            \n        *   Verify that the profile name referenced in `dbt_project.yml` is defined in `profiles.yml`.\n            \n            Note\n            \n            Snowflake’s dbt project objects don’t need passwords, so if `profiles.yml` contains any, deployment stops until they are removed.\n            \n2.  Set up Snowflake CLI GitHub Action.\n    \n    Follow the guidelines for [setting up GitHub Action for Snowflake CLI](../cicd/integrate-ci-cd) and [verify your connection](../connecting/configure-connections.html#label-cli-test-connection) to Snowflake.\n    \n3.  Define your workflow.\n    \n    Determine which commands your workflow needs to run based on your organization’s needs. The following example illustrates a CI workflow that updates the version of the dbt project object named `product_pipeline` with new files, runs the transformations, and finally runs tests:\n    \n    ```\n    - name: Execute Snowflake CLI command\n      run: |\n        snow dbt deploy product_pipeline\n        snow dbt execute product_pipeline run\n        snow dbt execute product_pipeline test\n    \n    ```\n    \n    Copy\n    \n\nOn this page\n\n1.  [Deploying a dbt project object](#deploying-a-dbt-project-object)\n2.  [Listing all available dbt project objects](#listing-all-available-dbt-project-objects)\n3.  [Executing a dbt project object command](#executing-a-dbt-project-object-command)\n4.  [Describing a dbt project object](#describing-a-dbt-project-object)\n5.  [Dropping a dbt project object](#dropping-a-dbt-project-object)\n6.  [Use snow dbt commands in a CI/CD workflow](#use-snow-dbt-commands-in-a-ci-cd-workflow)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/data-pipelines/../index)\n2.  [snow dbt commands](/developer-guide/snowflake-cli/data-pipelines/../command-reference/dbt-commands/overview)\n3.  [dbt Projects on Snowflake](/developer-guide/snowflake-cli/data-pipelines/../../../user-guide/data-engineering/dbt-projects-on-snowflake)",
    "title": "Managing dbt Projects on Snowflake using Snowflake CLI¶",
    "full_command": "NULL",
    "last_scraped": "NULL",
    "category": "NULL",
    "command_group": "NULL"
  },
  {
    "category": "NULL",
    "id": "NULL",
    "parent_command": "NULL",
    "full_command": "NULL",
    "content_hash": "7c830269bc0b8f46f8dbb1be9798f1eab53a3fb340a46eb17b8099891417f6aa",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/auth-commands/overview",
    "last_scraped": "NULL",
    "title": "snow auth oidc commands¶",
    "raw_content": "# snow auth oidc commands[¶](#snow-auth-oidc-commands \"Link to this heading\")\n\nThe `snow auth oidc` commands enable secure, password-less authentication to Snowflake. It leverages OpenID Connect (OIDC) tokens from CI/CD environments like GitHub Actions. This feature supports workload identity federation (WIF), enabling automated systems to access Snowflake without static credentials, which aligns with security best practices.\n\nThe following Snowflake CLI `snow auth oidc` commands let you manage authentication for your Snowflake projects:\n\n*   [snow auth oidc read-token](read-token)\n    \n\nNote the following:\n\n*   The `snow auth oidc` commands are currently limited to GitHub Actions as the provider.\n    \n*   The OIDC token is only available when running inside a supported CI/CD environment, such as a GitHub Actions runner.\n    \n*   Short-lived OIDC tokens are detected dynamically; Snowflake CLI does not store any OIDC tokens.\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/auth-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/auth-commands/../overview)",
    "metadata": "NULL",
    "command_group": "NULL"
  },
  {
    "last_scraped": "NULL",
    "title": "snow bootstrap commands¶",
    "content_hash": "72d29036916f9b0b09cd8ce7f966560f2a0a1bf8a68f04e330613ad83330337f",
    "id": "NULL",
    "metadata": "NULL",
    "command_group": "NULL",
    "parent_command": "snow bootstrap",
    "full_command": "snow bootstrap overview",
    "raw_content": "# snow bootstrap commands[¶](#snow-bootstrap-commands \"Link to this heading\")\n\nThe Snowflake CLI bootstrap commands provide developers the ability to instantiate projects from templates.\n\n*   [snow init](init)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/bootstrap-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/bootstrap-commands/../overview)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/bootstrap-commands/overview",
    "category": "NULL"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/connection-commands/overview",
    "command_group": "NULL",
    "parent_command": "snow connection",
    "metadata": "NULL",
    "raw_content": "# snow connection commands[¶](#snow-connection-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands for managing Snowflake connections:\n\n> *   [snow connection add](add-connection)\n>     \n> *   [snow connection generate-jwt](generate-jwt)\n>     \n> *   [snow connection list](list-connections)\n>     \n> *   [snow connection remove](remove-connection)\n>     \n> *   [snow connection set-default](set-default-connection)\n>     \n> *   [snow connection test](test-connection)\n>     \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/connection-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/connection-commands/../overview)\n3.  [snow connection add](/developer-guide/snowflake-cli/command-reference/connection-commands/add-connection)\n4.  [snow connection list](/developer-guide/snowflake-cli/command-reference/connection-commands/list-connections)\n5.  [snow connection set-default](/developer-guide/snowflake-cli/command-reference/connection-commands/set-default-connection)\n6.  [snow connection test](/developer-guide/snowflake-cli/command-reference/connection-commands/test-connection)",
    "last_scraped": "NULL",
    "title": "snow connection commands¶",
    "content_hash": "5912f1d05142239bafa058abe5525e2a34b52c2468f5e9da207491d8764242fc",
    "full_command": "snow connection overview",
    "category": "NULL",
    "id": "NULL"
  },
  {
    "parent_command": "snow cortex",
    "last_scraped": "NULL",
    "id": "NULL",
    "metadata": "NULL",
    "category": "NULL",
    "title": "snow cortex commands¶",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/cortex-commands/overview",
    "raw_content": "# snow cortex commands[¶](#snow-cortex-commands \"Link to this heading\")\n\nSnowflake CLI provides the following commands to access [Snowflake Cortex](../../../../user-guide/snowflake-cortex/aisql) features:\n\n*   [snow cortex complete](complete)\n    \n*   [snow cortex extract-answer](extract-answer)\n    \n*   [snow cortex sentiment](sentiment)\n    \n*   [snow cortex summarize](summarize)\n    \n*   [snow cortex translate](translate)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/cortex-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/cortex-commands/../overview)\n3.  [Snowflake Cortex](/developer-guide/snowflake-cli/command-reference/cortex-commands/../../../../user-guide/snowflake-cortex/aisql)",
    "command_group": "NULL",
    "full_command": "snow cortex overview",
    "content_hash": "7865971c086c5d17b07a5590d86ae038e7efbd7a7c120907d04c1bd219d0946d"
  },
  {
    "last_scraped": "NULL",
    "content_hash": "a46b78abd54423935411d6d0a97399e008a417b7a2feefcbae697d96de5317a5",
    "full_command": "NULL",
    "parent_command": "NULL",
    "metadata": "NULL",
    "command_group": "NULL",
    "raw_content": "# snow dbt commands[¶](#snow-dbt-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands for managing Snowflake dbt project objects:\n\n*   [snow dbt describe](describe)\n    \n*   [snow dbt deploy](deploy)\n    \n*   [snow dbt drop](drop)\n    \n*   [snow dbt execute commands](execute/overview)\n    \n*   [snow dbt list](list)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/dbt-commands/../../index)\n2.  [Managing dbt Projects on Snowflake using Snowflake CLI](/developer-guide/snowflake-cli/command-reference/dbt-commands/../../data-pipelines/dbt-projects)",
    "title": "snow dbt commands¶",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/dbt-commands/overview",
    "id": "NULL",
    "category": "NULL"
  },
  {
    "content_hash": "ed1895d783146a08daf345425074e1cc09b0ac4df85c58728d560e7b6b7dffbd",
    "metadata": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/git-commands/overview",
    "category": "NULL",
    "id": "NULL",
    "parent_command": "snow git",
    "title": "snow git commands¶",
    "last_scraped": "NULL",
    "full_command": "snow git overview",
    "command_group": "NULL",
    "raw_content": "# snow git commands[¶](#snow-git-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands to support Git integration:\n\n*   [snow git copy](copy)\n    \n*   [snow git describe](describe)\n    \n*   [snow git drop](drop)\n    \n*   [snow git execute](execute)\n    \n*   [snow git fetch](fetch)\n    \n*   [snow git list](list)\n    \n*   [snow git list-branches](list-branches)\n    \n*   [snow git list-files](list-files)\n    \n*   [snow git list-tags](list-tags)\n    \n*   [snow git setup](setup)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/git-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/git-commands/../overview)"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/helpers-commands/overview",
    "category": "NULL",
    "command_group": "NULL",
    "parent_command": "snow helpers",
    "last_scraped": "NULL",
    "content_hash": "dbe4f882f5ef24c36df67144618e8d77b899a71772c549f489f43a94f4874b62",
    "metadata": "NULL",
    "title": "snow helpers commands¶",
    "id": "NULL",
    "full_command": "snow helpers overview",
    "raw_content": "# snow helpers commands[¶](#snow-helpers-commands \"Link to this heading\")\n\nSnowflake CLI supports the following workspace commands:\n\n*   [snow helpers check-snowsql-env-vars](check-snowsql-env-vars)\n    \n*   [snow helpers import-snowsql-connections](import-snowsql-connections)\n    \n*   [snow helpers v1-to-v2](v1-to-v2)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/helpers-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/helpers-commands/../overview)"
  },
  {
    "content_hash": "aa4d1bdede1c9fe814339bc78040466fe3a89e37b82817b2e6fc431fbc5ad2a0",
    "title": "snow notebook commands¶",
    "raw_content": "# snow notebook commands[¶](#snow-notebook-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands for managing Snowflake notebooks:\n\n*   [snow notebook create](create)\n    \n*   [snow notebook deploy](deploy)\n    \n*   [snow notebook execute](execute)\n    \n*   [snow notebook get-url](get-url)\n    \n*   [snow notebook open](open)\n    \n\nYou can get a list of all available notebooks by running the `snow object list notebook` command. For more information, see [snow object list](../object-commands/list).\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../index)\n2.  [Using Snowflake Notebooks](/developer-guide/snowflake-cli/command-reference/notebook-commands/../../notebooks/use-notebooks)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/notebook-commands/overview",
    "full_command": "snow notebook overview",
    "id": "NULL",
    "metadata": "NULL",
    "category": "NULL",
    "command_group": "NULL",
    "parent_command": "snow notebook",
    "last_scraped": "NULL"
  },
  {
    "title": "snow app commands¶",
    "command_group": "NULL",
    "full_command": "snow app overview",
    "parent_command": "snow app",
    "id": "NULL",
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/native-apps-commands/overview",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "content_hash": "8b176338147bef15f41c69af709e6af34a9ba6ae9f2c7678674b17eb1bb217b7",
    "raw_content": "# snow app commands[¶](#snow-app-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands for managing Snowflake Native App apps:\n\n> *   [snow app bundle](bundle-app)\n>     \n> *   [snow app deploy](deploy-app)\n>     \n> *   [snow app events](retrieve-app-events)\n>     \n> *   [snow app open](open-app)\n>     \n> *   [snow app publish](publish-app)\n>     \n> *   [snow app release-channel commands](release-channel/overview)\n>     \n> *   [snow app release-directive commands](release-directive/overview)\n>     \n> *   [snow app run](run-app)\n>     \n> *   [snow app teardown](teardown-app)\n>     \n> *   [snow app validate](validate-app)\n>     \n> *   [snow app version commands](version/overview)\n>     \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../overview)\n3.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../native-apps/overview)"
  },
  {
    "title": "snow object commands¶",
    "metadata": "NULL",
    "parent_command": "snow object",
    "full_command": "snow object overview",
    "id": "NULL",
    "category": "NULL",
    "raw_content": "# snow object commands[¶](#snow-object-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands to support Snowflake objects:\n\n*   [snow object create](create)\n    \n*   [snow object describe](describe)\n    \n*   [snow object drop](drop)\n    \n*   [snow object list](list)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/overview",
    "command_group": "NULL",
    "content_hash": "e40c688f29200052961f262b48c70123636ba88f7a75286cf8ceaefe58a2f1df",
    "last_scraped": "NULL"
  },
  {
    "parent_command": "snow snowpark",
    "command_group": "NULL",
    "title": "snow snowpark commands¶",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snowpark-commands/overview",
    "id": "NULL",
    "category": "NULL",
    "raw_content": "# snow snowpark commands[¶](#snow-snowpark-commands \"Link to this heading\")\n\nSnowflake CLI supports the following Snowpark commands:\n\n*   [snow snowpark build](build)\n    \n*   [snow snowpark deploy](deploy)\n    \n*   [snow snowpark describe](describe)\n    \n*   [snow snowpark drop](drop)\n    \n*   [snow snowpark execute](execute)\n    \n*   [snow snowpark list](list)\n    \n*   [snow snowpark package commands](package-commands/overview)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/snowpark-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/../overview)",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "full_command": "snow",
    "content_hash": "8e4e1bd660e3d327834579437119ebe430ffaf9175aefbc74abb64c3b3f4a0c7"
  },
  {
    "category": "NULL",
    "raw_content": "# Snowpark Container Services (`spcs`) commands[¶](#snowpark-container-services-spcs-commands \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nSnowflake CLI supports the following commands to support Snowpark Container Services:\n\n> *   [snow spcs image-registry commands](image-registry-commands/overview)\n>     \n> *   [snow spcs image-repository commands](image-repository-commands/overview)\n>     \n> *   [snow spcs compute-pool commands](compute-pool-commands/overview)\n>     \n> *   [snow spcs service commands](service-commands/overview)\n>     \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/../overview)",
    "content_hash": "3882213b547dbf26af543e434ffdceb035c8ccacfbec2ce6609e2c7617c39e2d",
    "metadata": "NULL",
    "id": "NULL",
    "parent_command": "snow spcs",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/overview",
    "last_scraped": "NULL",
    "title": "Snowpark Container Services (spcs) commands¶",
    "command_group": "NULL",
    "full_command": "snow spcs overview"
  },
  {
    "category": "NULL",
    "content_hash": "e7e947812fd94802c361d37a623bf7127e8b24ed6e47cf269bf5ba2768d569bd",
    "parent_command": "snow sql",
    "raw_content": "# snow sql commands[¶](#snow-sql-commands \"Link to this heading\")\n\nSQL commands provide developers the ability to execute SQL queries with Snowflake CLI.\n\n*   [snow sql](sql)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/sql-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/sql-commands/../overview)",
    "id": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/sql-commands/overview",
    "title": "snow sql commands¶",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "full_command": "snow sql overview"
  },
  {
    "raw_content": "# snow stage commands[¶](#snow-stage-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands to support Snowflake stage objects:\n\n*   [snow stage copy](copy)\n    \n*   [snow stage create](create)\n    \n*   [snow stage describe](describe)\n    \n*   [snow stage drop](drop)\n    \n*   [snow stage execute](execute)\n    \n*   [snow stage list](list)\n    \n*   [snow stage list-files](list-files)\n    \n*   [snow stage remove](remove)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)\n3.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",
    "title": "snow stage commands¶",
    "parent_command": "snow stage",
    "command_group": "NULL",
    "last_scraped": "NULL",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/overview",
    "metadata": "NULL",
    "category": "NULL",
    "full_command": "snow stage overview",
    "content_hash": "c5d41c4d5e1602fee36db4ac137887d57f4e9854e3977c2564a68afa27360cb7"
  },
  {
    "metadata": "NULL",
    "content_hash": "8efe77900fe4228a88756343ca00fd27937ad27e7d0e926b63f32df988b271aa",
    "raw_content": "# snow streamlit commands[¶](#snow-streamlit-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands for managing Streamlit apps:\n\n*   [snow streamlit deploy](deploy)\n    \n*   [snow streamlit describe](describe)\n    \n*   [snow streamlit drop](drop)\n    \n*   [snow streamlit execute](execute)\n    \n*   [snow streamlit get-url](get-url)\n    \n*   [snow streamlit list](list)\n    \n*   [snow streamlit share](share)\n    \n\nFor more information about Streamlit apps, refer to [About Streamlit in Snowflake](../../../streamlit/about-streamlit) and [Add a Streamlit app](../../../native-apps/adding-streamlit).\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../overview)",
    "id": "NULL",
    "full_command": "snow streamlit overview",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/streamlit-commands/overview",
    "title": "snow streamlit commands¶",
    "category": "NULL",
    "last_scraped": "NULL",
    "command_group": "NULL",
    "parent_command": "snow streamlit"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/overview",
    "command_group": "NULL",
    "parent_command": "snow snowpark",
    "category": "NULL",
    "raw_content": "# snow snowpark package commands[¶](#snow-snowpark-package-commands \"Link to this heading\")\n\nSnowflake CLI supports the following commands to support Snowpark packages:\n\n*   [snow package create](create)\n    \n*   [snow package lookup](lookup)\n    \n*   [snow package upload](upload)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../overview)\n3.  [snow snowpark commands](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../overview)",
    "content_hash": "5b8de12ee55ca836f798b8d8cab7dbcd833b5dce5fcf54dce380afec193b10b0",
    "metadata": "NULL",
    "id": "NULL",
    "full_command": "snow",
    "last_scraped": "NULL",
    "title": "snow snowpark package commands¶"
  },
  {
    "content_hash": "f291273c11b1dc9fb9f1230baf262d9d399d0648fc6ad122257db88ae1131e3d",
    "parent_command": "snow spcs",
    "metadata": "NULL",
    "last_scraped": "NULL",
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/overview",
    "full_command": "snow spcs image registry commands",
    "title": "snow spcs image-registry commands¶",
    "raw_content": "# snow spcs image-registry commands[¶](#snow-spcs-image-registry-commands \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nSnowflake CLI provides the following commands for managing image registries:\n\n*   [snow spcs image-registry login](login)\n    \n*   [snow spcs image-registry token](token)\n    \n*   [snow spcs image-registry url](url)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../overview)",
    "command_group": "NULL",
    "id": "NULL"
  },
  {
    "full_command": "snow spcs image repository commands",
    "title": "snow spcs image-repository commands¶",
    "content_hash": "bad3d24fdbfdf51ef1ff4e9427734057df68abd6b025aba0930dc46965e349c7",
    "metadata": "NULL",
    "category": "NULL",
    "last_scraped": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview",
    "raw_content": "# snow spcs image-repository commands[¶](#snow-spcs-image-repository-commands \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nSnowflake CLI provides the following commands to manage image repositories:\n\n*   [snow spcs image-repository create](create)\n    \n*   [snow spcs image-repository deploy](deploy)\n    \n*   [snow spcs image-repository drop](drop)\n    \n*   [snow spcs image-repository list](list)\n    \n*   [snow spcs image-repository list-images](list-images)\n    \n*   [snow spcs image-repository list-tags](list-tags)\n    \n*   [snow spcs image-repository url](url)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)\n4.  [image-registry command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../image-registry-commands/overview)",
    "id": "NULL",
    "parent_command": "snow spcs"
  },
  {
    "last_scraped": "NULL",
    "full_command": "snow spcs compute pool commands",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/overview",
    "title": "snow spcs compute-pool commands¶",
    "category": "NULL",
    "raw_content": "# snow spcs compute-pool commands[¶](#snow-spcs-compute-pool-commands \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nSnowflake CLI supports the following commands to support compute pools:\n\n*   [snow spcs compute-pool create](create)\n    \n*   [snow spcs compute-pool deploy](deploy)\n    \n*   [snow spcs compute-pool describe](describe)\n    \n*   [snow spcs compute-pool drop](drop)\n    \n*   [snow spcs compute-pool resume](resume)\n    \n*   [snow spcs compute-pool set](set)\n    \n*   [snow spcs compute-pool status](status)\n    \n*   [snow spcs compute-pool stop-all](stop-all)\n    \n*   [snow spcs compute-pool suspend](suspend)\n    \n*   [snow spcs compute-pool unset](unset)\n    \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../overview)",
    "parent_command": "snow spcs",
    "command_group": "NULL",
    "content_hash": "399fbb236a7d33f7b8139b1d7e177a24e1d3a7dbf8d1861f16ce1804ef78a153",
    "metadata": "NULL",
    "id": "NULL"
  },
  {
    "title": "snow spcs service commands¶",
    "category": "NULL",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview",
    "command_group": "NULL",
    "last_scraped": "NULL",
    "content_hash": "133b6f19e72eea675d632386183007efc683c1ed2f3bffde8a00c7b43beb5154",
    "parent_command": "snow spcs",
    "full_command": "snow spcs service commands",
    "raw_content": "# snow spcs service commands[¶](#snow-spcs-service-commands \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nSnowflake CLI supports the following commands for managing services:\n\n> *   [snow spcs service create](create)\n>     \n> *   [snow spcs service deploy](deploy)\n>     \n> *   [snow spcs service describe](describe)\n>     \n> *   [snow spcs service drop](drop)\n>     \n> *   [snow spcs service events](events)\n>     \n> *   [snow spcs service execute-job](execute-job)\n>     \n> *   [snow spcs service list](list)\n>     \n> *   [snow spcs service list-containers](list-containers)\n>     \n> *   [snow spcs service list-endpoints](list-endpoints)\n>     \n> *   [snow spcs service list-instances](list-instances)\n>     \n> *   [snow spcs service list-roles](list-roles)\n>     \n> *   [snow spcs service logs](logs)\n>     \n> *   [snow spcs service metrics](metrics)\n>     \n> *   [snow spcs service resume](resume)\n>     \n> *   [snow spcs service set](set)\n>     \n> *   [snow spcs service status](status)\n>     \n> *   [snow spcs service suspend](suspend)\n>     \n> *   [snow spcs service unset](unset)\n>     \n> *   [snow spcs service upgrade](upgrade)\n>     \n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [Snowpark Container Services (spcs) commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../overview)",
    "metadata": "NULL"
  },
  {
    "id": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/helpers-commands/import-snowsql-connections",
    "parent_command": "snow helpers",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "content_hash": "3820b1f1bb5f33fa8d467a5213e2a47539018de3e3ebb0b07379d43eae9af101",
    "full_command": "snow helpers import snowsql connections",
    "raw_content": "# snow helpers import-snowsql-connections[¶](#snow-helpers-import-snowsql-connections \"Link to this heading\")\n\nImport your existing connections from your SnowSQL configuration.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow helpers import-snowsql-connections\n  --snowsql-config-file <custom_snowsql_config_files>\n  --default-connection-name <default_cli_connection_name>\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\nNone\n\n## Options[¶](#options \"Link to this heading\")\n\n`--snowsql-config-file _FILE_`\n\nSpecifies file paths to custom SnowSQL configuration. The option can be used multiple times to specify more than 1 file.\n\n`--default-connection-name _TEXT_`\n\nSpecifies the name which will be given in Snowflake CLI to the default connection imported from SnowSQL. Default: default.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow helpers import-snowsql-connections` command imports existing connection definitions from SnowSQL into your `config.toml` configuration file.\n\nBy default, the command reads the SnowSQL configuration files in the order described in the [Configuring SnowSQL](../../../../user-guide/snowsql-config.html#label-configuring-snowsql) topic. If more than one of these configurations define the same connection, this command overwrites the previously imported connection definition with the most recent one. To illustrate, assume the same `[connections.example]` connection is defined with different parameters in the following locations:\n\n| Location of the configuration file | Connection definition |\n| --- | --- |\n| /etc/snowsql.cnf | [connections]\n\n[connections.example]\nusername=user1\nCopy |\n| <HOME_DIR>/.snowsql/config | [connections]\n\n[connections.example]\nusername=user2\npassword=<my-pwd>\nCopy |\n\nAfter you run the command, your Snowflake CLI `config.toml` file contains the following `[connections.example]` definition (from the file with the higher precedence):\n\n```\n[connections]\n\n[connections.example]\nusername=user2\npassword=<my-pwd>\n\n```\n\nCopy\n\nYou can use the `--snowsql-config-file` option to override this default behavior and import from one or more specific SnowSQL configuration files instead.\n\nThe `snow helpers import-snowsql-connections` command also imports the default connection from SnowSQL, which is not a named connection. It is defined directly in the `[connections]` section of the configuration file. Because Snowflake CLI requires all connections to be named, the command defines a connection named `[default]`. If you want to use another name for the default connection, you can specify it with the `--default-connection-name` option.\n\nIf a SnowSQL connection matches the name of an existing Snowflake CLI connection, the command prompt asks whether you want to overwrite the existing connection or skip importing that SnowSQL connection.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example imports SnowSQL connections from the standard configuration file locations:\n\n```\nsnow helpers import-snowsql-connections\n\n```\n\nCopy\n\nAs the command processes the SnowSQL configuration files, it shows the progress and prompts for confirmation when a connection with the same name is already defined in the Snowflake CLI `config.toml` file.\n\n```\nSnowSQL config file [/etc/snowsql.cnf] does not exist. Skipping.\nSnowSQL config file [/etc/snowflake/snowsql.cnf] does not exist. Skipping.\nSnowSQL config file [/usr/local/etc/snowsql.cnf] does not exist. Skipping.\nTrying to read connections from [/Users/<user>/.snowsql.cnf].\nReading SnowSQL's connection configuration [connections.connection1] from [/Users/<user>/.snowsql.cnf]\nTrying to read connections from [/Users/<user>/.snowsql/config].\nReading SnowSQL's default connection configuration from [/Users/<user>/.snowsql/config]\nReading SnowSQL's connection configuration [connections.connection1] from [/Users/<user>/.snowsql/config]\nReading SnowSQL's connection configuration [connections.connection2] from [/Users/<user>/.snowsql/config]\nConnection 'connection1' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: Y\nConnection 'connection2' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: n\nConnection 'default' already exists in Snowflake CLI, do you want to use SnowSQL definition and override existing connection in Snowflake CLI? [y/N]: n\nSaving [connection1] connection in Snowflake CLI's config.\nConnections successfully imported from SnowSQL to Snowflake CLI.\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/helpers-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/helpers-commands/../overview)\n3.  [snow helpers commands](/developer-guide/snowflake-cli/command-reference/helpers-commands/overview)\n4.  [Import connections from SnowSQL](/developer-guide/snowflake-cli/command-reference/helpers-commands/../../connecting/configure-connections#label-snowcli-import-connections-snowsql)",
    "title": "snow helpers import-snowsql-connections¶",
    "category": "NULL"
  },
  {
    "metadata": "NULL",
    "category": "NULL",
    "parent_command": "NULL",
    "command_group": "NULL",
    "id": "NULL",
    "full_command": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/publish-app.html",
    "title": "Publishing a Snowflake Native App to customers¶",
    "raw_content": "# Publishing a Snowflake Native App to customers[¶](#publishing-a-native-app-to-customers \"Link to this heading\")\n\n## Prerequisites[¶](#prerequisites \"Link to this heading\")\n\n*   You must have an existing connection in your `config.toml` file.\n    \n*   You must have a `snowflake.yml` file in your Snowflake Native App project.\n    \n*   You must have an existing listing if you are publishing a Snowflake Native App to the [Snowflake Marketplace](../../../collaboration/collaboration-marketplace-about).\n    \n\n## How to publish a Snowflake Native App to customers[¶](#how-to-publish-a-native-app-to-customers \"Link to this heading\")\n\nIn Snowflake, publishing a Snowflake Native App to customers is done by setting release directives. Release directives are a set of rules that determine which version and patch of the Snowflake Native App is available to which customers.\n\nRelease channels provide a way to manage separate release processes for different types of customers. For example, early access customers can use the ALPHA channel, the internal QA team can use the QA channel, and general customers can use the DEFAULT channel.\n\nIf release channels are enabled for an application package, the release directives are tied to the release channels; otherwise, the release directives are tied directly to the application package.\n\nNote\n\nThe release channels feature might not be available in all regions. Please contact Snowflake Support for more information.\n\n### Process with release channels enabled[¶](#process-with-release-channels-enabled \"Link to this heading\")\n\nTo explicitly enable release channels, add `enable_release_channels=true` to the [application package definition](project-definitions.html#label-cli-app-pkg-entity-props) in your `snowflake.yml` file. You need to update or recreate your application package after enabling release channels.\n\nNote\n\nAfter enabling, release channels cannot be disabled\n\nTo confirm that release channels have been enabled, run the [snow app release-channel list](../command-reference/native-apps-commands/release-channel/list) command. A list of release channels in the application package is then displayed:\n\n```\nsnow app release-channel list\n\n```\n\nCopy\n\nThe simplest way to publish an existing version and patch to all customers on the default release channel is to use the [snow app publish](../command-reference/native-apps-commands/publish-app) command with the `--version` and `--patch` options:\n\n```\nsnow app publish --version v1 --patch 1\n\n```\n\nCopy\n\nTo automatically create a new version and patch, use the `--create-version` option:\n\n```\nsnow app publish --version v1 --create-version\n\n```\n\nCopy\n\nTo publish a Snowflake Native App to a non-default release channel, use the `--channel` option:\n\n```\nsnow app publish --version v1 --patch 1 --channel ALPHA\n\n```\n\nCopy\n\nTo publish a Snowflake Native App to a custom release directive targeting specific customers, use the `--directive` option:\n\n```\nsnow app publish --version v1 --patch 1 --channel ALPHA --directive customers_group_1\n\n```\n\nCopy\n\nThe `snow app publish` command adds the version to the release channel. If the release channel already has the maximum number of versions allowed, this command first attempts to remove from the channel one of the versions not referenced by any release directive.\n\nAfter adding the version to the release channel, the command sets the default release directive of that release channel to the specified version and patch.\n\nFor more control over what is happening, replace the previous command with the following commands:\n\n```\nsnow app release-channel add-version --version v1 ALPHA\nsnow app release-directive set customers_group_1 --version v1 --patch 1\n\n```\n\nCopy\n\nFor more information on managing release channels and release directives, see the [snow app release-channel](../command-reference/native-apps-commands/release-channel/overview) and [snow app release-directive](../command-reference/native-apps-commands/release-directive/overview) command references.\n\n### Process with release channels disabled[¶](#process-with-release-channels-disabled \"Link to this heading\")\n\nIf release channels are not enabled for an application package, the release directives are tied directly to the application package.\n\nThe simplest way to publish an existing version and patch to all customers is to use the [snow app publish](../command-reference/native-apps-commands/publish-app) command with the `--version` and `--patch` options.\n\n```\nsnow app publish --version v1 --patch 1\n\n```\n\nCopy\n\nThis command sets the default release directive of the application package to the specified version and patch. In this case, release channels are not enabled, so no release channel is involved in this process.\n\nIf you want the publish command to automatically create a new version and patch, use the `--create-version` option:\n\n```\nsnow app publish --version v1 --create-version\n\n```\n\nCopy\n\nTo publish a Snowflake Native App to a custom release directive targeting specific customers, use the `--directive` option:\n\n```\nsnow app publish --version v1 --patch 1 --directive customers_group_1\n\n```\n\nCopy\n\nThese `snow app publish` commands continue to work even if release channels are enabled in the future. When release channels are enabled, the command starts using the default release channel.\n\nOn this page\n\n1.  [Prerequisites](#prerequisites)\n2.  [How to publish a Snowflake Native App to customers](#how-to-publish-a-native-app-to-customers)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)\n3.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)\n4.  [snow app version commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/version/overview)\n5.  [snow app release-channel commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/release-channel/overview)\n6.  [snow app release-directive commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/release-directive/overview)\n7.  [snow app publish](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/publish-app)",
    "last_scraped": "NULL",
    "content_hash": "3a4aec93330d00a5372a04bc956ccaa3cc179cebd2f45a8e9e3480098bcc9f64"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/native-apps/bundle-app.html",
    "category": "NULL",
    "title": "Preparing a local folder with configured Snowflake Native App artifacts¶",
    "raw_content": "# Preparing a local folder with configured Snowflake Native App artifacts[¶](#preparing-a-local-folder-with-configured-native-app-artifacts \"Link to this heading\")\n\n## Create a local folder with configured artifacts[¶](#create-a-local-folder-with-configured-artifacts \"Link to this heading\")\n\nThe `snow app bundle` command creates a local directory in your project, populates it with the file structure you specified in the project definition file, and generates CREATE FUNCTION or CREATE PROCEDURE declarations in Snowflake Native App setup scripts from Snowpark Python code that includes decorators (such as `@sproc` or `@udaf`). For more information, see the Snowpark Python documentation corresponding to your chosen function decorator, such as [snowflake.snowpark.functions.udaf](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.udaf).\n\nThe `snow app deploy` and `snow app run` commands already use this functionality. However, now with an explicit `snow app bundle` command at your disposal, you can explore this directory before it gets uploaded to the stage, to verify the artifacts were created as expected.\n\nTo create a local folder with the configured artifacts, do the following:\n\n1.  Create or verify your Snowflake `snowflake.yml` project definition file, such as:\n    \n    ```\n    definition_version: 2\n    entities:\n      codegen_nativeapp_pkg:\n        type: application package\n        manifest: root_files/_manifest.yml\n        artifacts:\n          - src: root_files/README.md\n            dest: README.md\n          - src: root_files/_manifest.yml\n            dest: manifest.yml\n          - src: root_files/setup_scripts/*\n            dest: setup_scripts/\n          - src: python/user_gen/echo.py\n            dest: user_gen/echo.py\n          - src: python/cli_gen/*\n            dest: cli_gen/\n            processors:\n              - snowpark\n      codegen_nativeapp:\n        type: application\n        from:\n          target: codegen_nativeapp_pkg\n    \n    ```\n    \n    Copy\n    \n2.  From your project directory, run the `snow app bundle` command to create the temporary `output/deploy` directory that contains your configured artifacts.\n    \n    ```\n    snow app bundle\n    \n    ```\n    \n    Copy\n    \n3.  Verify the contents of the output or deploy directory match the rules you specified in the snowflake.yml. file. If you invoked Snowpark annotation processing in your Python files, you can see the generated code in the amended setup script in the directory.\n    \n\nFor more information, see the [snow app bundle](../command-reference/native-apps-commands/bundle-app) command.\n\n## Generate SQL code using Snowpark annotation processing[¶](#generate-sql-code-using-snowpark-annotation-processing \"Link to this heading\")\n\nAs a Snowflake Native App developer with a limited SQL background, you might find it cumbersome to write and maintain [setup scripts](../../native-apps/creating-setup-script), which can get quite large and complicated over time. Setup scripts contain all the application logic that a customer can use with their data, and hence are a required part of developing a Snowflake Native App. One of the core components of setup scripts is your ability to use Snowpark Python extension functions for functions and stored procedures. In addition to writing Snowpark code in Python, Java, or other Snowpark supported languages, you need to write the corresponding portions of those functions and procedures using SQL in the setup script.\n\nFor example, you could create a basic function and stored procedure using Snowpark Python, as shown:\n\n```\n# Example python file \"echo.py\" that a developer writes\n\ndef echo_fn(data):\n    return 'echo_fn: ' + data\n\ndef echo_proc(session, data):\n    return 'echo_proc: ' + data\n\n```\n\nCopy\n\nYou would then need to upload the file to a stage and refer to it from the setup script SQL code, similar to the following:\n\n```\n-- Sample setup_script.sql SQL file for a Snowflake Native App\n\nCREATE APPLICATION ROLE IF NOT EXISTS app_instance_role;\n\nCREATE OR ALTER VERSIONED SCHEMA ext_code_schema;\nGRANT USAGE ON SCHEMA ext_code_schema TO APPLICATION ROLE app_instance_role;\n\nCREATE OR REPLACE PROCEDURE ext_code_schema.py_echo_proc(DATA string)\n  RETURNS STRING\n  LANGUAGE PYTHON\n  RUNTIME_VERSION = 3.12\n  PACKAGES=('snowflake-snowpark-python')\n  HANDLER='echo.echo_proc'\n  IMPORTS=('/echo.py');\n\n    GRANT USAGE ON PROCEDURE ext_code_schema.py_echo_proc(string)\n      TO APPLICATION ROLE app_instance_role;\n\n-- Wraps a function from a python file\nCREATE OR REPLACE FUNCTION ext_code_schema.py_echo_fn(string)\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = 3.12\nPACKAGES=('snowflake-snowpark-python')\nHANDLER='echo.echo_fn'\nIMPORTS=('/echo.py');\n\nGRANT USAGE ON FUNCTION ext_code_schema.py_echo_fn(DATA string)\n  TO APPLICATION ROLE app_instance_role;\n\n```\n\nCopy\n\n### Automatic SQL code generation[¶](#automatic-sql-code-generation \"Link to this heading\")\n\nNote\n\nTo take advantage of automatic SQL code generation, you must use Snowpark Python version 1.15.0 and above.\n\nTo help alleviate this extra work, Snowflake CLI can automatically generate the necessary SQL for your setup scripts. Snowpark Python supports a feature called extension function decorators (`@udf`, `@sproc`, `@udtf`, and `@udaf`) that let you annotate your Python code, such as using the [snowflake.snowpark.functions.udf](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.udf) function decorator. Snowflake CLI can use these decorators to automatically create and validate the necessary SQL code for your setup scripts.\n\nFor example, you can use the `@udf` decorator for the function in the previous example:\n\n```\n# some python file echo.py\n@udf(name=\"echo_fn\")\ndef echo_fn(data) -> str:\n  return 'echo_fn: ' + str\n\n```\n\nCopy\n\nUsing the `@udf` decorator tells the Snowflake CLI [snow app bundle](../command-reference/native-apps-commands/bundle-app) (and other commands that internally invoke the `snow app bundle` command) to process the Snowpark Python decorators, generate the corresponding SQL commands, and include them in the setup script automatically, as shown. You can, therefore, minimize the amount of SQL code you need to write for your setup script.\n\n```\n-- Sample setup_script.sql SQL file for a Snowflake Native App\n\n-- User-written code\nCREATE OR REPLACE APPLICATION ROLE app_instance_role;\n\nCREATE OR ALTER VERSIONED SCHEMA ext_code_schema;\nGRANT USAGE ON SCHEMA ext_code_schema TO APPLICATION ROLE app_instance_role;\n\n-- Snowflake CLI generated code\nCREATE OR REPLACE FUNCTION ext_code_schema.py_echo_fn(DATA string)\n  RETURNS STRING\n  LANGUAGE PYTHON\n  RUNTIME_VERSION = 3.12\n  PACKAGES=('snowflake-snowpark-python')\n  HANDLER='echo.echo_fn'\n  IMPORTS=('/echo.py');\n\n  GRANT USAGE ON FUNCTION ext_code_schema.py_echo_fn(string)\n    TO APPLICATION ROLE app_instance_role;\n\n```\n\nCopy\n\n## Using the Snowpark Python decorators[¶](#using-the-snowpark-python-decorators \"Link to this heading\")\n\nWhile the Snowpark decorators in Snowflake CLI work the same as regular Snowpark Python decorators, you should be aware of the following differences when writing Python code files specifically for a Snowflake Native App:\n\n*   You can’t use any `Session` objects in these files, as Snowflake CLI executes these Python files in a sandbox environment with no connection to Snowflake. As a result, any reference of a Snowpark `Session` results in an error.\n    \n*   You can use only the `@udf`, `@sproc`, `@udaf` and `@udtf` Snowpark Python decorators.\n    \n*   You can’t use these decorators as regular functions to register your code as a Snowflake object. Only code explicitly annotated with the supported decorators is recognized. Therefore, the Python function must be a named function. Lambda functions are not supported.\n    \n*   Snowflake CLI always generates CREATE OR REPLACE statements, as recommended by Snowflake, for creating functions and procedures in your setup scripts.\n    \n\n### More about decorator properties[¶](#more-about-decorator-properties \"Link to this heading\")\n\nThe following table lists the Python decorator properties and explains how Snowflake CLI uses them.\n\n| Property | Details |\n| --- | --- |\n| nameOptional | Name of the function or stored procedure Snowflake CLI uses to generate the SQL statements.If you omit this property, Snowflake CLI reuses the Python function name to generate the SQL statements. |\n| input_typesRequired | Types for each input parameter for this function or stored procedure.You must provide this information either in this decorator parameter or provide type annotations directly in your code. If this information is not available in either location, Snowflake CLI does not generate SQL statements for this function or stored procedure. |\n| return_typeRequired | Type for the return value for this function or stored procedure.You must provide this information either in this decorator parameter or provide type annotation directly in your code. If this information is not available in either location, Snowflake CLI does not generate SQL statements for this function or stored procedure. |\n| packagesOptional | List of packages. You can specify snowflake-snowpark-python with or without a version number. If you provide a version number for this package, Snowflake CLI does not use the version as part of its SQL generation, but does retain the version number for any other packages in the list.If you omit this property, Snowflake CLI automatically adds snowflake-snowpark-python as the only package and reflects it in the generated SQL statements. |\n| importsOptional | List of files your Snowflake function or stored procedure needs to import from the stage. You can specify them either as a string or a tuple of strings. If you specify a tuple, Snowflake CLI only uses the string at the 0th index. For an example of using a tuple, see Use external Python files.If you do not specify any imports, Snowflake CLI automatically adds an import for the Python file that contains the function or stored procedure for which it generates SQL. The path of the import is determined by the dest parameter of the Python file in the deploy root directory, based on the project definition file. |\n| execute_asOptional | Persona to use when executing a stored procedure. Values include: caller and owner. If unspecified, Snowflake CLI defaults to owner. Note that this property does not apply to functions. |\n| handlerN/A | Handler for the function or stored procedure. Snowflake CLI automatically populates this field. |\n| replaceUnused | Snowflake CLI assumes true for code generation. |\n| sessionRequired | Must be None. If omitted, Snowflake CLI throws an error. |\n| is_permanentUnused | Snowflake CLI does not use this field for SQL generation. |\n| stage_locationUnused | Snowflake CLI does not use this field for SQL generation. |\n| if_not_existsUnused | Snowflake CLI does not use this field for SQL generation. |\n| strictUnused | Snowflake CLI does not use this field for SQL generation. |\n| secureUnused | Snowflake CLI does not use this field for SQL generation. |\n| immutableUnused | Snowflake CLI does not use this field for SQL generation. |\n| native_app_paramsOptional | (For a Snowflake Native App only)Python dictionary containing the following Snowflake Native App parameters:schema: Name of the schema to contain the Snowpark function or stored procedure. This schema must already be defined in your setup script. Snowflake recommends setting the value to the name of a versioned schema in your setup script file. Snowflake CLI prefixes this value to the name of the Snowpark function or procedure name in the generated SQL statement. Note that Snowflake CLI does not create the schema for you.application_roles: List of application roles to be granted USAGE privileges on the generated Snowpark function or procedure. Snowflake CLI does not create the application roles; it only creates SQL statements like GRANT USAGE ON FUNCTION <schema_name.func_name> TO APPLICATION ROLE <app_role> and adds them to the setup script.While technically optional, not specifying the native_app_params property in your project definition file might result in an invalid setup script. |\n\nWhen uploading your Python files to a destination stage, Snowflake CLI converts the decorators to comments so these UDFs and stored procedures are not created in your current session. The original source files are not changed so that the `snow app bundle` command remains idempotent. Only Python files in the deploy root directory are changed to contain the comments, as the deploy root is recreated every time you run the `snow app bundle` command. The following example illustrates how Snowflake CLI comments decorators.\n\n```\n# output/deploy/dest_dir1/dest_dir2/echo.py\n#: @sproc(\n#:    return_type=IntegerType(),\n#:    input_types=[IntegerType(), IntegerType()],\n#:    packages=[\"snowflake-snowpark-python==1.15.0\"],\n#:    native_app_params={\n#:        \"schema\": \"ext_code_schema\",\n#:        \"application_roles\": [\"app_instance_role\"],\n#:    },\n#: )\ndef add_sp(session_, x, y):\n    return x + y\n\n```\n\nCopy\n\nAlso, only the Python files with a `processors` property in the project definition file are affected.\n\nOn this page\n\n1.  [Create a local folder with configured artifacts](#create-a-local-folder-with-configured-artifacts)\n2.  [Generate SQL code using Snowpark annotation processing](#generate-sql-code-using-snowpark-annotation-processing)\n3.  [Using the Snowpark Python decorators](#using-the-snowpark-python-decorators)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/native-apps/../index)\n2.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/native-apps/overview)\n3.  [Creating and installing your application](/developer-guide/snowflake-cli/native-apps/create-package)\n4.  [snow app commands](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/overview)\n5.  [snow app bundle](/developer-guide/snowflake-cli/native-apps/../command-reference/native-apps-commands/bundle-app)",
    "content_hash": "f72ec4912c9b40f4e8a54e7734e358163f441c13aeda20a910fc1d42ae2d9e68",
    "last_scraped": "NULL",
    "id": "NULL",
    "command_group": "NULL",
    "parent_command": "NULL",
    "full_command": "NULL",
    "metadata": "NULL"
  },
  {
    "category": "NULL",
    "content_hash": "5279f0b9dc3c4410f1dab61618f83b8765b7ce704f721a8417ef37cec943ff9e",
    "metadata": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/native-apps-commands/bundle-app",
    "id": "NULL",
    "title": "snow app bundle¶",
    "full_command": "snow app bundle app",
    "raw_content": "# snow app bundle[¶](#snow-app-bundle \"Link to this heading\")\n\nPrepares a local folder with configured app artifacts.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow app bundle\n  --package-entity-id <package_entity_id>\n  --app-entity-id <app_entity_id>\n  --project <project_definition>\n  --env <env_overrides>\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\nNone\n\n## Options[¶](#options \"Link to this heading\")\n\n`--package-entity-id _TEXT_`\n\nThe ID of the package entity on which to operate when the definition\\_version is 2 or higher.\n\n`--app-entity-id _TEXT_`\n\nThe ID of the application entity on which to operate when the definition\\_version is 2 or higher.\n\n`-p, --project _TEXT_`\n\nPath where the Snowflake project is stored. Defaults to the current working directory.\n\n`--env _TEXT_`\n\nString in the format key=value. Overrides variables from the env section used for templates. Default: \\[\\].\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow app bundle` command creates a temporary local directory that contains all of the Snowflake Native App artifacts. It can also automatically generate SQL scripts from your Snowpark Python code. This command is called automatically by the [snow app deploy](deploy-app), [snow app run](run-app), and [snow app version create](version/app-version-create) commands. If, however, you want to see the setup script, artifacts, and generated SQL, before uploading them to a stage, you can run this command manually. For more information about generating SQL code, see [Preparing a local folder with configured Snowflake Native App artifacts](../../native-apps/bundle-app).\n\n*   The command uses the [project definition file](../../native-apps/project-definitions) to determine the name of the temporary folder to create within your project directory.\n    \n    *   By default, it will be `<project_directory>/output/deploy`. This directory, which is also known as the deploy root, mirrors what the structure of the stage will be, once files are uploaded to stage in subsequent commands.\n        \n    *   If you want Snowflake CLI to create a folder with a custom name instead of `output/deploy`, you can do so by providing the `deploy_root` field on the `application package` entity in the [project definition file](../../native-apps/project-definitions).\n        \n        Note\n        \n        You must provide a relative path for the deploy root; absolute paths are rejected. The deploy root path is created inside the project directory.\n        \n    *   The deploy root is a temporary directory because it gets deleted and recreated every you `run snow app bundle` or another command invokes the `bundle` functionality.\n        \n*   Because `snow app bundle` is automatically called as part of he [snow app deploy](deploy-app), [snow app run](run-app), and [snow app version create](version/app-version-create) commands, you should make changes to the source files only, outside the deploy root. If you modify files in the deploy root, the files are overwritten by the most recent state of your source files the next time you call one of these commands.\n    \n*   If using a version control system such as `git`, you can choose to not to track the deploy root, as it can change frequently.\n    \n*   `snow app bundle` does not build or compile your artifacts for you, such as creating jar files from your Java files. It only copies the artifacts specified in the project definition file and adds them to the deploy root to mimic the stage’s directory structure.\n    \n*   `snow app bundle` does not need access to your Snowflake account; it only affects your local filesystem.\n    \n*   The command has the following copying and symlinking behavior for any `artifacts` of the `application package` entity in the [project definition file](../../native-apps/project-definitions):\n    \n    *   All directory names in a source path are also created in the deploy root.\n        \n    *   All files in a source path are symlinked within these directories in the deploy root.\n        \n    *   Some symlinked files in the deploy root can become hard links if you invoke SQL generation from those files. For more information, see [Preparing a local folder with configured Snowflake Native App artifacts](../../native-apps/bundle-app).\n        \n    \n    Consider the following `artifacts` list example from a project definition file:\n    \n    ```\n    entities:\n      pkg:\n        type: application package\n        ...\n        artifacts:\n          - src: dir1/dir2/*\n            dest: dest_dir1/dest_dir2/\n          - src: dir8/dir9/file.txt\n            dest: dest_dir8/dest_file.txt\n      ...\n    \n    ```\n    \n    Copy\n    \n    where `dir1/dir2` in the project root could have other subdirectories, such as `dir3` and `dir4`, and some files, such as `file3.txt` and `file4.txt`.\n    \n    After running the `snow app bundle` command, your deploy root should look like the following:\n    \n    ```\n    -- deploy_root\n          -- dest_dir1\n                -- dest_dir2\n                      -- dir3\n                          -- ... <entire directory tree of dir3>\n                      -- dir4\n                          -- ... <entire directory tree of dir4>\n                      -- file3.txt\n                      -- file4.txt\n          -- dest_dir8\n                -- dest_file.txt\n    \n    ```\n    \n    Copy\n    \n\n### Snowpark annotation processing[¶](#snowpark-annotation-processing \"Link to this heading\")\n\nBeginning with Snowflake CLI version 2.5.0 and [Snowpark Python API](../../../snowpark/python/index) version 1.15.0, you can leverage the Snowpark annotation processing feature with the `snow app bundle` command. This feature lets you annotate your Python code files with Snowpark Python decorators, such as `@udf`, `@sproc`, `@udaf`, and `@udtf` to let Snowflake CLI automatically the corresponding CREATE FUNCTION or CREATE PROCEDURE SQL statements in setup script files in the project directory. For a better understanding of these decorators, please refer to corresponding Python decorators documentation.\n\nSnowpark annotation processing involves the following:\n\n*   It reads all Python files you marked with a `processor` field in the project definition file.\n    \n*   It creates a separate temporary sandbox Python environment using the environment information provided in the processor’s `properties` sub-field.\n    \n*   It executes those Python files in the sandboxed environment.\n    \n*   It collects all decorated functions from those files.\n    \n*   With the collected information, Snowflake CLI generates the necessary SQL statements and adds them to the setup script whose location is specified in your `manifest.yaml` file.\n    \n\nYou no longer need to repeat boilerplate SQL code for writing Snowpark extension functions for your Snowflake Native App apps.\n\nFor more information about enabling this feature in your project definition files, see [Using the Snowpark Python decorators](../../native-apps/bundle-app.html#label-cli-sf-annotation-processing).\n\nFor more information about all supported artifact processors, see [More information about artifacts processors](../../native-apps/project-definitions.html#label-cli-na-artifacts-processors).\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThis example assumes you have made the necessary changes to your code files and added them to your `snowflake.yml` or `snowflake.local.yml` files, and also built or compiled any relevant artifacts.\n\n```\ncd my_app_project\nsnow app bundle\n\n```\n\nCopy\n\nThe command displays information about the various steps that occur while the command runs and creates a new directory a the location specified in your project definition file (default: `my_app_project/output/deploy`).\n\nTo see a simple use case in action, you can leverage the ready-to-use templates using the following commands:\n\n```\nsnow init my_app_bundle_project --template app_basic\ncd \"my_app_bundle_project\"\nsnow app bundle\nls my_app_bundle_project/output/deploy\n\n```\n\nCopy\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../overview)\n3.  [Using Snowflake Native App in Snowflake CLI](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../native-apps/overview)\n4.  [Preparing a local folder with configured Snowflake Native App artifacts](/developer-guide/snowflake-cli/command-reference/native-apps-commands/../../native-apps/bundle-app)\n5.  [snow app commands](/developer-guide/snowflake-cli/command-reference/native-apps-commands/overview)\n6.  [snow app deploy](/developer-guide/snowflake-cli/command-reference/native-apps-commands/deploy-app)\n7.  [snow app run](/developer-guide/snowflake-cli/command-reference/native-apps-commands/run-app)\n8.  [snow app version create](/developer-guide/snowflake-cli/command-reference/native-apps-commands/version/app-version-create)",
    "parent_command": "snow app",
    "last_scraped": "NULL"
  },
  {
    "metadata": "NULL",
    "id": "NULL",
    "content_hash": "57e4caa9650e89db4a9956ea5c3dcd958c3bd98768bd02bef8ea27bb1335427e",
    "raw_content": "# snow spcs compute-pool create[¶](#snow-spcs-compute-pool-create \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nCreates a new compute pool.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/create-compute-pool)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs compute-pool create\n  <name>\n  --family <instance_family>\n  --min-nodes <min_nodes>\n  --max-nodes <max_nodes>\n  --auto-resume\n  --no-auto-resume\n  --init-suspend / --no-init-suspend\n  --auto-suspend-secs <auto_suspend_secs>\n  --tag <tags>\n  --comment <comment>\n  --if-not-exists\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the compute pool; for example: my\\_compute\\_pool.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--family _TEXT_`\n\nName of the instance family. For more information about instance families, refer to the SQL CREATE COMPUTE POOL command.\n\n`--min-nodes _INTEGER RANGE_`\n\nMinimum number of nodes for the compute pool. Default: 1.\n\n`--max-nodes _INTEGER RANGE_`\n\nMaximum number of nodes for the compute pool.\n\n`--auto-resume`\n\nThe compute pool will automatically resume when a service or job is submitted to it. Default: False.\n\n`--no-auto-resume`\n\nThe compute pool will automatically resume when a service or job is submitted to it. Default: False.\n\n`--init-suspend / --no-init-suspend`\n\nStarts the compute pool in a suspended state. Default: False.\n\n`--auto-suspend-secs _INTEGER RANGE_`\n\nNumber of seconds of inactivity after which you want Snowflake to automatically suspend the compute pool. Default: 3600.\n\n`--tag _NAME=VALUE_`\n\nTag for the compute pool.\n\n`--comment _TEXT_`\n\nComment for the compute pool.\n\n`--if-not-exists`\n\nOnly apply this operation if the specified object does not already exist. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example creates a compute pool named “pool\\_1” using the minimal CPU\\_X64\\_XS family, which comprises two CPUs with 4GB of memory.\n\n```\nsnow spcs compute-pool create \"pool_1\" --min-nodes 2 --max-nodes 2 --family \"CPU_X64_XS\"\n\n```\n\nCopy\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../overview)\n4.  [compute-pool commands reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/overview)\n5.  [snow spcs compute-pool stop-all](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/stop-all)",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/create",
    "last_scraped": "NULL",
    "category": "NULL",
    "title": "snow spcs compute-pool create¶",
    "parent_command": "snow spcs",
    "full_command": "snow spcs compute pool commands"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/stop-all",
    "category": "NULL",
    "metadata": "NULL",
    "id": "NULL",
    "raw_content": "# snow spcs compute-pool stop-all[¶](#snow-spcs-compute-pool-stop-all \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nDeletes all services running on the compute pool.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/alter-compute-pool)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs compute-pool stop-all\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the compute pool; for example: my\\_compute\\_pool.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example stops a compute pool named “pool1” and deletes all services running on it:\n\n```\nsnow spcs compute-pool stop-all \"pool1\"\n\n```\n\nCopy\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../overview)\n4.  [compute-pool commands reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/overview)\n5.  [snow spcs compute-pool create](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/create)",
    "parent_command": "snow spcs",
    "title": "snow spcs compute-pool stop-all¶",
    "command_group": "NULL",
    "full_command": "snow spcs compute pool commands",
    "last_scraped": "NULL",
    "content_hash": "2d263608bddc86540f5c0d274e8b668985d72f2ddc5f1dc983d085f14f0721e0"
  },
  {
    "command_group": "NULL",
    "title": "snow spcs compute-pool deploy¶",
    "parent_command": "snow spcs",
    "full_command": "snow spcs compute pool commands",
    "category": "NULL",
    "last_scraped": "NULL",
    "content_hash": "2bd0fba56540317520c3d3b8e597b70f2be9b895c7ba2d92510115da40f301a7",
    "id": "NULL",
    "url": "https://docs.snowflake.com/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/deploy",
    "metadata": "NULL",
    "raw_content": "# snow spcs compute-pool deploy[¶](#snow-spcs-compute-pool-deploy \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nDeploys a compute pool from the project definition file.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs compute-pool deploy\n  <entity_id>\n  --upgrade\n  --project <project_definition>\n  --env <env_overrides>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_entity_id_`\n\nID of compute-pool entity.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--upgrade`\n\nUpdates the existing compute pool. Can update min\\_nodes, max\\_nodes, auto\\_resume, auto\\_suspend\\_seconds and comment. Default: False.\n\n`-p, --project _TEXT_`\n\nPath where the Snowflake project is stored. Defaults to the current working directory.\n\n`--env _TEXT_`\n\nString in the format key=value. Overrides variables from the env section used for templates. Default: \\[\\].\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow spcs compute pool deploy` command reads a `snowflake.yml` project definition file that defines a compute pool. If your project definition has precisely one compute pool entity, you can omit the `<entity_id>` argument. However, if your project definition has multiple compute pool entities, you must specify the compute pool name in the `<entity_id>` argument. For more information, see [Compute pools project definition](../../../services/manage-compute-pools.html#label-sfcli-pool-pdf).\n\nThe `--upgrade` option updates an existing service. You can update only the following project definition parameters:\n\n*   `min_instances`\n    \n*   `max_instances`\n    \n*   `query_warehouse`\n    \n*   `auto_resume`\n    \n*   `external_access_integrations`\n    \n*   `comment`\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example creates and deploys a compute pool defined in the `snowflake.yml` file in the current directory.\n\n```\nsnow spcs compute-pool deploy\n\n```\n\nCopy\n\n```\n+---------------------------------------------------------------------+\n| key    | value                                                      |\n|--------+------------------------------------------------------------|\n| status | Compute pool MY_COMPUTE_POOL successfully created.         |\n+---------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/../overview)\n4.  [compute-pool commands reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/overview)\n5.  [snow spcs compute-pool stop-all](/developer-guide/snowflake-cli/command-reference/spcs-commands/compute-pool-commands/stop-all)"
  },
  {
    "category": "NULL",
    "title": "snow spcs image-registry token¶",
    "command_group": "NULL",
    "full_command": "snow spcs image registry commands",
    "metadata": "NULL",
    "parent_command": "snow spcs",
    "last_scraped": "NULL",
    "content_hash": "9ff3a835ebb3fa7255163cab5102f9fa784c380a31dae5e42db437996cabbabc",
    "raw_content": "# snow spcs image-registry token[¶](#snow-spcs-image-registry-token \"Link to this heading\")\n\nRetrieves a registry authentication token based on your current connection. Note that this token is specific to your current user and will not grant access to any repositories that your current user cannot access.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs image-registry token\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\nNone\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example shows how to return the token associated with the specified connection that you can use to authenticate with the registry.\n\n```\nsnow spcs image-registry token --connection mytest\n\n```\n\nCopy\n\n```\n+----------------------------------------------------------------------------------------------------------------------+\n| key        | value                                                                                                   |\n|------------+---------------------------------------------------------------------------------------------------------|\n| token      | ****************************************************************************************************    |\n|            | ****************************************************************************************************    |\n| expires_in | 3600                                                                                                    |\n+----------------------------------------------------------------------------------------------------------------------+\n\n```\n\nExample usage with docker:\n\n```\nsnow spcs image-registry token --format=JSON | docker login YOUR_HOST -u 0sessiontoken --password-stdin\n\n```\n\nCopy\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../overview)\n4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/overview)\n5.  [Working with image registries and repositories](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../services/manage-images)",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/token"
  },
  {
    "id": "NULL",
    "metadata": "NULL",
    "category": "NULL",
    "full_command": "snow spcs image registry commands",
    "parent_command": "snow spcs",
    "content_hash": "a3953d5845870639ca9fed862bd635f4867744b50224e5d09af504e623b6f649",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/login",
    "title": "snow spcs image-registry login¶",
    "command_group": "NULL",
    "raw_content": "# snow spcs image-registry login[¶](#snow-spcs-image-registry-login \"Link to this heading\")\n\nLogs in to the account image registry with the current user’s credentials through Docker. Must be called from a role that can view at least one image repository in the image registry.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs image-registry login\n  --private-link\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\nNone\n\n## Options[¶](#options \"Link to this heading\")\n\n`--private-link`\n\nGet the private link URL instead of the public URL. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\n*   [Docker Desktop](https://www.docker.com/products/docker-desktop/) must be installed because the command uses docker to log in to Snowflake.\n    \n*   The current role must have READ privileges for the image repository in the account to get the registry URL.\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs image-registry login\n\n```\n\nCopy\n\n```\nLogin Succeeded\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../overview)\n4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/overview)\n5.  [Working with image registries and repositories](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../services/manage-images)",
    "last_scraped": "NULL"
  },
  {
    "command_group": "NULL",
    "full_command": "snow spcs image registry commands",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/url",
    "parent_command": "snow spcs",
    "title": "snow spcs image-registry url¶",
    "raw_content": "# snow spcs image-registry url[¶](#snow-spcs-image-registry-url \"Link to this heading\")\n\nGets the image registry URL for the current account. Must be called from a role that can view at least one image repository in the image registry.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs image-registry url\n  --private-link\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\nNone\n\n## Options[¶](#options \"Link to this heading\")\n\n`--private-link`\n\nGet the private link URL instead of the public URL. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe current role must have READ privileges for the image repository in the account to get the registry URL.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs image-registry url\n\n```\n\nCopy\n\n```\n<orgname-acctname>.registry.snowflakecomputing.com\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../overview)\n4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/overview)\n5.  [Working with image registries and repositories](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-registry-commands/../../../services/manage-images)",
    "category": "NULL",
    "id": "NULL",
    "last_scraped": "NULL",
    "content_hash": "5060df02594064e54a008bb812bfc147b83af2721e4ca3235fa2b532379572ee",
    "metadata": "NULL"
  },
  {
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/create",
    "raw_content": "# snow spcs image-repository create[¶](#snow-spcs-image-repository-create \"Link to this heading\")\n\nCreates a new image repository in the current schema.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/create-image-repository)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs image-repository create\n  <name>\n  --replace\n  --if-not-exists\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the image repository; for example: my\\_repository.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--replace`\n\nReplace this object if it already exists. Default: False.\n\n`--if-not-exists`\n\nOnly apply this operation if the specified object does not already exist. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs image-repository create tutorial_repository\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)\n4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview)",
    "parent_command": "snow spcs",
    "last_scraped": "NULL",
    "title": "snow spcs image-repository create¶",
    "full_command": "snow spcs image repository commands",
    "metadata": "NULL",
    "command_group": "NULL",
    "content_hash": "0a50fda054b5d2e8e91bac38169700e4454c467934de74f3e5ed9e8b9053b70d",
    "id": "NULL"
  },
  {
    "command_group": "NULL",
    "id": "NULL",
    "full_command": "snow spcs image repository commands",
    "parent_command": "snow spcs",
    "raw_content": "# snow spcs image-repository url[¶](#snow-spcs-image-repository-url \"Link to this heading\")\n\nReturns the URL for the given repository.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs image-repository url\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the image repository; for example: my\\_repository.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\n*   The current role must have READ privileges for the image repository in the account to get the registry URL.\n    \n*   The URL is returned as a text string, so you can store it in an environment variable for convenience. For example:\n    \n    ```\n    export REPO_URL = $(snow spcs image-repository url <name>)\n    \n    ```\n    \n    Copy\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs image-repository url tutorial_repository\n\n```\n\nCopy\n\n```\n<orgname-acctname>.registry.snowflakecomputing.com/tutorial_db/data_schema/tutorial_repository\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)\n4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview)",
    "last_scraped": "NULL",
    "content_hash": "fc073565c66ddef2c7c6332b2930e2b6023ad427d8ad4ff92c2b1e8e472db233",
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/url",
    "title": "snow spcs image-repository url¶",
    "metadata": "NULL"
  },
  {
    "raw_content": "# snow spcs image-repository list-images[¶](#snow-spcs-image-repository-list-images \"Link to this heading\")\n\nLists images in the given repository.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/show-images-in-image-repository)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs image-repository list-images\n  <name>\n  --like <like_option>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the image repository; for example: my\\_repository.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--like, -l _TEXT_`\n\nSQL LIKE pattern for filtering objects by name. For example, `--like \"my%\"` lists all image repositories that begin with “my”.. Default: %%.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example lists the images and tags in a repository named `images` in the `my_db` database:\n\n```\nsnow spcs image-repository list-images images --database my_db\n\n```\n\nCopy\n\n```\n+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n| created_on                | image_name            | tags   | digest                                         | image_path                               |\n|---------------------------+-----------------------+--------+------------------------------------------------+------------------------------------------|\n| 2024-10-11 14:23:49-07:00 | echo_service          | latest | sha256:a8a001fef406fdb3125ce8e8bf9970c35af7084 | my_db/test_schema/images/echo_service:   |\n|                           |                       |        | fc33b0886d7a8915d3082c781                      | latest                                   |\n| 2024-10-14 22:21:14-07:00 | test_counter          | latest | sha256:8cae96dac29a4a05f54bb5520003f964baf67fc | my_db/test_schema/images/test_counter:   |\n|                           |                       |        | 38dcad3d2c85d6c5aa7381174                      | latest                                   |\n+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)\n4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview)",
    "last_scraped": "NULL",
    "parent_command": "snow spcs",
    "content_hash": "26c220f58556f27cd085892904a2b460a5fbed3a172fd73754fd676f9f85df81",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/list-images",
    "category": "NULL",
    "command_group": "NULL",
    "id": "NULL",
    "full_command": "snow spcs image repository commands",
    "metadata": "NULL",
    "title": "snow spcs image-repository list-images¶"
  },
  {
    "title": "snow spcs image-repository deploy¶",
    "url": "https://docs.snowflake.com/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/deploy",
    "category": "NULL",
    "full_command": "snow spcs image repository commands",
    "raw_content": "# snow spcs image-repository deploy[¶](#snow-spcs-image-repository-deploy \"Link to this heading\")\n\nDeploys a new image repository from snowflake.yml file.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs image-repository deploy\n  <entity_id>\n  --replace\n  --project <project_definition>\n  --env <env_overrides>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_entity_id_`\n\nID of image-repository entity.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--replace`\n\nReplace the image repository if it already exists. Default: False.\n\n`-p, --project _TEXT_`\n\nPath where the Snowflake project is stored. Defaults to the current working directory.\n\n`--env _TEXT_`\n\nString in the format key=value. Overrides variables from the env section used for templates. Default: \\[\\].\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow spcs image repository deploy` command creates an image repository from its definition in a `snowflake.yml` project definition file. For more information, see [Image repository project definition file](../../../services/manage-images.html#label-sfcli-repo-pdf).\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example creates an image repository defined in the `snowflake.yml` file in the current directory.\n\n```\nsnow spcs image-repository deploy\n\n```\n\nCopy\n\n```\n+---------------------------------------------------------------------+\n| key    | value                                                      |\n|--------+------------------------------------------------------------|\n| status | Image Repository MY_IMAGE_REPOSITORY successfully created. |\n+---------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/../overview)\n4.  [image-repository command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/image-repository-commands/overview)",
    "last_scraped": "NULL",
    "command_group": "NULL",
    "content_hash": "3cea9a37e1f0df9d5ab11d063ee74cebf5386171bc8b286f6d98c186bd339e56",
    "id": "NULL",
    "metadata": "NULL",
    "parent_command": "snow spcs"
  },
  {
    "last_scraped": "NULL",
    "full_command": "snow spcs service commands",
    "metadata": "NULL",
    "parent_command": "snow spcs",
    "command_group": "NULL",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/create",
    "title": "snow spcs service create¶",
    "raw_content": "# snow spcs service create[¶](#snow-spcs-service-create \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nCreates a new service in the current schema.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/create-service)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service create\n  <name>\n  --compute-pool <compute_pool>\n  --spec-path <spec_path>\n  --min-instances <min_instances>\n  --max-instances <max_instances>\n  --auto-resume / --no-auto-resume\n  --eai-name <external_access_integrations>\n  --query-warehouse <query_warehouse>\n  --tag <tags>\n  --comment <comment>\n  --if-not-exists\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--compute-pool _TEXT_`\n\nCompute pool to run the service on.\n\n`--spec-path _FILE_`\n\nPath to service specification file.\n\n`--min-instances _INTEGER RANGE_`\n\nMinimum number of service instances to run. Default: 1.\n\n`--max-instances _INTEGER RANGE_`\n\nMaximum number of service instances to run.\n\n`--auto-resume / --no-auto-resume`\n\nThe service will automatically resume when a service function or ingress is called. Default: True.\n\n`--eai-name _TEXT_`\n\nIdentifies external access integrations (EAI) that the service can access. This option may be specified multiple times for multiple EAIs.\n\n`--query-warehouse _TEXT_`\n\nWarehouse to use if a service container connects to Snowflake to execute a query without explicitly specifying a warehouse to use.\n\n`--tag _NAME=VALUE_`\n\nTag for the service.\n\n`--comment _TEXT_`\n\nComment for the service.\n\n`--if-not-exists`\n\nOnly apply this operation if the specified object does not already exist. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nYou can optionally choose to run more than one instance of your service. Each service instance is a collection of containers, as defined in the service specification file, that run together on a node in your compute pool. If you choose to run multiple instances of a service, a load balancer manages incoming traffic.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs service create \"my-service\" --compute-pool \"pool_1\" --spec-path \"/some-dir/echo-speck.yaml\"\n\n```\n\nCopy\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",
    "content_hash": "45408d2ed2f4c62ff946dc67f27dcd9f04d595b9d840224c621e29318da40a43",
    "category": "NULL"
  },
  {
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/suspend",
    "command_group": "NULL",
    "parent_command": "snow spcs",
    "full_command": "snow spcs service commands",
    "raw_content": "# snow spcs service suspend[¶](#snow-spcs-service-suspend \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nSuspends the service, shutting down and deleting all its containers.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/alter-service)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service suspend\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe current role must have OPERATE privilege on the service to suspend a service.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs service suspend echo_service\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",
    "category": "NULL",
    "content_hash": "f59bb355a43071f15467c8cd0ad06d642e531dd7c801ec18310c8bd6c0eb1b9f",
    "title": "snow spcs service suspend¶",
    "metadata": "NULL",
    "id": "NULL"
  },
  {
    "command_group": "NULL",
    "full_command": "snow spcs service commands",
    "parent_command": "snow spcs",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/resume",
    "category": "NULL",
    "content_hash": "a69176cbc8f204e08feb585f1c50a8c79fa6eb235d2baf299e969afcd6c148ca",
    "raw_content": "# snow spcs service resume[¶](#snow-spcs-service-resume \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nResumes the service from a SUSPENDED state.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/alter-service)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service resume\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe current role must have OPERATE privilege on the service to resume a service.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs service resume echo_service\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",
    "id": "NULL",
    "title": "snow spcs service resume¶",
    "last_scraped": "NULL",
    "metadata": "NULL"
  },
  {
    "category": "NULL",
    "id": "NULL",
    "parent_command": "snow spcs",
    "full_command": "snow spcs service commands",
    "last_scraped": "NULL",
    "title": "snow spcs service list¶",
    "content_hash": "3c82af51645917a6a1728f98cf61944af9b81c2573c32b1832426b90b46e34fa",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list",
    "command_group": "NULL",
    "metadata": "NULL",
    "raw_content": "# snow spcs service list[¶](#snow-spcs-service-list \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nLists all available services.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/show-services)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service list\n  --like <like>\n  --in <scope>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\nNone\n\n## Options[¶](#options \"Link to this heading\")\n\n`--like, -l _TEXT_`\n\nSQL LIKE pattern for filtering objects by name. For example, `list --like \"my%\"` lists all services that begin with “my”.. Default: %%.\n\n`--in _<TEXT TEXT>..._`\n\nSpecifies the scope of this command using ‘–in <scope> <name>’, for example `list --in compute-pool my_pool`. Default: (None, None).\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following command lists the services and their statuses:\n\n```\nsnow spcs service list\n\n```\n\nCopy\n\n```\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|        |        |        |        |        |        |        |        |        |        |        |         | extern |         |        |         |        |         |        |        |         |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         | al_acc |         |        |         |        |         |        |        |         |        | managin | managi |\n|        |        | databa |        |        |        |        | curren | target | min_in | max_in |         | ess_in |         |        |         |        | owner_r | query_ |        |         |        | g_objec | ng_obj |\n|        |        | se_nam | schema |        | comput | dns_na | t_inst | _insta | stance | stance | auto_re | tegrat | created | update | resumed | commen | ole_typ | wareho |        | spec_di | is_upg | t_domai | ect_na |\n| name   | status | e      | _name  | owner  | e_pool | me     | ances  | nces   | s      | s      | sume    | ions   | _on     | d_on   | _on     | t      | e       | use    | is_job | gest    | rading | n       | me     |\n|--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+--------+---------+--------+---------+--------+---------+--------+--------+---------+--------+---------+--------|\n| ECHO_S | RUNNIN | TEST00 | TEST_S | SYSADM | TUTORI | echo-s | 1      | 1      | 1      | 1      | true    | None   | 2024-10 | 2024-1 | None    | This   | ROLE    | COMPUT | false  | 52e62d1 | false  | None    | None   |\n| ERVICE | G      | _DB    | CHEMA  | IN     | AL_COM | ervice |        |        |        |        |         |        | -16     | 0-16   |         | is a   |         | E_WH   |        | f19c720 |        |         |        |\n|        |        |        |        |        | PUTE_P | .imhd. |        |        |        |        |         |        | 15:09:3 | 15:09: |         | test   |         |        |        | 6b5f4ef |        |         |        |\n|        |        |        |        |        | OOL    | svc.sp |        |        |        |        |         |        | 0.49300 | 31.905 |         | servic |         |        |        | c069557 |        |         |        |\n|        |        |        |        |        |        | cs.int |        |        |        |        |         |        | 0-07:00 | 000-07 |         | e      |         |        |        | 8b6c2b3 |        |         |        |\n|        |        |        |        |        |        | ernal  |        |        |        |        |         |        |         | :00    |         |        |         |        |        | 806ad76 |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 67d78cc |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | ce8b6ed |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 6501a8a |        |         |        |\n|        |        |        |        |        |        |        |        |        |        |        |         |        |         |        |         |        |         |        |        | 3       |        |         |        |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [SHOW SERVICES](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/show-services)"
  },
  {
    "raw_content": "# snow spcs service describe[¶](#snow-spcs-service-describe \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nProvides description of service.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/desc-service)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service describe\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nNone.\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [DESCRIBE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/desc-service)",
    "last_scraped": "NULL",
    "parent_command": "snow spcs",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/describe",
    "full_command": "snow spcs service commands",
    "metadata": "NULL",
    "category": "NULL",
    "title": "snow spcs service describe¶",
    "content_hash": "24ff13044640494af0a51f81f34b7d1e122df90125ac39aeec8494f4c6690dc6",
    "id": "NULL"
  },
  {
    "last_scraped": "NULL",
    "raw_content": "# snow spcs service list-instances[¶](#snow-spcs-service-list-instances \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nLists all service instances in a service.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/show-service-instances-in-service)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service list-instances\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThis example lists the instances in the `echo_service` service:\n\n```\nsnow spcs service list-instances echo_service\n\n```\n\nCopy\n\n```\n+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| database_name | schema_name | service_name | instance_id | status | spec_digest                                                      | creation_time        | start_time           |\n|---------------+-------------+--------------+-------------+--------+------------------------------------------------------------------+----------------------+----------------------|\n| TEST00_DB     | TEST_SCHEMA | ECHO_SERVICE | 0           | READY  | 336c065739dd2b96e770f01804affdc7810e6df68a23b23052d851627abfbdf9 | 2024-10-10T06:06:30Z | 2024-10-10T06:06:30Z |\n+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [DROP SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/drop-service)",
    "parent_command": "snow spcs",
    "title": "snow spcs service list-instances¶",
    "full_command": "snow spcs service commands",
    "metadata": "NULL",
    "content_hash": "8dc9aa27ef16daa22449145595c111a29963b5dc296268316cb136d7ef8aeaa7",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list-instances",
    "category": "NULL",
    "command_group": "NULL",
    "id": "NULL"
  },
  {
    "parent_command": "snow spcs",
    "category": "NULL",
    "full_command": "snow spcs service commands",
    "command_group": "NULL",
    "metadata": "NULL",
    "content_hash": "fe969ef7b246355c91a8b24b4b5aaf8dd7f5d0051fb087a165b07f7c190af16b",
    "raw_content": "# snow spcs service list-containers[¶](#snow-spcs-service-list-containers \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nLists all service containers in a service.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/show-service-containers-in-service)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service list-containers\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThis example lists containers in the `echo_service` service:\n\n```\nsnow spcs service list-containers echo_service\n\n```\n\nCopy\n\n```\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| database_name | schema_name | service_name | instance_id | container_name | status | message | image_name                                | image_digest                              | restart_count | start_time           |\n|---------------+-------------+--------------+-------------+----------------+--------+---------+-------------------------------------------+-------------------------------------------+---------------+----------------------|\n| TEST00_DB     | TEST_SCHEMA | ECHO_SERVICE | 0           | main           | READY  | Running | org-test-account-00.registry.registry.sno | sha256:06c3d54edc24925abe398eda70d37eb6b8 | 0             | 2024-10-16T22:09:35Z |\n|               |             |              |             |                |        |         | wflakecomputing.com/test00_db/test_schema | 7b1c4dd6211317592764e1e7d94498            |               |                      |\n|               |             |              |             |                |        |         | /test00_repo/echo_service:latest          |                                           |               |                      |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [DROP SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/drop-service)",
    "id": "NULL",
    "title": "snow spcs service list-containers¶",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list-containers",
    "last_scraped": "NULL"
  },
  {
    "last_scraped": "NULL",
    "category": "NULL",
    "content_hash": "add841b1078155d7381c95dd12df0279c21d988b209a3a709b55b59b5b815873",
    "title": "snow spcs service list-endpoints¶",
    "command_group": "NULL",
    "metadata": "NULL",
    "full_command": "snow spcs service commands",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list-endpoints",
    "id": "NULL",
    "parent_command": "snow spcs",
    "raw_content": "# snow spcs service list-endpoints[¶](#snow-spcs-service-list-endpoints \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nLists the endpoints in a service.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/show-endpoints)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service list-endpoints\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs service list-endpoints echo_service\n\n```\n\nCopy\n\n```\n+--------------+------+----------+-----------------+-----------------------------------------+\n| name         | port | protocol | ingress_enabled | ingress_url                             |\n|--------------+------+----------+-----------------+-----------------------------------------|\n| echoendpoint | 8000 | TCP      | true            | org-id-acct-id.snowflakecomputing.app   |\n+--------------+------+----------+-----------------+-----------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [SHOW ENDPOINTS](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/show-endpoints)"
  },
  {
    "raw_content": "# snow spcs service list-roles[¶](#snow-spcs-service-list-roles \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nLists all service roles in a service.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/show-roles)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service list-roles\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example gets a list of service roles created for a service:\n\n```\nsnow spcs service list-roles my_service\n\n```\n\nCopy\n\n```\n+------------------------------------------------------------------+\n| created_on                       | name                | comment |\n|----------------------------------+---------------------+---------|\n| 2024-10-09 16:48:52.980000-07:00 | ALL_ENDPOINTS_USAGE | None    |\n+------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [DROP SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/drop-service)",
    "content_hash": "426d9fa510a0f41149e743f78da5436c2ed277bb0d4606282294725722973ec8",
    "command_group": "NULL",
    "metadata": "NULL",
    "id": "NULL",
    "parent_command": "snow spcs",
    "title": "snow spcs service list-roles¶",
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/list-roles",
    "full_command": "snow spcs service commands",
    "last_scraped": "NULL"
  },
  {
    "last_scraped": "NULL",
    "raw_content": "# snow spcs service set[¶](#snow-spcs-service-set \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nSets one or more properties for the service.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/alter-service)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service set\n  <name>\n  --min-instances <min_instances>\n  --max-instances <max_instances>\n  --query-warehouse <query_warehouse>\n  --auto-resume / --no-auto-resume\n  --auto-suspend-secs <auto_suspend_secs>\n  --eai-name <external_access_integrations>\n  --comment <comment>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--min-instances _INTEGER RANGE_`\n\nMinimum number of service instances to run.\n\n`--max-instances _INTEGER RANGE_`\n\nMaximum number of service instances to run.\n\n`--query-warehouse _TEXT_`\n\nWarehouse to use if a service container connects to Snowflake to execute a query without explicitly specifying a warehouse to use.\n\n`--auto-resume / --no-auto-resume`\n\nThe service will automatically resume when a service function or ingress is called.\n\n`--auto-suspend-secs _INTEGER RANGE_`\n\nNumber of seconds of inactivity after which the service will be automatically suspended.\n\n`--eai-name _TEXT_`\n\nIdentifies external access integrations (EAI) that the service can access. This option may be specified multiple times for multiple EAIs.\n\n`--comment _TEXT_`\n\nComment for the service.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe current role must have OPERATE privilege on the service to set properties.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs service set echo_service --min-instances 2 --max-instances 4\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [UNSET](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/unset)",
    "title": "snow spcs service set¶",
    "metadata": "NULL",
    "command_group": "NULL",
    "id": "NULL",
    "category": "NULL",
    "full_command": "snow spcs service commands",
    "parent_command": "snow spcs",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/set",
    "content_hash": "4baa115c4b292e09355d8715370bf7ea2e2e7c9b98d3daac89e6752e417e37d0"
  },
  {
    "raw_content": "# snow spcs service logs[¶](#snow-spcs-service-logs \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nRetrieves local logs from a service container.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/call)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service logs\n  <name>\n  --container-name <container_name>\n  --instance-id <instance_id>\n  --num-lines <num_lines>\n  --previous-logs\n  --since <since_timestamp>\n  --include-timestamps\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--container-name _TEXT_`\n\nName of the container.\n\n`--instance-id _TEXT_`\n\nID of the service instance, starting with 0.\n\n`--num-lines _INTEGER_`\n\nNumber of lines to retrieve. Default: 500.\n\n`--previous-logs`\n\nRetrieve logs from the last terminated container. Default: False.\n\n`--since _TEXT_`\n\nStart log retrieval from a specified UTC timestamp.\n\n`--include-timestamps`\n\nInclude timestamps in logs. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\n*   The current role must have the MONITOR privilege on the service to access the container logs.\n    \n*   The function returns a container log as a string.\n    \n*   When using the `--follow` option for real-time log streaming, the `--num-lines` and `--previous-logs` options are not supported.\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   The following example displays the last three lines of the `echo_service` logs:\n    \n    ```\n    snow spcs service logs echo_service --container-name echo --instance-id 0 --num-lines 3\n    \n    ```\n    \n    Copy\n    \n    ```\n    10.18.94.31 - - [22/Nov/2024 09:16:47] \"GET /healthcheck HTTP/1.1\" 200 -\n    10.18.94.31 - - [22/Nov/2024 09:16:52] \"GET /healthcheck HTTP/1.1\" 200 -\n    10.18.94.31 - - [22/Nov/2024 09:16:57] \"GET /healthcheck HTTP/1.1\" 200 -\n    \n    ```\n    \n*   This example streams the logs for the `echo_service` service and updates them every 10 seconds:\n    \n    ```\n    snow spcs service logs echo_service --container-name echo --instance-id 0 --follow --follow-interval 10\n    \n    ```\n    \n    Copy\n    \n*   The following example displays the log entries since 9:30 UTC, 21 Nov 2024:\n    \n    ```\n    snow spcs service logs echo_service --container-name echo --instance-id 0 --since 2024-11-21T09:30:00Z\n    \n    ```\n    \n    Copy\n    \n*   The following example retrieves logs from the last-terminated container:\n    \n    ```\n    snow spcs service logs example_job_service --container-name main --instance-id 0 --previous-logs\n    \n    ```\n    \n    Copy\n    \n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [spcs command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../overview)\n4.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n5.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n6.  [SYSTEM$GET\\_SERVICE\\_LOGS](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/functions/system_get_service_logs)",
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/logs",
    "full_command": "snow spcs service commands",
    "parent_command": "snow spcs",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "title": "snow spcs service logs¶",
    "content_hash": "d3e8e37e5bec184fb39b841a9f9d43ec3d77313953a65eaa858b139485d955e2",
    "command_group": "NULL",
    "id": "NULL"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/upgrade",
    "parent_command": "snow spcs",
    "id": "NULL",
    "command_group": "NULL",
    "title": "snow spcs service upgrade¶",
    "category": "NULL",
    "last_scraped": "NULL",
    "content_hash": "8a70f67b4ab58377881723b0079b9c6bcb64ac59237cd815b39b1b2e38d0c86b",
    "metadata": "NULL",
    "raw_content": "# snow spcs service upgrade[¶](#snow-spcs-service-upgrade \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nUpdates an existing service with a new specification file.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/alter-service)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service upgrade\n  <name>\n  --spec-path <spec_path>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the service; for example: my\\_service.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--spec-path _FILE_`\n\nPath to service specification file.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe current role must have OPERATE privilege on the service to upgrade a service.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow spcs service upgrade echo_service --spec-path spec.yml\n\n```\n\nCopy\n\n```\n+-------------------------------------------+\n| key    | value                            |\n|--------+----------------------------------|\n| status | Statement executed successfully. |\n+-------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",
    "full_command": "snow spcs service commands"
  },
  {
    "id": "NULL",
    "parent_command": "snow spcs",
    "full_command": "snow spcs service commands",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/deploy",
    "raw_content": "# snow spcs service deploy[¶](#snow-spcs-service-deploy \"Link to this heading\")\n\nNote\n\nYou can use Snowpark Container Services from Snowflake CLI only if you have the necessary permissions to use Snowpark Container Services.\n\nDeploys a service defined in the project definition file.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow spcs service deploy\n  <entity_id>\n  --upgrade\n  --project <project_definition>\n  --env <env_overrides>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_entity_id_`\n\nID of service entity.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--upgrade`\n\nUpdates the existing service. Can update min\\_instances, max\\_instances, query\\_warehouse, auto\\_resume, auto\\_suspend\\_secs, external\\_access\\_integrations and comment. Default: False.\n\n`-p, --project _TEXT_`\n\nPath where the Snowflake project is stored. Defaults to the current working directory.\n\n`--env _TEXT_`\n\nString in the format key=value. Overrides variables from the env section used for templates. Default: \\[\\].\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow spcs service deploy` command reads a `snowflake.yml` project definition file that defines a service, then creates and deploys the compute pool to a stage named in the `snowflake.yml` file. If your project definition has precisely one service entity, you can omit the `<entity_id>` argument. However, if your project definition has multiple service entities, you must specify the service name in the `<entity_id>` argument. For more information, see [Services project definition](../../../services/manage-services.html#label-sfcli-service-pdf).\n\nYou can optionally choose to run more than one instance of your service. Each service instance is a collection of containers, as defined in the service specification file, that run together on a node in your compute pool. If you choose to run multiple instances of a service, a load balancer manages incoming traffic.\n\nThe `--upgrade` option updates an existing service. You can update only the following project definition parameters:\n\n*   `min_instances`\n    \n*   `max_instances`\n    \n*   `query_warehouse`\n    \n*   `auto_resume`\n    \n*   `external_access_integrations`\n    \n*   `comment`\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example creates and deploys a service defined in the `snowflake.yml` file in the current directory.\n\n```\nsnow spcs service deploy\n\n```\n\nCopy\n\n```\n+---------------------------------------------------------------------+\n| key    | value                                                      |\n|--------+------------------------------------------------------------|\n| status | Service MY_SERVICE successfully created.                   |\n+---------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../overview)\n3.  [service commands](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/overview)\n4.  [Snowpark Container Services: Working with services](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../snowpark-container-services/working-with-services)\n5.  [CREATE SERVICE](/developer-guide/snowflake-cli/command-reference/spcs-commands/service-commands/../../../../../sql-reference/sql/create-service)",
    "title": "snow spcs service deploy¶",
    "command_group": "NULL",
    "content_hash": "a59428147934da18ba194381a4c0f81bce32e522e8b7aeaf051419929d09b800",
    "category": "NULL",
    "metadata": "NULL"
  },
  {
    "id": "NULL",
    "metadata": "NULL",
    "content_hash": "8881ae6dd183b5047508cbe1a83e8c009f6871fe2e402257a7daf9922d9805b9",
    "category": "NULL",
    "command_group": "NULL",
    "last_scraped": "NULL",
    "parent_command": "snow object",
    "full_command": "snow object create",
    "raw_content": "# snow object create[¶](#snow-object-create \"Link to this heading\")\n\nCreate an object of a given type. Check documentation for the list of supported objects and parameters.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow object create\n  <object_type>\n  <object_attributes>\n  --json <object_json>\n  --if-not-exists\n  --replace\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_object_type_`\n\nType of object. For example table, database, compute-pool.\n\n`_object_attributes..._`\n\nObject attributes provided as a list of key=value pairs, for example name=my\\_db comment=’created with Snowflake CLI’. Check documentation for the full list of available parameters for every object. .\n\n## Options[¶](#options \"Link to this heading\")\n\n`--json _TEXT_`\n\nObject definition in JSON format, for example ‘{“name”: “my\\_db”, “comment”: “created with Snowflake CLI”}’. Check documentation for the full list of available parameters for every object.\n\n`--if-not-exists`\n\nOnly apply this operation if the specified object does not already exist. Default: False.\n\n`--replace`\n\nReplace this object if it already exists. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow object create` command creates one of the following types Snowflake objects, based on the provided object attributes or definitions:\n\n*   `account`\n    \n*   `catalog-integration`\n    \n*   `compute-pool`\n    \n*   `database`\n    \n*   `database-role`\n    \n*   `dynamic-table`\n    \n*   `event-table`\n    \n*   `external-volume`\n    \n*   `function`\n    \n*   `image-repository`\n    \n*   `managed-account`\n    \n*   `network-policy`\n    \n*   `notebook`\n    \n*   `notification-integration`\n    \n*   `pipe`\n    \n*   `procedure`\n    \n*   `role`\n    \n*   `schema`\n    \n*   `service`\n    \n*   `stage`\n    \n*   `stream`\n    \n*   `table`\n    \n*   `task`\n    \n*   `user-defined-function`\n    \n*   `view`\n    \n*   `warehouse`\n    \n\nFor each object, you must specify the appropriate object details using either the object attributes or the object definitions.\n\n*   Use the `object_attributes` parameter specifies the object details as a series of `<key>=<value>` pairs, such as:\n    \n    ```\n    snow object create database name=my_db comment=\"Created with Snowflake CLI\"\n    \n    ```\n    \n    Copy\n    \n*   Use the `--json object_definition` option to specify the object details as JSON, such as:\n    \n    ```\n    snow object create table name=my_table columns='[{\"name\":\"col1\",\"datatype\":\"number\", \"nullable\":false}]' constraints='[{\"name\":\"prim_key\", \"column_names\":[\"col1\"], \"constraint_type\":\"PRIMARY KEY\"}]' --database my_db --schema public\n    \n    ```\n    \n    Copy\n    \n*   See [Examples](#label-cli-create-examples) for more examples.\n    \n\nNote\n\nThe following object types require a database to be identified in the connection configuration, such as `config.toml`, or passed to the command using the `--database` option.\n\n*   image-repository\n    \n*   schema\n    \n*   service\n    \n*   table\n    \n*   task\n    \n\nThe following sections describe the attributes that Snowflake CLI supports for selected object types.\n\n*   [compute-pool](#label-cli-object-attrs-compute-pool)\n    \n*   [database](#label-cli-object-attrs-database)\n    \n*   [image-repository](#label-cli-object-attrs-image-repository)\n    \n*   [schema](#label-cli-object-attrs-schema)\n    \n*   [service](#label-cli-object-attrs-service)\n    \n*   [table](#label-cli-object-attrs-table)\n    \n*   [task](#label-cli-object-attrs-task)\n    \n*   [warehouse](#label-cli-object-attrs-database)\n    \n\nYou can find attributes for other types of objects by checking their corresponding SQL CREATE command references, such as [CREATE ACCOUNT](../../../../sql-reference/sql/create-account).\n\n### Compute pool object attributes[¶](#compute-pool-object-attributes \"Link to this heading\")\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Snowflake object identifier. |\n| min_nodesrequired, integer | Minimum number of nodes for the compute pool. |\n| max_nodesrequired, integer | Maximum number of nodes for the compute pool. |\n| instance_familyrequired, string | Name of the instance family. For more information about instance families, refer to the SQL CREATE COMPUTE POOL command. |\n| auto_resumeoptional, string | Whether to resume the compute pool automatically when any statement that requires the compute pool is submitted. |\n| commentoptional, string | Comment describing the compute pool. |\n| auto_suspend_secsoptional, string | Number of seconds of inactivity after which you want Snowflake to automatically suspend the compute pool. |\n\n### Database object attributes[¶](#database-object-attributes \"Link to this heading\")\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Snowflake object identifier. |\n| commentoptional, string | Comment describing the database. |\n| data_retention_time_in_daysoptional, integer | Number of days for which Time Travel actions (CLONE and UNDROP) can be performed on the schema, as well as the default Time Travel retention time for all tables created in the schema. |\n| default_ddl_collationoptional, string | Default collation specification for all schemas and tables added to the database. You can override this default at the schema and individual table level. |\n| max_data_extension_time_in_daysoptional, integer | Maximum number of days for which Snowflake can extend the data retention period for tables in the database to prevent streams on the tables from becoming stale. |\n| suspend_task_after_num_failuresoptional, integer | Number of consecutive failed task runs after which the current task is suspended automatically. |\n| user_task_managed_initial_warehouse_sizeoptional, integer | Size of the compute resources to provision for the first run of the task, before a task history is available for Snowflake to determine an ideal size. Possible values include: XSMALL, SMALL, MEDIUM, LARGE, and XLARGE. |\n| user_task_timeout_msoptional, integer | Time limit, in milliseconds, for a single run of the task before it times out. For information, see USER_TASK_TIMEOUT_MS. |\n\n### Image repository object attributes[¶](#image-repository-object-attributes \"Link to this heading\")\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Snowflake object identifier. |\n\n### Schema object attributes[¶](#schema-object-attributes \"Link to this heading\")\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Snowflake object identifier. |\n| commentoptional, string | Comment describing the schema. |\n| data_retention_time_in_daysoptional, integer | Number of days for which Time Travel actions (CLONE and UNDROP) can be performed on the schema, as well as the default Time Travel retention time for all tables created in the schema. |\n| default_ddl_collationoptional, string | Default collation specification for all schemas and tables added to the database. You can override this default at the schema and individual table level. |\n| max_data_extension_time_in_daysoptional, integer | Maximum number of days for which Snowflake can extend the data retention period for tables in the database to prevent streams on the tables from becoming stale. |\n| suspend_task_after_num_failuresoptional, integer | Number of consecutive failed task runs after which the current task is suspended automatically. |\n| user_task_managed_initial_warehouse_sizeoptional, integer | Size of the compute resources to provision for the first run of the task, before a task history is available for Snowflake to determine an ideal size. |\n| user_task_timeout_msoptional, integer | Time limit, in milliseconds, for a single run of the task before it times out. For information, see USER_TASK_TIMEOUT_MS. |\n\n### Service object attributes[¶](#service-object-attributes \"Link to this heading\")\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Snowflake object identifier. |\n| compute_poolrequired, string | Name of the compute pool in your account on which to run the service. |\n| specrequired, object | Service specification. See service specification table for details. |\n| external_access_integrationsoptional, string list | Names of the external access integrations that allow your service to access external sites. |\n| auto_resumeoptional, boolean | Whether to automatically resume a service when a service function or ingress is called. |\n| min_instancesoptional, integer | Minimum number of service instances to run. |\n| max_instancesoptional, integer | Maximum number of service instances to run. |\n| query_warehouseoptional, string | Warehouse to use if a service container connects to Snowflake to execute a query but does not explicitly specify a warehouse to use. |\n| commentoptional, string | Comment for the service. |\n\n**Service specification attributes**\n\n| Attribute | Description |\n| --- | --- |\n| spec_typerequired, string | Type of the service specification. Possible values include from_file or from_inline. |\n| spec_textrequired, string | (Valid only for spec_type=\"from_inline\")Service specification. You can use a pair of dollar signs ($$) to delimit the beginning and ending of the specification string. |\n| stagerequired, string | (Valid only for spec_type=\"from_inline\")Snowflake internal stage where the specification file is stored, such as @tutorial_stage. |\n| namerequired, string | (Valid only for spec_type=\"from_inline\")Path to the service specification file on the stage, such as some-dir/echo_spec.yaml. |\n\n### Table object attributes[¶](#table-object-attributes \"Link to this heading\")\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Snowflake object identifier. The name must be unique for the schema in which the table is created. |\n| kindoptional, string | Table type. Possible values include: TABLE for permanent tables, TEMPORARY, and TRANSIENT. |\n| commentoptional, string | Description of the table. |\n| cluster_by[]optional, string list | List of one or more columns or column expressions in the table as the clustering key. |\n| enable_schema_evolutionoptional, boolean | Whether to enable or disable schema evolution for the table. |\n| change_trackingoptional, boolean | Whether to enable or disable change tracking for the table. |\n| data_retention_time_in_daysoptional, integer | Retention period, in days, for the table so that Time Travel actions SELECT, CLONE, UNDROP can be performed on historical data in the table. |\n| max_data_extension_time_in_daysoptional, integer | Maximum number of days Snowflake can extend the data retention period to prevent streams on the table from becoming stale. |\n| default_ddl_collationoptional, string | Default collation specification for the columns in the table, including columns added to the table in the future. |\n| columnsrequired, column list | List of column definitions. See Column definition attributes. |\n| constraintsoptional, constraint list | List of constraint definitions. See Constrain definition attributes. |\n\n**Column definition attributes**\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Column name. |\n| datatyperequired, string | Type of data contained in the column. |\n| nullableoptional, boolean | Whether the column allows NULL values. |\n| collateoptional, string | Collation to use for column operations such as string comparison. |\n| defaultoptional, string | Whether to automatically insert a default value in the column if a value is not explicitly specified with an INSERT or CREATE TABLE AS SELECT statement. |\n| autoincrementoptional, boolean | Whether to automatically increment and include the number in successive columns. |\n| autoincrement_startoptional, integer | Staring value for the column. |\n| autoincrement_incrementoptional, integer | Increment for determining the next auto-incremented number. |\n| commentoptional, string | Column description. |\n\n**Constraint definition attributes**\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Constraint name. |\n| column_namesrequired, string list | Names of columns to apply the constraint. |\n| constraint_typerequired, string | Type of the constraint. Possible values include: UNIQUE, PRIMARY KEY and FOREIGN KEY. |\n| referenced_table_namerequired, string | (Valid only for constraint_type=\"FOREIGN KEY\")Name of table referenced by foreign key |\n| referenced_column_namesoptional, string | (Valid only for constraint_type=\"FOREIGN KEY\")Names of columns referenced by foreign key |\n\n### Task attributes[¶](#task-attributes \"Link to this heading\")\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Snowflake object identifier. |\n| definitionrequired, string | SQL definition for the task. It can be a single SQL statement, a call to a stored procedure, or procedural logic using Snowflake scripting. |\n| warehouseoptional, string | Virtual warehouse that provides compute resources for task runs. |\n| scheduleoptional, string | Schedule for periodically running the task. See Task schedule attributes for details. |\n| commentoptional, string | Comment description for the task. |\n| predecessorsoptional, string list | One or more predecessor tasks for the current task. |\n| user_task_managed_initial_warehouse_sizeoptional, string | Size of the compute resources to provision for the first run of the task. |\n| user_task_timeout_msoptional, string | Time limit, in milliseconds, on a single run of the task before it times out. For information, see USER_TASK_TIMEOUT_MS. |\n| suspend_task_after_num_failuresoptional, integer | Number of consecutive failed task runs after which the current task is suspended automatically. |\n| conditionoptional, string | Boolean SQL expression condition; multiple conditions joined with AND/OR are supported. |\n| allow_overlapping_executionoptional, boolean | Whether to allow multiple instances of the DAG to run concurrently. |\n\n**Task schedule attributes**\n\n| Attribute | Description |\n| --- | --- |\n| schedule_typeoptional, string | Type of the schedule. Possible values include CRON_TYPE or MINUTES_TYPE. |\n| cron_exproptional, string | (Valid only for schedule_type=\"CRON_TYPE\")A cron expression for the task execution, such as “* * * * ? *”. |\n| timezoneoptional, string | (Valid only for schedule_type=\"CRON_TYPE\")Time zone for the schedule, for example \"america/los_angeles\". |\n| minutesoptional, string | (Valid only for schedule_type=\"MINUTES_TYPE\")Number of minutes between each task run. |\n\n### Warehouse attributes[¶](#warehouse-attributes \"Link to this heading\")\n\n| Attribute | Description |\n| --- | --- |\n| namerequired, string | Snowflake object identifier. |\n| commentoptional, string | Description of the warehouse. |\n| warehouse_typeoptional, string | Type of warehouse. Possible values include: STANDARD and SNOWPARK-OPTIMIZED. |\n| warehouse_sizeoptional, string | Size of warehouse. Possible values include: XSMALL, SMALL, MEDIUM, LARGE, XLARGE, XXLARGE, XXXLARGE, X4LARGE, X5LARGE, and X6LARGE. |\n| auto_suspendoptional, string | Time, in seconds, before the warehouse automatically suspends itself. |\n| auto_resumeoptional, string | Whether to automatically resume a warehouse when a SQL statement is submitted to it. Possible values include: “true” and “false”. |\n| max_concurrency_leveloptional, integer | Concurrency level for SQL statements executed by a warehouse cluster. |\n| statement_queued_timeout_in_secondsoptional, integer | Time, in seconds, a SQL statement can be queued on a warehouse before it is canceled by the system. |\n| statement_timeout_in_secondsoptional, integer | Time, in seconds, after which a running SQL statement is canceled by the system. |\n| resource_monitoroptional, string | Name of a resource monitor that is explicitly assigned to the warehouse. When a resource monitor is explicitly assigned to a warehouse, the monitor controls the monthly credits used by the warehouse. |\n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   Create a database object using the `option-attributes` parameter:\n    \n    ```\n    snow object create database name=my_db comment='Created with Snowflake CLI'\n    \n    ```\n    \n    Copy\n    \n*   Create a table object using the `option-attributes` parameter:\n    \n    ```\n    snow object create table name=my_table columns='[{\"name\":\"col1\",\"datatype\":\"number\", \"nullable\":false}]' constraints='[{\"name\":\"prim_key\", \"column_names\":[\"col1\"], \"constraint_type\":\"PRIMARY KEY\"}]' --database my_db --schema public\n    \n    ```\n    \n    Copy\n    \n*   Create a database using the `--json object-definition` option:\n    \n    ```\n    snow object create database --json '{\"name\":\"my_db\", \"comment\":\"Created with Snowflake CLI\"}'\n    \n    ```\n    \n    Copy\n    \n*   Create a table using the `--json object-definition` option:\n    \n    ```\n    snow object create table --json \"$(cat table.json)\" --database my_db\n    \n    ```\n    \n    Copy\n    \n    where `table.json` contains the following:\n    \n    ```\n    {\n      \"name\": \"my_table\",\n      \"columns\": [\n        {\n          \"name\": \"col1\",\n          \"datatype\": \"number\",\n          \"nullable\": false\n        }\n      ],\n      \"constraints\": [\n        {\n          \"name\": \"prim_key\",\n          \"column_names\": [\"col1\"],\n          \"constraint_type\": \"PRIMARY KEY\"\n        }\n      ]\n    }\n    \n    ```\n    \n    Copy\n    \n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Compute pool object attributes](#compute-pool-object-attributes)\n6.  [Database object attributes](#database-object-attributes)\n7.  [Image repository object attributes](#image-repository-object-attributes)\n8.  [Schema object attributes](#schema-object-attributes)\n9.  [Service object attributes](#service-object-attributes)\n10.  [Table object attributes](#table-object-attributes)\n11.  [Task attributes](#task-attributes)\n12.  [Warehouse attributes](#warehouse-attributes)\n13.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)\n3.  [snow object commands](/developer-guide/snowflake-cli/command-reference/object-commands/overview)",
    "title": "snow object create¶",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/create"
  },
  {
    "title": "snow object describe¶",
    "raw_content": "# snow object describe[¶](#snow-object-describe \"Link to this heading\")\n\nProvides description of an object of given type. Supported types: compute-pool, database, external-access-integration, function, git-repository, integration, network-rule, notebook, procedure, role, schema, secret, service, stage, stream, streamlit, table, task, user, view, warehouse\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow object describe\n  <object_type>\n  <object_name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_object_type_`\n\nType of object. For example table, database, compute-pool.\n\n`_object_name_`\n\nName of the object.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `IDENTIFIER` for procedures and functions must specify argument types, such as `\"hello(int,string)\"`.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nTo describe a function, run a command similar to the following:\n\n```\nsnow object describe function \"hello_function(string)\"\n\n```\n\nCopy\n\n```\ndescribe function hello_function(string)\n+---------------------------------------------------------------------\n| property           | value\n|--------------------+------------------------------------------------\n| signature          | (NAME VARCHAR)\n| returns            | VARCHAR(16777216)\n| language           | PYTHON\n| null handling      | CALLED ON NULL INPUT\n| volatility         | VOLATILE\n| body               | None\n| imports            |\n| handler            | functions.hello_function\n| runtime_version    | 3.12\n| packages           | ['snowflake-snowpark-python']\n| installed_packages | ['_libgcc_mutex==0.1','_openmp_mutex==5.1',...\n+---------------------------------------------------------------------\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "parent_command": "snow object",
    "content_hash": "66dd939ade942cdd7fcc60175a9fbc4655ecdd6bdb8addad6359f372cbcf1e1a",
    "category": "NULL",
    "id": "NULL",
    "command_group": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/describe",
    "full_command": "snow object describe"
  },
  {
    "parent_command": "snow object",
    "category": "NULL",
    "metadata": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/drop",
    "id": "NULL",
    "title": "snow object drop¶",
    "raw_content": "# snow object drop[¶](#snow-object-drop \"Link to this heading\")\n\nDrops Snowflake object of given name and type. Supported types: compute-pool, database, external-access-integration, function, git-repository, image-repository, integration, network-rule, notebook, procedure, role, schema, secret, service, stage, stream, streamlit, table, task, user, view, warehouse\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow object drop\n  <object_type>\n  <object_name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_object_type_`\n\nType of object. For example table, database, compute-pool.\n\n`_object_name_`\n\nName of the object.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `IDENTIFIER` for procedures and functions must specify argument types, such as `\"hello(int,string)\"`.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nTo delete a procedure, run a command similar to the following:\n\n```\nsnow object drop procedure \"test_procedure()\"\n\n```\n\nCopy\n\n```\ndrop procedure test_procedure()\n+--------------------------------------+\n| status                               |\n|--------------------------------------|\n| TEST_PROCEDURE successfully dropped. |\n+--------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)",
    "command_group": "NULL",
    "last_scraped": "NULL",
    "full_command": "snow object drop",
    "content_hash": "5af42a609ad1a044d7a2bb53d95249cbf34ca5766e4616d80066ccb0fe68487b"
  },
  {
    "title": "snow object list¶",
    "full_command": "snow object list",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/object-commands/list",
    "category": "NULL",
    "raw_content": "# snow object list[¶](#snow-object-list \"Link to this heading\")\n\nLists all available Snowflake objects of given type. Supported types: compute-pool, database, external-access-integration, function, git-repository, image-repository, integration, network-rule, notebook, procedure, role, schema, secret, service, stage, stream, streamlit, table, task, user, view, warehouse\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow object list\n  <object_type>\n  --like <like>\n  --in <scope>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_object_type_`\n\nType of object. For example table, database, compute-pool.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--like, -l _TEXT_`\n\nSQL LIKE pattern for filtering objects by name. For example, `list function --like \"my%\"` lists all functions that begin with “my”. Default: %%.\n\n`--in _<TEXT TEXT>..._`\n\nSpecifies the scope of this command using ‘–in <scope> <name>’, for example `list table --in database my_db`. Some object types have specialized scopes (e.g. list service –in compute-pool my\\_pool). Default: (None, None).\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `--like [-l] <pattern>` option lets you specify a SQL LIKE pattern for filtering objects by name. For example, `snow object list function --like \"my%\"` lists all functions that begin with **my**. For more information about SQL patterns syntax, see [SQL LIKE Keyword](https://www.w3schools.com/sql/sql_ref_like.asp).\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example lists all roles beginning with **public**. The `--like` option\n\n```\nsnow object list role --like public%\n\n```\n\nCopy\n\n```\nshow roles like 'public%'\n+-------------------------------------------------------------------------------\n| created_on                       | name        | is_default | is_current | ...\n|----------------------------------+-------------+------------+------------+----\n| 2023-02-01 15:25:04.105000-08:00 | PUBLIC      | N          | N          | ...\n| 2024-01-15 12:55:05.840000-08:00 | PUBLIC_TEST | N          | N          | ...\n+-------------------------------------------------------------------------------\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/object-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/object-commands/../overview)\n3.  [snow object commands](/developer-guide/snowflake-cli/command-reference/object-commands/overview)",
    "content_hash": "deb395039a58fe702a1606efd6c8f288513013df72a398731889a89822333fea",
    "command_group": "NULL",
    "metadata": "NULL",
    "last_scraped": "NULL",
    "parent_command": "snow object"
  },
  {
    "content_hash": "6ca1cb5389dc2294de1cdcdc04fd0c8afa188025cc2ac6e681d95a90bf28aa73",
    "metadata": "NULL",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/copy",
    "raw_content": "# snow stage copy[¶](#snow-stage-copy \"Link to this heading\")\n\nCopies all files from source path to target directory. This works for uploading to and downloading files from the stage, and copying between named stages.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/copy-into-table)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow stage copy\n  <source_path>\n  <destination_path>\n  --overwrite / --no-overwrite\n  --parallel <parallel>\n  --recursive / --no-recursive\n  --auto-compress / --no-auto-compress\n  --refresh / --no-refresh\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_source_path_`\n\nSource path for copy operation. Can be either stage path or local. You can use a glob pattern for local files but the pattern has to be enclosed in quotes.\n\n`_destination_path_`\n\nTarget directory path for copy operation.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--overwrite / --no-overwrite`\n\nOverwrites existing files in the target path. Default: False.\n\n`--parallel _INTEGER_`\n\nNumber of parallel threads to use when uploading files. Default: 4.\n\n`--recursive / --no-recursive`\n\nCopy files recursively with directory structure. Default: False.\n\n`--auto-compress / --no-auto-compress`\n\nSpecifies whether Snowflake uses gzip to compress files during upload. Ignored when downloading. Default: False.\n\n`--refresh / --no-refresh`\n\nSpecifies whether ALTER STAGE {name} REFRESH should be executed after uploading. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\n*   One of `SOURCE_PATH` or `DESTINATION_PATH` must be a local directory, while the other should be a directory in the Snowflake stage. The stage path must start with “@”. For example:\n    \n    *   `snow stage copy @my_stage dir/` - copies files from `my_stage` stage to the local `dir` directory.\n        \n    *   `snow stage copy dir/ @my_stage` - copies files from the local `dir` directory to `my_stage`.\n        \n*   You can specify multiple files matching a regular expression by using a glob pattern for the `source_path` argument. You must enclose the glob pattern in single or double quotes.\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   To copy files from the local machine to a stage, use a command similar to the following:\n    \n    ```\n    snow stage copy local_example_app @example_app_stage/app\n    \n    ```\n    \n    Copy\n    \n    ```\n    put file:///.../local_example_app/* @example_app_stage/app4 auto_compress=false parallel=4 overwrite=False\n    +--------------------------------------------------------------------------------------\n    | source           | target           | source_size | target_size | source_compression...\n    |------------------+------------------+-------------+-------------+--------------------\n    | environment.yml  | environment.yml  | 62          | 0           | NONE             ...\n    | snowflake.yml    | snowflake.yml    | 252         | 0           | NONE             ...\n    | streamlit_app.py | streamlit_app.py | 109         | 0           | NONE             ...\n    +--------------------------------------------------------------------------------------\n    \n    ```\n    \n*   To download files from a stage to a local directory, use a command similar to the following:\n    \n    ```\n    mkdir local_app_backup\n    snow stage copy @example_app_stage/app local_app_backup\n    \n    ```\n    \n    Copy\n    \n    ```\n    get @example_app_stage/app file:///.../local_app_backup/ parallel=4\n    +------------------------------------------------+\n    | file             | size | status     | message |\n    |------------------+------+------------+---------|\n    | environment.yml  | 62   | DOWNLOADED |         |\n    | snowflake.yml    | 252  | DOWNLOADED |         |\n    | streamlit_app.py | 109  | DOWNLOADED |         |\n    +------------------------------------------------+\n    \n    ```\n    \n*   The following example copies all `.txt` files in a directory to a stage.\n    \n    ```\n    snow stage copy \"testdir/*.txt\" @TEST_STAGE_3\n    \n    ```\n    \n    Copy\n    \n    ```\n    put file:///.../testdir/*.txt @TEST_STAGE_3 auto_compress=false parallel=4 overwrite=False\n    +------------------------------------------------------------------------------------------------------------+\n    | source | target | source_size | target_size | source_compression | target_compression | status   | message |\n    |--------+--------+-------------+-------------+--------------------+--------------------+----------+---------|\n    | b1.txt | b1.txt | 3           | 16          | NONE               | NONE               | UPLOADED |         |\n    | b2.txt | b2.txt | 3           | 16          | NONE               | NONE               | UPLOADED |         |\n    +------------------------------------------------------------------------------------------------------------+\n    \n    ```\n    \n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)\n3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)\n4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",
    "last_scraped": "NULL",
    "title": "snow stage copy¶",
    "command_group": "NULL",
    "parent_command": "snow stage",
    "category": "NULL",
    "full_command": "snow stage copy"
  },
  {
    "id": "NULL",
    "raw_content": "# snow stage create[¶](#snow-stage-create \"Link to this heading\")\n\nCreates a named stage if it does not already exist.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/create-stage)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow stage create\n  <stage_name>\n  --encryption <encryption>\n  --enable-directory\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_stage_name_`\n\nIdentifier of the stage; for example: @my\\_stage.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--encryption [SNOWFLAKE_FULL|SNOWFLAKE_SSE]`\n\nType of encryption supported for all files stored on the stage. Default: SNOWFLAKE\\_FULL.\n\n`--enable-directory`\n\nSpecifies whether directory support is enabled for the stage. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `stage create` command creates a named stage if it does not already exist. The stage name can be a fully qualified name or just a stage name. In the later case, the stage is created in the database and schema specified in the connection details.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example creates a stage called `new_stage` in the `bar` database:\n\n```\nsnow stage create new_stage --database=bar --schema=public\n\n```\n\nCopy\n\n```\n+-----------------------------------------------------+\n| key    | value                                      |\n|--------+--------------------------------------------|\n| status | Stage area NEW_STAGE successfully created. |\n+-----------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)\n3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)\n4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/create",
    "last_scraped": "NULL",
    "content_hash": "eb8b878c992a8b6bfbf7264aa4449b813388922d94ec14c93ee80463c23f443b",
    "command_group": "NULL",
    "full_command": "snow stage create",
    "metadata": "NULL",
    "title": "snow stage create¶",
    "parent_command": "snow stage",
    "category": "NULL"
  },
  {
    "category": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/describe",
    "parent_command": "snow stage",
    "metadata": "NULL",
    "content_hash": "5fdf780c329173ed1e41afd746da9e1c50e7dece8d30acfb140dfdafe626744f",
    "full_command": "snow stage describe",
    "raw_content": "# snow stage describe[¶](#snow-stage-describe \"Link to this heading\")\n\nProvides description of stage.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/desc-stage)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow stage describe\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the stage; for example: @my\\_stage.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nNone.\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)\n3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)\n4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",
    "last_scraped": "NULL",
    "command_group": "NULL",
    "title": "snow stage describe¶",
    "id": "NULL"
  },
  {
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/drop",
    "full_command": "snow stage drop",
    "raw_content": "# snow stage drop[¶](#snow-stage-drop \"Link to this heading\")\n\nDrops stage with given name.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/drop-stage)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow stage drop\n  <name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the stage; for example: @my\\_stage.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nNone.\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)\n3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)\n4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",
    "content_hash": "5cd160ae25bfc0807d003a6ff4fcdc2e51893d070c9950cdf9e5b037933a03f0",
    "id": "NULL",
    "category": "NULL",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "parent_command": "snow stage",
    "title": "snow stage drop¶",
    "command_group": "NULL"
  },
  {
    "full_command": "snow stage execute",
    "id": "NULL",
    "parent_command": "snow stage",
    "command_group": "NULL",
    "category": "NULL",
    "content_hash": "b927889d5d526a236df7fdadfcc4fd63066fdacb02a070799837e9a3c43d6211",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/execute",
    "title": "snow stage execute¶",
    "raw_content": "# snow stage execute[¶](#snow-stage-execute \"Link to this heading\")\n\nExecute immediate all files from the stage path. Files can be filtered with a glob-like pattern, e.g. `@stage/*.sql`, `@stage/dev/*`. Only files with `.sql` extension will be executed.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow stage execute\n  <stage_path>\n  --on-error <on_error>\n  --variable <variables>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_stage_path_`\n\nStage path with files to be execute. For example `@stage/dev/*`.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--on-error [break|continue]`\n\nWhat to do when an error occurs. Defaults to break. Default: break.\n\n`--variable, -D _TEXT_`\n\nVariables for the execution context; for example: `-D \"<key>=<value>\"`. For SQL files, variables are used to expand the template, and any unknown variable will cause an error (consider embedding quoting in the file).For Python files, variables are used to update the os.environ dictionary. Provided keys are capitalized to adhere to best practices. In case of SQL files string values must be quoted in `''` (consider embedding quoting in the file).\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNote\n\nSnowflake CLI does not support executing Python files for Python versions 3.12 and above.\n\n*   The command searches for files with a `.sql` extension in the specified `STAGE_PATH` and executes `EXECUTE IMMEDIATE` on each of them. `STAGE_PATH` can be:\n    \n    *   Only a stage name, such as `@scripts`, which executes all `.sql` files from the stage.\n        \n    *   Glob-like pattern, such as `@scripts/dir/*`, which executes `.sql` files from the `dir` directory.\n        \n    *   Direct file path, such as `@scripts/script.sql`, which executes only the `script.sql` file from the `scripts`.\n        \n\nThe `--silent` options hides intermediate messages with file execution results.\n\nWhen using Jinja templates for the SQL files, you can pass template variables using `-D` (or `--variable`) option, such as `-D \"<key>=<value>\"`. You must enclose string values in single quotes (`''`).\n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   Specify only a stage name to execute all `.sql` files in the stage:\n    \n    ```\n    snow stage execute \"@scripts\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    SUCCESS - scripts/script1.sql\n    SUCCESS - scripts/script2.sql\n    SUCCESS - scripts/dir/script.sql\n    +------------------------------------------+\n    | File                   | Status  | Error |\n    |------------------------+---------+-------|\n    | scripts/script1.sql    | SUCCESS | None  |\n    | scripts/script2.sql    | SUCCESS | None  |\n    | scripts/dir/script.sql | SUCCESS | None  |\n    +------------------------------------------+\n    \n    ```\n    \n*   Specify a glob-like pattern to execute all `.sql` files in the `dir` directory:\n    \n    ```\n    snow stage execute \"@scripts/dir/*\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    SUCCESS - scripts/dir/script.sql\n    +------------------------------------------+\n    | File                   | Status  | Error |\n    |------------------------+---------+-------|\n    | scripts/dir/script.sql | SUCCESS | None  |\n    +------------------------------------------+\n    \n    ```\n    \n*   Specify a glob-like pattern to execute only `.sql` files in the `dir` directory that begin with “script”, followed by one character:\n    \n    ```\n    snow stage execute \"@scripts/script?.sql\"\n    \n    ```\n    \n    Copy\n    \n    ```\n    SUCCESS - scripts/script1.sql\n    SUCCESS - scripts/script2.sql\n    +---------------------------------------+\n    | File                | Status  | Error |\n    |---------------------+---------+-------|\n    | scripts/script1.sql | SUCCESS | None  |\n    | scripts/script2.sql | SUCCESS | None  |\n    +---------------------------------------+\n    \n    ```\n    \n*   Specify a direct file path with the `--silent` option:\n    \n    ```\n    snow stage execute \"@scripts/script1.sql\" --silent\n    \n    ```\n    \n    Copy\n    \n    ```\n    +---------------------------------------+\n    | File                | Status  | Error |\n    |---------------------+---------+-------|\n    | scripts/script1.sql | SUCCESS | None  |\n    +---------------------------------------+\n    \n    ```\n    \n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)\n3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)\n4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",
    "metadata": "NULL",
    "last_scraped": "NULL"
  },
  {
    "id": "NULL",
    "command_group": "NULL",
    "parent_command": "snow stage",
    "full_command": "snow stage list",
    "last_scraped": "NULL",
    "content_hash": "d0b8edf1e1f39c59cb5f1e2a1ddb5b3d936ba244163f9f5476ebbc75b01c9e62",
    "category": "NULL",
    "raw_content": "# snow stage list[¶](#snow-stage-list \"Link to this heading\")\n\nLists all available stages.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/show-stages)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow stage list\n  --like <like>\n  --in <scope>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\nNone\n\n## Options[¶](#options \"Link to this heading\")\n\n`--like, -l _TEXT_`\n\nSQL LIKE pattern for filtering objects by name. For example, `list --like \"my%\"` lists all stages that begin with “my”. Default: %%.\n\n`--in _<TEXT TEXT>..._`\n\nSpecifies the scope of this command using ‘–in <scope> <name>’, for example `list --in database my_db`. Default: (None, None).\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nNone.\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)\n3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)\n4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",
    "metadata": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/list",
    "title": "snow stage list¶"
  },
  {
    "content_hash": "582cc33ff336fb1e6c2547417c4faa7ed52ea7ac619326d4efd21e6c77982cd0",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/list-files",
    "title": "snow stage list-files¶",
    "raw_content": "# snow stage list-files[¶](#snow-stage-list-files \"Link to this heading\")\n\nLists the stage contents.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/list)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow stage list-files\n  <stage_name>\n  --pattern <pattern>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_stage_name_`\n\nIdentifier of the stage; for example: @my\\_stage/path.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--pattern _TEXT_`\n\nRegex pattern for filtering files by name. For example –pattern “.\\*.txt” will filter only files with .txt extension.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example lists the contents of the `jdoe.public.test` stage:\n\n```\nsnow stage list-files jdoe.public.test\n\n```\n\nCopy\n\n```\nls @jdoe.public.test\n+------------------------------------------------------------------------------+\n| name            | size    | md5              | last_modified                 |\n|-----------------+---------+------------------+-------------------------------|\n| test/file.csv   | 195424  | 4fc596b5e00681d8 | Mon, 11 Mar 2024 17:09:01 GMT |\n| test/data.csv   | 133248  | c0ddc25c1d3745d6 | Mon, 11 Mar 2024 17:08:57 GMT |\n+------------------------------------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)\n3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)\n4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",
    "parent_command": "snow stage",
    "full_command": "snow stage list files",
    "last_scraped": "NULL",
    "category": "NULL",
    "command_group": "NULL",
    "id": "NULL",
    "metadata": "NULL"
  },
  {
    "raw_content": "# snow stage remove[¶](#snow-stage-remove \"Link to this heading\")\n\nRemoves a file from a stage.\n\n### For more information\n\nGo to the SQL command page to view more information about arguments, options, privileges requirements, and usage guidelines.\n\n[View](/sql-reference/sql/remove)\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow stage remove\n  <stage_name>\n  <file_name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_stage_name_`\n\nIdentifier of the stage; for example: @my\\_stage.\n\n`_file_name_`\n\nName of the file to remove.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nNone.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example removes the `app/pages/my_page.py` file from a stage:\n\n```\nsnow stage remove example_app_stage app/pages/my_page.py\n\n```\n\nCopy\n\n```\n+-------------------------------------------------+\n| key    | value                                  |\n|--------+----------------------------------------|\n| name   | example_app_stage/app/pages/my_page.py |\n| result | removed                                |\n+-------------------------------------------------+\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/stage-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/stage-commands/../overview)\n3.  [snow stage commands](/developer-guide/snowflake-cli/command-reference/stage-commands/overview)\n4.  [Managing Snowflake stages](/developer-guide/snowflake-cli/command-reference/stage-commands/../../stages/manage-stages)",
    "content_hash": "9e4aac29130d15297135526cfa6f886d66bb27d6a137fbc013e8b81dd5f902b1",
    "metadata": "NULL",
    "id": "NULL",
    "full_command": "snow stage remove",
    "parent_command": "snow stage",
    "title": "snow stage remove¶",
    "category": "NULL",
    "command_group": "NULL",
    "last_scraped": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/stage-commands/remove"
  },
  {
    "content_hash": "062fb3b78e7e4d3fdde5eb729e13aa6467de0bf76a128fae0635455589c148f3",
    "last_scraped": "NULL",
    "category": "NULL",
    "command_group": "NULL",
    "parent_command": "snow snowpark",
    "id": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/lookup",
    "metadata": "NULL",
    "full_command": "snow",
    "title": "snow package lookup¶",
    "raw_content": "# snow package lookup[¶](#snow-package-lookup \"Link to this heading\")\n\nChecks if a package is available on the Snowflake Anaconda channel.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow snowpark package lookup\n  <package_name>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_package_name_`\n\nName of the package.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snow snowpark lookup` command checks to see whether a package is available on the Snowflake Anaconda channel.\n\n## Examples[¶](#examples \"Link to this heading\")\n\nThe following example illustrates looking up a package that is already available on the Snowflake Anaconda channel:\n\n```\nsnow snowpark package lookup numpy\n\n```\n\nCopy\n\n```\nPackage `numpy` is available in Anaconda. Latest available version: 1.26.4.\n\n```\n\nIf a package is not available on the Snowflake Anaconda channel, you can get a message similar to the following:\n\n```\nsnow snowpark package lookup july\n\n```\n\nCopy\n\n```\nPackage `july` is not available in Anaconda. To prepare Snowpark compatible package run:\n\n  snow snowpark package create july\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../overview)\n3.  [Package command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/overview)\n4.  [snow package create](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/create)\n5.  [snow package upload](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/upload)"
  },
  {
    "command_group": "NULL",
    "id": "NULL",
    "title": "snow package create¶",
    "content_hash": "c137c1aca1fd8d4c33dcb5fb1e7f63fc0b44856d505d68a82d7c88a9b30fd318",
    "metadata": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/create",
    "parent_command": "snow snowpark",
    "last_scraped": "NULL",
    "full_command": "snow",
    "raw_content": "# snow package create[¶](#snow-package-create \"Link to this heading\")\n\nCreates a Python package as a zip file that can be uploaded to a stage and imported for a Snowpark Python app.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow snowpark package create\n  <name>\n  --ignore-anaconda\n  --index-url <index_url>\n  --skip-version-check\n  --allow-shared-libraries\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nName of the package to create.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--ignore-anaconda`\n\nDoes not lookup packages on Snowflake Anaconda channel. Default: False.\n\n`--index-url _TEXT_`\n\nBase URL of the Python Package Index to use for package lookup. This should point to a repository compliant with PEP 503 (the simple repository API) or a local directory laid out in the same format.\n\n`--skip-version-check`\n\nSkip comparing versions of dependencies between requirements and Anaconda. Default: False.\n\n`--allow-shared-libraries`\n\nAllows shared (.so) libraries, when using packages installed through PIP. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `snowpark package create` command does the following:\n\n*   Creates an artifact ready to upload to a stage.\n    \n*   Checks for native libraries and asks if you want to continue. If the native libraries are present in the downloaded packages, this command works the same as the `snowpark package build` command.\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   This example creates a Python package as a zip file that can be uploaded to a stage and later imported by a Snowpark Python app. Dependencies for the “july” package are found on the Anaconda channel, so they were excluded from the `.zip` file. The command displays the packages you would need to include in `requirements.txt` of your Snowpark project.\n    \n    ```\n    snow snowpark package create july==0.1\n    \n    ```\n    \n    Copy\n    \n    ```\n    Package july.zip created. You can now upload it to a stage using\n    snow snowpark package upload -f july.zip -s <stage-name>`\n    and reference it in your procedure or function.\n    Remember to add it to imports in the procedure or function definition.\n    \n    The package july is successfully created, but depends on the following\n    Anaconda libraries. They need to be included in project requirements,\n    as their are not included in .zip.\n    matplotlib\n    contourpy >=1.0.1\n    numpy>=1.20\n    bokeh\n    selenium\n    mypy==1.8.0\n    Pillow\n    pytest-xdist\n    wurlitzer\n    cycler >=0.10\n    fonttools >=4.22.0\n    kiwisolver >=1.3.1\n    pyparsing >=2.3.1\n    jinja2\n    python-dateutil >=2.7\n    six >=1.5\n    importlib-resources >=3.2.0\n    \n    ```\n    \n*   This example creates the `july.zip` package that you can use in your Snowpark project without needing to add any dependencies to the `requirements.txt` file. The error messages indicate that some packages contain shared libraries, which might not work, such as when creating a package using Windows.\n    \n    ```\n    snow snowpark package create july==0.1 --ignore-anaconda --allow-shared-libraries\n    \n    ```\n    \n    Copy\n    \n    ```\n    2024-04-11 16:24:56 ERROR Following dependencies utilise shared libraries, not supported by Conda:\n    2024-04-11 16:24:56 ERROR numpy\n    contourpy\n    fonttools\n    kiwisolver\n    matplotlib\n    pillow\n    2024-04-11 16:24:56 ERROR You may still try to create your package with --allow-shared-libraries, but the might not work.\n    2024-04-11 16:24:56 ERROR You may also request adding the package to Snowflake Conda channel\n    2024-04-11 16:24:56 ERROR at https://support.anaconda.com/\n    \n    Package july.zip created. You can now upload it to a stage using\n    snow snowpark package upload -f july.zip -s <stage-name>`\n    and reference it in your procedure or function.\n    Remember to add it to imports in the procedure or function definition.\n    \n    ```\n    \n*   This example fails to create the package because it already exists. You can still forcibly create the package by using the `--ignore-anaconda` option.\n    \n    ```\n    snow snowpark package create matplotlib\n    \n    ```\n    \n    Copy\n    \n    ```\n    Package matplotlib is already available in Snowflake Anaconda Channel.\n    \n    ```\n    \n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/../../overview)\n3.  [Package command reference](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/overview)\n4.  [snow package lookup](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/lookup)\n5.  [snow package upload](/developer-guide/snowflake-cli/command-reference/snowpark-commands/package-commands/upload)",
    "category": "NULL"
  },
  {
    "title": "snow streamlit deploy¶",
    "content_hash": "06d07049743110896fc358cdc8b7da59238e5a30c9bf1a170dc4f98e946eb197",
    "full_command": "snow streamlit deploy",
    "command_group": "NULL",
    "raw_content": "# snow streamlit deploy[¶](#snow-streamlit-deploy \"Link to this heading\")\n\nDeploys a Streamlit app defined in the project definition file (snowflake.yml). By default, the command uploads environment.yml and any other pages or folders, if present. If you don’t specify a stage name, the `streamlit` stage is used. If the specified stage does not exist, the command creates it. If multiple Streamlits are defined in snowflake.yml and no entity\\_id is provided then command will raise an error.\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow streamlit deploy\n  <entity_id>\n  --replace\n  --prune / --no-prune\n  --open\n  --legacy\n  --project <project_definition>\n  --env <env_overrides>\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_entity_id_`\n\nID of streamlit entity.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--replace`\n\nReplaces the Streamlit app if it already exists. It only uploads new and overwrites existing files, but does not remove any files already on the stage. Default: False.\n\n`--prune / --no-prune`\n\nDelete files that exist in the stage, but not in the local filesystem. Default: False.\n\n`--open`\n\nWhether to open the Streamlit app in a browser. Default: False.\n\n`--legacy`\n\nUse legacy ROOT\\_LOCATION SQL syntax. Default: False.\n\n`-p, --project _TEXT_`\n\nPath where the Snowflake project is stored. Defaults to the current working directory.\n\n`--env _TEXT_`\n\nString in the format key=value. Overrides variables from the env section used for templates. Default: \\[\\].\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified. \\[env var: SNOWFLAKE\\_DECIMAL\\_PRECISION\\].\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThis command creates a Streamlit app object in the database and a schema configured in the specified `connection`.\n\nThe command uploads local files to a specified stage and creates a Streamlit app using those files. You must specify the main Python file and query warehouse. By default, the command uploads the `environment.yml` and `pages/` folder if present. The Streamlit app is created in the database and schema configured in the specified `connection`.\n\nIf you don’t specify a stage name, the `streamlit` stage is used. If the specified stage does not exist, the command creates it. You can modify the behavior by using [command-line options](#).\n\nIf you specify the `--replace` option, the command uploads new files and overwrites existing files. It does not remove any files already on the stage.\n\nIf you specify the `--prune` option, the command removes files that exist in the stage, but not files in the local filesystem.\n\n## Examples[¶](#examples \"Link to this heading\")\n\n```\nsnow streamlit deploy demo_app --replace\n\n```\n\nCopy\n\n```\nStreamlit successfully deployed and available under https://app.snowflake.com/myorg/myacc/#/streamlit-apps/JDOE.PUBLIC.DEMO_APP\n\n```\n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../overview)\n3.  [Streamlit commands](/developer-guide/snowflake-cli/command-reference/streamlit-commands/overview)",
    "parent_command": "snow streamlit",
    "id": "NULL",
    "last_scraped": "NULL",
    "metadata": "NULL",
    "url": "https://docs.snowflake.com/en/developer-guide/snowflake-cli/command-reference/streamlit-commands/deploy",
    "category": "NULL"
  },
  {
    "last_scraped": "NULL",
    "full_command": "snow streamlit get url",
    "raw_content": "# snow streamlit get-url[¶](#snow-streamlit-get-url \"Link to this heading\")\n\nReturns a URL to the specified Streamlit app\n\n## Syntax[¶](#syntax \"Link to this heading\")\n\n```\nsnow streamlit get-url\n  <name>\n  --open\n  --connection <connection>\n  --host <host>\n  --port <port>\n  --account <account>\n  --user <user>\n  --password <password>\n  --authenticator <authenticator>\n  --workload-identity-provider <workload_identity_provider>\n  --private-key-file <private_key_file>\n  --token <token>\n  --token-file-path <token_file_path>\n  --database <database>\n  --schema <schema>\n  --role <role>\n  --warehouse <warehouse>\n  --temporary-connection\n  --mfa-passcode <mfa_passcode>\n  --enable-diag\n  --diag-log-path <diag_log_path>\n  --diag-allowlist-path <diag_allowlist_path>\n  --oauth-client-id <oauth_client_id>\n  --oauth-client-secret <oauth_client_secret>\n  --oauth-authorization-url <oauth_authorization_url>\n  --oauth-token-request-url <oauth_token_request_url>\n  --oauth-redirect-uri <oauth_redirect_uri>\n  --oauth-scope <oauth_scope>\n  --oauth-disable-pkce\n  --oauth-enable-refresh-tokens\n  --oauth-enable-single-use-refresh-tokens\n  --client-store-temporary-credential\n  --format <format>\n  --verbose\n  --debug\n  --silent\n  --enhanced-exit-codes\n  --decimal-precision <decimal_precision>\n\n```\n\nCopy\n\n## Arguments[¶](#arguments \"Link to this heading\")\n\n`_name_`\n\nIdentifier of the Streamlit app; for example: my\\_streamlit.\n\n## Options[¶](#options \"Link to this heading\")\n\n`--open`\n\nWhether to open the Streamlit app in a browser. Default: False.\n\n`--connection, -c, --environment _TEXT_`\n\nName of the connection, as defined in your `config.toml` file. Default: `default`.\n\n`--host _TEXT_`\n\nHost address for the connection. Overrides the value specified for the connection.\n\n`--port _INTEGER_`\n\nPort for the connection. Overrides the value specified for the connection.\n\n`--account, --accountname _TEXT_`\n\nName assigned to your Snowflake account. Overrides the value specified for the connection.\n\n`--user, --username _TEXT_`\n\nUsername to connect to Snowflake. Overrides the value specified for the connection.\n\n`--password _TEXT_`\n\nSnowflake password. Overrides the value specified for the connection.\n\n`--authenticator _TEXT_`\n\nSnowflake authenticator. Overrides the value specified for the connection.\n\n`--workload-identity-provider _TEXT_`\n\nWorkload identity provider (AWS, AZURE, GCP, OIDC). Overrides the value specified for the connection.\n\n`--private-key-file, --private-key-path _TEXT_`\n\nSnowflake private key file path. Overrides the value specified for the connection.\n\n`--token _TEXT_`\n\nOAuth token to use when connecting to Snowflake.\n\n`--token-file-path _TEXT_`\n\nPath to file with an OAuth token to use when connecting to Snowflake.\n\n`--database, --dbname _TEXT_`\n\nDatabase to use. Overrides the value specified for the connection.\n\n`--schema, --schemaname _TEXT_`\n\nDatabase schema to use. Overrides the value specified for the connection.\n\n`--role, --rolename _TEXT_`\n\nRole to use. Overrides the value specified for the connection.\n\n`--warehouse _TEXT_`\n\nWarehouse to use. Overrides the value specified for the connection.\n\n`--temporary-connection, -x`\n\nUses a connection defined with command-line parameters, instead of one defined in config. Default: False.\n\n`--mfa-passcode _TEXT_`\n\nToken to use for multi-factor authentication (MFA).\n\n`--enable-diag`\n\nWhether to generate a connection diagnostic report. Default: False.\n\n`--diag-log-path _TEXT_`\n\nPath for the generated report. Defaults to system temporary directory. Default: <system\\_temporary\\_directory>.\n\n`--diag-allowlist-path _TEXT_`\n\nPath to a JSON file that contains allowlist parameters.\n\n`--oauth-client-id _TEXT_`\n\nValue of client id provided by the Identity Provider for Snowflake integration.\n\n`--oauth-client-secret _TEXT_`\n\nValue of the client secret provided by the Identity Provider for Snowflake integration.\n\n`--oauth-authorization-url _TEXT_`\n\nIdentity Provider endpoint supplying the authorization code to the driver.\n\n`--oauth-token-request-url _TEXT_`\n\nIdentity Provider endpoint supplying the access tokens to the driver.\n\n`--oauth-redirect-uri _TEXT_`\n\nURI to use for authorization code redirection.\n\n`--oauth-scope _TEXT_`\n\nScope requested in the Identity Provider authorization request.\n\n`--oauth-disable-pkce`\n\nDisables Proof Key for Code Exchange (PKCE). Default: `False`.\n\n`--oauth-enable-refresh-tokens`\n\nEnables a silent re-authentication when the actual access token becomes outdated. Default: `False`.\n\n`--oauth-enable-single-use-refresh-tokens`\n\nWhether to opt-in to single-use refresh token semantics. Default: `False`.\n\n`--client-store-temporary-credential`\n\nStore the temporary credential.\n\n`--format [TABLE|JSON|JSON_EXT|CSV]`\n\nSpecifies the output format. Default: TABLE.\n\n`--verbose, -v`\n\nDisplays log entries for log levels `info` and higher. Default: False.\n\n`--debug`\n\nDisplays log entries for log levels `debug` and higher; debug logs contain additional information. Default: False.\n\n`--silent`\n\nTurns off intermediate output to console. Default: False.\n\n`--enhanced-exit-codes`\n\nDifferentiate exit error codes based on failure type. Default: False.\n\n`--decimal-precision _INTEGER_`\n\nNumber of decimal places to display for decimal values. Uses Python’s default precision if not specified.\n\n`--help`\n\nDisplays the help text for this command.\n\n## Usage notes[¶](#usage-notes \"Link to this heading\")\n\nThe `streamlit get-url` command returns a url link to an existing Streamlit application. You can also use the `--open` option to automatically open the Streamlit in a new tab in your browser.\n\nNote the following requirements:\n\n*   The app must already be deployed.\n    \n*   You must use the same connection that was used to deploy the app.\n    \n*   If your app is running under different database and schema than specified in the connection, you must provide them in name as a fully-qualified name, such as `database.schema.name`.\n    \n\n## Examples[¶](#examples \"Link to this heading\")\n\n*   Get a URL for an app using the database and schema specified in the default connection and opens it in your browser:\n    \n    ```\n    snow streamlit get-url my_streamlit_app --open\n    \n    ```\n    \n    Copy\n    \n    ```\n    https://snowflake.com/provider-deduced-from-connection/#/streamlit-apps/DB.PUBLIC.MY_STREAMLIT_APP\n    \n    ```\n    \n*   Get a URL for an app using a fully-qualified database and schema name:\n    \n    ```\n    snow streamlit get-url database.schema.my_streamlit_app\n    \n    ```\n    \n    Copy\n    \n    ```\n    https://snowflake.com/provider-deduced-from-connection/#/streamlit-apps/DATABASE.SCHEMA.MY_STREAMLIT_APP\n    \n    ```\n    \n\nOn this page\n\n1.  [Syntax](#syntax)\n2.  [Arguments](#arguments)\n3.  [Options](#options)\n4.  [Usage notes](#usage-notes)\n5.  [Examples](#examples)\n\nRelated content\n\n1.  [Snowflake CLI](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../../index)\n2.  [Snowflake CLI command reference](/developer-guide/snowflake-cli/command-reference/streamlit-commands/../overview)\n3.  [Streamlit commands](/developer-guide/snowflake-cli/command-reference/streamlit-commands/overview)",
    "category": "NULL",
    "title": "snow streamlit get-url¶",
    "metadata": "NULL",
    "id": "NULL",
    "parent_command": "snow streamlit",
    "url": "https://docs.snowflake.com/developer-guide/snowflake-cli/command-reference/streamlit-commands/get-url",
    "command_group": "NULL",
    "content_hash": "fada8cff6a197c92d4f74a6fc3ed242d66b157c2a2910ffd1f0c04be9d0ccb9b"
  }
]